{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize features? \n",
    "## Invert h-bond and charge? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_siamese_071222'\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import DenseDataLoader #To make use of this data loader, all graph attributes in the dataset need to have the same shape. In particular, this data loader should only be used when working with dense adjacency matrices.\n",
    "from torch_geometric.nn import DenseGCNConv, dense_diff_pool\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_1 = 'C:/Users/david/pyproj/pyg/adl/patch_label_1'\n",
    "data_dir_0 = 'C:/Users/david/pyproj/pyg/adl/patch_label_0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "572"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from c_PatchDataset import PatchDataset\n",
    "dataset = PatchDataset(data_dir_label_0 = data_dir_0,  data_dir_label_1=data_dir_1,  neg_pos_ratio=1)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: PatchDataset(572):\n",
      "====================\n",
      "Number of graphs pairs: 572\n",
      "\n",
      "PairData(adj1=[100, 100], x1=[100, 3], adj2=[100, 100], x2=[100, 3], y=1)\n",
      "=============================================================\n",
      "Number of nodes in each: None\n",
      "Number of node features: 0\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs pairs: {len(dataset)}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "print()\n",
    "print(data)\n",
    "print('=============================================================')\n",
    "\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes in each: {data.num_nodes}')\n",
    "print(f'Number of node features: {data.num_node_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 1., 0., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 1., 0., 1.]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.adj2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does not work we do not have pos\n",
    "#visualize_points(data.pos, data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs pairs: 382\n",
      "Number of validation graphs: 95\n",
      "Number of test graphs: 95\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader \n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "n_train = math.ceil((4/6) * len(dataset))\n",
    "n_val = math.ceil((len(dataset) - n_train)/2)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "print(f'Number of training graphs pairs: {len(train_dataset)}')\n",
    "print(f'Number of validation graphs: {len(val_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')\n",
    "\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size= batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset = val_dataset, batch_size= batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size= batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PairDataBatch(adj1=[100, 100], x1=[100, 3], adj2=[100, 100], x2=[100, 3], y=[1])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "databatch = next(iter(train_loader))\n",
    "databatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_nodes, in_channels, hidden_channels, out_channels,\n",
    "                 normalize=False, lin=True):\n",
    "        super(GNN, self).__init__()\n",
    "\n",
    "        # Each instance of this GNN will have 3 convolutional layers and three batch norm layers        \n",
    "        self.conv1 = DenseGCNConv(in_channels, hidden_channels, normalize)\n",
    "        self.bns1 = torch.nn.BatchNorm1d(in_nodes)\n",
    "        \n",
    "        self.conv2 = DenseGCNConv(hidden_channels, hidden_channels, normalize)\n",
    "        self.bns2 = torch.nn.BatchNorm1d(in_nodes)\n",
    "        \n",
    "        self.conv3 = DenseGCNConv(hidden_channels, out_channels, normalize)\n",
    "        self.bns3 = torch.nn.BatchNorm1d(in_nodes)\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        \n",
    "        #Step 1\n",
    "        x = self.conv1(x, adj, mask)\n",
    "        x = self.bns1(x)\n",
    "        \n",
    "        #Step 2\n",
    "        x = self.conv2(x, adj, mask)\n",
    "        x = self.bns2(x)\n",
    "\n",
    "        #Step 3\n",
    "        x = self.conv3(x, adj, mask)\n",
    "        if x.shape[2] != 1: \n",
    "            x = self.bns3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class DiffPool(torch.nn.Module):\n",
    "    def __init__(self, num_nodes):\n",
    "        super(DiffPool, self).__init__()\n",
    "\n",
    "        #Hierarchical Step #1\n",
    "        in_nodes = num_nodes\n",
    "        out_nodes = 25 # Number of clusters / nodes in the next layer\n",
    "        self.gnn1_pool = GNN(in_nodes, dataset.num_features, 16, out_nodes) # PoolGNN --> Cluster Assignment Matrix to reduce to num_nodes\n",
    "        self.gnn1_embed = GNN(in_nodes, dataset.num_features, 8, 8) # EmbGNN --> Convolutions to create new node embedding\n",
    "\n",
    "        # Hierarchical Step #2\n",
    "        in_nodes = out_nodes\n",
    "        out_nodes = 10\n",
    "        self.gnn2_pool = GNN(in_nodes, 8, 8, out_nodes)\n",
    "        self.gnn2_embed = GNN(in_nodes, 8, 12, 16, lin=False)\n",
    "\n",
    "        # Hierarchical Step #3\n",
    "        in_nodes = out_nodes\n",
    "        out_nodes = 1\n",
    "        self.gnn3_pool = GNN(in_nodes, 16, 16, out_nodes)\n",
    "        self.gnn3_embed = GNN(in_nodes, 16, 16, 32, lin=False)\n",
    "\n",
    "        # Final Classifier\n",
    "        self.lin1 = torch.nn.Linear(32, 64) \n",
    "        #self.lin2 = torch.nn.Linear(64, 2)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, batch, mask=None):\n",
    "        \n",
    "        #if batch == 0: print('Shape of input data batch:')\n",
    "        #if batch == 0: print(f'Feature Matrix: {tuple(x.shape)}')\n",
    "        #if batch == 0: print(f'Adjacency Matrix: {tuple(adj.shape)}')\n",
    "       \n",
    "\n",
    "\n",
    "        #Hierarchical Step #1\n",
    "        #if batch == 0: print('Hierarchical Step #1')\n",
    "        x1 = self.gnn1_embed(x, adj, mask) # node feature embedding\n",
    "        s = self.gnn1_pool(x, adj, mask) # cluster assignment matrix\n",
    "\n",
    "        #if batch == 0: print(f'X1 = {tuple(x1.shape)}    S1: {tuple(s.shape)}')\n",
    "\n",
    "        x, adj, l1, e1 = dense_diff_pool(x1, adj, s, mask) # does the necessary matrix multiplications\n",
    "        adj = torch.softmax(adj, dim=-1)\n",
    "\n",
    "        #if batch == 0: print(f'---matmul---> New feature matrix (softmax(s_0.t()) @ z_0) = {tuple(x.shape)}')\n",
    "        #if batch == 0: print(f'---matmul---> New adjacency matrix (s_0.t() @ adj_0 @ s_0) = {tuple(adj.shape)}')\n",
    "   \n",
    "\n",
    "\n",
    "        # Hierarchical Step #2\n",
    "        #if batch == 0: print('Hierarchical Step #2')\n",
    "        x2 = self.gnn2_embed(x, adj)\n",
    "        s = self.gnn2_pool(x, adj)\n",
    "\n",
    "        #if batch == 0: print(f'X2: {tuple(x2.shape)}    S2: {tuple(s.shape)}')\n",
    "        \n",
    "        x, adj, l2, e2 = dense_diff_pool(x2, adj, s)\n",
    "        adj = torch.softmax(adj, dim=-1)\n",
    "\n",
    "        #if batch == 0: print(f'---matmul---> New feature matrix (softmax(s_0.t()) @ z_0) = {tuple(x.shape)}')\n",
    "        #if batch == 0: print(f'---matmul---> New adjacency matrix (s_0.t() @ adj_0 @ s_0) = {tuple(adj.shape)}')\n",
    "      \n",
    "        \n",
    "\n",
    "        # Hierarchical Step #3\n",
    "        #if batch == 0: print('Hierarchical Step #3')\n",
    "        x3 = self.gnn3_embed(x, adj)\n",
    "        s = self.gnn3_pool(x, adj)\n",
    "        \n",
    "        #if batch == 0: print(f'X3: {tuple(x3.shape)}    S3: {tuple(s.shape)}')\n",
    "\n",
    "        x, adj, l3, e3 = dense_diff_pool(x3, adj, s)\n",
    "        adj = torch.softmax(adj, dim=-1)\n",
    "\n",
    "        #if batch == 0: print(f'---matmul---> New feature matrix (softmax(s_0.t()) @ z_0) = {tuple(x.shape)}')\n",
    "        #if batch == 0: print(f'---matmul---> New adjacency matrix (s_0.t() @ adj_0 @ s_0) = {tuple(adj.shape)}')\n",
    "     \n",
    "        \n",
    "\n",
    "        # Final Classification\n",
    "        #if batch == 0: print('Final Output')\n",
    "        x = x.mean(dim=1) # Pool the features of all nodes (global mean pool)  dim = 1 refers to columns\n",
    "        #if batch == 0: print(f'---X Output after mean= {tuple(x.shape)}')\n",
    "\n",
    "        x = F.relu(self.lin1(x)) # Fully connected layer + relu\n",
    "        #if batch == 0: print(f'------ X Output 3 after lin= {tuple(x.shape)}')\n",
    "\n",
    "        \n",
    "        return x, l1 + l2 + l3, e1 + e2 + e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An attempt of a contrastive loss function\n",
    "#   pairs with label 1 --> should get small euclid dist = small loss\n",
    "#   pairs with label 0 --> should get large euclid dist = large loss\n",
    "\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, x0, x1, y):\n",
    "        # euclidian distance\n",
    "        #print(x0)\n",
    "        #print(x1)\n",
    "        #print(y)\n",
    "        diff = x0 - x1\n",
    "        #print(diff)\n",
    "        pow = torch.pow(diff, 2)\n",
    "        #print(pow)\n",
    "        dist_sq = torch.sum(pow, 1)\n",
    "        #print(dist_sq) # sum of squared distance = 0.5 = 9\n",
    "        dist = torch.sqrt(dist_sq)\n",
    "        #print(dist) # euclidean distance = 0.7 = 3\n",
    "\n",
    "        mdist = self.margin - dist #negative euclidean distance - margin = 0.3 = -2\n",
    "        #print(mdist)\n",
    "        dist = torch.clamp(mdist, min=0.0) # only distances <margin will be still positive here = 0.3 = 0\n",
    "        #print(dist)\n",
    "        loss = y * dist_sq + (1 - y) * torch.pow(dist, 2)\n",
    "\n",
    "        # What happens to a pair with squared euclid dist (dist_sq) of 0.5\n",
    "        # if label = 0 --> 0 + squared clampled euclid distance --> loss = 0.3^2\n",
    "        # if label = 1 --> squared euclidean distance + 0 --> loss = 0.5\n",
    "\n",
    "        # What happens to a pair with squared euclid dist (dist_sq) of 9\n",
    "        # if label = 0 --> 0 + squared clampled euclid distance --> loss = 0\n",
    "        # if label = 1 --> squared euclidean distance + 0 --> loss = 9\n",
    "\n",
    "        #print(loss)\n",
    "        loss = torch.sum(loss) / 2.0 / x0.size()[0]\n",
    "        #print(loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch: 001, Train Loss: 10.964\n",
      "Epoch: 002, Train Loss: 0.141\n",
      "Epoch: 003, Train Loss: 0.179\n",
      "Epoch: 004, Train Loss: 0.166\n",
      "Epoch: 005, Train Loss: 0.178\n",
      "Epoch: 006, Train Loss: 0.307\n",
      "Epoch: 007, Train Loss: 0.266\n",
      "Epoch: 008, Train Loss: 0.254\n",
      "Epoch: 009, Train Loss: 0.254\n",
      "Epoch: 010, Train Loss: 0.254\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = DiffPool(num_nodes = 100).to(device)\n",
    "criterion = ContrastiveLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    batch = 0\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output1, _, _ = model(data.x1, data.adj1, batch)\n",
    "        output2, _, _ = model(data.x2, data.adj2, batch = None)\n",
    "        \n",
    "        #Contrastive Loss\n",
    "        loss_contrastive = criterion(output1,output2,data.y)\n",
    "        loss_contrastive.backward()\n",
    "        loss_all += data.y.size(0) * loss_contrastive.item()\n",
    "        optimizer.step()\n",
    "        batch +=1\n",
    "\n",
    "    return loss_all / len(train_dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    distances_lab1 = []\n",
    "    distances_lab0 = []\n",
    "    labels = []\n",
    "    losses = []\n",
    "    \n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output1, _, _ = model(data.x1, data.adj2, batch=None)\n",
    "        output2, _, _ = model(data.x2, data.adj2, batch=None)\n",
    "\n",
    "        test_loss_contrastive = criterion(output1, output2, data.y)\n",
    "        \n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        label = data.y\n",
    "\n",
    "        if int(label) == 1: \n",
    "            distances_lab1.append(float(euclidean_distance))\n",
    "            labels.append(int(label))\n",
    "            losses.append(float(test_loss_contrastive))\n",
    "        else:\n",
    "            distances_lab0.append(float(euclidean_distance))\n",
    "            labels.append(int(label))\n",
    "            losses.append(float(test_loss_contrastive))\n",
    "\n",
    "    return  distances_lab0, distances_lab1, losses, labels\n",
    "\n",
    "\n",
    "\n",
    "train_distances_lab0 = []\n",
    "train_distances_lab1 = []\n",
    "train_losses = []\n",
    "train_labels = []\n",
    "\n",
    "validation_distances_lab0 = []\n",
    "validation_distances_lab1 = []\n",
    "validation_losses = []\n",
    "validation_labels = []\n",
    "\n",
    "test_distances_lab0 = []\n",
    "test_distances_lab1 = []\n",
    "test_losses = []\n",
    "test_labels = []\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    train_loss = train(epoch)\n",
    "\n",
    "    train_results = test(train_loader)\n",
    "    train_distances_lab0.append(train_results[0])\n",
    "    train_distances_lab1.append(train_results[1])\n",
    "    train_losses.append(train_results[2])\n",
    "    train_labels.append(train_results[3])\n",
    "\n",
    "\n",
    "    validation_results = test(val_loader)\n",
    "    validation_distances_lab0.append(train_results[0])\n",
    "    validation_distances_lab1.append(train_results[1])\n",
    "    validation_losses.append(validation_results[2])\n",
    "    validation_labels.append(validation_results[3])\n",
    "\n",
    "    test_results = test(test_loader)\n",
    "    test_distances_lab0.append(test_results[0])\n",
    "    test_distances_lab1.append(test_results[1])\n",
    "    test_losses.append(test_results[2])\n",
    "    test_labels.append(test_results[3])\n",
    "\n",
    "\n",
    "    print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.3f}')\n",
    "    #Train Acc: {train_acc:.3f}, f'Val Acc: {val_acc:.3f}, Test Acc: {test_acc:.3f}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compare_euclid_distances(distances_lab0, distances_lab1):\n",
    "\n",
    "    w = 0.8    # bar width\n",
    "    x = [1, 2] # x-coordinates of your bars\n",
    "    colors = [(0, 0, 1, 1), (1, 0, 0, 1)]    # corresponding colors\n",
    "\n",
    "    # Epoch 0\n",
    "    y = [distances_lab0, distances_lab1]\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(x,\n",
    "        height=[np.mean(yi) for yi in y],\n",
    "        yerr=[np.std(yi) for yi in y],    # error bars\n",
    "        capsize=12, # error bar cap width in points\n",
    "        width=w,    # bar width\n",
    "        tick_label=[\"Label 0\", \"Label 1\"],\n",
    "        color=(0,0,0,0),  # face color transparent\n",
    "        edgecolor=colors,\n",
    "        )\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        # distribute scatter randomly across whole width of bar\n",
    "        ax.scatter(x[i] + np.random.random(len(y[i])) * w - w / 2, y[i], color=colors[i])\n",
    "\n",
    "    plt.ylabel = 'Euclidean Distance'\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_euclid_distances(train_distances_lab0[9], train_distances_lab1[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "gnn1_pool.conv1.bias \t torch.Size([16])\n",
      "gnn1_pool.conv1.lin.weight \t torch.Size([16, 3])\n",
      "gnn1_pool.bns1.weight \t torch.Size([100])\n",
      "gnn1_pool.bns1.bias \t torch.Size([100])\n",
      "gnn1_pool.bns1.running_mean \t torch.Size([100])\n",
      "gnn1_pool.bns1.running_var \t torch.Size([100])\n",
      "gnn1_pool.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn1_pool.conv2.bias \t torch.Size([16])\n",
      "gnn1_pool.conv2.lin.weight \t torch.Size([16, 16])\n",
      "gnn1_pool.bns2.weight \t torch.Size([100])\n",
      "gnn1_pool.bns2.bias \t torch.Size([100])\n",
      "gnn1_pool.bns2.running_mean \t torch.Size([100])\n",
      "gnn1_pool.bns2.running_var \t torch.Size([100])\n",
      "gnn1_pool.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn1_pool.conv3.bias \t torch.Size([25])\n",
      "gnn1_pool.conv3.lin.weight \t torch.Size([25, 16])\n",
      "gnn1_pool.bns3.weight \t torch.Size([100])\n",
      "gnn1_pool.bns3.bias \t torch.Size([100])\n",
      "gnn1_pool.bns3.running_mean \t torch.Size([100])\n",
      "gnn1_pool.bns3.running_var \t torch.Size([100])\n",
      "gnn1_pool.bns3.num_batches_tracked \t torch.Size([])\n",
      "gnn1_embed.conv1.bias \t torch.Size([8])\n",
      "gnn1_embed.conv1.lin.weight \t torch.Size([8, 3])\n",
      "gnn1_embed.bns1.weight \t torch.Size([100])\n",
      "gnn1_embed.bns1.bias \t torch.Size([100])\n",
      "gnn1_embed.bns1.running_mean \t torch.Size([100])\n",
      "gnn1_embed.bns1.running_var \t torch.Size([100])\n",
      "gnn1_embed.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn1_embed.conv2.bias \t torch.Size([8])\n",
      "gnn1_embed.conv2.lin.weight \t torch.Size([8, 8])\n",
      "gnn1_embed.bns2.weight \t torch.Size([100])\n",
      "gnn1_embed.bns2.bias \t torch.Size([100])\n",
      "gnn1_embed.bns2.running_mean \t torch.Size([100])\n",
      "gnn1_embed.bns2.running_var \t torch.Size([100])\n",
      "gnn1_embed.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn1_embed.conv3.bias \t torch.Size([8])\n",
      "gnn1_embed.conv3.lin.weight \t torch.Size([8, 8])\n",
      "gnn1_embed.bns3.weight \t torch.Size([100])\n",
      "gnn1_embed.bns3.bias \t torch.Size([100])\n",
      "gnn1_embed.bns3.running_mean \t torch.Size([100])\n",
      "gnn1_embed.bns3.running_var \t torch.Size([100])\n",
      "gnn1_embed.bns3.num_batches_tracked \t torch.Size([])\n",
      "gnn2_pool.conv1.bias \t torch.Size([8])\n",
      "gnn2_pool.conv1.lin.weight \t torch.Size([8, 8])\n",
      "gnn2_pool.bns1.weight \t torch.Size([25])\n",
      "gnn2_pool.bns1.bias \t torch.Size([25])\n",
      "gnn2_pool.bns1.running_mean \t torch.Size([25])\n",
      "gnn2_pool.bns1.running_var \t torch.Size([25])\n",
      "gnn2_pool.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn2_pool.conv2.bias \t torch.Size([8])\n",
      "gnn2_pool.conv2.lin.weight \t torch.Size([8, 8])\n",
      "gnn2_pool.bns2.weight \t torch.Size([25])\n",
      "gnn2_pool.bns2.bias \t torch.Size([25])\n",
      "gnn2_pool.bns2.running_mean \t torch.Size([25])\n",
      "gnn2_pool.bns2.running_var \t torch.Size([25])\n",
      "gnn2_pool.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn2_pool.conv3.bias \t torch.Size([10])\n",
      "gnn2_pool.conv3.lin.weight \t torch.Size([10, 8])\n",
      "gnn2_pool.bns3.weight \t torch.Size([25])\n",
      "gnn2_pool.bns3.bias \t torch.Size([25])\n",
      "gnn2_pool.bns3.running_mean \t torch.Size([25])\n",
      "gnn2_pool.bns3.running_var \t torch.Size([25])\n",
      "gnn2_pool.bns3.num_batches_tracked \t torch.Size([])\n",
      "gnn2_embed.conv1.bias \t torch.Size([12])\n",
      "gnn2_embed.conv1.lin.weight \t torch.Size([12, 8])\n",
      "gnn2_embed.bns1.weight \t torch.Size([25])\n",
      "gnn2_embed.bns1.bias \t torch.Size([25])\n",
      "gnn2_embed.bns1.running_mean \t torch.Size([25])\n",
      "gnn2_embed.bns1.running_var \t torch.Size([25])\n",
      "gnn2_embed.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn2_embed.conv2.bias \t torch.Size([12])\n",
      "gnn2_embed.conv2.lin.weight \t torch.Size([12, 12])\n",
      "gnn2_embed.bns2.weight \t torch.Size([25])\n",
      "gnn2_embed.bns2.bias \t torch.Size([25])\n",
      "gnn2_embed.bns2.running_mean \t torch.Size([25])\n",
      "gnn2_embed.bns2.running_var \t torch.Size([25])\n",
      "gnn2_embed.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn2_embed.conv3.bias \t torch.Size([16])\n",
      "gnn2_embed.conv3.lin.weight \t torch.Size([16, 12])\n",
      "gnn2_embed.bns3.weight \t torch.Size([25])\n",
      "gnn2_embed.bns3.bias \t torch.Size([25])\n",
      "gnn2_embed.bns3.running_mean \t torch.Size([25])\n",
      "gnn2_embed.bns3.running_var \t torch.Size([25])\n",
      "gnn2_embed.bns3.num_batches_tracked \t torch.Size([])\n",
      "gnn3_pool.conv1.bias \t torch.Size([16])\n",
      "gnn3_pool.conv1.lin.weight \t torch.Size([16, 16])\n",
      "gnn3_pool.bns1.weight \t torch.Size([10])\n",
      "gnn3_pool.bns1.bias \t torch.Size([10])\n",
      "gnn3_pool.bns1.running_mean \t torch.Size([10])\n",
      "gnn3_pool.bns1.running_var \t torch.Size([10])\n",
      "gnn3_pool.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn3_pool.conv2.bias \t torch.Size([16])\n",
      "gnn3_pool.conv2.lin.weight \t torch.Size([16, 16])\n",
      "gnn3_pool.bns2.weight \t torch.Size([10])\n",
      "gnn3_pool.bns2.bias \t torch.Size([10])\n",
      "gnn3_pool.bns2.running_mean \t torch.Size([10])\n",
      "gnn3_pool.bns2.running_var \t torch.Size([10])\n",
      "gnn3_pool.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn3_pool.conv3.bias \t torch.Size([1])\n",
      "gnn3_pool.conv3.lin.weight \t torch.Size([1, 16])\n",
      "gnn3_pool.bns3.weight \t torch.Size([10])\n",
      "gnn3_pool.bns3.bias \t torch.Size([10])\n",
      "gnn3_pool.bns3.running_mean \t torch.Size([10])\n",
      "gnn3_pool.bns3.running_var \t torch.Size([10])\n",
      "gnn3_pool.bns3.num_batches_tracked \t torch.Size([])\n",
      "gnn3_embed.conv1.bias \t torch.Size([16])\n",
      "gnn3_embed.conv1.lin.weight \t torch.Size([16, 16])\n",
      "gnn3_embed.bns1.weight \t torch.Size([10])\n",
      "gnn3_embed.bns1.bias \t torch.Size([10])\n",
      "gnn3_embed.bns1.running_mean \t torch.Size([10])\n",
      "gnn3_embed.bns1.running_var \t torch.Size([10])\n",
      "gnn3_embed.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn3_embed.conv2.bias \t torch.Size([16])\n",
      "gnn3_embed.conv2.lin.weight \t torch.Size([16, 16])\n",
      "gnn3_embed.bns2.weight \t torch.Size([10])\n",
      "gnn3_embed.bns2.bias \t torch.Size([10])\n",
      "gnn3_embed.bns2.running_mean \t torch.Size([10])\n",
      "gnn3_embed.bns2.running_var \t torch.Size([10])\n",
      "gnn3_embed.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn3_embed.conv3.bias \t torch.Size([32])\n",
      "gnn3_embed.conv3.lin.weight \t torch.Size([32, 16])\n",
      "gnn3_embed.bns3.weight \t torch.Size([10])\n",
      "gnn3_embed.bns3.bias \t torch.Size([10])\n",
      "gnn3_embed.bns3.running_mean \t torch.Size([10])\n",
      "gnn3_embed.bns3.running_var \t torch.Size([10])\n",
      "gnn3_embed.bns3.num_batches_tracked \t torch.Size([])\n",
      "lin1.weight \t torch.Size([64, 32])\n",
      "lin1.bias \t torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer's state_dict:\n",
      "state \t {0: {'step': tensor(3820.), 'exp_avg': tensor([-5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45]), 'exp_avg_sq': tensor([ 2.0432,  5.2599,  2.1936,  4.4298,  1.0170,  3.1238, 12.8967,  0.8877,\n",
      "         5.0011, 14.8512,  6.7464, 15.9772,  7.2873,  2.2017,  2.2661, 11.4351])}, 1: {'step': tensor(3820.), 'exp_avg': tensor([[-5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45]]), 'exp_avg_sq': tensor([[7.7337e-02, 7.6014e-03, 5.0843e-01],\n",
      "        [4.1269e-01, 2.9321e-02, 6.0164e-01],\n",
      "        [2.9401e-01, 3.6971e-03, 3.3346e-01],\n",
      "        [1.7118e-01, 1.4631e-02, 2.1168e+00],\n",
      "        [1.8034e-01, 2.2107e-03, 1.1283e+00],\n",
      "        [6.0207e-01, 3.9437e-03, 1.2946e+00],\n",
      "        [7.1756e-01, 3.9243e-02, 1.1345e+00],\n",
      "        [1.7518e-01, 1.2827e-03, 5.4979e-01],\n",
      "        [5.8987e-01, 1.1923e-02, 5.6386e-01],\n",
      "        [8.6893e-01, 4.3699e-02, 2.0556e+00],\n",
      "        [2.3454e-01, 2.9963e-02, 8.6438e-01],\n",
      "        [9.4407e-01, 6.1940e-02, 1.6751e+00],\n",
      "        [7.7190e-01, 1.6048e-02, 1.7144e+00],\n",
      "        [2.0261e-01, 6.5498e-03, 2.7928e-01],\n",
      "        [1.4710e-01, 7.1418e-03, 6.0934e-01],\n",
      "        [6.6879e-01, 3.2021e-02, 2.1958e+00]])}, 2: {'step': tensor(3820.), 'exp_avg': tensor([ 5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45]), 'exp_avg_sq': tensor([4.5444e-04, 6.0045e-04, 5.2951e-04, 1.8989e-04, 6.6477e-04, 4.3482e-04,\n",
      "        9.8704e-05, 1.7143e-04, 2.8884e-04, 1.0115e-03, 3.3110e-04, 1.8754e-04,\n",
      "        1.2746e-04, 1.0058e-03, 4.9080e-04, 2.7859e-04, 6.9933e-04, 2.7281e-04,\n",
      "        8.9264e-05, 8.7433e-04, 3.6696e-04, 5.3379e-04, 5.6731e-04, 2.6976e-04,\n",
      "        4.2105e-04, 1.6077e-04, 1.2819e-04, 5.3381e-04, 1.9217e-03, 5.1940e-04,\n",
      "        5.4672e-04, 1.1660e-04, 7.2267e-04, 3.1212e-03, 1.0954e-03, 1.0553e-03,\n",
      "        2.4896e-04, 4.6373e-05, 4.5580e-04, 2.5110e-04, 2.5295e-04, 7.1403e-04,\n",
      "        2.1182e-04, 8.2379e-04, 5.3862e-04, 2.5227e-04, 1.6743e-04, 5.9386e-04,\n",
      "        4.2959e-04, 5.8086e-04, 5.0860e-04, 1.4950e-03, 2.7868e-04, 4.8066e-04,\n",
      "        3.0858e-04, 2.1719e-04, 1.2344e-04, 1.6773e-03, 2.1973e-04, 4.6665e-04,\n",
      "        2.7670e-04, 4.4582e-04, 1.9850e-04, 4.1156e-04, 2.3280e-04, 8.6625e-04,\n",
      "        5.6557e-04, 2.5362e-04, 1.2027e-03, 7.1103e-04, 5.4545e-04, 1.5696e-04,\n",
      "        2.9509e-04, 8.2217e-04, 1.8598e-04, 6.5645e-04, 5.6042e-04, 9.3089e-05,\n",
      "        2.5624e-04, 9.0246e-04, 6.6467e-04, 4.5613e-04, 7.2534e-04, 7.3924e-04,\n",
      "        2.8058e-04, 3.8652e-04, 5.4983e-04, 9.0279e-04, 1.8311e-04, 2.8752e-04,\n",
      "        5.5230e-04, 2.2080e-04, 5.7876e-04, 3.4956e-04, 6.7213e-04, 7.1105e-04,\n",
      "        7.7111e-04, 3.9704e-04, 1.8564e-04, 1.6107e-04])}, 3: {'step': tensor(3820.), 'exp_avg': tensor([ 5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45]), 'exp_avg_sq': tensor([0.0045, 0.0085, 0.0040, 0.0030, 0.0037, 0.0077, 0.0018, 0.0024, 0.0031,\n",
      "        0.0079, 0.0020, 0.0030, 0.0066, 0.0037, 0.0043, 0.0032, 0.0044, 0.0080,\n",
      "        0.0041, 0.0021, 0.0042, 0.0047, 0.0035, 0.0025, 0.0038, 0.0013, 0.0074,\n",
      "        0.0038, 0.0024, 0.0026, 0.0043, 0.0027, 0.0159, 0.0059, 0.0042, 0.0023,\n",
      "        0.0027, 0.0012, 0.0032, 0.0099, 0.0030, 0.0056, 0.0034, 0.0049, 0.0047,\n",
      "        0.0012, 0.0016, 0.0054, 0.0060, 0.0019, 0.0072, 0.0060, 0.0089, 0.0027,\n",
      "        0.0041, 0.0022, 0.0051, 0.0027, 0.0039, 0.0082, 0.0015, 0.0041, 0.0034,\n",
      "        0.0034, 0.0028, 0.0051, 0.0025, 0.0068, 0.0047, 0.0050, 0.0086, 0.0037,\n",
      "        0.0022, 0.0041, 0.0086, 0.0063, 0.0028, 0.0047, 0.0033, 0.0024, 0.0035,\n",
      "        0.0052, 0.0040, 0.0019, 0.0028, 0.0021, 0.0110, 0.0058, 0.0020, 0.0036,\n",
      "        0.0016, 0.0017, 0.0085, 0.0016, 0.0043, 0.0025, 0.0062, 0.0046, 0.0048,\n",
      "        0.0014])}, 4: {'step': tensor(3820.), 'exp_avg': tensor([ 5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45]), 'exp_avg_sq': tensor([0.5891, 0.8451, 0.1835, 0.2418, 0.0473, 1.3581, 0.4165, 0.1076, 0.4692,\n",
      "        0.5270, 0.6422, 0.3555, 0.8186, 0.6665, 0.5293, 0.1100])}, 5: {'step': tensor(3820.), 'exp_avg': tensor([[-5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45]]), 'exp_avg_sq': tensor([[0.1377, 0.6026, 0.0757, 0.0809, 0.1238, 0.0823, 0.1686, 0.3807, 0.1246,\n",
      "         0.1912, 0.3124, 0.1176, 0.2580, 0.4813, 0.2400, 0.4372],\n",
      "        [0.1574, 0.4730, 0.0985, 0.0837, 0.1156, 0.0698, 0.1266, 0.3529, 0.1122,\n",
      "         0.1796, 0.2896, 0.0938, 0.2204, 0.4019, 0.1870, 0.3899],\n",
      "        [0.0708, 0.1186, 0.0312, 0.0464, 0.0968, 0.0156, 0.0456, 0.0737, 0.0136,\n",
      "         0.0296, 0.0276, 0.0752, 0.0575, 0.0922, 0.0550, 0.0589],\n",
      "        [0.0845, 0.2878, 0.0401, 0.0521, 0.0854, 0.0417, 0.0813, 0.1799, 0.0541,\n",
      "         0.0952, 0.1368, 0.0737, 0.1287, 0.2380, 0.1173, 0.2119],\n",
      "        [0.0241, 0.1360, 0.0160, 0.0169, 0.0333, 0.0223, 0.0386, 0.0544, 0.0236,\n",
      "         0.0449, 0.0514, 0.0303, 0.0448, 0.0884, 0.0501, 0.0950],\n",
      "        [0.1584, 0.1706, 0.0971, 0.0811, 0.1170, 0.0406, 0.0400, 0.1806, 0.0519,\n",
      "         0.1163, 0.1325, 0.0681, 0.1024, 0.1655, 0.0634, 0.2098],\n",
      "        [0.1092, 0.2219, 0.0234, 0.0720, 0.1116, 0.0228, 0.0840, 0.2055, 0.0341,\n",
      "         0.0433, 0.1036, 0.0902, 0.1352, 0.2205, 0.1151, 0.1098],\n",
      "        [0.0776, 0.2480, 0.0424, 0.0505, 0.1040, 0.0355, 0.0767, 0.1266, 0.0414,\n",
      "         0.0762, 0.0898, 0.0854, 0.0978, 0.1767, 0.1009, 0.1621],\n",
      "        [0.1034, 0.2288, 0.0905, 0.0577, 0.1078, 0.0383, 0.0622, 0.1517, 0.0611,\n",
      "         0.1076, 0.1384, 0.0759, 0.1011, 0.1777, 0.0866, 0.2104],\n",
      "        [0.2255, 0.8932, 0.0971, 0.1514, 0.2596, 0.1120, 0.2870, 0.5538, 0.1607,\n",
      "         0.2292, 0.3989, 0.2382, 0.3898, 0.7037, 0.3854, 0.5365],\n",
      "        [0.2672, 0.8967, 0.1782, 0.1704, 0.2986, 0.1292, 0.2682, 0.5370, 0.1893,\n",
      "         0.3081, 0.4399, 0.2345, 0.3691, 0.6618, 0.3593, 0.6513],\n",
      "        [0.0668, 0.1994, 0.0599, 0.0402, 0.0863, 0.0349, 0.0575, 0.0911, 0.0424,\n",
      "         0.0798, 0.0889, 0.0692, 0.0737, 0.1364, 0.0741, 0.1574],\n",
      "        [0.1896, 0.3493, 0.2161, 0.0997, 0.2109, 0.0746, 0.0739, 0.1691, 0.1118,\n",
      "         0.2357, 0.2125, 0.1277, 0.1118, 0.2053, 0.1026, 0.4153],\n",
      "        [0.1782, 0.2226, 0.1519, 0.0987, 0.2017, 0.0459, 0.0572, 0.1473, 0.0680,\n",
      "         0.1493, 0.1322, 0.1241, 0.1021, 0.1648, 0.0811, 0.2577],\n",
      "        [0.0899, 0.3961, 0.0844, 0.0527, 0.1018, 0.0654, 0.1042, 0.1928, 0.0867,\n",
      "         0.1535, 0.1969, 0.0890, 0.1475, 0.2847, 0.1452, 0.3224],\n",
      "        [0.1125, 0.2667, 0.0469, 0.0760, 0.1419, 0.0335, 0.0952, 0.1773, 0.0435,\n",
      "         0.0685, 0.1079, 0.1150, 0.1368, 0.2328, 0.1260, 0.1522]])}, 6: {'step': tensor(3820.), 'exp_avg': tensor([ 5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45]), 'exp_avg_sq': tensor([2.8061e-04, 4.8922e-04, 2.7866e-04, 3.9205e-05, 3.0428e-04, 4.8024e-04,\n",
      "        8.5715e-05, 2.0582e-04, 4.5369e-04, 7.3197e-04, 3.2906e-04, 1.8714e-04,\n",
      "        1.3880e-04, 1.5819e-04, 5.1548e-04, 8.0075e-04, 6.5600e-04, 1.7386e-04,\n",
      "        1.2465e-04, 2.9900e-04, 2.3033e-04, 2.4992e-04, 1.9753e-04, 2.4460e-04,\n",
      "        2.4286e-04, 2.3561e-04, 1.2663e-04, 2.8887e-04, 3.0107e-04, 4.2604e-04,\n",
      "        3.6430e-04, 9.7169e-05, 5.3847e-04, 2.2290e-04, 2.2254e-04, 3.5258e-04,\n",
      "        1.2333e-04, 6.4704e-05, 1.2829e-04, 1.3038e-04, 1.3984e-04, 3.0567e-04,\n",
      "        1.4609e-04, 2.8067e-04, 5.1363e-04, 5.1338e-04, 8.9525e-05, 1.4050e-04,\n",
      "        3.1036e-04, 5.3392e-04, 1.9986e-04, 5.8694e-04, 1.1147e-04, 3.0011e-04,\n",
      "        2.2005e-04, 1.0163e-04, 1.8880e-04, 3.2254e-04, 1.9111e-04, 5.1425e-04,\n",
      "        1.8245e-04, 2.1274e-04, 4.3392e-04, 1.7259e-04, 1.9525e-04, 5.1266e-04,\n",
      "        1.8697e-04, 3.0867e-04, 3.1854e-04, 7.8394e-04, 3.5375e-04, 1.6768e-04,\n",
      "        3.2398e-04, 4.2981e-04, 9.0298e-05, 1.4764e-04, 6.2925e-04, 1.1162e-04,\n",
      "        2.1641e-04, 7.5692e-05, 3.9851e-04, 3.2172e-04, 6.8021e-04, 1.9865e-04,\n",
      "        1.8270e-04, 2.3069e-04, 5.1774e-04, 5.8571e-04, 7.2298e-05, 2.5207e-04,\n",
      "        7.2465e-05, 2.2448e-04, 4.4025e-04, 1.7673e-04, 6.3683e-04, 2.1985e-04,\n",
      "        7.3607e-04, 4.3806e-04, 1.2818e-04, 6.3684e-05])}, 7: {'step': tensor(3820.), 'exp_avg': tensor([ 5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45]), 'exp_avg_sq': tensor([0.0004, 0.0003, 0.0006, 0.0005, 0.0004, 0.0004, 0.0003, 0.0004, 0.0003,\n",
      "        0.0005, 0.0004, 0.0005, 0.0002, 0.0004, 0.0006, 0.0002, 0.0006, 0.0007,\n",
      "        0.0004, 0.0002, 0.0006, 0.0006, 0.0005, 0.0005, 0.0002, 0.0005, 0.0007,\n",
      "        0.0003, 0.0005, 0.0002, 0.0004, 0.0005, 0.0006, 0.0003, 0.0005, 0.0002,\n",
      "        0.0005, 0.0004, 0.0003, 0.0004, 0.0003, 0.0003, 0.0003, 0.0003, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0007, 0.0003, 0.0003, 0.0006, 0.0006, 0.0003,\n",
      "        0.0004, 0.0006, 0.0005, 0.0004, 0.0001, 0.0006, 0.0003, 0.0006, 0.0003,\n",
      "        0.0005, 0.0003, 0.0005, 0.0004, 0.0004, 0.0004, 0.0010, 0.0003, 0.0002,\n",
      "        0.0003, 0.0001, 0.0004, 0.0009, 0.0005, 0.0004, 0.0006, 0.0003, 0.0008,\n",
      "        0.0003, 0.0007, 0.0004, 0.0005, 0.0005, 0.0005, 0.0002, 0.0005, 0.0005,\n",
      "        0.0004, 0.0002, 0.0003, 0.0001, 0.0003, 0.0004, 0.0003, 0.0010, 0.0008,\n",
      "        0.0002])}, 8: {'step': tensor(3820.), 'exp_avg': tensor([-5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45]), 'exp_avg_sq': tensor([0.5362, 0.0092, 0.0132, 0.2428, 0.0129, 0.1795, 0.3575, 0.0529, 0.4360,\n",
      "        0.0196, 0.0202, 0.0595, 0.0137, 0.0569, 0.0848, 0.0102, 0.0098, 0.0152,\n",
      "        0.0060, 0.0544, 0.0135, 0.0034, 0.1290, 0.0423, 2.7244])}, 9: {'step': tensor(3820.), 'exp_avg': tensor([[ 5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45]]), 'exp_avg_sq': tensor([[1.3917e-01, 6.3905e-02, 1.1222e-01, 5.5788e-01, 5.7635e-01, 5.8472e-01,\n",
      "         3.8948e-01, 5.9482e-01, 1.7110e-02, 3.6747e-01, 4.2220e-02, 8.4792e-02,\n",
      "         1.2139e-02, 1.0748e-01, 8.7087e-01, 4.5529e-02],\n",
      "        [4.5633e-02, 3.7449e-04, 3.3773e-02, 1.3877e-02, 2.1952e-02, 2.9954e-02,\n",
      "         1.0517e-02, 1.1905e-01, 1.9934e-03, 2.9392e-03, 7.6498e-03, 6.4634e-03,\n",
      "         2.2062e-03, 9.4291e-04, 3.7633e-02, 6.0365e-03],\n",
      "        [3.3465e-02, 4.8242e-04, 2.4704e-02, 1.0645e-02, 1.6242e-02, 1.4670e-02,\n",
      "         4.7358e-03, 8.1185e-02, 2.1023e-03, 2.2764e-03, 5.0038e-03, 3.9672e-03,\n",
      "         1.0357e-03, 7.0542e-04, 2.7812e-02, 6.0994e-03],\n",
      "        [4.2903e-01, 8.0364e-03, 2.8369e-01, 1.7851e-01, 2.3106e-01, 2.0607e-01,\n",
      "         7.0543e-02, 1.1463e+00, 1.6055e-02, 5.8874e-02, 8.6677e-02, 6.3644e-02,\n",
      "         1.8004e-02, 1.6842e-02, 3.8945e-01, 4.9666e-02],\n",
      "        [5.4331e-02, 1.2877e-03, 3.9143e-02, 2.8215e-02, 4.0881e-02, 2.1516e-02,\n",
      "         8.0985e-03, 1.5854e-01, 2.5261e-03, 7.6177e-03, 1.0391e-02, 9.8654e-03,\n",
      "         1.7995e-03, 2.1759e-03, 6.7096e-02, 7.4606e-03],\n",
      "        [2.2867e-01, 2.1830e-02, 1.7972e-01, 8.1616e-02, 8.6578e-02, 2.4538e-01,\n",
      "         1.1492e-01, 4.1537e-01, 1.8961e-02, 8.4923e-02, 2.3735e-02, 1.8491e-02,\n",
      "         7.8316e-03, 3.4791e-02, 1.4102e-01, 5.8396e-02],\n",
      "        [5.1374e-01, 2.3554e-02, 3.7618e-01, 9.8722e-02, 1.2188e-01, 2.5094e-01,\n",
      "         9.6435e-02, 9.2216e-01, 4.3743e-02, 3.3044e-02, 5.0979e-02, 1.9230e-02,\n",
      "         1.1330e-02, 1.7526e-02, 2.0608e-01, 1.3105e-01],\n",
      "        [1.3726e-01, 1.1403e-03, 8.9426e-02, 6.1678e-02, 7.2293e-02, 3.1115e-02,\n",
      "         8.0425e-03, 3.4289e-01, 7.6154e-03, 1.0779e-02, 2.4356e-02, 1.5089e-02,\n",
      "         2.9368e-03, 3.2412e-03, 1.2110e-01, 2.2466e-02],\n",
      "        [1.0804e+00, 1.0630e-02, 8.9254e-01, 3.0152e-01, 5.8526e-01, 3.9184e-01,\n",
      "         1.2317e-01, 2.8747e+00, 7.0907e-02, 3.8561e-02, 1.5299e-01, 1.4103e-01,\n",
      "         2.0998e-02, 1.0536e-02, 9.8989e-01, 2.2681e-01],\n",
      "        [1.8517e-02, 7.8894e-04, 1.2953e-02, 9.7351e-03, 1.2626e-02, 1.0336e-02,\n",
      "         4.4745e-03, 5.0785e-02, 8.2323e-04, 5.2768e-03, 3.6773e-03, 3.5038e-03,\n",
      "         5.8319e-04, 1.9151e-03, 2.0288e-02, 2.4040e-03],\n",
      "        [2.9351e-02, 1.0891e-03, 1.9972e-02, 1.4854e-02, 1.9889e-02, 1.1384e-02,\n",
      "         4.6624e-03, 8.4175e-02, 1.2175e-03, 7.1409e-03, 6.2229e-03, 5.6073e-03,\n",
      "         6.8259e-04, 2.0286e-03, 3.1267e-02, 4.7027e-03],\n",
      "        [1.6868e-01, 3.9654e-03, 1.0747e-01, 8.7010e-02, 9.8951e-02, 6.8043e-02,\n",
      "         2.7562e-02, 4.4792e-01, 8.0120e-03, 2.5313e-02, 3.2476e-02, 2.3153e-02,\n",
      "         4.7281e-03, 7.1183e-03, 1.6168e-01, 2.4731e-02],\n",
      "        [2.0076e-01, 1.8422e-03, 1.5479e-01, 8.0808e-02, 1.3938e-01, 4.8108e-02,\n",
      "         1.0658e-02, 5.4412e-01, 1.1600e-02, 8.7844e-03, 3.0677e-02, 3.4007e-02,\n",
      "         4.1972e-03, 3.1537e-03, 2.3607e-01, 3.4123e-02],\n",
      "        [1.3310e-01, 1.9531e-03, 8.4270e-02, 5.5127e-02, 6.4247e-02, 2.8835e-02,\n",
      "         7.6723e-03, 3.2697e-01, 7.0122e-03, 1.1214e-02, 2.3942e-02, 1.3913e-02,\n",
      "         2.6661e-03, 3.2949e-03, 1.0627e-01, 2.2103e-02],\n",
      "        [1.8134e-01, 6.9317e-03, 1.3048e-01, 1.5483e-01, 1.7181e-01, 7.2680e-02,\n",
      "         4.2903e-02, 5.0818e-01, 1.5434e-02, 4.2292e-02, 3.3545e-02, 2.3712e-02,\n",
      "         3.7551e-03, 1.0783e-02, 2.8052e-01, 4.6658e-02],\n",
      "        [3.5987e-02, 7.2545e-04, 2.6528e-02, 1.4936e-02, 2.2606e-02, 9.2966e-03,\n",
      "         2.6707e-03, 9.2117e-02, 2.3829e-03, 3.8356e-03, 5.6658e-03, 5.1228e-03,\n",
      "         7.4499e-04, 1.1121e-03, 3.7636e-02, 6.9378e-03],\n",
      "        [2.3615e-01, 1.2095e-03, 1.7751e-01, 9.2817e-02, 1.6147e-01, 4.0547e-02,\n",
      "         4.1491e-03, 6.4250e-01, 1.3336e-02, 9.6156e-03, 3.5887e-02, 4.0107e-02,\n",
      "         3.9088e-03, 3.1952e-03, 2.7133e-01, 3.8436e-02],\n",
      "        [2.8588e-02, 5.8067e-04, 2.0063e-02, 1.1740e-02, 1.6192e-02, 9.4184e-03,\n",
      "         3.0975e-03, 6.9939e-02, 1.8675e-03, 3.1680e-03, 4.5781e-03, 3.6010e-03,\n",
      "         7.7835e-04, 1.0374e-03, 2.6765e-02, 4.9874e-03],\n",
      "        [2.8016e-02, 6.7688e-04, 2.0526e-02, 1.3008e-02, 1.8077e-02, 9.1662e-03,\n",
      "         3.2776e-03, 7.3625e-02, 1.8345e-03, 3.2706e-03, 4.6379e-03, 3.8717e-03,\n",
      "         6.6844e-04, 8.8698e-04, 2.9946e-02, 5.3094e-03],\n",
      "        [1.0208e-01, 3.0371e-03, 6.9561e-02, 5.3785e-02, 7.1945e-02, 4.4647e-02,\n",
      "         1.7749e-02, 2.8815e-01, 4.3906e-03, 2.2956e-02, 2.0980e-02, 1.9033e-02,\n",
      "         3.0794e-03, 6.8052e-03, 1.1632e-01, 1.3311e-02],\n",
      "        [2.9003e-02, 7.6973e-04, 2.0486e-02, 1.3788e-02, 1.9484e-02, 8.4503e-03,\n",
      "         2.9839e-03, 7.5193e-02, 1.8457e-03, 4.3738e-03, 4.9518e-03, 4.3793e-03,\n",
      "         7.2823e-04, 1.2886e-03, 3.1577e-02, 5.1528e-03],\n",
      "        [3.2523e-02, 3.3459e-04, 2.4418e-02, 1.1667e-02, 1.9615e-02, 1.0351e-02,\n",
      "         2.6849e-03, 8.9197e-02, 1.6983e-03, 2.0028e-03, 5.3054e-03, 5.3130e-03,\n",
      "         7.8615e-04, 5.9703e-04, 3.2490e-02, 4.7581e-03],\n",
      "        [3.9891e-02, 6.4722e-03, 3.7555e-02, 7.3884e-02, 1.0202e-01, 5.9856e-02,\n",
      "         3.9515e-02, 1.7878e-01, 3.3911e-03, 4.5671e-02, 9.5399e-03, 2.0217e-02,\n",
      "         2.6805e-03, 1.0029e-02, 1.4529e-01, 1.2048e-02],\n",
      "        [8.0431e-02, 2.7142e-03, 6.3199e-02, 3.6753e-02, 4.9716e-02, 3.5463e-02,\n",
      "         1.5366e-02, 1.9972e-01, 6.3508e-03, 1.1175e-02, 1.1356e-02, 9.3539e-03,\n",
      "         1.7096e-03, 3.7672e-03, 8.3178e-02, 1.9115e-02],\n",
      "        [2.4822e+00, 1.1383e-01, 1.5101e+00, 1.1480e+00, 1.1890e+00, 2.4924e+00,\n",
      "         1.0999e+00, 6.0288e+00, 7.5606e-02, 6.9173e-01, 5.0564e-01, 3.2783e-01,\n",
      "         1.6923e-01, 2.0066e-01, 1.9406e+00, 2.0011e-01]])}, 10: {'step': tensor(3820.), 'exp_avg': tensor([-5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45]), 'exp_avg_sq': tensor([0.0034, 0.0020, 0.0023, 0.0020, 0.0016, 0.0019, 0.0013, 0.0032, 0.0033,\n",
      "        0.0032, 0.0018, 0.0020, 0.0015, 0.0023, 0.0045, 0.0013, 0.0054, 0.0041,\n",
      "        0.0007, 0.0012, 0.0037, 0.0010, 0.0026, 0.0036, 0.0020, 0.0010, 0.0020,\n",
      "        0.0022, 0.0005, 0.0021, 0.0020, 0.0023, 0.0051, 0.0022, 0.0028, 0.0012,\n",
      "        0.0025, 0.0018, 0.0007, 0.0031, 0.0029, 0.0003, 0.0015, 0.0013, 0.0025,\n",
      "        0.0006, 0.0012, 0.0019, 0.0034, 0.0026, 0.0011, 0.0033, 0.0049, 0.0030,\n",
      "        0.0027, 0.0009, 0.0025, 0.0013, 0.0016, 0.0050, 0.0006, 0.0012, 0.0033,\n",
      "        0.0029, 0.0023, 0.0029, 0.0010, 0.0025, 0.0023, 0.0062, 0.0022, 0.0009,\n",
      "        0.0009, 0.0012, 0.0036, 0.0014, 0.0031, 0.0030, 0.0010, 0.0017, 0.0043,\n",
      "        0.0022, 0.0021, 0.0005, 0.0016, 0.0016, 0.0054, 0.0030, 0.0012, 0.0033,\n",
      "        0.0031, 0.0013, 0.0005, 0.0011, 0.0009, 0.0007, 0.0042, 0.0037, 0.0065,\n",
      "        0.0011])}, 11: {'step': tensor(3820.), 'exp_avg': tensor([ 5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45]), 'exp_avg_sq': tensor([3.4620e-16, 1.1424e-16, 4.7785e-17, 6.2644e-17, 3.2505e-17, 9.2855e-17,\n",
      "        6.4815e-17, 8.8884e-17, 8.4947e-17, 1.0883e-16, 9.6740e-17, 1.5395e-16,\n",
      "        2.2141e-16, 1.0610e-16, 9.6932e-17, 2.9726e-17, 1.4537e-16, 3.0086e-17,\n",
      "        1.0172e-16, 4.7363e-17, 1.3376e-16, 5.6786e-17, 8.0469e-17, 2.2273e-16,\n",
      "        7.3898e-17, 4.6112e-17, 1.0445e-16, 2.7980e-17, 9.1356e-17, 8.6910e-17,\n",
      "        1.8226e-16, 1.5932e-16, 7.8716e-17, 1.0670e-16, 8.8744e-17, 5.2976e-17,\n",
      "        5.4200e-17, 4.6495e-17, 1.2737e-16, 1.2607e-16, 7.2639e-17, 4.4844e-17,\n",
      "        1.2421e-16, 9.4455e-17, 1.7990e-16, 9.3015e-17, 8.5208e-17, 6.8805e-17,\n",
      "        1.7543e-16, 7.2296e-17, 9.1277e-17, 1.9263e-16, 1.6089e-16, 9.6483e-17,\n",
      "        1.2715e-16, 1.5441e-16, 7.9265e-17, 2.0737e-16, 2.2330e-17, 1.5760e-16,\n",
      "        4.2908e-17, 7.4521e-17, 5.1059e-17, 7.1323e-17, 2.5210e-17, 6.0528e-17,\n",
      "        6.9746e-17, 1.2960e-16, 5.8302e-17, 3.4543e-16, 6.0287e-17, 7.6916e-17,\n",
      "        1.4302e-17, 1.3449e-16, 1.4603e-16, 5.3732e-17, 1.8028e-16, 4.8531e-17,\n",
      "        6.1521e-17, 1.3536e-16, 7.0374e-17, 4.1965e-17, 7.0654e-17, 2.2605e-17,\n",
      "        1.4522e-16, 1.5296e-16, 5.0149e-16, 6.7034e-17, 7.9009e-17, 1.2794e-16,\n",
      "        1.7129e-16, 7.0927e-17, 4.8866e-17, 4.6973e-17, 9.9574e-17, 8.8283e-17,\n",
      "        1.2270e-16, 2.9094e-16, 3.6773e-16, 9.6240e-17])}, 12: {'step': tensor(3820.), 'exp_avg': tensor([-5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45]), 'exp_avg_sq': tensor([142.4552, 113.6227,  50.2868,  15.3930,  17.5696,  50.8817,  59.6539,\n",
      "          6.2989])}, 13: {'step': tensor(3820.), 'exp_avg': tensor([[ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45]]), 'exp_avg_sq': tensor([[1.6859e+01, 6.9171e-02, 3.5096e+00],\n",
      "        [2.4819e+01, 9.2421e-02, 2.4165e+00],\n",
      "        [5.8048e+00, 3.1555e-02, 2.7689e+00],\n",
      "        [9.6263e-01, 8.5186e-03, 1.5838e-01],\n",
      "        [1.8462e+00, 9.8057e-03, 6.0792e-01],\n",
      "        [1.6495e+01, 5.2216e-02, 1.2257e+00],\n",
      "        [7.9855e+00, 3.4582e-02, 3.0118e+00],\n",
      "        [1.3488e+00, 1.1053e-02, 4.6234e-01]])}, 14: {'step': tensor(3820.), 'exp_avg': tensor([-5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45]), 'exp_avg_sq': tensor([0.0021, 0.0009, 0.0012, 0.0004, 0.0026, 0.0021, 0.0002, 0.0008, 0.0004,\n",
      "        0.0018, 0.0006, 0.0007, 0.0004, 0.0043, 0.0007, 0.0037, 0.0023, 0.0007,\n",
      "        0.0002, 0.0013, 0.0010, 0.0002, 0.0016, 0.0018, 0.0012, 0.0006, 0.0014,\n",
      "        0.0007, 0.0092, 0.0006, 0.0015, 0.0003, 0.0042, 0.0026, 0.0014, 0.0035,\n",
      "        0.0022, 0.0003, 0.0013, 0.0014, 0.0024, 0.0013, 0.0011, 0.0011, 0.0022,\n",
      "        0.0003, 0.0027, 0.0025, 0.0040, 0.0011, 0.0016, 0.0035, 0.0029, 0.0006,\n",
      "        0.0017, 0.0005, 0.0005, 0.0036, 0.0029, 0.0004, 0.0006, 0.0017, 0.0019,\n",
      "        0.0021, 0.0006, 0.0037, 0.0038, 0.0015, 0.0039, 0.0008, 0.0067, 0.0041,\n",
      "        0.0031, 0.0020, 0.0009, 0.0022, 0.0018, 0.0011, 0.0043, 0.0005, 0.0026,\n",
      "        0.0020, 0.0017, 0.0022, 0.0023, 0.0057, 0.0003, 0.0022, 0.0021, 0.0017,\n",
      "        0.0019, 0.0018, 0.0005, 0.0014, 0.0025, 0.0013, 0.0032, 0.0009, 0.0011,\n",
      "        0.0005])}, 15: {'step': tensor(3820.), 'exp_avg': tensor([ 5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45]), 'exp_avg_sq': tensor([0.0017, 0.0028, 0.0013, 0.0037, 0.0056, 0.0054, 0.0028, 0.0024, 0.0028,\n",
      "        0.0039, 0.0021, 0.0040, 0.0043, 0.0038, 0.0027, 0.0028, 0.0038, 0.0038,\n",
      "        0.0013, 0.0065, 0.0030, 0.0037, 0.0019, 0.0031, 0.0014, 0.0006, 0.0025,\n",
      "        0.0028, 0.0045, 0.0020, 0.0022, 0.0025, 0.0067, 0.0034, 0.0020, 0.0013,\n",
      "        0.0024, 0.0008, 0.0043, 0.0039, 0.0015, 0.0016, 0.0028, 0.0030, 0.0039,\n",
      "        0.0024, 0.0018, 0.0031, 0.0032, 0.0043, 0.0064, 0.0021, 0.0024, 0.0031,\n",
      "        0.0078, 0.0034, 0.0028, 0.0034, 0.0034, 0.0028, 0.0020, 0.0018, 0.0041,\n",
      "        0.0016, 0.0027, 0.0015, 0.0024, 0.0031, 0.0027, 0.0027, 0.0039, 0.0031,\n",
      "        0.0019, 0.0050, 0.0038, 0.0021, 0.0026, 0.0032, 0.0050, 0.0034, 0.0028,\n",
      "        0.0020, 0.0046, 0.0043, 0.0018, 0.0052, 0.0081, 0.0037, 0.0029, 0.0013,\n",
      "        0.0021, 0.0036, 0.0051, 0.0015, 0.0054, 0.0025, 0.0036, 0.0036, 0.0016,\n",
      "        0.0041])}, 16: {'step': tensor(3820.), 'exp_avg': tensor([-5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45]), 'exp_avg_sq': tensor([ 5.1113, 19.6066,  3.6466, 31.7455, 60.9713, 11.6359, 15.6730, 10.9711])}, 17: {'step': tensor(3820.), 'exp_avg': tensor([[ 5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45]]), 'exp_avg_sq': tensor([[ 2.0271,  0.1875,  1.7517,  0.3296,  0.8837,  0.5624,  0.4591,  0.6480],\n",
      "        [ 2.7261,  0.4706,  2.6620,  0.8961,  3.3186,  1.7937,  1.4121,  3.7100],\n",
      "        [ 0.5743,  0.0446,  0.5342,  0.0775,  0.3982,  0.2539,  0.2039,  0.3719],\n",
      "        [ 3.1476,  1.2050,  3.9414,  2.2901,  4.4725,  1.7645,  1.2582,  4.5555],\n",
      "        [12.3895,  1.6830, 13.4226,  2.9820, 10.5422,  5.8619,  4.4757,  9.0347],\n",
      "        [ 1.4367,  0.4466,  1.6509,  0.9075,  1.2545,  0.5208,  0.3917,  1.4573],\n",
      "        [ 6.0707,  0.5716,  5.9681,  1.0163,  3.7086,  2.3639,  1.8670,  2.9455],\n",
      "        [ 1.9476,  0.3482,  2.0438,  0.6005,  2.0570,  1.0374,  0.7964,  1.8467]])}, 18: {'step': tensor(3820.), 'exp_avg': tensor([-5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45]), 'exp_avg_sq': tensor([2.9081e-04, 4.4724e-04, 8.1883e-04, 1.4932e-04, 4.9262e-04, 5.2101e-04,\n",
      "        2.5250e-04, 4.4297e-04, 1.1610e-04, 7.2495e-04, 3.5995e-04, 7.1361e-04,\n",
      "        3.8159e-04, 1.2552e-03, 3.3162e-04, 7.0403e-04, 6.7377e-04, 5.9430e-04,\n",
      "        9.8054e-05, 4.7861e-04, 5.3524e-04, 1.4618e-04, 5.0316e-04, 5.4081e-04,\n",
      "        4.9174e-04, 5.0158e-04, 5.5966e-04, 4.1426e-04, 8.0736e-04, 3.5636e-04,\n",
      "        6.8871e-04, 3.1176e-04, 1.6582e-03, 6.2234e-04, 7.6042e-04, 8.8666e-04,\n",
      "        9.0316e-04, 1.9310e-04, 3.9077e-04, 7.4348e-04, 8.2054e-04, 2.3189e-04,\n",
      "        3.6534e-04, 6.1434e-04, 4.8369e-04, 3.1840e-04, 8.2970e-04, 7.6870e-04,\n",
      "        2.1179e-03, 5.8955e-04, 1.9958e-04, 7.3811e-04, 1.1355e-03, 6.0326e-04,\n",
      "        5.2716e-04, 5.0901e-04, 5.2628e-04, 7.5627e-04, 7.8135e-04, 9.5872e-04,\n",
      "        4.8062e-04, 2.0424e-03, 1.0910e-03, 4.6930e-04, 3.8780e-04, 5.5449e-04,\n",
      "        1.4935e-04, 8.7506e-04, 1.1002e-03, 3.1156e-04, 1.2597e-03, 8.4532e-04,\n",
      "        7.0128e-04, 1.1248e-03, 3.5192e-04, 8.2893e-04, 6.4652e-04, 5.5418e-04,\n",
      "        6.4489e-04, 3.7772e-04, 6.8583e-04, 5.8179e-04, 9.0503e-04, 6.8615e-04,\n",
      "        1.0397e-03, 1.2977e-03, 8.2062e-04, 7.4627e-04, 5.9942e-04, 5.1669e-04,\n",
      "        3.4742e-04, 6.1754e-04, 5.6958e-04, 5.0244e-04, 7.5014e-04, 3.8137e-04,\n",
      "        7.0812e-04, 8.2373e-04, 7.8249e-04, 1.4483e-04])}, 19: {'step': tensor(3820.), 'exp_avg': tensor([5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
      "        5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
      "        5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
      "        5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
      "        5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
      "        5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
      "        5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
      "        5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
      "        5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
      "        5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
      "        5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
      "        5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
      "        5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
      "        5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
      "        5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
      "        5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
      "        5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45]), 'exp_avg_sq': tensor([0.0017, 0.0030, 0.0078, 0.0116, 0.0095, 0.0074, 0.0058, 0.0031, 0.0050,\n",
      "        0.0044, 0.0023, 0.0049, 0.0010, 0.0029, 0.0032, 0.0018, 0.0033, 0.0016,\n",
      "        0.0013, 0.0029, 0.0039, 0.0024, 0.0032, 0.0030, 0.0046, 0.0015, 0.0012,\n",
      "        0.0030, 0.0091, 0.0030, 0.0051, 0.0024, 0.0050, 0.0040, 0.0021, 0.0042,\n",
      "        0.0037, 0.0014, 0.0029, 0.0018, 0.0024, 0.0018, 0.0023, 0.0035, 0.0059,\n",
      "        0.0035, 0.0029, 0.0077, 0.0091, 0.0102, 0.0048, 0.0014, 0.0018, 0.0081,\n",
      "        0.0035, 0.0026, 0.0026, 0.0116, 0.0025, 0.0020, 0.0031, 0.0080, 0.0108,\n",
      "        0.0026, 0.0109, 0.0024, 0.0032, 0.0023, 0.0017, 0.0088, 0.0032, 0.0047,\n",
      "        0.0037, 0.0041, 0.0023, 0.0031, 0.0051, 0.0097, 0.0061, 0.0072, 0.0035,\n",
      "        0.0043, 0.0042, 0.0027, 0.0084, 0.0046, 0.0137, 0.0035, 0.0048, 0.0034,\n",
      "        0.0021, 0.0066, 0.0125, 0.0026, 0.0062, 0.0101, 0.0062, 0.0030, 0.0065,\n",
      "        0.0026])}, 20: {'step': tensor(3820.), 'exp_avg': tensor([-5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45]), 'exp_avg_sq': tensor([14.1889,  6.6983,  8.3991,  5.3644, 19.4155, 12.5455,  6.4883,  2.0632])}, 21: {'step': tensor(3820.), 'exp_avg': tensor([[-5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45,  5.6052e-45]]), 'exp_avg_sq': tensor([[ 2.5066,  1.0179,  2.9610,  5.8297,  0.3585,  0.7054,  0.4770,  0.2008],\n",
      "        [ 2.0177,  0.8185,  4.3262,  2.5673,  0.3185,  0.3519,  0.2683,  0.1490],\n",
      "        [ 1.8035,  0.3847,  1.8907,  2.1328,  0.1646,  0.2643,  0.1700,  0.0943],\n",
      "        [ 1.3316,  0.3379,  1.3509,  2.0798,  0.1408,  0.2380,  0.1504,  0.0698],\n",
      "        [ 5.2584,  2.6056, 11.8232,  9.4926,  1.4112,  1.5149,  0.9909,  0.4357],\n",
      "        [ 5.3132,  1.2235, 11.2677,  3.9527,  1.2237,  0.6872,  0.3632,  0.1886],\n",
      "        [ 1.5141,  0.3254,  1.8188,  2.5674,  0.1617,  0.2083,  0.1573,  0.0769],\n",
      "        [ 0.5200,  0.1238,  0.6998,  0.7558,  0.0989,  0.1026,  0.0456,  0.0250]])}, 22: {'step': tensor(3820.), 'exp_avg': tensor([ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45]), 'exp_avg_sq': tensor([0.0024, 0.0023, 0.0038, 0.0024, 0.0017, 0.0018, 0.0035, 0.0035, 0.0018,\n",
      "        0.0035, 0.0028, 0.0036, 0.0022, 0.0038, 0.0029, 0.0016, 0.0040, 0.0032,\n",
      "        0.0023, 0.0027, 0.0036, 0.0020, 0.0036, 0.0028, 0.0021, 0.0023, 0.0020,\n",
      "        0.0019, 0.0013, 0.0027, 0.0026, 0.0029, 0.0033, 0.0019, 0.0031, 0.0021,\n",
      "        0.0033, 0.0027, 0.0016, 0.0021, 0.0031, 0.0019, 0.0018, 0.0021, 0.0027,\n",
      "        0.0023, 0.0017, 0.0023, 0.0043, 0.0026, 0.0023, 0.0040, 0.0043, 0.0031,\n",
      "        0.0025, 0.0025, 0.0021, 0.0031, 0.0020, 0.0030, 0.0016, 0.0024, 0.0031,\n",
      "        0.0029, 0.0026, 0.0025, 0.0028, 0.0024, 0.0022, 0.0047, 0.0024, 0.0023,\n",
      "        0.0013, 0.0018, 0.0032, 0.0035, 0.0026, 0.0025, 0.0017, 0.0030, 0.0020,\n",
      "        0.0028, 0.0020, 0.0016, 0.0019, 0.0032, 0.0025, 0.0022, 0.0029, 0.0023,\n",
      "        0.0034, 0.0023, 0.0018, 0.0023, 0.0017, 0.0015, 0.0016, 0.0024, 0.0051,\n",
      "        0.0024])}, 23: {'step': tensor(3820.), 'exp_avg': tensor([-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45]), 'exp_avg_sq': tensor([0.0057, 0.0048, 0.0050, 0.0043, 0.0057, 0.0056, 0.0050, 0.0055, 0.0072,\n",
      "        0.0059, 0.0056, 0.0063, 0.0050, 0.0043, 0.0050, 0.0050, 0.0046, 0.0059,\n",
      "        0.0045, 0.0063, 0.0049, 0.0053, 0.0049, 0.0065, 0.0050, 0.0061, 0.0045,\n",
      "        0.0061, 0.0044, 0.0064, 0.0042, 0.0050, 0.0055, 0.0052, 0.0041, 0.0050,\n",
      "        0.0059, 0.0051, 0.0040, 0.0060, 0.0063, 0.0048, 0.0048, 0.0052, 0.0063,\n",
      "        0.0066, 0.0049, 0.0070, 0.0050, 0.0052, 0.0052, 0.0050, 0.0059, 0.0053,\n",
      "        0.0050, 0.0063, 0.0063, 0.0075, 0.0053, 0.0044, 0.0046, 0.0050, 0.0060,\n",
      "        0.0058, 0.0044, 0.0047, 0.0058, 0.0042, 0.0042, 0.0059, 0.0045, 0.0054,\n",
      "        0.0061, 0.0061, 0.0048, 0.0067, 0.0044, 0.0061, 0.0068, 0.0073, 0.0045,\n",
      "        0.0069, 0.0047, 0.0054, 0.0055, 0.0058, 0.0054, 0.0064, 0.0052, 0.0064,\n",
      "        0.0051, 0.0046, 0.0054, 0.0044, 0.0058, 0.0049, 0.0056, 0.0047, 0.0055,\n",
      "        0.0055])}, 24: {'step': tensor(3820.), 'exp_avg': tensor([-5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45,  5.6052e-45]), 'exp_avg_sq': tensor([0.0009, 0.0009, 0.0013, 0.0005, 0.0020, 0.0006, 0.0019, 0.0016])}, 25: {'step': tensor(3820.), 'exp_avg': tensor([[ 5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45]]), 'exp_avg_sq': tensor([[0.0006, 0.0037, 0.0061, 0.0017, 0.0040, 0.0016, 0.0047, 0.0122],\n",
      "        [0.0006, 0.0030, 0.0060, 0.0013, 0.0030, 0.0018, 0.0050, 0.0115],\n",
      "        [0.0009, 0.0048, 0.0043, 0.0005, 0.0023, 0.0013, 0.0029, 0.0059],\n",
      "        [0.0004, 0.0035, 0.0029, 0.0001, 0.0016, 0.0004, 0.0015, 0.0034],\n",
      "        [0.0011, 0.0058, 0.0079, 0.0013, 0.0036, 0.0017, 0.0061, 0.0136],\n",
      "        [0.0005, 0.0039, 0.0050, 0.0006, 0.0026, 0.0005, 0.0033, 0.0084],\n",
      "        [0.0012, 0.0068, 0.0106, 0.0015, 0.0045, 0.0032, 0.0081, 0.0163],\n",
      "        [0.0009, 0.0084, 0.0107, 0.0017, 0.0072, 0.0013, 0.0063, 0.0196]])}, 26: {'step': tensor(3820.), 'exp_avg': tensor([-5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45]), 'exp_avg_sq': tensor([2.6561e-06, 1.1410e-06, 2.1922e-07, 5.6319e-06, 1.1586e-06, 8.7010e-06,\n",
      "        1.1806e-05, 4.2904e-06, 3.9247e-06, 6.6881e-07, 7.0572e-07, 2.7423e-06,\n",
      "        1.0013e-06, 5.2768e-06, 1.3198e-06, 3.2626e-07, 6.2646e-07, 3.1326e-07,\n",
      "        1.1238e-06, 3.1089e-06, 3.4745e-07, 9.0015e-07, 1.1426e-06, 1.6680e-06,\n",
      "        3.8312e-05])}, 27: {'step': tensor(3820.), 'exp_avg': tensor([-5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45]), 'exp_avg_sq': tensor([1.6650e-04, 9.1265e-06, 9.2383e-06, 3.7732e-05, 8.4888e-06, 1.2590e-05,\n",
      "        1.1484e-05, 3.5958e-05, 2.8010e-04, 1.9500e-05, 2.0056e-05, 2.0309e-05,\n",
      "        9.1722e-06, 5.4626e-05, 2.0983e-05, 9.9063e-06, 8.2584e-06, 1.0452e-05,\n",
      "        8.2032e-06, 8.4268e-05, 1.0493e-05, 8.2063e-06, 1.7304e-05, 4.0313e-06,\n",
      "        2.0425e-03])}, 28: {'step': tensor(3820.), 'exp_avg': tensor([ 5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45]), 'exp_avg_sq': tensor([0.0030, 0.0014, 0.0045, 0.0008, 0.0014, 0.0016, 0.0047, 0.0002])}, 29: {'step': tensor(3820.), 'exp_avg': tensor([[-5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45]]), 'exp_avg_sq': tensor([[2.4120e-04, 3.1691e-04, 4.5395e-03, 4.5977e-04, 1.6911e-03, 2.9245e-03,\n",
      "         3.5692e-03, 2.0951e-03],\n",
      "        [1.1126e-04, 7.0534e-05, 4.4940e-03, 3.8942e-04, 6.2731e-04, 1.8411e-03,\n",
      "         2.3632e-03, 1.4490e-03],\n",
      "        [1.6187e-04, 1.9683e-04, 5.2174e-03, 1.5928e-04, 1.7281e-03, 6.6836e-03,\n",
      "         1.2604e-03, 1.0125e-03],\n",
      "        [7.0735e-05, 6.1234e-05, 2.4044e-03, 1.4034e-04, 3.6516e-04, 9.1332e-04,\n",
      "         8.7003e-04, 7.0845e-04],\n",
      "        [8.4333e-05, 7.5738e-05, 1.2788e-03, 7.6848e-05, 3.1999e-04, 7.3656e-04,\n",
      "         5.8753e-04, 5.6221e-04],\n",
      "        [1.8822e-04, 5.9079e-05, 1.8491e-03, 7.1437e-05, 9.6909e-04, 2.1264e-03,\n",
      "         3.6140e-04, 1.4746e-03],\n",
      "        [3.0566e-04, 1.4888e-04, 3.1213e-03, 8.8747e-05, 1.7140e-03, 4.2184e-03,\n",
      "         5.5121e-04, 1.6735e-03],\n",
      "        [3.4457e-05, 6.3377e-06, 6.2958e-04, 1.9796e-05, 2.2805e-04, 8.1714e-04,\n",
      "         9.9119e-05, 3.2858e-04]])}, 30: {'step': tensor(3820.), 'exp_avg': tensor([-5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45]), 'exp_avg_sq': tensor([1.7399e-06, 7.9341e-07, 3.3355e-07, 4.8230e-06, 7.9942e-07, 3.6353e-06,\n",
      "        4.9948e-06, 2.6882e-06, 3.0629e-06, 1.9391e-07, 4.3163e-07, 1.0667e-06,\n",
      "        7.7428e-07, 3.6453e-06, 9.6321e-07, 3.2714e-07, 5.5652e-07, 1.5504e-07,\n",
      "        6.4492e-07, 1.0083e-06, 1.9255e-07, 5.4105e-07, 8.9994e-07, 1.1253e-06,\n",
      "        5.0616e-05])}, 31: {'step': tensor(3820.), 'exp_avg': tensor([-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45]), 'exp_avg_sq': tensor([1.1618e-03, 1.4238e-05, 2.0387e-05, 2.2062e-04, 1.3753e-05, 1.0864e-04,\n",
      "        1.6398e-04, 1.2038e-04, 4.5965e-03, 3.3635e-05, 3.4790e-05, 1.0888e-04,\n",
      "        2.2447e-05, 1.3530e-04, 8.7055e-05, 2.1454e-05, 1.5351e-05, 2.5958e-05,\n",
      "        1.3566e-05, 1.3069e-04, 2.7249e-05, 1.2107e-05, 9.5816e-05, 1.3175e-05,\n",
      "        6.3649e-03])}, 32: {'step': tensor(3820.), 'exp_avg': tensor([ 5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45]), 'exp_avg_sq': tensor([0.0004, 0.0008, 0.0077, 0.0035, 0.0006, 0.0025, 0.0004, 0.0016, 0.0012,\n",
      "        0.0004])}, 33: {'step': tensor(3820.), 'exp_avg': tensor([[-5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45,  5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45]]), 'exp_avg_sq': tensor([[2.9388e-04, 1.1214e-04, 2.9696e-05, 1.0651e-04, 1.1680e-04, 4.2020e-04,\n",
      "         1.8488e-04, 1.7937e-04],\n",
      "        [8.0768e-04, 6.6536e-04, 1.1749e-04, 4.1090e-04, 3.7601e-04, 1.5176e-03,\n",
      "         2.2332e-04, 8.0480e-04],\n",
      "        [4.4165e-03, 6.9898e-03, 1.7150e-03, 6.0476e-03, 7.1600e-03, 5.2437e-03,\n",
      "         3.6140e-03, 2.7684e-03],\n",
      "        [4.0218e-03, 4.4822e-03, 4.1055e-04, 2.8688e-03, 2.9349e-03, 8.0923e-03,\n",
      "         1.1397e-03, 4.4983e-03],\n",
      "        [2.9483e-04, 2.9259e-04, 5.0217e-05, 1.9561e-04, 1.7736e-04, 7.2242e-04,\n",
      "         9.3628e-05, 4.1088e-04],\n",
      "        [2.6220e-03, 9.0356e-03, 6.9379e-04, 5.7483e-03, 6.6040e-03, 6.7792e-03,\n",
      "         2.0820e-04, 4.9408e-03],\n",
      "        [9.2902e-04, 6.7343e-04, 9.8078e-05, 3.0631e-04, 3.8753e-04, 1.2705e-03,\n",
      "         3.9070e-04, 5.5906e-04],\n",
      "        [1.1980e-03, 1.0518e-03, 2.8740e-04, 6.8208e-04, 8.8066e-04, 1.6332e-03,\n",
      "         8.4830e-04, 7.1182e-04],\n",
      "        [8.4352e-04, 9.2590e-04, 9.3052e-05, 6.0910e-04, 5.2764e-04, 2.1209e-03,\n",
      "         1.7583e-04, 1.2202e-03],\n",
      "        [1.7303e-04, 5.5482e-04, 4.0105e-05, 2.1728e-04, 3.5266e-04, 2.4823e-04,\n",
      "         4.9078e-05, 1.8622e-04]])}, 34: {'step': tensor(3820.), 'exp_avg': tensor([ 5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45]), 'exp_avg_sq': tensor([6.1221e-04, 2.7016e-05, 1.7649e-05, 8.6203e-05, 2.2231e-05, 9.9757e-05,\n",
      "        9.8970e-05, 2.8561e-05, 1.9963e-03, 2.4533e-05, 2.2803e-05, 3.5019e-05,\n",
      "        3.5153e-05, 3.6983e-05, 1.7112e-04, 1.5959e-05, 1.3816e-05, 1.8798e-05,\n",
      "        2.1111e-05, 5.4588e-05, 1.8008e-05, 2.1252e-05, 1.8372e-04, 2.1767e-05,\n",
      "        1.0657e-03])}, 35: {'step': tensor(3820.), 'exp_avg': tensor([ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45]), 'exp_avg_sq': tensor([7.5193e-17, 2.7709e-17, 3.1166e-17, 7.2286e-17, 3.6130e-17, 1.4006e-16,\n",
      "        1.1206e-16, 1.7397e-16, 5.0486e-17, 1.9161e-17, 5.3502e-17, 8.5221e-17,\n",
      "        2.4986e-17, 6.5545e-17, 6.1596e-17, 9.7343e-18, 3.2905e-18, 1.7733e-17,\n",
      "        5.7256e-17, 1.0431e-16, 8.7901e-18, 1.7248e-17, 6.3443e-17, 2.4456e-17,\n",
      "        1.6969e-16])}, 36: {'step': tensor(3820.), 'exp_avg': tensor([ 5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45]), 'exp_avg_sq': tensor([0.3241, 0.2207, 0.2910, 0.1804, 0.1024, 0.1459, 0.1593, 0.2572, 0.2804,\n",
      "        0.1753, 0.4620, 0.4065])}, 37: {'step': tensor(3820.), 'exp_avg': tensor([[-5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45,  5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45]]), 'exp_avg_sq': tensor([[1.2449, 2.0458, 1.2608, 0.6760, 0.8153, 0.5819, 2.7060, 3.0129],\n",
      "        [0.3478, 0.5914, 0.9071, 0.4170, 0.3342, 0.6696, 1.2262, 1.4364],\n",
      "        [0.9096, 1.6247, 0.9944, 0.5122, 0.6798, 0.3664, 2.0197, 2.3884],\n",
      "        [0.2458, 0.4946, 0.3255, 0.3227, 0.4731, 0.2284, 0.3798, 1.1123],\n",
      "        [0.1654, 0.2912, 0.2582, 0.1780, 0.1964, 0.2873, 0.4317, 0.5275],\n",
      "        [0.2620, 0.7017, 1.0862, 0.2609, 0.5637, 0.3399, 0.9738, 1.9495],\n",
      "        [0.5434, 1.0678, 1.0591, 0.3548, 0.3930, 0.2816, 1.6052, 1.9631],\n",
      "        [0.5097, 0.9460, 1.2143, 0.4178, 0.3443, 0.3530, 1.6718, 2.1553],\n",
      "        [0.4947, 0.8009, 0.6769, 0.4720, 0.3950, 0.4513, 1.1143, 1.5080],\n",
      "        [0.2832, 0.9478, 1.8107, 0.3211, 0.8445, 0.4546, 1.4881, 3.1231],\n",
      "        [1.2337, 1.9666, 1.8608, 1.1045, 0.8725, 1.0243, 3.2043, 3.9781],\n",
      "        [1.1266, 2.0027, 1.6600, 0.6254, 1.2364, 0.8274, 2.4653, 3.4233]])}, 38: {'step': tensor(3820.), 'exp_avg': tensor([ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45]), 'exp_avg_sq': tensor([0.0052, 0.0009, 0.0003, 0.0021, 0.0007, 0.0023, 0.0031, 0.0016, 0.0058,\n",
      "        0.0006, 0.0006, 0.0010, 0.0006, 0.0014, 0.0022, 0.0003, 0.0002, 0.0004,\n",
      "        0.0006, 0.0025, 0.0004, 0.0007, 0.0020, 0.0008, 0.0189])}, 39: {'step': tensor(3820.), 'exp_avg': tensor([-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45]), 'exp_avg_sq': tensor([0.0280, 0.0021, 0.0022, 0.0031, 0.0022, 0.0164, 0.0090, 0.0024, 0.1721,\n",
      "        0.0022, 0.0023, 0.0035, 0.0034, 0.0023, 0.0065, 0.0021, 0.0019, 0.0022,\n",
      "        0.0019, 0.0049, 0.0023, 0.0019, 0.0050, 0.0024, 0.0779])}, 40: {'step': tensor(3820.), 'exp_avg': tensor([ 5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45]), 'exp_avg_sq': tensor([0.1757, 1.1056, 0.4398, 0.8970, 0.7200, 0.0843, 0.3224, 0.4656, 2.4668,\n",
      "        1.3057, 0.2162, 0.6368])}, 41: {'step': tensor(3820.), 'exp_avg': tensor([[ 5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45]]), 'exp_avg_sq': tensor([[0.1072, 0.0276, 0.0991, 0.4158, 0.0516, 0.1475, 0.1265, 0.2830, 0.1862,\n",
      "         0.0799, 0.0715, 0.0967],\n",
      "        [0.6908, 0.3649, 1.6586, 2.0754, 0.8448, 1.3513, 1.1049, 1.3694, 1.4261,\n",
      "         1.0226, 0.7928, 1.0135],\n",
      "        [0.2432, 0.0542, 0.2462, 0.7905, 0.1056, 0.1737, 0.4071, 0.6283, 0.4426,\n",
      "         0.1566, 0.1901, 0.1953],\n",
      "        [0.9620, 0.8017, 3.9406, 1.4899, 0.9649, 1.5487, 1.4978, 1.2464, 2.3428,\n",
      "         1.8960, 0.9013, 1.2295],\n",
      "        [0.4477, 0.1382, 0.6106, 1.4139, 0.1608, 0.4498, 0.5459, 0.9456, 0.8039,\n",
      "         0.2765, 0.2522, 0.3535],\n",
      "        [0.0397, 0.0097, 0.0429, 0.1315, 0.0069, 0.0429, 0.0639, 0.1075, 0.0630,\n",
      "         0.0202, 0.0266, 0.0179],\n",
      "        [0.1640, 0.1059, 0.4727, 0.5127, 0.0997, 0.3812, 0.2006, 0.3505, 0.3180,\n",
      "         0.2470, 0.1269, 0.1587],\n",
      "        [0.2737, 0.1382, 0.5780, 0.7295, 0.3716, 0.5252, 0.5671, 0.5289, 0.5592,\n",
      "         0.3793, 0.3563, 0.4296],\n",
      "        [1.2998, 0.5672, 2.3611, 4.5261, 1.6639, 2.6634, 2.5070, 3.1379, 2.4934,\n",
      "         1.7342, 1.7606, 1.9269],\n",
      "        [0.6064, 0.5126, 2.2988, 1.9715, 0.5321, 1.3028, 1.0418, 1.7349, 1.2999,\n",
      "         1.3557, 0.6768, 0.6542],\n",
      "        [0.1193, 0.0438, 0.1716, 0.4367, 0.0626, 0.1932, 0.1239, 0.2681, 0.2124,\n",
      "         0.0992, 0.0689, 0.1124],\n",
      "        [0.5551, 0.1488, 0.8093, 0.9845, 0.3049, 0.1971, 0.7740, 0.7000, 1.1619,\n",
      "         0.3204, 0.3515, 0.5276]])}, 42: {'step': tensor(3820.), 'exp_avg': tensor([ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45]), 'exp_avg_sq': tensor([0.0031, 0.0009, 0.0002, 0.0018, 0.0007, 0.0036, 0.0047, 0.0012, 0.0074,\n",
      "        0.0005, 0.0006, 0.0009, 0.0004, 0.0012, 0.0017, 0.0002, 0.0001, 0.0003,\n",
      "        0.0006, 0.0022, 0.0004, 0.0007, 0.0015, 0.0010, 0.0182])}, 43: {'step': tensor(3820.), 'exp_avg': tensor([-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45]), 'exp_avg_sq': tensor([0.1111, 0.0124, 0.0122, 0.0136, 0.0123, 0.0231, 0.0215, 0.0122, 0.2414,\n",
      "        0.0122, 0.0126, 0.0143, 0.0132, 0.0123, 0.0200, 0.0119, 0.0116, 0.0120,\n",
      "        0.0114, 0.0144, 0.0121, 0.0115, 0.0199, 0.0119, 0.1404])}, 44: {'step': tensor(3820.), 'exp_avg': tensor([-5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45]), 'exp_avg_sq': tensor([0.3922, 0.1337, 0.5225, 1.1728, 0.1436, 0.7641, 0.4590, 0.6648, 1.6534,\n",
      "        0.6055, 1.2118, 0.4264, 0.5432, 0.1560, 0.5552, 0.2923])}, 45: {'step': tensor(3820.), 'exp_avg': tensor([[-5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45]]), 'exp_avg_sq': tensor([[0.9370, 0.3593, 0.8069, 0.2212, 0.1849, 0.3006, 0.7060, 0.1203, 0.3562,\n",
      "         0.1222, 0.4105, 0.9254],\n",
      "        [0.7838, 0.1383, 0.5616, 0.1947, 0.0452, 0.1617, 0.2561, 0.0426, 0.1950,\n",
      "         0.0739, 0.2452, 0.2536],\n",
      "        [1.4861, 0.4593, 1.0037, 0.3449, 0.2309, 0.4695, 0.7713, 0.1312, 0.4959,\n",
      "         0.1862, 0.6342, 1.0123],\n",
      "        [2.8677, 0.9701, 1.5230, 0.6899, 0.3967, 0.7171, 1.3058, 0.2692, 1.1357,\n",
      "         0.3431, 1.2612, 1.9433],\n",
      "        [0.2586, 0.0978, 0.2311, 0.0665, 0.0411, 0.0659, 0.2036, 0.0434, 0.1013,\n",
      "         0.0294, 0.1006, 0.2601],\n",
      "        [3.4242, 0.2539, 2.7738, 0.5714, 0.1581, 0.4122, 0.9147, 0.1532, 0.5636,\n",
      "         0.3047, 1.0648, 0.8118],\n",
      "        [0.7380, 0.3805, 0.2227, 0.2106, 0.1338, 0.0851, 0.3933, 0.1153, 0.4597,\n",
      "         0.0794, 0.3759, 0.8177],\n",
      "        [1.9203, 0.4294, 1.0999, 0.3988, 0.2634, 0.5060, 0.6612, 0.1414, 0.6677,\n",
      "         0.2230, 0.8539, 1.0029],\n",
      "        [1.8506, 1.0478, 0.6981, 0.5433, 0.4500, 0.4354, 1.1867, 0.3280, 1.2086,\n",
      "         0.2462, 1.0064, 2.4540],\n",
      "        [0.7440, 0.4424, 0.8598, 0.1698, 0.2485, 0.2598, 0.8537, 0.1839, 0.4019,\n",
      "         0.0988, 0.3590, 1.3284],\n",
      "        [2.0307, 0.9145, 0.8210, 0.5454, 0.4155, 0.5989, 1.0360, 0.2834, 1.1334,\n",
      "         0.2941, 1.1143, 2.0310],\n",
      "        [3.8557, 0.3167, 3.8806, 0.6109, 0.2740, 0.7599, 1.5941, 0.1810, 0.4674,\n",
      "         0.3381, 1.0736, 1.2073],\n",
      "        [1.4084, 0.2180, 0.6763, 0.3045, 0.1064, 0.1723, 0.2464, 0.0801, 0.4303,\n",
      "         0.1450, 0.5575, 0.4708],\n",
      "        [0.6862, 0.0950, 0.4178, 0.1601, 0.0452, 0.1225, 0.1618, 0.0338, 0.1847,\n",
      "         0.0664, 0.2415, 0.2054],\n",
      "        [1.4192, 0.2745, 0.8651, 0.3218, 0.1131, 0.2160, 0.4319, 0.1142, 0.4298,\n",
      "         0.1677, 0.5583, 0.6101],\n",
      "        [0.7606, 0.2389, 0.3732, 0.2388, 0.0654, 0.1643, 0.2611, 0.0759, 0.2811,\n",
      "         0.0824, 0.2781, 0.3391]])}, 46: {'step': tensor(3820.), 'exp_avg': tensor([ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45]), 'exp_avg_sq': tensor([0.0114, 0.0049, 0.0025, 0.0122, 0.0048, 0.0109, 0.0110, 0.0083, 0.0131,\n",
      "        0.0045, 0.0043, 0.0068, 0.0018, 0.0078, 0.0108, 0.0025, 0.0007, 0.0036,\n",
      "        0.0023, 0.0101, 0.0036, 0.0043, 0.0113, 0.0096, 0.0139])}, 47: {'step': tensor(3820.), 'exp_avg': tensor([-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45]), 'exp_avg_sq': tensor([0.0059, 0.0057, 0.0057, 0.0057, 0.0057, 0.0060, 0.0060, 0.0056, 0.0059,\n",
      "        0.0057, 0.0057, 0.0057, 0.0057, 0.0056, 0.0058, 0.0057, 0.0057, 0.0057,\n",
      "        0.0057, 0.0057, 0.0057, 0.0057, 0.0059, 0.0059, 0.0063])}, 48: {'step': tensor(3820.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 49: {'step': tensor(3820.), 'exp_avg': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'exp_avg_sq': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])}, 50: {'step': tensor(3820.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 51: {'step': tensor(3820.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 52: {'step': tensor(3820.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 53: {'step': tensor(3820.), 'exp_avg': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'exp_avg_sq': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])}, 54: {'step': tensor(3820.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 55: {'step': tensor(3820.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 56: {'step': tensor(3820.), 'exp_avg': tensor([0.]), 'exp_avg_sq': tensor([0.])}, 57: {'step': tensor(3820.), 'exp_avg': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'exp_avg_sq': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])}, 60: {'step': tensor(3820.), 'exp_avg': tensor([ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45]), 'exp_avg_sq': tensor([0.0609, 0.0900, 0.0350, 0.0344, 0.0324, 0.0523, 0.0887, 0.0221, 0.0368,\n",
      "        0.0194, 0.0139, 0.1100, 0.0652, 0.0450, 0.0574, 0.0333])}, 61: {'step': tensor(3820.), 'exp_avg': tensor([[ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45]]), 'exp_avg_sq': tensor([[1.3408e-01, 2.9326e-01, 2.8929e-01, 1.9685e-02, 9.4768e-02, 5.4857e-01,\n",
      "         5.2008e-01, 7.5756e-01, 3.7470e-02, 3.2130e-01, 1.9870e+00, 1.2341e-02,\n",
      "         3.1534e-01, 4.5164e-01, 1.0126e-01, 1.2014e+00],\n",
      "        [1.2739e-01, 2.2475e-01, 3.7531e-01, 2.2350e-02, 1.4194e-01, 9.0132e-01,\n",
      "         4.9902e-01, 5.6172e-01, 8.9018e-02, 4.5418e-01, 1.7219e+00, 2.2797e-02,\n",
      "         6.1261e-01, 8.2491e-01, 1.8688e-01, 1.0771e+00],\n",
      "        [1.4462e-01, 3.2462e-01, 1.7119e-01, 1.8394e-02, 5.8890e-02, 3.3407e-01,\n",
      "         8.1136e-01, 1.0041e+00, 4.8855e-02, 2.8829e-01, 1.7202e+00, 2.0003e-02,\n",
      "         4.5169e-01, 2.4158e-01, 1.4341e-01, 1.4263e+00],\n",
      "        [6.5814e-02, 1.7001e-01, 1.8619e-01, 1.3822e-02, 5.1804e-02, 2.8522e-01,\n",
      "         3.3527e-01, 4.2963e-01, 3.0555e-02, 2.0151e-01, 1.0409e+00, 1.1270e-02,\n",
      "         2.2234e-01, 2.5592e-01, 4.0861e-02, 5.5368e-01],\n",
      "        [7.6521e-02, 1.3242e-01, 1.0979e-01, 7.4708e-03, 6.8266e-02, 3.0441e-01,\n",
      "         4.8613e-01, 4.9401e-01, 2.4965e-02, 1.3681e-01, 6.9117e-01, 2.4194e-02,\n",
      "         5.4726e-01, 2.9879e-01, 1.1378e-01, 8.5186e-01],\n",
      "        [1.8129e-01, 3.2008e-01, 3.2279e-01, 1.7841e-02, 1.3718e-01, 6.6290e-01,\n",
      "         7.8123e-01, 9.0655e-01, 7.1400e-02, 3.4715e-01, 2.0180e+00, 2.9298e-02,\n",
      "         6.6390e-01, 6.1346e-01, 2.1988e-01, 1.6868e+00],\n",
      "        [1.2622e-01, 1.2682e-01, 2.6617e-01, 1.6068e-02, 1.9715e-01, 7.7100e-01,\n",
      "         4.9359e-01, 4.2948e-01, 8.5209e-02, 3.4429e-01, 1.0806e+00, 3.1479e-02,\n",
      "         8.7042e-01, 8.3601e-01, 1.9551e-01, 1.0004e+00],\n",
      "        [8.2409e-02, 1.6183e-01, 1.1972e-01, 1.2046e-02, 4.6181e-02, 3.1848e-01,\n",
      "         5.8179e-01, 6.7377e-01, 1.3353e-02, 1.7180e-01, 9.6303e-01, 2.1713e-02,\n",
      "         5.0246e-01, 2.7539e-01, 1.3562e-01, 1.0962e+00],\n",
      "        [9.6779e-02, 2.7227e-01, 2.0304e-01, 2.0363e-02, 5.5727e-02, 3.1901e-01,\n",
      "         5.6194e-01, 7.5857e-01, 2.8985e-02, 2.7828e-01, 1.5839e+00, 1.0192e-02,\n",
      "         2.7300e-01, 2.4971e-01, 6.8580e-02, 1.0093e+00],\n",
      "        [1.8783e-02, 1.9800e-02, 4.7364e-02, 2.5541e-03, 2.6317e-02, 1.6179e-01,\n",
      "         1.2125e-01, 1.0417e-01, 1.1535e-02, 6.0736e-02, 1.5505e-01, 1.1230e-02,\n",
      "         1.9876e-01, 1.5526e-01, 4.7487e-02, 2.0987e-01],\n",
      "        [1.0772e-01, 2.3649e-01, 1.1273e-01, 1.0599e-02, 3.8079e-02, 2.1590e-01,\n",
      "         7.0114e-01, 8.6740e-01, 1.4527e-02, 1.3688e-01, 1.2896e+00, 1.7480e-02,\n",
      "         4.4261e-01, 1.7308e-01, 1.3288e-01, 1.3508e+00],\n",
      "        [3.3575e-01, 5.7962e-01, 6.6593e-01, 4.0906e-02, 2.5041e-01, 1.3989e+00,\n",
      "         1.5777e+00, 1.9005e+00, 1.1763e-01, 6.7354e-01, 4.0048e+00, 5.1597e-02,\n",
      "         1.4175e+00, 1.2954e+00, 4.0235e-01, 3.3699e+00],\n",
      "        [1.1487e-01, 2.0033e-01, 3.2658e-01, 1.7350e-02, 1.2140e-01, 6.6870e-01,\n",
      "         4.5346e-01, 5.3727e-01, 6.1696e-02, 3.0509e-01, 1.5003e+00, 1.0757e-02,\n",
      "         5.2338e-01, 6.6311e-01, 1.3388e-01, 1.0134e+00],\n",
      "        [9.2635e-02, 1.2317e-01, 2.4732e-01, 1.5083e-02, 1.3123e-01, 5.1337e-01,\n",
      "         3.1789e-01, 3.3532e-01, 4.7374e-02, 2.4954e-01, 1.0097e+00, 1.1498e-02,\n",
      "         4.5753e-01, 5.3826e-01, 1.0414e-01, 6.9333e-01],\n",
      "        [5.5805e-02, 6.0912e-02, 2.0238e-01, 1.0355e-02, 9.3681e-02, 5.2810e-01,\n",
      "         2.6870e-01, 2.4839e-01, 3.8527e-02, 1.9246e-01, 6.4416e-01, 1.5248e-02,\n",
      "         5.1988e-01, 5.5882e-01, 1.0827e-01, 5.4428e-01],\n",
      "        [5.1948e-02, 8.9274e-02, 1.2344e-01, 9.6440e-03, 4.0601e-02, 3.2694e-01,\n",
      "         3.4216e-01, 3.8000e-01, 2.1586e-02, 1.5194e-01, 6.1874e-01, 1.6919e-02,\n",
      "         3.9523e-01, 2.8712e-01, 8.7346e-02, 6.2073e-01]])}, 62: {'step': tensor(3820.), 'exp_avg': tensor([5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
      "        5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45]), 'exp_avg_sq': tensor([1.1184e-04, 3.3494e-04, 1.5240e-03, 2.3900e-03, 1.7020e-04, 8.2267e-03,\n",
      "        5.8275e-05, 6.8754e-04, 3.0756e-04, 1.9449e-04])}, 63: {'step': tensor(3820.), 'exp_avg': tensor([-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45]), 'exp_avg_sq': tensor([0.0109, 0.0118, 0.0259, 0.0181, 0.0111, 0.0651, 0.0130, 0.0183, 0.0111,\n",
      "        0.0121])}, 64: {'step': tensor(3820.), 'exp_avg': tensor([-5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45]), 'exp_avg_sq': tensor([0.3482, 0.1127, 0.0731, 0.1981, 0.1502, 0.2520, 0.2051, 0.2083, 0.1413,\n",
      "        0.0990, 0.2127, 0.4220, 0.1934, 0.1031, 0.0662, 0.2041])}, 65: {'step': tensor(3820.), 'exp_avg': tensor([[-5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45]]), 'exp_avg_sq': tensor([[0.6816, 0.1155, 0.6205, 0.6523, 0.6512, 0.2006, 0.1161, 0.6415, 0.4255,\n",
      "         0.2138, 0.0540, 0.1341, 0.3964, 0.2954, 1.1065, 1.9688],\n",
      "        [0.1974, 0.0181, 0.2526, 0.0974, 0.1031, 0.0801, 0.0947, 0.1195, 0.1400,\n",
      "         0.1732, 0.0305, 0.0929, 0.1797, 0.0470, 0.1605, 0.6007],\n",
      "        [0.1930, 0.0437, 0.7270, 0.2539, 0.1962, 0.0829, 0.0751, 0.2994, 0.3780,\n",
      "         0.2653, 0.0851, 0.0981, 0.1186, 0.1050, 0.4325, 0.4735],\n",
      "        [0.7317, 0.1145, 1.0919, 0.7890, 0.6678, 0.3304, 0.1887, 0.7412, 0.6608,\n",
      "         0.5227, 0.0944, 0.2546, 0.3328, 0.3532, 1.1750, 2.0654],\n",
      "        [0.1573, 0.0215, 0.2389, 0.1297, 0.1295, 0.0748, 0.0604, 0.1440, 0.1453,\n",
      "         0.1300, 0.0270, 0.0697, 0.1308, 0.0619, 0.2326, 0.6141],\n",
      "        [0.2434, 0.1206, 1.7319, 0.9086, 0.7573, 0.1157, 0.1199, 1.0865, 1.0006,\n",
      "         0.5579, 0.1642, 0.1299, 0.2256, 0.4071, 1.5968, 1.5998],\n",
      "        [0.3334, 0.0654, 1.2917, 0.4563, 0.4074, 0.1945, 0.1594, 0.5817, 0.7600,\n",
      "         0.5984, 0.1694, 0.2147, 0.2397, 0.2244, 0.7710, 1.2527],\n",
      "        [0.5910, 0.1188, 1.4093, 0.7851, 0.6490, 0.2162, 0.2015, 0.7779, 0.8097,\n",
      "         0.6051, 0.1571, 0.2065, 0.3331, 0.3488, 1.1614, 1.7085],\n",
      "        [0.2750, 0.0318, 0.3806, 0.1877, 0.1966, 0.1072, 0.0706, 0.2315, 0.2358,\n",
      "         0.1444, 0.0482, 0.0895, 0.1740, 0.0930, 0.3391, 0.7046],\n",
      "        [0.2784, 0.0589, 1.0227, 0.4106, 0.3237, 0.1664, 0.1131, 0.4892, 0.5808,\n",
      "         0.4230, 0.1163, 0.1593, 0.1408, 0.1875, 0.6312, 0.7884],\n",
      "        [0.4883, 0.0237, 0.3960, 0.1684, 0.1620, 0.2595, 0.0873, 0.1906, 0.2311,\n",
      "         0.1841, 0.0617, 0.1908, 0.2368, 0.0923, 0.2521, 1.0398],\n",
      "        [0.2403, 0.0217, 0.2610, 0.1600, 0.1501, 0.1260, 0.0843, 0.1394, 0.1741,\n",
      "         0.1857, 0.0484, 0.1342, 0.2389, 0.0870, 0.3084, 1.3903],\n",
      "        [0.2357, 0.0264, 0.4606, 0.1020, 0.1317, 0.1543, 0.0694, 0.1556, 0.2567,\n",
      "         0.2275, 0.0828, 0.1403, 0.1694, 0.0555, 0.1924, 0.6562],\n",
      "        [0.2230, 0.0199, 0.2099, 0.0826, 0.1155, 0.1380, 0.0474, 0.1169, 0.1267,\n",
      "         0.1071, 0.0229, 0.1023, 0.1067, 0.0432, 0.1456, 0.4530],\n",
      "        [0.1230, 0.0277, 0.3061, 0.1647, 0.1317, 0.0537, 0.0357, 0.1639, 0.1656,\n",
      "         0.1159, 0.0302, 0.0495, 0.0645, 0.0700, 0.2676, 0.3814],\n",
      "        [0.6131, 0.0844, 0.7708, 0.3768, 0.3872, 0.2866, 0.0923, 0.4376, 0.4389,\n",
      "         0.2745, 0.0854, 0.2068, 0.2562, 0.1667, 0.6687, 1.0556]])}, 66: {'step': tensor(3820.), 'exp_avg': tensor([5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
      "        5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45]), 'exp_avg_sq': tensor([0.0002, 0.0003, 0.0006, 0.0009, 0.0003, 0.0026, 0.0002, 0.0004, 0.0003,\n",
      "        0.0002])}, 67: {'step': tensor(3820.), 'exp_avg': tensor([-5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45]), 'exp_avg_sq': tensor([0.0604, 0.0585, 0.0816, 0.0577, 0.0585, 0.1992, 0.0652, 0.0825, 0.0574,\n",
      "        0.0655])}, 68: {'step': tensor(3820.), 'exp_avg': tensor([ 5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "        -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45]), 'exp_avg_sq': tensor([0.2681, 0.2697, 0.2076, 0.3638, 0.1704, 0.4098, 0.1749, 0.1832, 0.7202,\n",
      "        0.7950, 0.7721, 0.2527, 0.1475, 0.2804, 0.1835, 0.2288, 0.1294, 0.2937,\n",
      "        0.1762, 0.3081, 0.2113, 0.3645, 0.3502, 0.1658, 0.4538, 0.3667, 0.4544,\n",
      "        0.1829, 0.3603, 0.1960, 0.1888, 0.1603])}, 69: {'step': tensor(3820.), 'exp_avg': tensor([[ 5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45, -5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "          5.6052e-45]]), 'exp_avg_sq': tensor([[0.6740, 1.4856, 0.1469, 1.9391, 1.9577, 0.4904, 0.5293, 0.4310, 0.1508,\n",
      "         0.1470, 0.9193, 0.4110, 0.3944, 0.2404, 1.2112, 0.0274],\n",
      "        [0.3463, 1.0300, 0.0878, 0.6310, 0.7424, 0.6302, 0.3608, 0.2130, 0.1967,\n",
      "         0.0447, 0.3413, 0.2673, 0.2220, 0.1169, 0.6028, 0.0242],\n",
      "        [0.4335, 1.0930, 0.1040, 1.0866, 1.1621, 0.4072, 0.3749, 0.3022, 0.1691,\n",
      "         0.0827, 0.5584, 0.3271, 0.2677, 0.1492, 0.8158, 0.0165],\n",
      "        [0.1668, 0.7026, 0.0530, 0.3763, 0.4771, 0.2772, 0.2443, 0.1287, 0.1274,\n",
      "         0.0199, 0.1762, 0.1928, 0.1333, 0.0692, 0.3727, 0.0110],\n",
      "        [0.2010, 0.7352, 0.0447, 0.5394, 0.6251, 0.1333, 0.2565, 0.1597, 0.1147,\n",
      "         0.0271, 0.2468, 0.1978, 0.1523, 0.0770, 0.4314, 0.0086],\n",
      "        [0.4583, 1.4835, 0.0831, 1.2261, 1.4074, 0.2660, 0.6256, 0.3618, 0.1944,\n",
      "         0.0513, 0.5567, 0.4149, 0.3430, 0.1843, 0.9760, 0.0160],\n",
      "        [0.3822, 0.9485, 0.0878, 0.8320, 0.8511, 0.4061, 0.3100, 0.2219, 0.1852,\n",
      "         0.0723, 0.3927, 0.2352, 0.2144, 0.1225, 0.6136, 0.0231],\n",
      "        [0.3905, 0.7087, 0.0879, 0.8394, 0.7927, 0.3715, 0.2216, 0.2202, 0.1592,\n",
      "         0.0797, 0.4171, 0.2200, 0.1744, 0.1072, 0.5678, 0.0155],\n",
      "        [0.2515, 1.3144, 0.0614, 0.5506, 0.8197, 0.3810, 0.4578, 0.2310, 0.1936,\n",
      "         0.0388, 0.2924, 0.2959, 0.2609, 0.1133, 0.6370, 0.0186],\n",
      "        [0.9980, 1.1515, 0.3001, 1.6408, 1.1816, 1.9682, 0.2958, 0.3330, 0.4572,\n",
      "         0.2807, 0.8998, 0.3048, 0.3135, 0.1778, 0.9018, 0.0780],\n",
      "        [0.2314, 0.9799, 0.0873, 0.3295, 0.4598, 0.8530, 0.4272, 0.1524, 0.1819,\n",
      "         0.0626, 0.2034, 0.2586, 0.1541, 0.0651, 0.4022, 0.0303],\n",
      "        [0.2855, 0.7813, 0.0585, 0.6168, 0.6950, 0.4558, 0.3340, 0.2003, 0.0941,\n",
      "         0.0580, 0.3144, 0.2408, 0.1522, 0.1038, 0.5287, 0.0181],\n",
      "        [0.2941, 0.7738, 0.0616, 0.5403, 0.6105, 0.3907, 0.2762, 0.1968, 0.1399,\n",
      "         0.0393, 0.2912, 0.2431, 0.1618, 0.0910, 0.4941, 0.0170],\n",
      "        [0.4546, 1.2282, 0.1062, 1.1007, 1.1783, 0.4088, 0.3725, 0.2861, 0.2122,\n",
      "         0.0867, 0.5412, 0.3191, 0.2961, 0.1448, 0.8039, 0.0205],\n",
      "        [0.7759, 0.7191, 0.1960, 1.6660, 1.2908, 1.0647, 0.1775, 0.3140, 0.1986,\n",
      "         0.2441, 0.8688, 0.2461, 0.2303, 0.1655, 0.8411, 0.0482],\n",
      "        [0.2804, 0.5421, 0.0795, 0.5293, 0.5388, 0.5046, 0.1551, 0.1462, 0.1124,\n",
      "         0.0540, 0.3168, 0.1518, 0.1421, 0.0831, 0.4140, 0.0174],\n",
      "        [0.1801, 0.3733, 0.0544, 0.3411, 0.3282, 0.2948, 0.1099, 0.0980, 0.0953,\n",
      "         0.0479, 0.1892, 0.1118, 0.0853, 0.0454, 0.2633, 0.0127],\n",
      "        [0.2719, 1.0468, 0.1224, 0.5249, 0.6475, 0.7867, 0.3891, 0.2108, 0.2220,\n",
      "         0.0540, 0.2863, 0.3783, 0.1857, 0.0936, 0.5712, 0.0315],\n",
      "        [0.4708, 2.0911, 0.0656, 1.3409, 1.7835, 0.3303, 0.8924, 0.5261, 0.1824,\n",
      "         0.0482, 0.6590, 0.6326, 0.4282, 0.2443, 1.3680, 0.0215],\n",
      "        [0.5456, 2.0351, 0.1435, 1.2946, 1.5497, 0.8430, 0.7903, 0.5092, 0.3270,\n",
      "         0.0625, 0.6498, 0.6782, 0.4097, 0.2222, 1.2875, 0.0277],\n",
      "        [0.1843, 0.8553, 0.0452, 0.4089, 0.6100, 0.2286, 0.2991, 0.1939, 0.1163,\n",
      "         0.0287, 0.2458, 0.2594, 0.1718, 0.0866, 0.5228, 0.0114],\n",
      "        [0.3344, 1.3659, 0.0832, 0.8180, 1.1104, 0.3079, 0.4144, 0.3051, 0.1797,\n",
      "         0.0539, 0.4695, 0.3682, 0.2944, 0.1504, 0.8439, 0.0161],\n",
      "        [1.2881, 0.8753, 0.3603, 2.5945, 1.8868, 2.2429, 0.2304, 0.4616, 0.3077,\n",
      "         0.3873, 1.3985, 0.3477, 0.3275, 0.2596, 1.2345, 0.0854],\n",
      "        [0.2480, 1.1663, 0.0430, 0.7579, 1.0098, 0.1426, 0.4416, 0.2625, 0.1007,\n",
      "         0.0302, 0.3732, 0.3036, 0.2497, 0.1385, 0.7375, 0.0126],\n",
      "        [0.3307, 0.8973, 0.0717, 0.5568, 0.6236, 0.4340, 0.3129, 0.1976, 0.1962,\n",
      "         0.0728, 0.2979, 0.2540, 0.1790, 0.0913, 0.5181, 0.0186],\n",
      "        [0.4792, 1.9117, 0.0842, 1.3467, 1.7542, 0.3165, 0.7207, 0.4682, 0.1660,\n",
      "         0.0560, 0.6860, 0.5171, 0.4148, 0.2513, 1.2899, 0.0147],\n",
      "        [0.4619, 0.5991, 0.1437, 0.8041, 0.5766, 0.8534, 0.1754, 0.1638, 0.2286,\n",
      "         0.1419, 0.4143, 0.1799, 0.1387, 0.0822, 0.4394, 0.0352],\n",
      "        [0.1924, 0.7145, 0.0381, 0.3671, 0.5125, 0.2283, 0.2301, 0.1590, 0.1015,\n",
      "         0.0453, 0.2263, 0.2137, 0.1386, 0.0718, 0.4272, 0.0134],\n",
      "        [0.3742, 1.5611, 0.0816, 1.2686, 1.5037, 0.2193, 0.6504, 0.3338, 0.1430,\n",
      "         0.0494, 0.5350, 0.3876, 0.3325, 0.1813, 0.9351, 0.0186],\n",
      "        [0.2300, 0.8404, 0.0604, 0.4802, 0.6083, 0.2334, 0.2364, 0.1609, 0.1667,\n",
      "         0.0363, 0.2493, 0.2151, 0.1803, 0.0850, 0.4717, 0.0155],\n",
      "        [0.1799, 0.8882, 0.0384, 0.4459, 0.6427, 0.1646, 0.2697, 0.1614, 0.1179,\n",
      "         0.0165, 0.2313, 0.1862, 0.1949, 0.0985, 0.4836, 0.0084],\n",
      "        [0.2680, 0.9954, 0.0609, 0.5518, 0.7305, 0.3054, 0.3277, 0.2118, 0.1665,\n",
      "         0.0372, 0.2938, 0.2762, 0.1985, 0.1129, 0.5835, 0.0165]])}, 70: {'step': tensor(3820.), 'exp_avg': tensor([5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
      "        5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45]), 'exp_avg_sq': tensor([1.7633, 1.7559, 1.7543, 1.7469, 1.7589, 1.7801, 1.7603, 1.7671, 1.7582,\n",
      "        1.7664])}, 71: {'step': tensor(3820.), 'exp_avg': tensor([5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45,\n",
      "        5.6052e-45, 5.6052e-45, 5.6052e-45, 5.6052e-45]), 'exp_avg_sq': tensor([0.1045, 0.1045, 0.1045, 0.1045, 0.1045, 0.1045, 0.1045, 0.1045, 0.1045,\n",
      "        0.1045])}, 72: {'step': tensor(3820.), 'exp_avg': tensor([[-5.6052e-45, -5.6052e-45, -5.6052e-45,  ...,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45,  5.6052e-45,  ...,  5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45,  ...,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45],\n",
      "        ...,\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45,  ...,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45,  ...,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45,  ...,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45]]), 'exp_avg_sq': tensor([[0.0164, 0.0416, 1.0504,  ..., 0.1013, 0.1035, 0.1869],\n",
      "        [0.0836, 0.0741, 1.6653,  ..., 1.0598, 0.2063, 0.2580],\n",
      "        [0.2068, 0.0857, 2.5315,  ..., 0.7683, 0.3373, 0.2714],\n",
      "        ...,\n",
      "        [0.0672, 0.1409, 2.9772,  ..., 0.3556, 0.1606, 0.5085],\n",
      "        [0.0180, 0.0371, 0.7767,  ..., 0.1037, 0.0372, 0.1192],\n",
      "        [0.0317, 0.0353, 0.8392,  ..., 0.1327, 0.0804, 0.1519]])}, 73: {'step': tensor(3820.), 'exp_avg': tensor([ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45]), 'exp_avg_sq': tensor([0.0025, 0.0042, 0.0038, 0.0049, 0.0143, 0.0044, 0.0086, 0.0003, 0.0033,\n",
      "        0.0018, 0.0032, 0.0005, 0.0027, 0.0010, 0.0020, 0.0124, 0.0040, 0.0014,\n",
      "        0.0015, 0.0010, 0.0020, 0.0009, 0.0120, 0.0004, 0.0045, 0.0035, 0.0024,\n",
      "        0.0008, 0.0018, 0.0012, 0.0050, 0.0008, 0.0049, 0.0016, 0.0066, 0.0084,\n",
      "        0.0007, 0.0019, 0.0023, 0.0029, 0.0022, 0.0005, 0.0018, 0.0034, 0.0006,\n",
      "        0.0025, 0.0003, 0.0014, 0.0049, 0.0175, 0.0009, 0.0032, 0.0013, 0.0009,\n",
      "        0.0137, 0.0037, 0.0013, 0.0015, 0.0018, 0.0042, 0.0048, 0.0066, 0.0016,\n",
      "        0.0013])}}\n",
      "param_groups \t [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]}]\n"
     ]
    }
   ],
   "source": [
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'{model_name}_state_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, model_name+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2.704826593399048,\n",
       "  5.198240756988525,\n",
       "  13.315263748168945,\n",
       "  2.823438882827759,\n",
       "  3.2965333461761475,\n",
       "  16.09800910949707,\n",
       "  9.872518539428711,\n",
       "  1.0003350973129272,\n",
       "  0.7661793828010559,\n",
       "  6.772861480712891,\n",
       "  5.174842834472656,\n",
       "  9.828278541564941,\n",
       "  15.874943733215332,\n",
       "  53.55030059814453,\n",
       "  1.0800198316574097,\n",
       "  10.528260231018066,\n",
       "  53.853294372558594,\n",
       "  4.662607669830322,\n",
       "  4.270350933074951,\n",
       "  0.867901086807251,\n",
       "  1.5554147958755493,\n",
       "  2.229698896408081,\n",
       "  2.005354166030884,\n",
       "  3.3499433994293213,\n",
       "  15.229602813720703,\n",
       "  14.188955307006836,\n",
       "  16.699132919311523,\n",
       "  22.360225677490234,\n",
       "  22.466737747192383,\n",
       "  31.5380802154541,\n",
       "  1.7847511768341064,\n",
       "  2.5743556022644043,\n",
       "  53.521114349365234,\n",
       "  2.719676971435547,\n",
       "  2.6633896827697754,\n",
       "  18.13672637939453,\n",
       "  3.7198853492736816,\n",
       "  0.4871591627597809,\n",
       "  8.857869148254395,\n",
       "  45.62668991088867,\n",
       "  3.154035806655884,\n",
       "  4.935939311981201,\n",
       "  5.192224979400635,\n",
       "  9.803498268127441,\n",
       "  17.924827575683594,\n",
       "  9.848934173583984,\n",
       "  3.585824489593506,\n",
       "  86.6318130493164,\n",
       "  17.3171443939209,\n",
       "  2.581406354904175,\n",
       "  2.7631795406341553,\n",
       "  16.747119903564453,\n",
       "  3.547388792037964,\n",
       "  0.8788779377937317,\n",
       "  0.5995727181434631,\n",
       "  5.787005424499512,\n",
       "  2.118100166320801,\n",
       "  1.919079065322876,\n",
       "  11.341294288635254,\n",
       "  2.263032913208008,\n",
       "  0.6949743628501892,\n",
       "  4.012384414672852,\n",
       "  0.35861092805862427,\n",
       "  0.8392153978347778,\n",
       "  1.9523204565048218,\n",
       "  1.5161124467849731,\n",
       "  22.870882034301758,\n",
       "  9.66711711883545,\n",
       "  0.4888782203197479,\n",
       "  5.462646484375,\n",
       "  6.092201232910156,\n",
       "  1.016375184059143,\n",
       "  5.394891738891602,\n",
       "  0.7768035531044006,\n",
       "  17.16086196899414,\n",
       "  0.9088374376296997,\n",
       "  1.3090628385543823,\n",
       "  4.259058475494385,\n",
       "  0.8640763759613037,\n",
       "  1.96882963180542,\n",
       "  2.9054343700408936,\n",
       "  10.186197280883789,\n",
       "  8.666426658630371,\n",
       "  2.021890640258789,\n",
       "  37.51947021484375,\n",
       "  15.764997482299805,\n",
       "  2.097499132156372,\n",
       "  6.830977916717529,\n",
       "  3.6878957748413086,\n",
       "  19.14760971069336,\n",
       "  1.3249049186706543,\n",
       "  4.118762016296387,\n",
       "  7.989927768707275,\n",
       "  10.915167808532715,\n",
       "  29.659832000732422,\n",
       "  35.79417419433594,\n",
       "  16.774860382080078,\n",
       "  1.543757438659668,\n",
       "  110.32952880859375,\n",
       "  12.100777626037598,\n",
       "  0.5776466727256775,\n",
       "  10.142349243164062,\n",
       "  3.035236358642578,\n",
       "  13.713397979736328,\n",
       "  3.816195487976074,\n",
       "  9.482223510742188,\n",
       "  3.255971908569336,\n",
       "  24.57541275024414,\n",
       "  10.109694480895996,\n",
       "  12.866683959960938,\n",
       "  11.060444831848145,\n",
       "  20.535160064697266,\n",
       "  5.805521488189697,\n",
       "  9.43932056427002,\n",
       "  10.969657897949219,\n",
       "  14.198473930358887,\n",
       "  5.688391208648682,\n",
       "  20.013891220092773,\n",
       "  8.729480743408203,\n",
       "  1.674066185951233,\n",
       "  36.130615234375,\n",
       "  6.818122863769531,\n",
       "  3.175856351852417,\n",
       "  22.70490074157715,\n",
       "  5.9099812507629395,\n",
       "  0.4547455608844757,\n",
       "  1.45606529712677,\n",
       "  25.354225158691406,\n",
       "  9.80893325805664,\n",
       "  18.04686164855957,\n",
       "  8.206413269042969,\n",
       "  13.117918014526367,\n",
       "  20.550674438476562,\n",
       "  13.554835319519043,\n",
       "  1.045912265777588,\n",
       "  45.946327209472656,\n",
       "  0.7859334349632263,\n",
       "  42.173946380615234,\n",
       "  7.0339250564575195,\n",
       "  11.827227592468262,\n",
       "  4.80800724029541,\n",
       "  4.400030612945557,\n",
       "  3.5169429779052734,\n",
       "  42.460262298583984,\n",
       "  2.992161750793457,\n",
       "  61.76719665527344,\n",
       "  13.275609970092773,\n",
       "  41.199893951416016,\n",
       "  1.9388231039047241,\n",
       "  1.7367182970046997,\n",
       "  5.621242523193359,\n",
       "  7.279980659484863,\n",
       "  5.48419189453125,\n",
       "  49.14460372924805,\n",
       "  4.1668596267700195,\n",
       "  21.214513778686523,\n",
       "  3.4210243225097656,\n",
       "  24.54138946533203,\n",
       "  1.8284838199615479,\n",
       "  13.43665599822998,\n",
       "  1.6863292455673218,\n",
       "  0.40624549984931946,\n",
       "  16.733816146850586,\n",
       "  2.2687463760375977,\n",
       "  1.8972417116165161,\n",
       "  25.289302825927734,\n",
       "  4.335816860198975,\n",
       "  0.8518805503845215,\n",
       "  2.106466054916382,\n",
       "  1.0783138275146484,\n",
       "  1.1433900594711304,\n",
       "  18.154211044311523,\n",
       "  14.370222091674805,\n",
       "  6.093416213989258,\n",
       "  45.29472351074219,\n",
       "  0.9568530917167664,\n",
       "  5.3788676261901855,\n",
       "  5.844310283660889,\n",
       "  3.7407867908477783,\n",
       "  1.1640912294387817,\n",
       "  5.3128886222839355,\n",
       "  0.44115859270095825,\n",
       "  8.20824909210205,\n",
       "  4.9891581535339355,\n",
       "  2.888672113418579,\n",
       "  4.037245273590088,\n",
       "  0.322966068983078,\n",
       "  0.23082919418811798,\n",
       "  4.936459541320801,\n",
       "  39.93437957763672,\n",
       "  0.22667832672595978,\n",
       "  29.57611083984375,\n",
       "  62.06330108642578,\n",
       "  8.148748397827148],\n",
       " [27.181671142578125,\n",
       "  46.7053108215332,\n",
       "  0.5775931477546692,\n",
       "  18.145309448242188,\n",
       "  19.823272705078125,\n",
       "  1.222131609916687,\n",
       "  1.5900646448135376,\n",
       "  1.0873397588729858,\n",
       "  0.6155239343643188,\n",
       "  25.250816345214844,\n",
       "  0.21160487830638885,\n",
       "  23.210893630981445,\n",
       "  3.53255558013916,\n",
       "  0.49781733751296997,\n",
       "  6.42727518081665,\n",
       "  1.8676376342773438,\n",
       "  5.443838596343994,\n",
       "  35.25676727294922,\n",
       "  0.8407770991325378,\n",
       "  36.5833625793457,\n",
       "  1.2122560739517212,\n",
       "  25.440689086914062,\n",
       "  55.801753997802734,\n",
       "  3.1841704845428467,\n",
       "  1.1490204334259033,\n",
       "  1.726120114326477,\n",
       "  0.6069270968437195,\n",
       "  0.8175901174545288,\n",
       "  0.3303978741168976,\n",
       "  5.444737911224365,\n",
       "  0.7473751902580261,\n",
       "  20.440824508666992,\n",
       "  2.3824214935302734,\n",
       "  2.538160562515259,\n",
       "  1.1115511655807495,\n",
       "  2.5566086769104004,\n",
       "  4.197916507720947,\n",
       "  8.023086547851562,\n",
       "  2.8924777507781982,\n",
       "  25.886518478393555,\n",
       "  9.207832336425781,\n",
       "  3.2628908157348633,\n",
       "  4.177851676940918,\n",
       "  0.26979491114616394,\n",
       "  32.592506408691406,\n",
       "  5.443792343139648,\n",
       "  20.047550201416016,\n",
       "  1.6963348388671875,\n",
       "  1.475588083267212,\n",
       "  0.7018646001815796,\n",
       "  25.359506607055664,\n",
       "  29.34391975402832,\n",
       "  2.70133113861084,\n",
       "  0.5495991706848145,\n",
       "  12.431327819824219,\n",
       "  48.082149505615234,\n",
       "  0.529217541217804,\n",
       "  0.9486518502235413,\n",
       "  0.1961567997932434,\n",
       "  0.8649198412895203,\n",
       "  7.758583068847656,\n",
       "  3.615036725997925,\n",
       "  4.44827938079834,\n",
       "  9.91455078125,\n",
       "  9.520406723022461,\n",
       "  30.620840072631836,\n",
       "  32.2344856262207,\n",
       "  0.5394095778465271,\n",
       "  1.0339170694351196,\n",
       "  53.23109817504883,\n",
       "  9.778298377990723,\n",
       "  12.965744018554688,\n",
       "  12.68330192565918,\n",
       "  8.50987434387207,\n",
       "  0.4265194833278656,\n",
       "  24.38487434387207,\n",
       "  0.7621620297431946,\n",
       "  36.87624740600586,\n",
       "  0.7346929907798767,\n",
       "  5.7444353103637695,\n",
       "  16.96875,\n",
       "  4.063361167907715,\n",
       "  0.3896864354610443,\n",
       "  14.440710067749023,\n",
       "  2.7547202110290527,\n",
       "  0.3997734785079956,\n",
       "  6.123706817626953,\n",
       "  1.8189308643341064,\n",
       "  21.993806838989258,\n",
       "  5.953886032104492,\n",
       "  11.222068786621094,\n",
       "  0.7353714108467102,\n",
       "  0.11078941076993942,\n",
       "  15.505916595458984,\n",
       "  20.05398178100586,\n",
       "  58.98081588745117,\n",
       "  13.300873756408691,\n",
       "  29.598037719726562,\n",
       "  6.715970039367676,\n",
       "  3.714550018310547,\n",
       "  3.7526729106903076,\n",
       "  1.6419223546981812,\n",
       "  52.779850006103516,\n",
       "  0.3401187062263489,\n",
       "  7.360928058624268,\n",
       "  28.85964012145996,\n",
       "  6.290478229522705,\n",
       "  37.85420227050781,\n",
       "  9.8411865234375,\n",
       "  11.932409286499023,\n",
       "  0.6800362467765808,\n",
       "  49.429298400878906,\n",
       "  1.2473052740097046,\n",
       "  8.519445419311523,\n",
       "  5.326987266540527,\n",
       "  0.9189756512641907,\n",
       "  7.105715274810791,\n",
       "  1.892228364944458,\n",
       "  12.138153076171875,\n",
       "  6.111774921417236,\n",
       "  3.589543104171753,\n",
       "  1.2883989810943604,\n",
       "  1.7023115158081055,\n",
       "  3.8498706817626953,\n",
       "  2.908352851867676,\n",
       "  0.9184759855270386,\n",
       "  1.0212591886520386,\n",
       "  7.122376441955566,\n",
       "  6.732410907745361,\n",
       "  5.144501686096191,\n",
       "  4.854119777679443,\n",
       "  6.543369293212891,\n",
       "  0.3381232023239136,\n",
       "  9.557618141174316,\n",
       "  2.9639039039611816,\n",
       "  8.982439994812012,\n",
       "  53.80054473876953,\n",
       "  0.6904776692390442,\n",
       "  4.799500465393066,\n",
       "  1.9255938529968262,\n",
       "  0.45198413729667664,\n",
       "  0.38417744636535645,\n",
       "  25.38662338256836,\n",
       "  13.64249038696289,\n",
       "  10.207216262817383,\n",
       "  1.3610576391220093,\n",
       "  21.111278533935547,\n",
       "  24.605722427368164,\n",
       "  1.0504916906356812,\n",
       "  4.160204887390137,\n",
       "  18.85479736328125,\n",
       "  1.2725862264633179,\n",
       "  0.4366109073162079,\n",
       "  9.999670028686523,\n",
       "  46.153873443603516,\n",
       "  7.210074424743652,\n",
       "  2.3893697261810303,\n",
       "  7.822183132171631,\n",
       "  45.8588981628418,\n",
       "  3.8593175411224365,\n",
       "  1.6076730489730835,\n",
       "  1.328518271446228,\n",
       "  6.223233222961426,\n",
       "  1.3316060304641724,\n",
       "  5.251704692840576,\n",
       "  4.568398952484131,\n",
       "  5.108389854431152,\n",
       "  4.268512725830078,\n",
       "  1.5620540380477905,\n",
       "  30.523239135742188,\n",
       "  0.5821083188056946,\n",
       "  28.851144790649414,\n",
       "  3.05397367477417,\n",
       "  13.137351989746094,\n",
       "  86.47338104248047,\n",
       "  11.000306129455566,\n",
       "  0.7675381898880005,\n",
       "  0.8615167737007141,\n",
       "  1.1916416883468628,\n",
       "  13.696884155273438,\n",
       "  1.2448304891586304,\n",
       "  16.48255157470703,\n",
       "  0.9224311113357544,\n",
       "  0.48528560996055603,\n",
       "  64.15789794921875,\n",
       "  21.540653228759766,\n",
       "  6.004839897155762,\n",
       "  1.528403639793396],\n",
       " [369.4215087890625,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1090.693359375,\n",
       "  0.16680756211280823,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  164.62606811523438,\n",
       "  196.48118591308594,\n",
       "  0.746796727180481,\n",
       "  0.0,\n",
       "  1.2641557455062866,\n",
       "  0.0,\n",
       "  0.027335483580827713,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.5911548137664795,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.18943478167057037,\n",
       "  318.8017578125,\n",
       "  0.022387951612472534,\n",
       "  0.0,\n",
       "  269.3727111816406,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  6.239467144012451,\n",
       "  0.00872468389570713,\n",
       "  0.12391109764575958,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  20.654966354370117,\n",
       "  1.7440382242202759,\n",
       "  14.81767749786377,\n",
       "  0.0,\n",
       "  621.52001953125,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.3534511625766754,\n",
       "  669.17138671875,\n",
       "  0.7347842454910278,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  323.6144714355469,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1556.918212890625,\n",
       "  5.069479465484619,\n",
       "  0.0,\n",
       "  0.6601237058639526,\n",
       "  1.4897452592849731,\n",
       "  0.18417902290821075,\n",
       "  0.33422502875328064,\n",
       "  0.054580677300691605,\n",
       "  0.0,\n",
       "  14.822598457336426,\n",
       "  0.27928391098976135,\n",
       "  0.0,\n",
       "  208.91375732421875,\n",
       "  0.0,\n",
       "  2.837961435317993,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  3.2211248874664307,\n",
       "  0.6177758574485779,\n",
       "  0.0,\n",
       "  3.2681310176849365,\n",
       "  8.811262130737305,\n",
       "  0.13150343298912048,\n",
       "  32.1849250793457,\n",
       "  4.183220386505127,\n",
       "  335.0560607910156,\n",
       "  0.0,\n",
       "  42.39211654663086,\n",
       "  0.0,\n",
       "  5.323235034942627,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  8.727231979370117,\n",
       "  0.03639485687017441,\n",
       "  531.1358642578125,\n",
       "  0.0,\n",
       "  14.817427635192871,\n",
       "  200.9522705078125,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.438779354095459,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0886812210083008,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.2463073432445526,\n",
       "  321.5522155761719,\n",
       "  430.532958984375,\n",
       "  0.0,\n",
       "  3.6485891342163086,\n",
       "  0.15102963149547577,\n",
       "  77.26891326904297,\n",
       "  1155.94677734375,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.14003604650497437,\n",
       "  0.007335471920669079,\n",
       "  0.08017150312662125,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.4499712586402893,\n",
       "  0.0,\n",
       "  0.01923861913383007,\n",
       "  0.3740415871143341,\n",
       "  30.09784507751465,\n",
       "  0.046519555151462555,\n",
       "  6.534254550933838,\n",
       "  0.0,\n",
       "  0.20569008588790894,\n",
       "  9.893606185913086,\n",
       "  0.012925470247864723,\n",
       "  49.14921569824219,\n",
       "  0.0,\n",
       "  45.319091796875,\n",
       "  0.0,\n",
       "  468.81805419921875,\n",
       "  519.5311889648438,\n",
       "  0.14548057317733765,\n",
       "  0.5344939827919006,\n",
       "  0.0,\n",
       "  1416.775146484375,\n",
       "  47.807586669921875,\n",
       "  0.0,\n",
       "  0.13062375783920288,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  84.05532836914062,\n",
       "  0.0,\n",
       "  80.4331283569336,\n",
       "  36.20896530151367,\n",
       "  0.0909595862030983,\n",
       "  0.0,\n",
       "  297.3111572265625,\n",
       "  0.29044386744499207,\n",
       "  679.9290161132812,\n",
       "  0.2698877453804016,\n",
       "  0.024907981976866722,\n",
       "  0.0,\n",
       "  0.004155474714934826,\n",
       "  0.0,\n",
       "  16.499284744262695,\n",
       "  0.0,\n",
       "  0.009237494319677353,\n",
       "  143.96932983398438,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  8.255437850952148,\n",
       "  0.07592713832855225,\n",
       "  0.0,\n",
       "  104.26712799072266,\n",
       "  3.794236898422241,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.07990852743387222,\n",
       "  18.74992561340332,\n",
       "  0.0,\n",
       "  1.6542521715164185,\n",
       "  241.86387634277344,\n",
       "  17.724409103393555,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  62.96738815307617,\n",
       "  0.0,\n",
       "  0.27038389444351196,\n",
       "  0.006136915180832148,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  120.216796875,\n",
       "  201.08119201660156,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1739.36865234375,\n",
       "  88.45665740966797,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  438.0220947265625,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  22.55211067199707,\n",
       "  6.89896297454834,\n",
       "  7.041296005249023,\n",
       "  1.3479567766189575,\n",
       "  0.0,\n",
       "  1392.8565673828125,\n",
       "  0.08919113874435425,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.05784056335687637,\n",
       "  0.0,\n",
       "  27.091596603393555,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  416.43927001953125,\n",
       "  19.785079956054688,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  716.4700927734375,\n",
       "  48.42450714111328,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  71.19123077392578,\n",
       "  0.0,\n",
       "  0.23122519254684448,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1221.6280517578125,\n",
       "  0.0,\n",
       "  0.7778826951980591,\n",
       "  36.29043197631836,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  14.188423156738281,\n",
       "  0.0,\n",
       "  0.4222561717033386,\n",
       "  25.245635986328125,\n",
       "  0.0,\n",
       "  1.7902697324752808,\n",
       "  73.66743469238281,\n",
       "  0.0,\n",
       "  18.676931381225586,\n",
       "  0.14865238964557648,\n",
       "  0.0,\n",
       "  6.442417621612549,\n",
       "  0.8299885392189026,\n",
       "  0.0,\n",
       "  1.448937177658081,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  7.410762786865234,\n",
       "  0.0,\n",
       "  4.229274272918701,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.42179790139198303,\n",
       "  0.0,\n",
       "  0.022912221029400826,\n",
       "  0.5214875340461731,\n",
       "  25.36416244506836,\n",
       "  22.662694931030273,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  13.232925415039062,\n",
       "  11.78125286102295,\n",
       "  21.407855987548828,\n",
       "  0.0,\n",
       "  0.057163625955581665,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  45.674072265625,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  4.392370700836182,\n",
       "  0.0,\n",
       "  40.342079162597656,\n",
       "  1447.2496337890625,\n",
       "  0.0,\n",
       "  0.23837828636169434,\n",
       "  11.517620086669922,\n",
       "  1.8539519309997559,\n",
       "  0.10214409232139587,\n",
       "  0.0,\n",
       "  0.07379524409770966,\n",
       "  0.0,\n",
       "  322.24041748046875,\n",
       "  0.0,\n",
       "  93.05884552001953,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  52.09365463256836,\n",
       "  0.9262378215789795,\n",
       "  0.0,\n",
       "  222.84317016601562,\n",
       "  0.0,\n",
       "  0.17627356946468353,\n",
       "  302.72088623046875,\n",
       "  0.0,\n",
       "  0.5517711043357849,\n",
       "  8.653677940368652,\n",
       "  0.0,\n",
       "  177.7516326904297,\n",
       "  0.0,\n",
       "  0.8097395300865173,\n",
       "  0.0,\n",
       "  0.09531355649232864,\n",
       "  49.996742248535156,\n",
       "  0.0,\n",
       "  0.010969500057399273,\n",
       "  1065.09033203125,\n",
       "  25.992618560791016,\n",
       "  0.0,\n",
       "  2.854539632797241,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  30.593305587768555,\n",
       "  1051.51904296875,\n",
       "  7.44715690612793,\n",
       "  0.0,\n",
       "  1.2923084497451782,\n",
       "  0.8824797868728638,\n",
       "  0.0,\n",
       "  19.364330291748047,\n",
       "  0.8865857124328613,\n",
       "  13.790212631225586,\n",
       "  0.0,\n",
       "  0.0009307044092565775,\n",
       "  10.435123443603516,\n",
       "  13.047834396362305,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  9.110109329223633,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.15615229308605194,\n",
       "  1.220004677772522,\n",
       "  0.0,\n",
       "  465.8341979980469,\n",
       "  0.1694256216287613,\n",
       "  0.0,\n",
       "  416.1944274902344,\n",
       "  4.663385391235352,\n",
       "  86.2950439453125,\n",
       "  0.0,\n",
       "  3738.822509765625,\n",
       "  0.0,\n",
       "  60.50342559814453,\n",
       "  0.22918786108493805,\n",
       "  0.2958122491836548,\n",
       "  0.29455557465553284,\n",
       "  0.3711045980453491,\n",
       "  0.710006594657898,\n",
       "  93.80224609375,\n",
       "  0.7748044729232788,\n",
       "  0.0,\n",
       "  135.83729553222656,\n",
       "  0.42544129490852356,\n",
       "  0.11775003373622894,\n",
       "  2058.11865234375,\n",
       "  231.99996948242188,\n",
       "  18.02908706665039,\n",
       "  0.0,\n",
       "  0.299012154340744,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.1680129766464233,\n",
       "  0.0],\n",
       " [1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_16884\\3520072505.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tr_results = np.asarray(train_results)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "tr_results = np.asarray(train_results)\n",
    "tr_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [117], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tr_results[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mshape\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "tr_results[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(123)\n",
    "\n",
    "w = 0.8    # bar width\n",
    "x = [1, 2] # x-coordinates of your bars\n",
    "colors = [(0, 0, 1, 1), (1, 0, 0, 1)]    # corresponding colors\n",
    "y = [np.random.random(30) * 2 + 5,       # data series\n",
    "    np.random.random(10) * 3 + 8]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(x,\n",
    "       height=[np.mean(yi) for yi in y],\n",
    "       yerr=[np.std(yi) for yi in y],    # error bars\n",
    "       capsize=12, # error bar cap width in points\n",
    "       width=w,    # bar width\n",
    "       tick_label=[\"control\", \"test\"],\n",
    "       color=(0,0,0,0),  # face color transparent\n",
    "       edgecolor=colors,\n",
    "       #ecolor=colors,    # error bar colors; setting this raises an error for whatever reason.\n",
    "       )\n",
    "\n",
    "for i in range(len(x)):\n",
    "    # distribute scatter randomly across whole width of bar\n",
    "    ax.scatter(x[i] + np.random.random(y[i].size) * w - w / 2, y[i], color=colors[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save(f'{model_name}_training_loss.npy', tr_loss, allow_pickle=True)\n",
    "np.save(f'{model_name}_training_accuracy.npy', tr_acc, allow_pickle=True)\n",
    "\n",
    "np.save(f'{model_name}_validation_loss.npy', v_loss, allow_pickle=True)\n",
    "np.save(f'{model_name}_validation_accuracy.npy', v_acc, allow_pickle=True)\n",
    "\n",
    "np.save(f'{model_name}_test_loss.npy', tst_loss, allow_pickle=True)\n",
    "np.save(f'{model_name}_test_accuracy.npy', tst_acc, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "training_loss = np.load(f'{model_name}_training_loss.npy', allow_pickle=True)\n",
    "training_accuracy = np.load(f'{model_name}_training_accuracy.npy', allow_pickle=True)\n",
    "\n",
    "validation_loss = np.load(f'{model_name}_validation_loss.npy', allow_pickle=True)\n",
    "validation_accuracy = np.load(f'{model_name}_validation_accuracy.npy', allow_pickle=True)\n",
    "\n",
    "test_loss = np.load(f'{model_name}_test_loss.npy', allow_pickle=True)\n",
    "test_accuracy = np.load(f'{model_name}_test_accuracy.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a sequence of integers to represent the epoch numbers\n",
    "epochs = range(1, num_epochs+1)\n",
    " \n",
    "# Plot and label the training and validation loss values\n",
    "plt.plot(epochs, training_loss, label='Training Loss')\n",
    "plt.plot(epochs, validation_loss, label='Validation Loss')\n",
    " \n",
    "# Add in a title and axes labels\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    " \n",
    "# Set the tick locations\n",
    "plt.xticks(np.arange(0, num_epochs+1, num_epochs/10))\n",
    " \n",
    "# Display the plot\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(f'{model_name}_Training and Validation Loss.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a sequence of integers to represent the epoch numbers\n",
    "epochs = range(1, num_epochs+1)\n",
    " \n",
    "# Plot and label the training and validation loss values\n",
    "plt.plot(epochs, training_accuracy, label='Training Accuracy')\n",
    "plt.plot(epochs, validation_accuracy, label='Validation Accuracy')\n",
    "plt.plot(epochs, test_accuracy, label='Test Accuracy')\n",
    " \n",
    "# Add in a title and axes labels\n",
    "plt.title('Accuracy vs. Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    " \n",
    "# Set the tick locations\n",
    "plt.xticks(np.arange(0, num_epochs+1, num_epochs/10))\n",
    "plt.ylim(0,1)\n",
    " \n",
    "# Display the plot\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(f'{model_name}_Accuracy vs. Epochs.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_fraction = [0,0]\n",
    "\n",
    "train_fraction = [0,0]\n",
    "val_fraction = [0,0]\n",
    "test_fraction = [0,0]\n",
    "\n",
    "for grph in train_dataset: \n",
    "    if grph.y == 1: \n",
    "        train_fraction[1] +=1\n",
    "        dataset_fraction[1] +=1 \n",
    "    else: \n",
    "        train_fraction[0] +=1\n",
    "        dataset_fraction[0] +=1 \n",
    "\n",
    "for grph in val_dataset: \n",
    "    if grph.y == 1:\n",
    "         val_fraction[1] +=1\n",
    "         dataset_fraction[1] +=1  \n",
    "    else:\n",
    "         val_fraction[0] +=1\n",
    "         dataset_fraction[0] +=1\n",
    "\n",
    "for grph in test_dataset: \n",
    "    if grph.y == 1:\n",
    "         test_fraction[1] +=1\n",
    "         dataset_fraction[1] +=1 \n",
    "    else:\n",
    "         test_fraction[0] +=1\n",
    "         dataset_fraction[0] +=1\n",
    "\n",
    "print(f'Overall dataset percentage of label 1 = {dataset_fraction[1]/len(dataset)})')\n",
    "print(f'Training dataset percentage of label 1 = {train_fraction} = {train_fraction[1]/len(train_dataset)}')\n",
    "print(f'Validation dataset percentage of label 1 = {val_fraction} = {val_fraction[1]/len(val_dataset)}')\n",
    "print(f'Test dataset percentage of label 1 = {test_fraction} = {test_fraction[1]/len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Graph: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, pos0, adj0 = torch.load(f'{model_name}_img0_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Embedding GNN\n",
    "print(x0[0].shape)\n",
    "x0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pos0[0].shape)\n",
    "pos0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adj0[0].shape)\n",
    "adj0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index, _ = dense_to_sparse(adj0[0])\n",
    "visualize_points(pos0[0].cpu(), edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph After 1st Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_emb, x1_pool, pos1, adj1, s1= torch.load(f'{model_name}_img1_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Embedding GNN (adj0 @ x_0 @ w_gnn_emb)\n",
    "print(x1_emb[0].shape)\n",
    "x1_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Pooling GNN: adj_0 @ x_0 @ w_gnn_pool\n",
    "print(s1[0].shape)\n",
    "s1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Coordinate Matrix (pos_out = softmax(s).t() @ pos_in)\n",
    "print(pos1[0].shape)\n",
    "pos1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Feature Matrix (x_out = softmax(s).t() @ x_in)\n",
    "print(x1_pool[0].shape)\n",
    "x1_pool[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Adjacency Matrix = softmax(adj_out = softmax(s.t()) @ adj_in @ softmax(s))\n",
    "print(adj1[0].shape)\n",
    "adj1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index, _ = dense_to_sparse(adj1[0])\n",
    "visualize_points(pos1[0].cpu(), edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph after 2nd reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_emb, x2_pool, pos2, adj2, s2 = torch.load(f'{model_name}_img2_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Embedding GNN (adj1 @ x1_pool @ w_gnn_emb)\n",
    "print(x2_emb[0].shape)\n",
    "x2_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Pooling GNN: adj1 @ x1_pool @ w_gnn_pool), dim=1\n",
    "print(s2[0].shape)\n",
    "s2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Coordinate Matrix (pos_out = softmax(s.t()) @ pos_in)\n",
    "print(pos2[0].shape)\n",
    "pos2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Feature Matrix (x_out = softmax(s2).t() @ x2_emb)\n",
    "print(x2_pool[0].shape)\n",
    "x2_pool[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Adjacency Matrix (adj = softmax(s).T @ adj @ softmax(s)\n",
    "print(adj2[0].shape)\n",
    "adj2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index, _ = dense_to_sparse(adj2[0])\n",
    "visualize_points(pos2[0].cpu(), edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph after 3rd reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3_emb, x3_pool, pos3, adj3, s3 = torch.load(f'{model_name}_img3_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Embedding GNN (adj_0 @ x_0 @ w_gnn_emb)\n",
    "print(x3_emb[0].shape)\n",
    "x3_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Pooling GNN: torch.softmax(adj_0 @ x_0 @ w_gnn_pool), dim=1)\n",
    "print(s3[0].shape)\n",
    "s3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Coordinate Matrix (pos_out = softmax(s.t()) @ pos_in)\n",
    "print(pos3[0].shape)\n",
    "pos3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Feature Matrix (x_out = softmax(s.t()) @ x_0)\n",
    "print(x3_pool[0].shape)\n",
    "x3_pool[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Adjacency Matrix (adj = softmax(s.t()) @ adj @ softmax(s)\n",
    "print(adj3[0].shape)\n",
    "adj3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index, _ = dense_to_sparse(adj3[0])\n",
    "visualize_points(pos3[0].cpu(), edge_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pyg_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5295f743bc4e47f7cb4c7d5e484c5cf6bb52e824ff35c3fecf2642e2b62ae0ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
