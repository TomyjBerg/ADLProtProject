{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize features? \n",
    "## Invert h-bond and charge? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_siamese_071222'\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import DenseDataLoader #To make use of this data loader, all graph attributes in the dataset need to have the same shape. In particular, this data loader should only be used when working with dense adjacency matrices.\n",
    "from torch_geometric.nn import DenseGCNConv, dense_diff_pool\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dir_1 = 'C:/Users/david/pyproj/pyg/adl/patch_label_1'\n",
    "#data_dir_0 = 'C:/Users/david/pyproj/pyg/adl/patch_label_0'\n",
    "data_dir_1 = 'C:/Users/thoma/OneDrive - ZHAW/ProteinSurfaces-DESKTOP-AQ00763/patch_label_1'\n",
    "data_dir_0 = 'C:/Users/thoma/OneDrive - ZHAW/ProteinSurfaces-DESKTOP-AQ00763/patch_label_0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "572"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from c_PatchDataset import PatchDataset\n",
    "dataset = PatchDataset(data_dir_label_0 = data_dir_0,  data_dir_label_1=data_dir_1,  neg_pos_ratio=1)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: PatchDataset(572):\n",
      "====================\n",
      "Number of graphs pairs: 572\n",
      "\n",
      "PairData(adj1=[100, 100], x1=[100, 3], adj2=[100, 100], x2=[100, 3], y=0)\n",
      "=============================================================\n",
      "Number of nodes in each: None\n",
      "Number of node features: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thoma\\Desktop\\ZHAW MLS\\David prod\\ADLProtProject\\.venv\\lib\\site-packages\\torch_geometric\\data\\storage.py:271: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'x1', 'y', 'adj1', 'adj2', 'x2'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs pairs: {len(dataset)}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "print()\n",
    "print(data)\n",
    "print('=============================================================')\n",
    "\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes in each: {data.num_nodes}')\n",
    "print(f'Number of node features: {data.num_node_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.7718e-02,  0.0000e+00,  9.9962e-01],\n",
       "        [-3.3849e-01, -1.9016e-01, -9.2156e-01],\n",
       "        [-3.1892e-01, -4.8161e-02, -9.4656e-01],\n",
       "        [-3.2381e-01,  0.0000e+00, -9.4612e-01],\n",
       "        [ 2.6426e-02,  0.0000e+00, -9.9965e-01],\n",
       "        [ 6.7311e-03,  0.0000e+00,  9.9998e-01],\n",
       "        [ 5.4087e-01,  0.0000e+00, -8.4111e-01],\n",
       "        [ 1.3966e-01,  0.0000e+00,  9.9020e-01],\n",
       "        [ 1.0029e-01,  0.0000e+00, -9.9496e-01],\n",
       "        [-1.7477e-01,  0.0000e+00,  9.8461e-01],\n",
       "        [ 2.4914e-01,  0.0000e+00,  9.6847e-01],\n",
       "        [-4.0950e-02,  0.0000e+00,  9.9916e-01],\n",
       "        [-1.0908e-02,  0.0000e+00,  9.9994e-01],\n",
       "        [ 9.7845e-02,  0.0000e+00,  9.9520e-01],\n",
       "        [-8.8174e-01, -6.6108e-02, -4.6708e-01],\n",
       "        [-3.8549e-01, -4.1804e-01, -8.2258e-01],\n",
       "        [-3.2489e-02,  0.0000e+00,  9.9947e-01],\n",
       "        [ 3.5636e-02,  0.0000e+00,  9.9936e-01],\n",
       "        [ 1.9670e-04,  0.0000e+00,  1.0000e+00],\n",
       "        [ 7.3794e-01,  2.1169e-02, -6.7453e-01],\n",
       "        [ 5.1134e-01,  0.0000e+00, -8.5938e-01],\n",
       "        [-3.2126e-01, -1.9182e-03, -9.4699e-01],\n",
       "        [ 4.0707e-02,  0.0000e+00,  9.9917e-01],\n",
       "        [ 7.9814e-02,  0.0000e+00, -9.9681e-01],\n",
       "        [-2.7049e-02,  0.0000e+00,  9.9963e-01],\n",
       "        [-5.7440e-01, -3.4777e-01,  7.4103e-01],\n",
       "        [ 4.9834e-02,  0.0000e+00,  9.9876e-01],\n",
       "        [-6.4583e-02,  0.0000e+00,  9.9791e-01],\n",
       "        [-2.1888e-01,  0.0000e+00,  9.7575e-01],\n",
       "        [ 5.4765e-02,  0.0000e+00,  9.9850e-01],\n",
       "        [-2.3802e-01,  0.0000e+00, -9.7126e-01],\n",
       "        [ 6.2945e-01,  0.0000e+00, -7.7704e-01],\n",
       "        [-1.0807e-01,  0.0000e+00, -9.9414e-01],\n",
       "        [-8.0854e-02,  0.0000e+00,  9.9673e-01],\n",
       "        [ 1.7404e-01,  0.0000e+00,  9.8474e-01],\n",
       "        [ 2.6798e-01, -1.0479e-01, -9.5771e-01],\n",
       "        [ 9.6014e-02,  9.1765e-02, -9.9114e-01],\n",
       "        [ 6.6024e-01,  0.0000e+00, -7.5105e-01],\n",
       "        [-8.2131e-01,  0.0000e+00, -5.7048e-01],\n",
       "        [-3.5083e-01,  0.0000e+00, -9.3644e-01],\n",
       "        [ 1.0267e-01,  0.0000e+00,  9.9472e-01],\n",
       "        [-1.7226e-01,  0.0000e+00, -9.8505e-01],\n",
       "        [-1.4885e-01,  0.0000e+00,  9.8886e-01],\n",
       "        [ 7.0637e-02,  0.0000e+00,  9.9750e-01],\n",
       "        [-1.0291e-01,  0.0000e+00, -9.9469e-01],\n",
       "        [ 7.3684e-01,  4.8166e-01, -4.7441e-01],\n",
       "        [ 1.0766e-01,  0.0000e+00,  9.9419e-01],\n",
       "        [-1.7007e-01,  0.0000e+00, -9.8543e-01],\n",
       "        [-1.1975e-01,  0.0000e+00, -9.9280e-01],\n",
       "        [-4.3727e-01, -1.8338e-01, -8.8043e-01],\n",
       "        [ 5.6835e-02,  0.0000e+00,  9.9838e-01],\n",
       "        [-1.1713e-01,  0.0000e+00,  9.9312e-01],\n",
       "        [ 3.1017e-03, -1.2360e-01, -9.9233e-01],\n",
       "        [-8.0433e-02,  0.0000e+00,  9.9676e-01],\n",
       "        [-2.8331e-01, -1.3877e-01, -9.4894e-01],\n",
       "        [-6.6566e-03,  0.0000e+00,  9.9998e-01],\n",
       "        [-1.2184e-01,  0.0000e+00,  9.9255e-01],\n",
       "        [-2.1632e-01, -6.4762e-02, -9.7417e-01],\n",
       "        [ 4.6117e-02,  0.0000e+00,  9.9894e-01],\n",
       "        [ 4.7574e-02,  0.0000e+00, -9.9887e-01],\n",
       "        [-5.4953e-01, -6.3280e-01, -5.4551e-01],\n",
       "        [ 4.5621e-02,  0.0000e+00,  9.9896e-01],\n",
       "        [ 1.5732e-01,  0.0000e+00,  9.8755e-01],\n",
       "        [-4.4458e-01,  0.0000e+00, -8.9574e-01],\n",
       "        [ 4.9918e-01,  0.0000e+00, -8.6650e-01],\n",
       "        [ 3.3064e-01,  0.0000e+00, -9.4376e-01],\n",
       "        [ 2.1417e-01,  0.0000e+00,  9.7680e-01],\n",
       "        [ 3.1443e-02,  0.0000e+00, -9.9951e-01],\n",
       "        [ 7.7314e-02,  0.0000e+00,  9.9701e-01],\n",
       "        [ 8.9848e-02,  0.0000e+00, -9.9596e-01],\n",
       "        [-2.4183e-01,  0.0000e+00,  9.7032e-01],\n",
       "        [-6.0206e-01,  0.0000e+00, -7.9845e-01],\n",
       "        [ 1.1329e-01,  0.0000e+00, -9.9356e-01],\n",
       "        [ 4.0751e-03,  0.0000e+00, -9.9999e-01],\n",
       "        [ 2.5434e-01,  0.0000e+00, -9.6711e-01],\n",
       "        [ 6.3834e-03,  0.0000e+00,  9.9998e-01],\n",
       "        [-3.9265e-01, -9.1128e-02, -9.1516e-01],\n",
       "        [ 6.8445e-02,  0.0000e+00,  9.9765e-01],\n",
       "        [-4.2403e-01, -2.0996e-01, -8.8097e-01],\n",
       "        [ 7.6678e-03,  0.0000e+00,  9.9997e-01],\n",
       "        [-1.5694e-02,  0.0000e+00,  9.9988e-01],\n",
       "        [-2.5693e-01,  0.0000e+00,  9.6643e-01],\n",
       "        [-1.1340e-01,  0.0000e+00,  9.9355e-01],\n",
       "        [ 7.8977e-02,  0.0000e+00,  9.9688e-01],\n",
       "        [ 2.6468e-01,  0.0000e+00,  9.6434e-01],\n",
       "        [-2.4598e-03,  0.0000e+00,  1.0000e+00],\n",
       "        [-1.1763e-01,  0.0000e+00, -9.9306e-01],\n",
       "        [ 2.6503e-01,  0.0000e+00, -9.6424e-01],\n",
       "        [-1.9812e-02, -6.7332e-03, -9.9978e-01],\n",
       "        [-2.1855e-01,  0.0000e+00,  9.7583e-01],\n",
       "        [-1.7555e-02,  0.0000e+00,  9.9985e-01],\n",
       "        [-1.8040e-01,  0.0000e+00, -9.8359e-01],\n",
       "        [-2.8311e-02,  0.0000e+00,  9.9960e-01],\n",
       "        [-6.6700e-02,  0.0000e+00,  9.9777e-01],\n",
       "        [ 1.7291e-02,  0.0000e+00,  9.9985e-01],\n",
       "        [-1.7192e-01, -5.7730e-02, -9.8342e-01],\n",
       "        [ 2.4492e-01,  0.0000e+00, -9.6954e-01],\n",
       "        [-1.7886e-01, -1.0868e-01, -9.7785e-01],\n",
       "        [-5.7254e-01, -5.4099e-01, -6.1605e-01],\n",
       "        [-4.2768e-01,  0.0000e+00, -9.0393e-01]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does not work we do not have pos\n",
    "#visualize_points(data.pos, data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs pairs: 382\n",
      "Number of validation graphs: 95\n",
      "Number of test graphs: 95\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader \n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "n_train = math.ceil((4/6) * len(dataset))\n",
    "n_val = math.ceil((len(dataset) - n_train)/2)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "print(f'Number of training graphs pairs: {len(train_dataset)}')\n",
    "print(f'Number of validation graphs: {len(val_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')\n",
    "\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size= batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset = val_dataset, batch_size= batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size= batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PairDataBatch(adj1=[100, 100], x1=[100, 3], adj2=[100, 100], x2=[100, 3], y=[1])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "databatch = next(iter(train_loader))\n",
    "databatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_nodes, in_channels, hidden_channels, out_channels,\n",
    "                 normalize=False, lin=True):\n",
    "        super(GNN, self).__init__()\n",
    "\n",
    "        # Each instance of this GNN will have 3 convolutional layers and three batch norm layers        \n",
    "        self.conv1 = DenseGCNConv(in_channels, hidden_channels, normalize)\n",
    "        self.bns1 = torch.nn.BatchNorm1d(in_nodes)\n",
    "        \n",
    "        self.conv2 = DenseGCNConv(hidden_channels, hidden_channels, normalize)\n",
    "        self.bns2 = torch.nn.BatchNorm1d(in_nodes)\n",
    "        \n",
    "        self.conv3 = DenseGCNConv(hidden_channels, out_channels, normalize)\n",
    "        self.bns3 = torch.nn.BatchNorm1d(in_nodes)\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        \n",
    "        #Step 1\n",
    "        x = self.conv1(x, adj, mask)\n",
    "        x = self.bns1(x)\n",
    "        \n",
    "        #Step 2\n",
    "        x = self.conv2(x, adj, mask)\n",
    "        x = self.bns2(x)\n",
    "\n",
    "        #Step 3\n",
    "        x = self.conv3(x, adj, mask)\n",
    "        if x.shape[2] != 1: \n",
    "            x = self.bns3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class DiffPool(torch.nn.Module):\n",
    "    def __init__(self, num_nodes):\n",
    "        super(DiffPool, self).__init__()\n",
    "\n",
    "        #Hierarchical Step #1\n",
    "        in_nodes = num_nodes\n",
    "        out_nodes = 25 # Number of clusters / nodes in the next layer\n",
    "        self.gnn1_pool = GNN(in_nodes, dataset.num_features, 16, out_nodes) # PoolGNN --> Cluster Assignment Matrix to reduce to num_nodes\n",
    "        self.gnn1_embed = GNN(in_nodes, dataset.num_features, 8, 8) # EmbGNN --> Convolutions to create new node embedding\n",
    "\n",
    "        # Hierarchical Step #2\n",
    "        in_nodes = out_nodes\n",
    "        out_nodes = 10\n",
    "        self.gnn2_pool = GNN(in_nodes, 8, 8, out_nodes)\n",
    "        self.gnn2_embed = GNN(in_nodes, 8, 12, 16, lin=False)\n",
    "\n",
    "        # Hierarchical Step #3\n",
    "        in_nodes = out_nodes\n",
    "        out_nodes = 1\n",
    "        self.gnn3_pool = GNN(in_nodes, 16, 16, out_nodes)\n",
    "        self.gnn3_embed = GNN(in_nodes, 16, 16, 32, lin=False)\n",
    "\n",
    "        # Final Classifier\n",
    "        self.lin1 = torch.nn.Linear(32, 64) \n",
    "        #self.lin2 = torch.nn.Linear(64, 2)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, batch, mask=None):\n",
    "        \n",
    "        #if batch == 0: print('Shape of input data batch:')\n",
    "        #if batch == 0: print(f'Feature Matrix: {tuple(x.shape)}')\n",
    "        #if batch == 0: print(f'Adjacency Matrix: {tuple(adj.shape)}')\n",
    "       \n",
    "\n",
    "\n",
    "        #Hierarchical Step #1\n",
    "        #if batch == 0: print('Hierarchical Step #1')\n",
    "        x1 = self.gnn1_embed(x, adj, mask) # node feature embedding\n",
    "        s = self.gnn1_pool(x, adj, mask) # cluster assignment matrix\n",
    "\n",
    "        #if batch == 0: print(f'X1 = {tuple(x1.shape)}    S1: {tuple(s.shape)}')\n",
    "\n",
    "        x, adj, l1, e1 = dense_diff_pool(x1, adj, s, mask) # does the necessary matrix multiplications\n",
    "        adj = torch.softmax(adj, dim=-1)\n",
    "\n",
    "        #if batch == 0: print(f'---matmul---> New feature matrix (softmax(s_0.t()) @ z_0) = {tuple(x.shape)}')\n",
    "        #if batch == 0: print(f'---matmul---> New adjacency matrix (s_0.t() @ adj_0 @ s_0) = {tuple(adj.shape)}')\n",
    "   \n",
    "\n",
    "\n",
    "        # Hierarchical Step #2\n",
    "        #if batch == 0: print('Hierarchical Step #2')\n",
    "        x2 = self.gnn2_embed(x, adj)\n",
    "        s = self.gnn2_pool(x, adj)\n",
    "\n",
    "        #if batch == 0: print(f'X2: {tuple(x2.shape)}    S2: {tuple(s.shape)}')\n",
    "        \n",
    "        x, adj, l2, e2 = dense_diff_pool(x2, adj, s)\n",
    "        adj = torch.softmax(adj, dim=-1)\n",
    "\n",
    "        #if batch == 0: print(f'---matmul---> New feature matrix (softmax(s_0.t()) @ z_0) = {tuple(x.shape)}')\n",
    "        #if batch == 0: print(f'---matmul---> New adjacency matrix (s_0.t() @ adj_0 @ s_0) = {tuple(adj.shape)}')\n",
    "      \n",
    "        \n",
    "\n",
    "        # Hierarchical Step #3\n",
    "        #if batch == 0: print('Hierarchical Step #3')\n",
    "        x3 = self.gnn3_embed(x, adj)\n",
    "        s = self.gnn3_pool(x, adj)\n",
    "        \n",
    "        #if batch == 0: print(f'X3: {tuple(x3.shape)}    S3: {tuple(s.shape)}')\n",
    "\n",
    "        x, adj, l3, e3 = dense_diff_pool(x3, adj, s)\n",
    "        adj = torch.softmax(adj, dim=-1)\n",
    "\n",
    "        #if batch == 0: print(f'---matmul---> New feature matrix (softmax(s_0.t()) @ z_0) = {tuple(x.shape)}')\n",
    "        #if batch == 0: print(f'---matmul---> New adjacency matrix (s_0.t() @ adj_0 @ s_0) = {tuple(adj.shape)}')\n",
    "     \n",
    "        \n",
    "\n",
    "        # Final Classification\n",
    "        #if batch == 0: print('Final Output')\n",
    "        x = x.mean(dim=1) # Pool the features of all nodes (global mean pool)  dim = 1 refers to columns\n",
    "        #if batch == 0: print(f'---X Output after mean= {tuple(x.shape)}')\n",
    "\n",
    "        x = F.relu(self.lin1(x)) # Fully connected layer + relu\n",
    "        #if batch == 0: print(f'------ X Output 3 after lin= {tuple(x.shape)}')\n",
    "\n",
    "        \n",
    "        return x, l1 + l2 + l3, e1 + e2 + e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An attempt of a contrastive loss function\n",
    "#   pairs with label 1 --> should get small euclid dist = small loss\n",
    "#   pairs with label 0 --> should get large euclid dist = small loss\n",
    "\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, margin=1):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, x0, x1, y,epochs):\n",
    "        # euclidian distance\n",
    "        #print(x0)\n",
    "        #print(x1)\n",
    "        #print(y)\n",
    "        diff = x0 - x1\n",
    "        #print(diff)\n",
    "        pow = torch.pow(diff, 2)\n",
    "        #print(pow)\n",
    "        dist_sq = torch.sum(pow, 1)\n",
    "        #print(dist_sq) # sum of squared distance = 0.5 = 9\n",
    "        dist = torch.sqrt(dist_sq)\n",
    "        #print(dist) # euclidean distance = 0.7 = 3\n",
    "\n",
    "        mdist = self.margin- dist #negative euclidean distance - margin = 0.3 = -2\n",
    "        #print(mdist)\n",
    "        dist_marg = torch.clamp(mdist, min=0.0) # only distances <margin will be still positive here = 0.3 = 0\n",
    "        #print(dist)\n",
    "        loss =  y * torch.pow(dist, 2) + (1-y) * torch.pow(dist_marg,2)\n",
    "\n",
    "        # What happens to a pair with squared euclid dist (dist_sq) of 0.5\n",
    "        # if label = 0 --> 0 + squared clampled euclid distance --> loss = 0.3^2\n",
    "        # if label = 1 --> squared euclidean distance + 0 --> loss = 0.5\n",
    "\n",
    "        # What happens to a pair with squared euclid dist (dist_sq) of 9\n",
    "        # if label = 0 --> 0 + squared clampled euclid distance --> loss = 0\n",
    "        # if label = 1 --> squared euclidean distance + 0 --> loss = 9\n",
    "\n",
    "        #print(loss)\n",
    "        #loss = torch.sum(loss) / 2.0 \n",
    "        #print(loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch: 001, Train Loss: 257.896\n",
      "Epoch: 002, Train Loss: 88.244\n",
      "Epoch: 003, Train Loss: 30.920\n",
      "Epoch: 004, Train Loss: 10.519\n",
      "Epoch: 005, Train Loss: 3.862\n",
      "Epoch: 006, Train Loss: 1.726\n",
      "Epoch: 007, Train Loss: 1.026\n",
      "Epoch: 008, Train Loss: 0.754\n",
      "Epoch: 009, Train Loss: 0.591\n",
      "Epoch: 010, Train Loss: 0.497\n",
      "Epoch: 011, Train Loss: 0.425\n",
      "Epoch: 012, Train Loss: 0.392\n",
      "Epoch: 013, Train Loss: 0.361\n",
      "Epoch: 014, Train Loss: 0.350\n",
      "Epoch: 015, Train Loss: 0.341\n",
      "Epoch: 016, Train Loss: 0.312\n",
      "Epoch: 017, Train Loss: 0.322\n",
      "Epoch: 018, Train Loss: 0.344\n",
      "Epoch: 019, Train Loss: 0.324\n",
      "Epoch: 020, Train Loss: 0.362\n",
      "Epoch: 021, Train Loss: 0.316\n",
      "Epoch: 022, Train Loss: 0.312\n",
      "Epoch: 023, Train Loss: 0.303\n",
      "Epoch: 024, Train Loss: 0.309\n",
      "Epoch: 025, Train Loss: 0.354\n",
      "Epoch: 026, Train Loss: 0.327\n",
      "Epoch: 027, Train Loss: 0.324\n",
      "Epoch: 028, Train Loss: 0.285\n",
      "Epoch: 029, Train Loss: 0.306\n",
      "Epoch: 030, Train Loss: 0.313\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = DiffPool(num_nodes = 100).to(device)\n",
    "criterion = ContrastiveLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "num_epochs = 30\n",
    "\n",
    "def train(epoch):\n",
    "    batch = 0\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output1, _, _ = model(data.x1, data.adj1, batch)\n",
    "        output2, _, _ = model(data.x2, data.adj2, batch = None)\n",
    "        \n",
    "        #Contrastive Loss\n",
    "        loss_contrastive = criterion(output1,output2,data.y,epoch)\n",
    "        loss_contrastive.backward()\n",
    "        loss_all += data.y.size(0) * loss_contrastive.item()\n",
    "        optimizer.step()\n",
    "        batch +=1\n",
    "\n",
    "    return loss_all / len(train_dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader,epochs):\n",
    "    model.eval()\n",
    "\n",
    "    distances_lab1 = []\n",
    "    distances_lab0 = []\n",
    "    labels = []\n",
    "    losses = []\n",
    "    \n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output1, _, _ = model(data.x1, data.adj1, batch=None)\n",
    "        output2, _, _ = model(data.x2, data.adj2, batch=None)\n",
    "\n",
    "        test_loss_contrastive = criterion(output1, output2, data.y,epochs)\n",
    "        #diff = output1 -output2\n",
    "        #print(diff)\n",
    "        #pow = torch.pow(diff, 2)\n",
    "        #print(pow)\n",
    "        #dist_sq = torch.sum(pow, 1)\n",
    "        #print(dist_sq) # sum of squared distance = 0.5 = 9\n",
    "        #euclidean_distance = torch.sqrt(dist_sq)\n",
    "        #print(dist) # euclidean distance = 0.7 = 3\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        label = data.y\n",
    "\n",
    "        if int(label) == 1: \n",
    "            distances_lab1.append(float(euclidean_distance))\n",
    "            labels.append(int(label))\n",
    "            losses.append(float(test_loss_contrastive))\n",
    "        else:\n",
    "            distances_lab0.append(float(euclidean_distance))\n",
    "            labels.append(int(label))\n",
    "            losses.append(float(test_loss_contrastive))\n",
    "\n",
    "    return  distances_lab0, distances_lab1, losses, labels\n",
    "\n",
    "\n",
    "\n",
    "train_distances_lab0 = []\n",
    "train_distances_lab1 = []\n",
    "train_losses = []\n",
    "train_labels = []\n",
    "\n",
    "validation_distances_lab0 = []\n",
    "validation_distances_lab1 = []\n",
    "validation_losses = []\n",
    "validation_labels = []\n",
    "\n",
    "test_distances_lab0 = []\n",
    "test_distances_lab1 = []\n",
    "test_losses = []\n",
    "test_labels = []\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    train_loss = train(epoch)\n",
    "\n",
    "    train_results = test(train_loader,epoch)\n",
    "    train_distances_lab0.append(train_results[0])\n",
    "    train_distances_lab1.append(train_results[1])\n",
    "    train_losses.append(train_results[2])\n",
    "    train_labels.append(train_results[3])\n",
    "\n",
    "\n",
    "    validation_results = test(val_loader,epoch)\n",
    "    validation_distances_lab0.append(validation_results[0])\n",
    "    validation_distances_lab1.append(validation_results[1])\n",
    "    validation_losses.append(validation_results[2])\n",
    "    validation_labels.append(validation_results[3])\n",
    "\n",
    "    test_results = test(test_loader,epoch)\n",
    "    test_distances_lab0.append(test_results[0])\n",
    "    test_distances_lab1.append(test_results[1])\n",
    "    test_losses.append(test_results[2])\n",
    "    test_labels.append(test_results[3])\n",
    "\n",
    "\n",
    "    print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.3f}')\n",
    "    #Train Acc: {train_acc:.3f}, f'Val Acc: {val_acc:.3f}, Test Acc: {test_acc:.3f}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compare_euclid_distances(distances_lab0, distances_lab1):\n",
    "\n",
    "    w = 0.8    # bar width\n",
    "    x = [1, 2] # x-coordinates of your bars\n",
    "    colors = [(0, 0, 1, 1), (1, 0, 0, 1)]    # corresponding colors\n",
    "\n",
    "    # Epoch 0\n",
    "    y = [distances_lab0, distances_lab1]\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(x,\n",
    "        height=[np.mean(yi) for yi in y],\n",
    "        yerr=[np.std(yi) for yi in y],    # error bars\n",
    "        capsize=12, # error bar cap width in points\n",
    "        width=w,    # bar width\n",
    "        tick_label=[\"Label 0\", \"Label 1\"],\n",
    "        color=(0,0,0,0),  # face color transparent\n",
    "        edgecolor=colors,\n",
    "        )\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        # distribute scatter randomly across whole width of bar\n",
    "        ax.scatter(x[i] + np.random.random(len(y[i])) * w - w / 2, y[i], color=colors[i])\n",
    "\n",
    "    plt.ylabel = 'Euclidean Distance'\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_euclid_distances(train_distances_lab0[2], train_distances_lab1[2])\n",
    "compare_euclid_distances(train_distances_lab0[6], train_distances_lab1[6])\n",
    "\n",
    "compare_euclid_distances(train_distances_lab0[8], train_distances_lab1[8])\n",
    "compare_euclid_distances(train_distances_lab0[24], train_distances_lab1[24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "gnn1_pool.conv1.bias \t torch.Size([16])\n",
      "gnn1_pool.conv1.lin.weight \t torch.Size([16, 3])\n",
      "gnn1_pool.bns1.weight \t torch.Size([100])\n",
      "gnn1_pool.bns1.bias \t torch.Size([100])\n",
      "gnn1_pool.bns1.running_mean \t torch.Size([100])\n",
      "gnn1_pool.bns1.running_var \t torch.Size([100])\n",
      "gnn1_pool.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn1_pool.conv2.bias \t torch.Size([16])\n",
      "gnn1_pool.conv2.lin.weight \t torch.Size([16, 16])\n",
      "gnn1_pool.bns2.weight \t torch.Size([100])\n",
      "gnn1_pool.bns2.bias \t torch.Size([100])\n",
      "gnn1_pool.bns2.running_mean \t torch.Size([100])\n",
      "gnn1_pool.bns2.running_var \t torch.Size([100])\n",
      "gnn1_pool.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn1_pool.conv3.bias \t torch.Size([25])\n",
      "gnn1_pool.conv3.lin.weight \t torch.Size([25, 16])\n",
      "gnn1_pool.bns3.weight \t torch.Size([100])\n",
      "gnn1_pool.bns3.bias \t torch.Size([100])\n",
      "gnn1_pool.bns3.running_mean \t torch.Size([100])\n",
      "gnn1_pool.bns3.running_var \t torch.Size([100])\n",
      "gnn1_pool.bns3.num_batches_tracked \t torch.Size([])\n",
      "gnn1_embed.conv1.bias \t torch.Size([8])\n",
      "gnn1_embed.conv1.lin.weight \t torch.Size([8, 3])\n",
      "gnn1_embed.bns1.weight \t torch.Size([100])\n",
      "gnn1_embed.bns1.bias \t torch.Size([100])\n",
      "gnn1_embed.bns1.running_mean \t torch.Size([100])\n",
      "gnn1_embed.bns1.running_var \t torch.Size([100])\n",
      "gnn1_embed.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn1_embed.conv2.bias \t torch.Size([8])\n",
      "gnn1_embed.conv2.lin.weight \t torch.Size([8, 8])\n",
      "gnn1_embed.bns2.weight \t torch.Size([100])\n",
      "gnn1_embed.bns2.bias \t torch.Size([100])\n",
      "gnn1_embed.bns2.running_mean \t torch.Size([100])\n",
      "gnn1_embed.bns2.running_var \t torch.Size([100])\n",
      "gnn1_embed.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn1_embed.conv3.bias \t torch.Size([8])\n",
      "gnn1_embed.conv3.lin.weight \t torch.Size([8, 8])\n",
      "gnn1_embed.bns3.weight \t torch.Size([100])\n",
      "gnn1_embed.bns3.bias \t torch.Size([100])\n",
      "gnn1_embed.bns3.running_mean \t torch.Size([100])\n",
      "gnn1_embed.bns3.running_var \t torch.Size([100])\n",
      "gnn1_embed.bns3.num_batches_tracked \t torch.Size([])\n",
      "gnn2_pool.conv1.bias \t torch.Size([8])\n",
      "gnn2_pool.conv1.lin.weight \t torch.Size([8, 8])\n",
      "gnn2_pool.bns1.weight \t torch.Size([25])\n",
      "gnn2_pool.bns1.bias \t torch.Size([25])\n",
      "gnn2_pool.bns1.running_mean \t torch.Size([25])\n",
      "gnn2_pool.bns1.running_var \t torch.Size([25])\n",
      "gnn2_pool.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn2_pool.conv2.bias \t torch.Size([8])\n",
      "gnn2_pool.conv2.lin.weight \t torch.Size([8, 8])\n",
      "gnn2_pool.bns2.weight \t torch.Size([25])\n",
      "gnn2_pool.bns2.bias \t torch.Size([25])\n",
      "gnn2_pool.bns2.running_mean \t torch.Size([25])\n",
      "gnn2_pool.bns2.running_var \t torch.Size([25])\n",
      "gnn2_pool.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn2_pool.conv3.bias \t torch.Size([10])\n",
      "gnn2_pool.conv3.lin.weight \t torch.Size([10, 8])\n",
      "gnn2_pool.bns3.weight \t torch.Size([25])\n",
      "gnn2_pool.bns3.bias \t torch.Size([25])\n",
      "gnn2_pool.bns3.running_mean \t torch.Size([25])\n",
      "gnn2_pool.bns3.running_var \t torch.Size([25])\n",
      "gnn2_pool.bns3.num_batches_tracked \t torch.Size([])\n",
      "gnn2_embed.conv1.bias \t torch.Size([12])\n",
      "gnn2_embed.conv1.lin.weight \t torch.Size([12, 8])\n",
      "gnn2_embed.bns1.weight \t torch.Size([25])\n",
      "gnn2_embed.bns1.bias \t torch.Size([25])\n",
      "gnn2_embed.bns1.running_mean \t torch.Size([25])\n",
      "gnn2_embed.bns1.running_var \t torch.Size([25])\n",
      "gnn2_embed.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn2_embed.conv2.bias \t torch.Size([12])\n",
      "gnn2_embed.conv2.lin.weight \t torch.Size([12, 12])\n",
      "gnn2_embed.bns2.weight \t torch.Size([25])\n",
      "gnn2_embed.bns2.bias \t torch.Size([25])\n",
      "gnn2_embed.bns2.running_mean \t torch.Size([25])\n",
      "gnn2_embed.bns2.running_var \t torch.Size([25])\n",
      "gnn2_embed.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn2_embed.conv3.bias \t torch.Size([16])\n",
      "gnn2_embed.conv3.lin.weight \t torch.Size([16, 12])\n",
      "gnn2_embed.bns3.weight \t torch.Size([25])\n",
      "gnn2_embed.bns3.bias \t torch.Size([25])\n",
      "gnn2_embed.bns3.running_mean \t torch.Size([25])\n",
      "gnn2_embed.bns3.running_var \t torch.Size([25])\n",
      "gnn2_embed.bns3.num_batches_tracked \t torch.Size([])\n",
      "gnn3_pool.conv1.bias \t torch.Size([16])\n",
      "gnn3_pool.conv1.lin.weight \t torch.Size([16, 16])\n",
      "gnn3_pool.bns1.weight \t torch.Size([10])\n",
      "gnn3_pool.bns1.bias \t torch.Size([10])\n",
      "gnn3_pool.bns1.running_mean \t torch.Size([10])\n",
      "gnn3_pool.bns1.running_var \t torch.Size([10])\n",
      "gnn3_pool.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn3_pool.conv2.bias \t torch.Size([16])\n",
      "gnn3_pool.conv2.lin.weight \t torch.Size([16, 16])\n",
      "gnn3_pool.bns2.weight \t torch.Size([10])\n",
      "gnn3_pool.bns2.bias \t torch.Size([10])\n",
      "gnn3_pool.bns2.running_mean \t torch.Size([10])\n",
      "gnn3_pool.bns2.running_var \t torch.Size([10])\n",
      "gnn3_pool.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn3_pool.conv3.bias \t torch.Size([1])\n",
      "gnn3_pool.conv3.lin.weight \t torch.Size([1, 16])\n",
      "gnn3_pool.bns3.weight \t torch.Size([10])\n",
      "gnn3_pool.bns3.bias \t torch.Size([10])\n",
      "gnn3_pool.bns3.running_mean \t torch.Size([10])\n",
      "gnn3_pool.bns3.running_var \t torch.Size([10])\n",
      "gnn3_pool.bns3.num_batches_tracked \t torch.Size([])\n",
      "gnn3_embed.conv1.bias \t torch.Size([16])\n",
      "gnn3_embed.conv1.lin.weight \t torch.Size([16, 16])\n",
      "gnn3_embed.bns1.weight \t torch.Size([10])\n",
      "gnn3_embed.bns1.bias \t torch.Size([10])\n",
      "gnn3_embed.bns1.running_mean \t torch.Size([10])\n",
      "gnn3_embed.bns1.running_var \t torch.Size([10])\n",
      "gnn3_embed.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn3_embed.conv2.bias \t torch.Size([16])\n",
      "gnn3_embed.conv2.lin.weight \t torch.Size([16, 16])\n",
      "gnn3_embed.bns2.weight \t torch.Size([10])\n",
      "gnn3_embed.bns2.bias \t torch.Size([10])\n",
      "gnn3_embed.bns2.running_mean \t torch.Size([10])\n",
      "gnn3_embed.bns2.running_var \t torch.Size([10])\n",
      "gnn3_embed.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn3_embed.conv3.bias \t torch.Size([32])\n",
      "gnn3_embed.conv3.lin.weight \t torch.Size([32, 16])\n",
      "gnn3_embed.bns3.weight \t torch.Size([10])\n",
      "gnn3_embed.bns3.bias \t torch.Size([10])\n",
      "gnn3_embed.bns3.running_mean \t torch.Size([10])\n",
      "gnn3_embed.bns3.running_var \t torch.Size([10])\n",
      "gnn3_embed.bns3.num_batches_tracked \t torch.Size([])\n",
      "lin1.weight \t torch.Size([64, 32])\n",
      "lin1.bias \t torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer's state_dict:\n",
      "state \t {0: {'step': tensor(11460.), 'exp_avg': tensor([-8.8733e-03, -1.5610e-02,  1.8878e-02, -1.8157e-02, -3.3420e-03,\n",
      "         1.2759e-02, -1.8007e-02,  1.3146e-02,  1.4073e-02, -1.8123e-02,\n",
      "         2.2194e-02,  2.7307e-03,  8.4511e-05, -4.2975e-04,  6.3594e-03,\n",
      "        -7.6844e-03]), 'exp_avg_sq': tensor([0.0719, 0.2525, 0.1971, 0.1310, 0.2391, 0.1148, 0.1293, 0.1168, 0.0794,\n",
      "        0.0599, 0.1119, 0.1011, 0.0565, 0.0494, 0.0625, 0.1263])}, 1: {'step': tensor(11460.), 'exp_avg': tensor([[ 1.3501e-03,  4.6236e-04,  4.2276e-03],\n",
      "        [ 3.0779e-03,  6.7676e-04,  6.2320e-03],\n",
      "        [-1.5505e-03, -3.7594e-04, -6.9326e-03],\n",
      "        [ 1.8295e-03,  3.3398e-04, -3.7741e-03],\n",
      "        [-2.0204e-03, -4.4609e-04,  3.1121e-04],\n",
      "        [ 4.4832e-04,  7.9818e-04,  3.6110e-03],\n",
      "        [ 9.2038e-05, -7.7407e-05, -5.1036e-03],\n",
      "        [-9.1690e-04, -3.3408e-04,  2.6269e-03],\n",
      "        [ 7.2699e-04, -5.1197e-07, -3.1980e-03],\n",
      "        [ 2.9717e-05,  1.3626e-04,  1.1252e-03],\n",
      "        [-1.0644e-03, -3.5957e-05,  4.9319e-04],\n",
      "        [-2.6348e-04,  2.9624e-04,  1.1197e-02],\n",
      "        [-6.0101e-04, -4.2836e-04, -3.8572e-03],\n",
      "        [ 5.3434e-04, -3.6733e-05,  7.2792e-03],\n",
      "        [-3.3118e-04, -5.8894e-04, -2.2337e-03],\n",
      "        [-1.3411e-03, -3.7978e-04, -1.2004e-02]]), 'exp_avg_sq': tensor([[8.1780e-04, 2.4227e-04, 1.7329e-02],\n",
      "        [2.7636e-03, 4.3135e-04, 1.0073e-02],\n",
      "        [3.0910e-03, 3.2585e-04, 1.5143e-02],\n",
      "        [1.0059e-03, 3.2884e-04, 9.5823e-03],\n",
      "        [1.5600e-03, 3.8286e-04, 6.5433e-03],\n",
      "        [3.4289e-03, 1.2758e-04, 1.4252e-02],\n",
      "        [1.5205e-03, 2.9377e-04, 5.4781e-03],\n",
      "        [1.4670e-03, 3.4306e-04, 4.7611e-03],\n",
      "        [1.5929e-03, 1.1901e-04, 2.1521e-02],\n",
      "        [1.0302e-03, 2.7282e-04, 6.4615e-03],\n",
      "        [1.0844e-03, 2.8830e-04, 5.5891e-03],\n",
      "        [1.3919e-03, 2.3596e-04, 2.4578e-02],\n",
      "        [7.0824e-04, 7.8812e-05, 1.3128e-02],\n",
      "        [5.2585e-04, 1.5138e-04, 7.7266e-03],\n",
      "        [3.3621e-03, 2.0575e-04, 9.7774e-03],\n",
      "        [3.0868e-03, 2.9252e-04, 2.0038e-02]])}, 2: {'step': tensor(11460.), 'exp_avg': tensor([-5.2764e-05, -1.3272e-04, -6.5271e-05,  9.7184e-05, -5.1113e-06,\n",
      "        -7.3547e-05, -4.3665e-05,  2.7154e-05, -4.2851e-05, -4.3375e-05,\n",
      "         3.0160e-05,  1.7316e-04, -6.4841e-05,  9.3265e-05, -4.1465e-05,\n",
      "        -3.6108e-05, -5.6764e-05,  1.0657e-05, -6.1914e-05, -3.7181e-05,\n",
      "         3.2727e-05,  5.6915e-05,  1.1475e-05,  4.9478e-05,  1.1474e-04,\n",
      "         4.3420e-05,  4.6098e-05,  5.6252e-05, -1.4912e-04,  5.9738e-05,\n",
      "         1.2119e-05, -1.1150e-04, -2.5579e-05,  1.2916e-05,  4.1920e-05,\n",
      "         1.2457e-04, -1.7215e-04,  1.9706e-04, -5.3110e-06,  2.9791e-04,\n",
      "         5.4601e-05, -1.2948e-04,  5.5370e-05, -1.6284e-07,  3.4207e-06,\n",
      "         1.0870e-05,  1.1959e-04, -2.9627e-05,  2.2465e-05, -3.8033e-06,\n",
      "        -6.0014e-05,  3.6461e-05, -4.9671e-05, -1.0524e-05, -6.9481e-06,\n",
      "        -1.0509e-04, -3.1811e-05, -1.8287e-04, -2.3496e-05,  5.7452e-05,\n",
      "         4.4437e-05,  3.9867e-05,  2.1308e-05, -1.4769e-05,  1.2882e-04,\n",
      "        -8.8192e-06, -1.2305e-05,  1.6919e-04,  7.4908e-05, -2.9211e-05,\n",
      "        -1.2976e-04, -5.9614e-05,  4.3129e-05, -2.9092e-05, -3.6042e-05,\n",
      "         5.1545e-05,  4.5721e-05,  2.4628e-05, -8.7081e-06,  1.2418e-04,\n",
      "        -1.8476e-04, -6.5662e-05, -1.8650e-04, -1.5037e-04,  4.1132e-05,\n",
      "        -3.6731e-05, -3.4376e-05,  2.0691e-05,  2.3622e-04,  4.5763e-05,\n",
      "        -1.8770e-04, -6.1908e-05,  3.1652e-05, -7.2974e-05,  1.9734e-05,\n",
      "         2.2838e-05, -9.4024e-05,  1.0988e-04,  1.3341e-05,  8.0131e-05]), 'exp_avg_sq': tensor([1.4854e-05, 3.8913e-06, 7.9818e-06, 2.6310e-06, 3.8321e-06, 2.4827e-06,\n",
      "        4.0975e-06, 2.0759e-06, 4.9089e-06, 2.7098e-06, 1.4748e-06, 3.9119e-06,\n",
      "        2.2122e-06, 3.9217e-06, 4.1115e-06, 2.7840e-06, 9.3921e-06, 3.3396e-06,\n",
      "        3.8000e-06, 2.0163e-06, 2.7835e-06, 1.0301e-05, 1.0055e-05, 9.7561e-06,\n",
      "        4.5466e-06, 2.3554e-06, 3.4101e-06, 2.9695e-06, 2.6091e-06, 5.0717e-06,\n",
      "        2.1504e-06, 5.0853e-06, 2.6723e-06, 4.1361e-06, 4.3133e-06, 3.3765e-06,\n",
      "        3.0670e-06, 3.2324e-06, 2.3382e-06, 3.8534e-06, 3.4434e-06, 3.4841e-06,\n",
      "        5.6306e-06, 7.1929e-06, 2.5328e-06, 1.1684e-05, 2.3660e-06, 4.4473e-06,\n",
      "        3.1794e-06, 7.6001e-06, 2.7911e-06, 3.8628e-06, 5.8252e-06, 2.7633e-06,\n",
      "        3.5321e-06, 4.0263e-06, 2.4253e-06, 2.4327e-06, 6.0421e-06, 3.4339e-06,\n",
      "        6.5488e-06, 5.1220e-06, 2.4231e-06, 3.8393e-06, 3.3736e-06, 4.4785e-06,\n",
      "        4.9589e-06, 5.9383e-06, 7.4485e-06, 3.8208e-06, 1.0290e-05, 2.6779e-06,\n",
      "        5.1819e-06, 4.0997e-06, 2.5368e-06, 3.0120e-06, 2.4153e-06, 3.4070e-06,\n",
      "        3.8854e-06, 3.8013e-06, 2.4742e-06, 2.5558e-06, 4.9294e-06, 2.6872e-06,\n",
      "        3.4989e-06, 2.8058e-06, 4.4945e-06, 3.5705e-06, 1.9197e-06, 5.5157e-06,\n",
      "        3.5364e-06, 5.3213e-06, 3.9079e-06, 3.8748e-06, 4.1673e-06, 3.0434e-06,\n",
      "        2.1849e-06, 2.9465e-06, 3.3165e-06, 2.0234e-06])}, 3: {'step': tensor(11460.), 'exp_avg': tensor([-3.2216e-05,  2.0248e-04,  5.0413e-07,  2.0850e-04,  2.2533e-04,\n",
      "         1.0846e-04,  1.9391e-04,  1.0568e-04,  1.3178e-04,  4.7434e-05,\n",
      "        -1.8933e-05,  6.6627e-05,  1.9979e-04,  2.3558e-06,  1.2246e-04,\n",
      "        -7.7254e-06,  1.1022e-04,  8.1750e-05, -3.0989e-06,  7.2598e-05,\n",
      "         3.0171e-05,  1.7524e-05,  1.6659e-04,  1.4486e-04,  1.0859e-04,\n",
      "        -3.5716e-05,  1.0720e-04,  9.3675e-05,  5.8055e-05,  2.0210e-04,\n",
      "         1.4283e-04,  2.0253e-05, -5.7397e-05, -2.5655e-05,  1.7055e-04,\n",
      "         9.5853e-05,  1.7785e-04,  7.1243e-05,  1.0961e-04,  1.2331e-04,\n",
      "         2.2810e-04,  6.9891e-05,  8.1087e-05, -5.3727e-05,  1.8233e-04,\n",
      "         1.2649e-04,  5.1730e-05,  1.3497e-04,  1.0692e-04,  2.4779e-04,\n",
      "        -4.0649e-05,  8.4222e-05,  1.5485e-05,  6.2275e-05,  1.0034e-04,\n",
      "         1.2984e-04,  1.2972e-04,  2.2109e-05,  1.6968e-04,  1.0199e-04,\n",
      "         1.1227e-04,  1.5343e-04,  7.8662e-05, -1.8800e-04,  8.9497e-05,\n",
      "         5.7453e-05,  9.3115e-05, -8.8701e-05, -7.4096e-05,  2.3113e-05,\n",
      "         4.2168e-05,  1.1229e-04,  1.5673e-04,  5.9701e-05,  7.6341e-05,\n",
      "         1.9578e-04, -1.6511e-05,  1.0514e-04,  1.1611e-04,  6.6243e-05,\n",
      "         6.0066e-05,  4.3587e-05, -4.0382e-05,  6.3507e-05,  3.5191e-05,\n",
      "         7.8795e-05,  6.3764e-05,  1.1677e-04,  5.2838e-05,  7.2431e-05,\n",
      "         1.4449e-05, -1.9352e-04, -5.1437e-05,  7.4691e-05, -1.3625e-04,\n",
      "         1.0776e-04, -5.4789e-05,  8.2274e-05, -1.0489e-04,  2.8328e-05]), 'exp_avg_sq': tensor([1.0003e-05, 2.9850e-05, 1.0571e-05, 4.3255e-06, 8.0995e-06, 6.9308e-06,\n",
      "        1.0327e-05, 5.7423e-06, 1.0581e-05, 9.1966e-06, 6.7189e-06, 7.4754e-06,\n",
      "        7.2734e-06, 1.1152e-05, 1.1970e-05, 1.0458e-05, 1.2141e-05, 9.2590e-06,\n",
      "        6.6053e-06, 8.2923e-06, 6.5605e-06, 1.3066e-05, 7.8555e-06, 1.3182e-05,\n",
      "        6.3566e-06, 1.5058e-05, 8.8418e-06, 1.5080e-05, 8.6252e-06, 1.4060e-05,\n",
      "        7.6249e-06, 8.1105e-06, 8.2111e-06, 1.0654e-05, 1.0036e-05, 4.8266e-06,\n",
      "        5.4473e-06, 1.0069e-05, 1.2694e-05, 9.5059e-06, 9.6140e-06, 2.2163e-05,\n",
      "        1.3440e-05, 1.3990e-05, 7.3573e-06, 1.3624e-05, 1.4515e-05, 6.4644e-06,\n",
      "        9.7753e-06, 6.9098e-06, 8.8844e-06, 1.4974e-05, 1.8817e-05, 5.3229e-06,\n",
      "        8.0057e-06, 8.8111e-06, 6.2395e-06, 8.9500e-06, 1.2620e-05, 1.6490e-05,\n",
      "        1.3488e-05, 1.3565e-05, 7.1365e-06, 3.2762e-05, 1.2900e-05, 1.0912e-05,\n",
      "        6.9337e-06, 1.3898e-05, 1.1782e-05, 9.8158e-06, 1.5101e-05, 6.7701e-06,\n",
      "        9.1582e-06, 4.6696e-06, 1.1480e-05, 7.3636e-06, 1.1221e-05, 6.5582e-06,\n",
      "        1.1474e-05, 1.0487e-05, 9.4972e-06, 1.4134e-05, 2.2420e-05, 8.2810e-06,\n",
      "        1.7865e-05, 6.8875e-06, 1.5621e-05, 1.3355e-05, 8.2623e-06, 9.1275e-06,\n",
      "        1.4419e-05, 1.3207e-05, 1.5424e-05, 1.1857e-05, 1.0091e-05, 4.9812e-06,\n",
      "        1.0147e-05, 1.9236e-05, 1.1461e-05, 8.2617e-06])}, 4: {'step': tensor(11460.), 'exp_avg': tensor([-6.8829e-04, -3.2397e-03,  1.8372e-03,  3.9709e-03, -5.0541e-03,\n",
      "        -8.9078e-04, -1.7101e-03,  2.5524e-03,  3.4415e-05,  2.9128e-03,\n",
      "         4.1621e-03, -2.7317e-03, -2.3994e-03,  2.9639e-03, -4.5549e-03,\n",
      "         2.8352e-03]), 'exp_avg_sq': tensor([0.0026, 0.0016, 0.0009, 0.0016, 0.0034, 0.0011, 0.0008, 0.0013, 0.0011,\n",
      "        0.0014, 0.0056, 0.0007, 0.0019, 0.0032, 0.0060, 0.0027])}, 5: {'step': tensor(11460.), 'exp_avg': tensor([[ 2.1539e-03,  1.3447e-05,  1.1952e-03,  8.1478e-04,  2.1281e-03,\n",
      "          6.7965e-04, -1.4947e-03, -4.1347e-04, -1.5971e-03, -9.9040e-04,\n",
      "         -7.9757e-04, -2.8283e-03,  2.2313e-03, -3.1140e-04,  7.6338e-04,\n",
      "         -1.5585e-03],\n",
      "        [-5.1926e-05, -5.0840e-05,  4.3752e-05, -1.8448e-04,  1.7135e-05,\n",
      "          2.2522e-04,  9.6391e-05, -5.3564e-05, -6.7340e-05, -1.0686e-04,\n",
      "          2.2646e-04,  3.1354e-04, -3.1839e-04,  3.3611e-05, -2.0952e-05,\n",
      "          3.2712e-05],\n",
      "        [-1.8774e-03, -9.1249e-04, -9.1342e-04, -6.6161e-05, -2.3976e-03,\n",
      "         -7.5526e-04,  1.3700e-03,  2.3572e-04,  1.1784e-03,  1.2429e-03,\n",
      "          6.4150e-04,  2.4301e-03, -1.6197e-03,  4.1860e-04, -1.2634e-03,\n",
      "          2.2195e-03],\n",
      "        [-1.4369e-05,  3.4748e-04, -1.9710e-04,  6.4920e-05,  3.7466e-05,\n",
      "         -3.2448e-04, -1.1155e-04,  1.8354e-04,  1.8754e-04,  5.3311e-05,\n",
      "         -2.0656e-04, -3.2832e-04,  2.3229e-04, -4.8341e-05,  1.7074e-04,\n",
      "         -2.1408e-04],\n",
      "        [-2.7421e-03, -6.8607e-04, -1.1619e-03, -1.0836e-03, -2.8508e-03,\n",
      "         -3.7297e-04,  2.1118e-03,  1.7365e-04,  1.7716e-03,  1.2687e-03,\n",
      "          1.2577e-03,  4.1303e-03, -3.1336e-03,  4.5974e-04, -1.3197e-03,\n",
      "          2.4208e-03],\n",
      "        [-1.8601e-03, -1.3208e-03, -8.9170e-04,  1.3087e-04, -2.5787e-03,\n",
      "         -6.5775e-04,  1.4079e-03,  2.4969e-04,  9.0057e-04,  1.2221e-03,\n",
      "          9.5619e-04,  2.5990e-03, -1.7755e-03,  5.7533e-04, -1.5240e-03,\n",
      "          2.6294e-03],\n",
      "        [ 2.2151e-03,  1.7265e-04,  1.0655e-03,  8.1630e-04,  2.2361e-03,\n",
      "          6.6628e-04, -1.5897e-03, -2.3518e-04, -1.7311e-03, -1.1677e-03,\n",
      "         -5.7537e-04, -2.9038e-03,  2.1191e-03, -2.3925e-04,  8.6010e-04,\n",
      "         -1.6502e-03],\n",
      "        [ 2.6406e-04,  6.0790e-04,  9.2146e-05, -2.1632e-04,  5.6987e-04,\n",
      "          1.3016e-05, -2.5046e-04, -2.6175e-05,  1.0959e-04, -1.9014e-04,\n",
      "         -3.9684e-04, -5.3738e-04,  3.7571e-04, -2.2151e-04,  4.8726e-04,\n",
      "         -7.9036e-04],\n",
      "        [ 1.1892e-03, -3.9454e-04, -9.6689e-05,  1.4457e-03,  5.7219e-04,\n",
      "         -3.1513e-04, -1.0925e-03,  6.6133e-04, -1.5339e-03, -6.5163e-04,\n",
      "          5.1973e-04, -1.8980e-03,  1.0999e-03,  4.2620e-04, -3.5440e-05,\n",
      "          1.1560e-04],\n",
      "        [ 9.8706e-04, -5.3993e-05,  4.4906e-04,  6.4424e-04,  8.2496e-04,\n",
      "          3.1086e-05, -7.4556e-04, -9.6811e-05, -6.8999e-04, -2.9638e-04,\n",
      "         -5.1611e-04, -1.5445e-03,  1.2924e-03, -1.2067e-04,  2.6842e-04,\n",
      "         -5.7301e-04],\n",
      "        [ 2.0015e-03,  1.4632e-03,  1.3373e-03, -3.7182e-04,  2.9043e-03,\n",
      "          8.2162e-04, -1.4034e-03, -7.3003e-04, -5.6808e-04, -1.0377e-03,\n",
      "         -1.7608e-03, -2.8436e-03,  2.3054e-03, -9.3340e-04,  1.7415e-03,\n",
      "         -3.1418e-03],\n",
      "        [-4.8979e-04,  8.7735e-05, -2.3336e-04, -4.1344e-04, -3.4825e-04,\n",
      "          6.4688e-05,  3.7540e-04,  6.4676e-05,  3.0599e-04,  5.8648e-05,\n",
      "          3.6274e-04,  8.4500e-04, -7.7070e-04,  7.1876e-05, -8.7416e-05,\n",
      "          2.2401e-04],\n",
      "        [-2.3724e-03, -5.0159e-04, -1.2015e-03, -7.4348e-04, -2.5416e-03,\n",
      "         -5.8506e-04,  1.7340e-03,  3.5903e-04,  1.5261e-03,  1.1237e-03,\n",
      "          1.1094e-03,  3.3541e-03, -2.5954e-03,  4.5959e-04, -1.1361e-03,\n",
      "          2.1446e-03],\n",
      "        [ 2.5023e-03,  1.6745e-03,  1.1962e-03, -2.6466e-05,  3.3694e-03,\n",
      "          7.6676e-04, -1.9059e-03, -3.4024e-04, -1.1889e-03, -1.5310e-03,\n",
      "         -1.3977e-03, -3.6020e-03,  2.5490e-03, -7.7310e-04,  1.9706e-03,\n",
      "         -3.4253e-03],\n",
      "        [-3.9692e-03, -1.8220e-03, -1.4478e-03, -1.0117e-03, -4.6074e-03,\n",
      "         -6.9298e-04,  3.1507e-03, -1.0806e-05,  2.5101e-03,  2.3098e-03,\n",
      "          1.4949e-03,  5.8962e-03, -4.0606e-03,  6.9693e-04, -2.4422e-03,\n",
      "          4.2157e-03],\n",
      "        [ 2.0644e-03,  1.3754e-03,  7.6428e-04,  2.0063e-04,  2.6647e-03,\n",
      "          4.3531e-04, -1.6523e-03, -2.1363e-05, -1.1135e-03, -1.3072e-03,\n",
      "         -9.1768e-04, -3.0823e-03,  2.0688e-03, -4.9420e-04,  1.5671e-03,\n",
      "         -2.6490e-03]]), 'exp_avg_sq': tensor([[5.4268e-03, 7.1753e-04, 9.0760e-04, 9.2173e-04, 6.2412e-03, 2.9947e-04,\n",
      "         3.0934e-03, 9.2686e-05, 3.0689e-03, 1.9228e-03, 4.9440e-04, 1.1084e-02,\n",
      "         5.2604e-03, 1.3562e-04, 1.4960e-03, 4.3282e-03],\n",
      "        [2.4297e-03, 5.2000e-04, 5.5613e-04, 7.9644e-04, 2.6858e-03, 2.0045e-04,\n",
      "         1.3347e-03, 1.1561e-04, 1.4624e-03, 7.2138e-04, 3.9431e-04, 4.8139e-03,\n",
      "         2.5787e-03, 1.2420e-04, 6.9780e-04, 2.0969e-03],\n",
      "        [7.0738e-04, 2.8903e-04, 1.1427e-04, 3.1394e-04, 8.8264e-04, 6.2599e-05,\n",
      "         4.1706e-04, 3.3814e-05, 4.7829e-04, 2.7557e-04, 8.8796e-05, 1.4809e-03,\n",
      "         6.8691e-04, 4.5351e-05, 2.8734e-04, 7.8574e-04],\n",
      "        [1.0792e-03, 2.8301e-04, 3.2912e-04, 4.2482e-04, 1.2275e-03, 1.2308e-04,\n",
      "         5.8600e-04, 1.1319e-04, 6.5032e-04, 2.9191e-04, 2.9563e-04, 2.1059e-03,\n",
      "         1.1982e-03, 9.0038e-05, 3.4820e-04, 1.0740e-03],\n",
      "        [6.7954e-03, 1.2318e-03, 1.7124e-03, 2.2614e-03, 7.1825e-03, 5.6454e-04,\n",
      "         3.6508e-03, 3.4490e-04, 4.0942e-03, 1.7886e-03, 1.2298e-03, 1.3227e-02,\n",
      "         7.3975e-03, 3.6290e-04, 1.7848e-03, 5.5347e-03],\n",
      "        [7.7512e-04, 2.5859e-04, 2.5225e-04, 3.1399e-04, 9.4632e-04, 9.5818e-05,\n",
      "         4.1161e-04, 7.9007e-05, 4.3717e-04, 2.0862e-04, 2.3507e-04, 1.4897e-03,\n",
      "         8.7163e-04, 7.6054e-05, 2.9712e-04, 8.9830e-04],\n",
      "        [7.6328e-04, 4.3448e-04, 1.3358e-04, 4.9999e-04, 9.6379e-04, 7.9618e-05,\n",
      "         4.6043e-04, 5.4032e-05, 5.7561e-04, 2.7255e-04, 1.4606e-04, 1.5929e-03,\n",
      "         7.5852e-04, 7.9953e-05, 3.7369e-04, 1.0172e-03],\n",
      "        [1.1560e-03, 2.7449e-04, 2.3362e-04, 5.3662e-04, 1.1470e-03, 7.8375e-05,\n",
      "         6.8227e-04, 8.7422e-05, 8.3668e-04, 3.4789e-04, 1.9336e-04, 2.4119e-03,\n",
      "         1.2300e-03, 6.5263e-05, 3.0847e-04, 8.9271e-04],\n",
      "        [4.7317e-04, 2.2871e-04, 8.4373e-05, 4.6150e-04, 3.6832e-04, 3.8375e-05,\n",
      "         2.7617e-04, 4.4471e-05, 5.0073e-04, 1.1987e-04, 7.7758e-05, 9.9639e-04,\n",
      "         5.3083e-04, 4.4009e-05, 1.2678e-04, 3.4233e-04],\n",
      "        [3.0172e-03, 4.2857e-04, 6.6312e-04, 7.2881e-04, 3.2782e-03, 2.2277e-04,\n",
      "         1.6432e-03, 1.1580e-04, 1.7595e-03, 9.1135e-04, 4.1146e-04, 5.9149e-03,\n",
      "         3.0902e-03, 1.1294e-04, 7.6840e-04, 2.3395e-03],\n",
      "        [5.8262e-03, 8.2858e-04, 1.6166e-03, 1.7682e-03, 5.9499e-03, 4.8067e-04,\n",
      "         3.0997e-03, 3.3406e-04, 3.3338e-03, 1.3951e-03, 1.1711e-03, 1.1220e-02,\n",
      "         6.5461e-03, 2.9425e-04, 1.3908e-03, 4.4820e-03],\n",
      "        [1.7326e-03, 3.1651e-04, 3.5900e-04, 6.2250e-04, 1.7883e-03, 1.2077e-04,\n",
      "         9.6403e-04, 6.4560e-05, 1.1070e-03, 4.8739e-04, 2.4318e-04, 3.4632e-03,\n",
      "         1.8378e-03, 7.8784e-05, 4.4458e-04, 1.3464e-03],\n",
      "        [8.5061e-03, 8.9922e-04, 1.5968e-03, 1.4930e-03, 9.4354e-03, 4.8956e-04,\n",
      "         4.7227e-03, 1.1224e-04, 4.6846e-03, 2.7128e-03, 8.7257e-04, 1.7057e-02,\n",
      "         8.5675e-03, 2.1537e-04, 2.1656e-03, 6.4916e-03],\n",
      "        [2.3051e-03, 2.4340e-04, 6.0099e-04, 6.6058e-04, 2.2983e-03, 1.7077e-04,\n",
      "         1.3065e-03, 1.8043e-04, 1.3500e-03, 5.9740e-04, 4.6746e-04, 4.5746e-03,\n",
      "         2.5223e-03, 1.0987e-04, 5.2135e-04, 1.6684e-03],\n",
      "        [2.5092e-03, 8.7024e-04, 9.0171e-04, 8.4387e-04, 3.0882e-03, 2.9545e-04,\n",
      "         1.3158e-03, 2.4773e-04, 1.2065e-03, 6.3451e-04, 8.2020e-04, 4.7379e-03,\n",
      "         2.9438e-03, 2.2831e-04, 9.8465e-04, 2.9841e-03],\n",
      "        [1.6828e-03, 6.7089e-04, 3.0739e-04, 1.3653e-03, 1.3498e-03, 1.0325e-04,\n",
      "         9.7703e-04, 9.0184e-05, 1.5247e-03, 3.7142e-04, 2.5662e-04, 3.4748e-03,\n",
      "         1.9476e-03, 1.2478e-04, 4.3189e-04, 1.2232e-03]])}, 6: {'step': tensor(11460.), 'exp_avg': tensor([-3.3623e-05, -8.8469e-05, -2.8888e-05,  1.3876e-04, -1.7468e-05,\n",
      "         4.4898e-05, -3.2616e-05,  4.9761e-08, -1.4377e-05, -6.0092e-05,\n",
      "         2.0833e-05,  1.0365e-04, -4.6795e-05,  1.0621e-04, -6.7352e-05,\n",
      "         7.1100e-06, -6.5350e-05,  3.2621e-05, -1.6494e-05, -2.8914e-05,\n",
      "         3.9452e-05, -1.7954e-05,  5.6220e-05,  4.3113e-05,  6.0278e-05,\n",
      "         5.1485e-05,  1.9647e-05,  2.0707e-05, -1.4221e-04, -2.3403e-05,\n",
      "         3.8775e-05, -3.0587e-05,  3.3190e-06, -3.2970e-05,  5.7750e-05,\n",
      "         9.8625e-05, -2.0389e-04,  1.7401e-04, -5.5356e-05,  1.7417e-04,\n",
      "         3.9891e-05, -5.2272e-05,  5.4032e-05, -8.3439e-05,  3.9190e-06,\n",
      "         1.4764e-05,  8.3091e-05, -4.0920e-05,  4.7628e-05, -1.2769e-06,\n",
      "        -4.5183e-05,  4.1313e-05, -2.1531e-05, -9.0475e-06, -2.1579e-05,\n",
      "        -1.9315e-05, -3.4631e-05, -1.1492e-04, -8.7897e-05,  3.4831e-05,\n",
      "         8.5743e-07,  8.6872e-05,  1.9647e-05,  5.1641e-05,  9.2741e-05,\n",
      "         3.0770e-05,  5.4392e-06,  4.8449e-05,  7.6572e-05, -3.6479e-06,\n",
      "        -4.5310e-05, -2.9967e-05,  4.2907e-06, -4.6097e-05, -5.7191e-05,\n",
      "        -5.0010e-05, -2.3595e-05,  1.7891e-05, -2.8275e-05,  8.3490e-05,\n",
      "        -7.5792e-05, -1.6940e-05, -2.0947e-04, -9.8499e-05, -7.7324e-05,\n",
      "        -4.9285e-06,  2.9838e-05,  5.2838e-05,  1.5508e-04,  6.7253e-05,\n",
      "        -1.4237e-04, -3.5205e-05,  2.8437e-05, -4.6513e-05,  8.3427e-05,\n",
      "         2.5362e-05, -1.0025e-04,  1.0604e-04, -6.1020e-05,  5.4182e-05]), 'exp_avg_sq': tensor([1.3313e-05, 2.7821e-06, 5.7637e-06, 3.0346e-06, 2.7931e-06, 2.3866e-06,\n",
      "        3.2636e-06, 1.7268e-06, 3.2909e-06, 1.8064e-06, 4.9798e-06, 2.5364e-06,\n",
      "        1.9769e-06, 5.5060e-06, 2.3032e-06, 2.3416e-06, 5.8050e-06, 2.3503e-06,\n",
      "        3.1918e-06, 1.7064e-06, 1.7031e-06, 2.9291e-06, 4.3897e-06, 3.5182e-06,\n",
      "        2.2971e-06, 3.1505e-06, 2.6394e-06, 2.9701e-06, 2.8438e-06, 2.9458e-06,\n",
      "        2.1056e-06, 3.1725e-06, 1.4489e-06, 5.1918e-06, 2.6348e-06, 4.9517e-06,\n",
      "        2.3248e-06, 2.6061e-06, 2.7611e-06, 3.6871e-06, 2.8422e-06, 2.8297e-06,\n",
      "        5.5919e-06, 2.7380e-06, 1.7925e-06, 3.1629e-06, 3.9627e-06, 2.9048e-06,\n",
      "        2.1673e-06, 4.2040e-06, 3.0014e-06, 5.5989e-06, 4.0313e-06, 3.2560e-06,\n",
      "        2.7906e-06, 2.4759e-06, 2.7561e-06, 1.6766e-06, 7.2995e-06, 3.9692e-06,\n",
      "        3.7134e-06, 4.7960e-06, 2.8873e-06, 3.6884e-06, 4.0176e-06, 4.1430e-06,\n",
      "        4.7851e-06, 6.4221e-06, 2.6799e-06, 2.3825e-06, 5.9603e-06, 2.7617e-06,\n",
      "        5.1576e-06, 2.2240e-06, 3.5895e-06, 3.7844e-06, 2.3746e-06, 2.6133e-06,\n",
      "        2.6207e-06, 4.0551e-06, 2.0482e-06, 3.1004e-06, 4.7415e-06, 2.4959e-06,\n",
      "        2.8391e-06, 3.5247e-06, 4.2969e-06, 2.2056e-06, 1.4083e-06, 4.5250e-06,\n",
      "        3.1180e-06, 4.6109e-06, 3.3913e-06, 3.8129e-06, 4.6108e-06, 2.7033e-06,\n",
      "        2.3745e-06, 3.8420e-06, 3.2612e-06, 2.1808e-06])}, 7: {'step': tensor(11460.), 'exp_avg': tensor([-1.1279e-04,  1.0752e-04,  6.5738e-05,  8.8039e-05,  7.7855e-06,\n",
      "         1.4086e-04,  5.6406e-05,  4.2266e-04,  9.4136e-05,  2.0158e-04,\n",
      "        -9.7501e-05,  2.3897e-04, -3.3255e-05,  2.1798e-04,  8.1509e-05,\n",
      "        -1.3060e-04, -8.0120e-05, -1.3589e-04, -1.2779e-04, -6.7873e-05,\n",
      "         2.9871e-04, -9.1791e-07,  1.2254e-04,  1.1684e-04,  7.9932e-05,\n",
      "         5.3664e-05,  2.0695e-05,  2.8913e-04,  2.3744e-04,  7.4875e-05,\n",
      "         1.8473e-04, -8.9355e-05, -1.1505e-04, -1.2367e-04,  2.4567e-04,\n",
      "         1.6388e-04,  2.6394e-04, -6.6751e-05,  1.6985e-04, -1.4227e-04,\n",
      "        -8.7789e-05, -1.3860e-04,  8.5802e-06,  1.6624e-04, -3.0799e-05,\n",
      "         2.1596e-04,  2.9235e-04,  7.2887e-05, -8.2633e-05,  3.2629e-05,\n",
      "        -3.7584e-05,  1.3821e-04, -2.9646e-05, -6.2834e-05, -9.8903e-05,\n",
      "         7.4184e-05,  1.0243e-04,  1.8532e-04,  2.0006e-04,  1.5890e-04,\n",
      "         2.4971e-04,  7.0418e-05,  1.5491e-04,  6.0774e-05,  1.1742e-04,\n",
      "        -1.2934e-04,  2.2418e-04, -1.1010e-04, -1.0900e-04, -6.3955e-05,\n",
      "         2.4871e-04, -9.0604e-05,  4.9452e-05, -1.5081e-04,  3.3171e-05,\n",
      "         2.6403e-04,  1.2814e-04, -3.8085e-05,  1.3536e-05,  3.0341e-05,\n",
      "        -3.1698e-05,  1.1504e-04, -5.9100e-05, -4.3642e-05, -1.1383e-04,\n",
      "         1.1924e-04,  9.7792e-05,  1.2489e-04,  2.4390e-04,  1.0924e-04,\n",
      "         2.0526e-04, -2.5889e-04, -4.6486e-05,  4.8319e-05, -6.6534e-07,\n",
      "         4.2368e-04,  1.9441e-04,  5.0454e-04,  4.0398e-05,  1.3934e-04]), 'exp_avg_sq': tensor([1.2132e-05, 1.1877e-05, 1.0732e-05, 1.0271e-05, 7.9381e-06, 7.5618e-06,\n",
      "        1.2790e-05, 7.9647e-06, 1.0240e-05, 9.7116e-06, 1.2686e-05, 1.2292e-05,\n",
      "        8.9159e-06, 1.2963e-05, 1.1651e-05, 1.3480e-05, 7.6707e-06, 1.0110e-05,\n",
      "        8.7647e-06, 1.1627e-05, 1.0185e-05, 1.0004e-05, 1.4306e-05, 1.2592e-05,\n",
      "        8.1318e-06, 1.2107e-05, 1.1489e-05, 1.3687e-05, 9.8962e-06, 1.6810e-05,\n",
      "        1.0411e-05, 1.0267e-05, 1.0145e-05, 9.2220e-06, 1.1394e-05, 8.5489e-06,\n",
      "        8.7662e-06, 1.3947e-05, 1.4094e-05, 8.0972e-06, 9.9592e-06, 1.1189e-05,\n",
      "        1.1531e-05, 8.9539e-06, 7.8162e-06, 1.2694e-05, 1.3175e-05, 1.0330e-05,\n",
      "        1.0251e-05, 1.3104e-05, 8.0179e-06, 1.1427e-05, 1.0006e-05, 9.0586e-06,\n",
      "        8.4132e-06, 8.0946e-06, 6.8622e-06, 1.2015e-05, 8.6212e-06, 1.6676e-05,\n",
      "        1.4431e-05, 1.3032e-05, 8.8659e-06, 1.2583e-05, 1.5609e-05, 1.0448e-05,\n",
      "        8.3055e-06, 1.1634e-05, 1.1446e-05, 9.7108e-06, 1.3254e-05, 9.6506e-06,\n",
      "        9.0453e-06, 9.3128e-06, 1.0016e-05, 9.8299e-06, 1.1650e-05, 1.0755e-05,\n",
      "        1.1671e-05, 1.2561e-05, 1.2304e-05, 1.0861e-05, 1.3879e-05, 9.3672e-06,\n",
      "        1.0205e-05, 1.1525e-05, 1.4000e-05, 1.2725e-05, 1.5573e-05, 1.1653e-05,\n",
      "        1.0066e-05, 8.8346e-06, 1.4800e-05, 1.4959e-05, 1.5479e-05, 9.7993e-06,\n",
      "        1.2832e-05, 9.2787e-06, 1.3108e-05, 9.4242e-06])}, 8: {'step': tensor(11460.), 'exp_avg': tensor([ 1.8688e-04, -1.2781e-03, -3.3436e-04,  3.7466e-06, -2.1355e-04,\n",
      "         5.0815e-04, -9.1651e-04, -4.2252e-04, -4.8721e-04, -9.2387e-04,\n",
      "         7.3151e-04, -2.2562e-04, -3.7384e-03, -4.0057e-04,  8.2990e-04,\n",
      "        -4.2852e-04, -8.1732e-04,  8.0285e-05,  2.5436e-03, -4.7969e-04,\n",
      "        -5.1485e-04, -1.8099e-04, -3.8717e-04,  7.9233e-03, -1.0582e-03]), 'exp_avg_sq': tensor([8.0141e-05, 5.2810e-04, 6.9436e-04, 2.0441e-04, 1.5585e-03, 9.4499e-05,\n",
      "        1.9742e-03, 1.7124e-04, 4.6427e-04, 4.7391e-04, 2.1542e-02, 8.9586e-05,\n",
      "        2.2544e-03, 2.3024e-04, 2.2947e-03, 3.6394e-04, 2.4032e-04, 7.4721e-04,\n",
      "        2.7654e-03, 2.0862e-04, 3.3935e-04, 1.0223e-04, 2.7653e-04, 1.6879e-02,\n",
      "        2.8195e-04])}, 9: {'step': tensor(11460.), 'exp_avg': tensor([[-1.4456e-04, -4.6307e-04,  3.0465e-04, -4.6694e-04,  7.4632e-05,\n",
      "          1.2602e-05, -3.8864e-04, -1.3067e-04,  4.7647e-05,  5.4159e-04,\n",
      "         -2.4742e-04,  5.8295e-04, -2.7559e-04,  3.8108e-04,  2.3518e-04,\n",
      "         -4.3329e-05],\n",
      "        [-7.3990e-04, -8.3604e-04,  1.8779e-03, -2.2451e-03,  6.6441e-04,\n",
      "         -1.7084e-03, -6.5262e-04, -1.9608e-03,  4.7414e-04,  2.4052e-03,\n",
      "         -1.0847e-03,  2.6340e-03, -1.0811e-03,  2.4464e-03, -2.1622e-04,\n",
      "         -4.0538e-05],\n",
      "        [-1.6101e-04, -5.2025e-04,  1.1805e-03, -1.2407e-03,  2.1679e-04,\n",
      "         -1.1267e-03, -4.3365e-04, -1.2330e-03,  1.7092e-04,  1.4682e-03,\n",
      "         -6.6672e-04,  1.6181e-03, -3.4023e-04,  1.4045e-03, -9.4792e-05,\n",
      "         -2.5137e-04],\n",
      "        [ 4.4458e-05, -3.9180e-05, -3.9429e-04,  4.0626e-04, -1.3426e-04,\n",
      "          5.9240e-04, -7.8930e-05,  5.8166e-04, -1.2341e-04, -4.4247e-04,\n",
      "          2.1440e-04, -4.6504e-04,  1.4007e-04, -5.0299e-04,  2.2029e-04,\n",
      "         -4.1137e-06],\n",
      "        [-4.8060e-05, -2.7086e-04,  1.3239e-03, -1.3734e-03,  2.9223e-04,\n",
      "         -1.6365e-03, -1.2680e-04, -1.6854e-03,  2.8262e-04,  1.6154e-03,\n",
      "         -7.7429e-04,  1.7256e-03, -3.6823e-04,  1.6018e-03, -3.8047e-04,\n",
      "         -1.8171e-04],\n",
      "        [ 5.9052e-04,  4.0733e-04, -1.9159e-04,  5.0584e-04, -2.9864e-04,\n",
      "         -2.4761e-04,  3.6976e-04, -6.9788e-05, -1.4857e-04, -3.7348e-04,\n",
      "          1.3290e-04, -4.3000e-04,  6.0989e-04, -4.0398e-04, -1.9598e-04,\n",
      "         -2.2018e-04],\n",
      "        [ 5.4428e-04,  7.6628e-04, -1.2034e-03,  1.8454e-03, -6.3431e-04,\n",
      "          1.0479e-03,  3.9051e-04,  1.3924e-03, -5.4357e-04, -1.9335e-03,\n",
      "          9.5988e-04, -1.9563e-03,  1.2692e-03, -1.7095e-03,  2.4015e-05,\n",
      "         -3.1185e-04],\n",
      "        [-4.1754e-04, -6.7337e-04,  1.0146e-03, -1.2660e-03,  3.2655e-04,\n",
      "         -7.1577e-04, -5.5600e-04, -9.1663e-04,  2.2368e-04,  1.3863e-03,\n",
      "         -6.2191e-04,  1.5194e-03, -6.2855e-04,  1.3035e-03,  7.0704e-05,\n",
      "         -6.4101e-05],\n",
      "        [ 3.8632e-04,  5.2386e-04, -8.2251e-04,  1.1973e-03, -3.9609e-04,\n",
      "          6.7329e-04,  3.2092e-04,  8.8774e-04, -3.2148e-04, -1.2572e-03,\n",
      "          6.0590e-04, -1.2996e-03,  7.8018e-04, -1.1370e-03,  1.7886e-06,\n",
      "         -1.4430e-04],\n",
      "        [ 4.7873e-04,  6.9048e-04, -9.3945e-04,  1.5424e-03, -5.4400e-04,\n",
      "          7.5886e-04,  3.5353e-04,  1.0779e-03, -4.7032e-04, -1.5995e-03,\n",
      "          8.0587e-04, -1.5974e-03,  1.1397e-03, -1.3621e-03, -3.7170e-05,\n",
      "         -3.1067e-04],\n",
      "        [ 5.6240e-04,  1.5659e-03,  6.5999e-04, -5.2713e-04,  4.1406e-04,\n",
      "         -2.7656e-03,  1.8118e-03, -2.3805e-03,  5.9913e-04,  5.2318e-04,\n",
      "         -4.4273e-04,  2.9918e-04, -1.0408e-04,  9.5253e-04, -1.6872e-03,\n",
      "          4.3721e-04],\n",
      "        [-4.9034e-05, -1.4822e-04,  1.2998e-05,  4.4272e-06, -4.0881e-05,\n",
      "          1.6698e-04, -1.8334e-04,  1.4184e-04, -6.0202e-05,  1.1222e-05,\n",
      "          1.8229e-05,  4.8638e-05,  3.4419e-05, -9.1315e-06,  1.3097e-04,\n",
      "         -7.8825e-05],\n",
      "        [-3.9510e-03, -3.2869e-03,  3.3440e-03, -5.6530e-03,  2.4762e-03,\n",
      "         -8.5074e-04, -2.7021e-03, -2.1961e-03,  1.4996e-03,  5.1906e-03,\n",
      "         -2.2181e-03,  5.6881e-03, -4.8082e-03,  5.2100e-03,  8.2216e-04,\n",
      "          1.2633e-03],\n",
      "        [-3.5922e-04, -5.9396e-04,  8.6349e-04, -1.0504e-03,  2.5481e-04,\n",
      "         -5.6956e-04, -5.1636e-04, -7.3665e-04,  1.6206e-04,  1.1577e-03,\n",
      "         -5.0895e-04,  1.2850e-03, -4.9282e-04,  1.0930e-03,  8.5876e-05,\n",
      "         -9.2560e-05],\n",
      "        [-5.7935e-04, -9.6632e-04, -1.2694e-04, -3.8088e-04,  1.5643e-04,\n",
      "          1.1709e-03, -8.5878e-04,  8.0438e-04,  2.8672e-05,  3.0194e-04,\n",
      "         -1.0196e-04,  3.2597e-04, -7.0483e-04, -2.7023e-05,  8.0517e-04,\n",
      "          1.8930e-04],\n",
      "        [-3.3504e-04, -6.1435e-04,  1.0503e-03, -1.2149e-03,  2.7369e-04,\n",
      "         -8.1720e-04, -5.2657e-04, -9.7817e-04,  1.8554e-04,  1.3670e-03,\n",
      "         -6.0780e-04,  1.5131e-03, -4.9593e-04,  1.3040e-03,  2.3434e-05,\n",
      "         -1.4564e-04],\n",
      "        [ 2.7092e-04,  3.7868e-04, -7.5296e-04,  1.1539e-03, -4.0611e-04,\n",
      "          7.9388e-04,  1.2127e-04,  9.8809e-04, -3.7367e-04, -1.2129e-03,\n",
      "          6.2261e-04, -1.1987e-03,  7.9224e-04, -1.0677e-03,  1.0576e-04,\n",
      "         -2.2514e-04],\n",
      "        [ 1.1515e-04,  2.9457e-04,  1.9154e-04, -1.9641e-04,  1.1059e-04,\n",
      "         -6.3713e-04,  3.7259e-04, -5.7358e-04,  1.5005e-04,  2.0821e-04,\n",
      "         -1.4769e-04,  1.6227e-04, -6.6318e-05,  2.7630e-04, -3.5342e-04,\n",
      "          1.0055e-04],\n",
      "        [-1.5075e-03, -2.4453e-03,  9.1181e-04, -2.3485e-03,  8.2192e-04,\n",
      "          1.1249e-03, -1.9427e-03,  1.6560e-04,  5.1370e-04,  2.3100e-03,\n",
      "         -1.0504e-03,  2.3931e-03, -2.3454e-03,  1.5215e-03,  1.4337e-03,\n",
      "          5.4911e-04],\n",
      "        [-2.4512e-04, -4.0146e-04,  5.8216e-04, -5.9578e-04,  1.0268e-04,\n",
      "         -3.1214e-04, -4.2737e-04, -3.9127e-04,  2.3942e-05,  6.7728e-04,\n",
      "         -2.6150e-04,  8.0886e-04, -1.7091e-04,  6.9114e-04,  8.8398e-05,\n",
      "         -1.7822e-04],\n",
      "        [ 6.0706e-04,  8.1772e-04, -9.0158e-04,  1.4448e-03, -4.9546e-04,\n",
      "          4.7590e-04,  5.7269e-04,  8.0243e-04, -3.7001e-04, -1.4808e-03,\n",
      "          6.9892e-04, -1.5427e-03,  1.0572e-03, -1.2912e-03, -1.8299e-04,\n",
      "         -2.1333e-04],\n",
      "        [-1.4566e-04, -3.2050e-04,  1.0724e-04, -1.5107e-04, -3.4451e-06,\n",
      "          2.2122e-04, -3.4148e-04,  1.4199e-04, -4.6865e-05,  1.7600e-04,\n",
      "         -4.7951e-05,  2.3569e-04, -7.7322e-05,  1.1796e-04,  2.2762e-04,\n",
      "         -8.5442e-05],\n",
      "        [-3.7330e-04, -5.5043e-04,  1.0082e-03, -1.3235e-03,  3.9142e-04,\n",
      "         -8.9539e-04, -3.6692e-04, -1.0887e-03,  3.1262e-04,  1.4291e-03,\n",
      "         -6.7844e-04,  1.5139e-03, -7.2638e-04,  1.3435e-03, -5.4442e-05,\n",
      "          5.3125e-05],\n",
      "        [ 4.8873e-03,  5.8451e-03, -8.1595e-03,  1.0304e-02, -3.0454e-03,\n",
      "          4.6314e-03,  5.3104e-03,  6.3684e-03, -1.7322e-03, -1.0792e-02,\n",
      "          4.5640e-03, -1.2186e-02,  5.6015e-03, -1.0747e-02, -9.2245e-04,\n",
      "          3.4240e-04],\n",
      "        [ 5.6917e-04,  8.4033e-04, -9.4109e-04,  1.6292e-03, -5.7778e-04,\n",
      "          6.1263e-04,  4.7882e-04,  9.8881e-04, -4.8404e-04, -1.6771e-03,\n",
      "          8.3789e-04, -1.6787e-03,  1.2614e-03, -1.3893e-03, -1.4991e-04,\n",
      "         -3.4367e-04]]), 'exp_avg_sq': tensor([[1.0502e-04, 1.9586e-04, 1.4577e-04, 3.3317e-04, 3.7883e-05, 5.8079e-05,\n",
      "         1.6852e-04, 8.0452e-05, 6.3527e-06, 3.2496e-04, 6.5392e-05, 4.5821e-04,\n",
      "         1.2858e-04, 2.8246e-04, 5.3906e-05, 5.7625e-06],\n",
      "        [1.5340e-04, 2.9904e-04, 3.6280e-04, 5.9558e-04, 6.3971e-05, 4.4227e-04,\n",
      "         2.8368e-04, 4.2025e-04, 1.9658e-05, 6.3982e-04, 1.2972e-04, 8.8286e-04,\n",
      "         1.8581e-04, 6.4734e-04, 1.2713e-04, 2.5792e-05],\n",
      "        [2.2712e-04, 4.2219e-04, 3.1366e-04, 6.5329e-04, 6.9997e-05, 1.5789e-04,\n",
      "         3.9729e-04, 1.6946e-04, 1.1179e-05, 6.6546e-04, 1.2981e-04, 9.8177e-04,\n",
      "         2.4333e-04, 5.8990e-04, 1.1510e-04, 2.5217e-05],\n",
      "        [6.0641e-04, 1.2651e-03, 6.6044e-04, 1.6466e-03, 1.5977e-04, 1.0426e-04,\n",
      "         1.1404e-03, 1.5614e-04, 1.3572e-05, 1.5792e-03, 3.0093e-04, 2.3426e-03,\n",
      "         6.2582e-04, 1.2760e-03, 3.7216e-04, 9.7844e-06],\n",
      "        [4.1898e-04, 8.8568e-04, 6.6863e-04, 1.3261e-03, 1.2313e-04, 2.2819e-04,\n",
      "         8.5949e-04, 2.8898e-04, 1.7019e-05, 1.3986e-03, 2.6832e-04, 2.0930e-03,\n",
      "         4.2055e-04, 1.2148e-03, 2.2342e-04, 5.4447e-05],\n",
      "        [1.1224e-04, 1.6731e-04, 1.3311e-04, 3.0564e-04, 4.3108e-05, 5.6370e-05,\n",
      "         1.4727e-04, 7.7853e-05, 9.9268e-06, 2.9307e-04, 5.9287e-05, 4.1469e-04,\n",
      "         1.4394e-04, 2.6003e-04, 4.2683e-05, 2.1198e-05],\n",
      "        [5.8891e-04, 1.6626e-03, 5.9239e-04, 6.2909e-04, 8.9298e-05, 4.7965e-03,\n",
      "         1.6632e-03, 3.1977e-03, 7.1591e-05, 6.6933e-04, 1.8617e-04, 8.1829e-04,\n",
      "         4.3828e-04, 9.3635e-04, 1.4984e-03, 2.8957e-05],\n",
      "        [1.4802e-04, 2.4551e-04, 1.8253e-04, 4.2462e-04, 5.1163e-05, 7.6562e-05,\n",
      "         2.1398e-04, 9.8549e-05, 8.8519e-06, 4.1219e-04, 8.1703e-05, 5.8102e-04,\n",
      "         1.7973e-04, 3.6166e-04, 6.3406e-05, 1.0855e-05],\n",
      "        [3.0648e-04, 4.5392e-04, 4.1564e-04, 1.0053e-03, 1.2697e-04, 1.3778e-04,\n",
      "         3.5346e-04, 2.6636e-04, 2.3000e-05, 9.3607e-04, 1.9382e-04, 1.2689e-03,\n",
      "         4.2252e-04, 8.4030e-04, 9.9319e-05, 1.2723e-05],\n",
      "        [1.8454e-04, 3.2924e-04, 3.3690e-04, 7.3242e-04, 8.3492e-05, 2.3290e-04,\n",
      "         2.5667e-04, 3.1381e-04, 2.1457e-05, 7.2820e-04, 1.5601e-04, 9.4758e-04,\n",
      "         2.8839e-04, 6.3923e-04, 8.8579e-05, 1.2137e-05],\n",
      "        [9.0875e-03, 1.4730e-02, 1.6218e-02, 3.7475e-02, 4.5830e-03, 6.8127e-03,\n",
      "         1.0518e-02, 1.2823e-02, 1.1007e-03, 3.6274e-02, 7.7252e-03, 4.6864e-02,\n",
      "         1.5385e-02, 3.2059e-02, 2.9046e-03, 6.5155e-04],\n",
      "        [1.6491e-04, 2.7187e-04, 2.2601e-04, 5.2238e-04, 6.1165e-05, 3.7093e-05,\n",
      "         2.2969e-04, 9.5007e-05, 1.0077e-05, 5.0378e-04, 1.0203e-04, 7.1177e-04,\n",
      "         2.1221e-04, 4.3803e-04, 5.6103e-05, 1.4402e-05],\n",
      "        [8.7130e-04, 1.1654e-03, 1.0296e-03, 2.2370e-03, 2.9405e-04, 3.4674e-04,\n",
      "         1.0452e-03, 5.1091e-04, 7.4232e-05, 2.1868e-03, 4.0425e-04, 3.0231e-03,\n",
      "         1.0317e-03, 2.0664e-03, 2.4133e-04, 7.9173e-05],\n",
      "        [1.7665e-04, 2.9416e-04, 2.4313e-04, 5.3292e-04, 6.3033e-05, 6.9950e-05,\n",
      "         2.6622e-04, 1.1176e-04, 1.0844e-05, 5.2779e-04, 1.0455e-04, 7.6217e-04,\n",
      "         2.1029e-04, 4.6727e-04, 6.5887e-05, 2.1912e-05],\n",
      "        [8.3109e-04, 1.2084e-03, 1.1719e-03, 2.8564e-03, 3.6792e-04, 2.7659e-04,\n",
      "         8.9688e-04, 7.1060e-04, 7.0335e-05, 2.6593e-03, 5.4951e-04, 3.5519e-03,\n",
      "         1.2313e-03, 2.3717e-03, 2.2769e-04, 5.3769e-05],\n",
      "        [1.9243e-04, 3.3777e-04, 2.8374e-04, 5.9701e-04, 6.6047e-05, 7.7445e-05,\n",
      "         3.1484e-04, 1.2512e-04, 1.0063e-05, 6.0015e-04, 1.1926e-04, 8.8389e-04,\n",
      "         2.1223e-04, 5.3704e-04, 7.4879e-05, 2.1153e-05],\n",
      "        [3.0919e-04, 5.7126e-04, 4.8546e-04, 1.0754e-03, 1.1660e-04, 1.1974e-04,\n",
      "         4.8566e-04, 2.4158e-04, 2.1124e-05, 1.0696e-03, 2.1780e-04, 1.4989e-03,\n",
      "         4.0895e-04, 9.1524e-04, 1.2471e-04, 2.7429e-05],\n",
      "        [3.6426e-04, 7.9437e-04, 7.2689e-04, 1.2272e-03, 2.1183e-04, 2.3334e-04,\n",
      "         9.1094e-04, 3.8244e-04, 1.0824e-04, 1.3175e-03, 2.5759e-04, 2.0063e-03,\n",
      "         6.3699e-04, 1.1829e-03, 2.1515e-04, 4.0225e-04],\n",
      "        [9.6459e-04, 1.5039e-03, 1.3654e-03, 3.3890e-03, 4.2463e-04, 3.2968e-04,\n",
      "         1.0948e-03, 8.2133e-04, 8.9287e-05, 3.2018e-03, 6.6074e-04, 4.1946e-03,\n",
      "         1.5131e-03, 2.7673e-03, 2.9295e-04, 6.2282e-05],\n",
      "        [1.7757e-04, 3.3822e-04, 2.8708e-04, 6.0252e-04, 7.2105e-05, 7.0010e-05,\n",
      "         3.0003e-04, 1.2928e-04, 2.0282e-05, 6.2432e-04, 1.2673e-04, 8.7997e-04,\n",
      "         2.6507e-04, 5.1809e-04, 7.4835e-05, 5.8499e-05],\n",
      "        [1.6150e-03, 1.8317e-03, 1.3121e-03, 3.8968e-03, 6.1106e-04, 1.9931e-04,\n",
      "         1.4602e-03, 5.3874e-04, 1.0256e-04, 3.2980e-03, 6.8394e-04, 4.6048e-03,\n",
      "         2.0669e-03, 3.0195e-03, 3.7710e-04, 8.3547e-05],\n",
      "        [1.4980e-04, 2.6074e-04, 2.0955e-04, 4.8927e-04, 5.6085e-05, 4.3757e-05,\n",
      "         2.1438e-04, 9.4219e-05, 9.7189e-06, 4.7683e-04, 9.7357e-05, 6.6232e-04,\n",
      "         2.0234e-04, 4.0595e-04, 5.7215e-05, 1.2579e-05],\n",
      "        [1.3004e-04, 2.8880e-04, 2.2873e-04, 4.2431e-04, 5.4854e-05, 4.2514e-04,\n",
      "         2.6492e-04, 3.5464e-04, 1.8890e-05, 4.2181e-04, 8.7867e-05, 5.7304e-04,\n",
      "         1.6157e-04, 4.3400e-04, 1.6543e-04, 1.2300e-05],\n",
      "        [8.9993e-03, 1.8847e-02, 1.7709e-02, 3.3555e-02, 3.0343e-03, 5.6589e-03,\n",
      "         1.7670e-02, 8.5833e-03, 4.5506e-04, 3.6091e-02, 7.0294e-03, 5.2150e-02,\n",
      "         9.8928e-03, 3.1594e-02, 3.9712e-03, 1.0644e-03],\n",
      "        [4.7354e-04, 5.2653e-04, 3.2635e-04, 9.9019e-04, 1.8169e-04, 2.5816e-04,\n",
      "         4.1785e-04, 2.5774e-04, 4.6526e-05, 8.4781e-04, 1.7935e-04, 1.1395e-03,\n",
      "         6.7988e-04, 7.5654e-04, 1.4544e-04, 7.3092e-05]])}, 10: {'step': tensor(11460.), 'exp_avg': tensor([-1.8696e-04,  1.3997e-04, -5.9381e-05,  2.3182e-04, -1.8359e-04,\n",
      "         4.5589e-04,  8.1088e-05,  9.9722e-04, -4.5695e-05, -1.7664e-04,\n",
      "        -1.0756e-04,  3.9368e-04, -1.0453e-04,  6.2163e-04, -9.9626e-06,\n",
      "        -1.7277e-04, -3.1508e-04, -3.2976e-04, -3.4984e-04, -2.1903e-04,\n",
      "         6.5471e-04,  1.3529e-04,  2.0893e-04,  1.0380e-04,  1.0991e-04,\n",
      "         8.7274e-05, -8.7450e-05,  3.2050e-04,  1.0189e-04, -1.8723e-05,\n",
      "         3.1980e-04, -6.1165e-05, -1.2895e-04, -3.1351e-04,  5.6322e-04,\n",
      "         3.8660e-04,  1.1941e-04,  7.8534e-06,  4.2409e-05, -2.1582e-04,\n",
      "        -3.0865e-04, -3.9475e-04, -6.4141e-05,  2.8503e-04, -2.5881e-04,\n",
      "         3.8610e-04,  5.6737e-04, -1.3458e-04, -1.9927e-04, -1.2386e-04,\n",
      "        -7.8428e-05,  7.3821e-05, -8.1328e-05, -3.6849e-04, -2.4985e-04,\n",
      "        -1.0720e-04,  3.8703e-05,  3.6542e-04,  5.6393e-05,  1.6407e-04,\n",
      "         2.1731e-04,  2.2525e-04,  1.6912e-04,  3.9324e-04,  1.0993e-04,\n",
      "        -9.2649e-05,  3.7508e-04, -2.4285e-04, -5.0466e-06, -1.6087e-04,\n",
      "        -3.1807e-06, -3.2736e-04, -1.1808e-04, -2.7474e-04, -4.2539e-04,\n",
      "         4.5916e-04,  2.3736e-04, -2.2736e-04, -4.1497e-05, -2.4525e-04,\n",
      "         2.2657e-04,  2.0288e-04, -3.9821e-04, -1.6323e-04, -2.8507e-04,\n",
      "         3.2649e-04,  2.3310e-04,  1.7839e-04,  7.1581e-04,  2.9923e-04,\n",
      "         2.4083e-04, -3.3572e-04, -1.2731e-04, -1.0792e-04,  4.7852e-04,\n",
      "         8.7707e-04,  3.3215e-05,  9.4107e-04,  2.7450e-04,  2.6929e-04]), 'exp_avg_sq': tensor([2.9076e-05, 3.0598e-05, 3.2418e-05, 3.9003e-05, 2.1396e-05, 1.9022e-05,\n",
      "        3.8790e-05, 2.6872e-05, 2.2569e-05, 2.1158e-05, 3.6030e-05, 4.1560e-05,\n",
      "        3.6704e-05, 4.7296e-05, 3.0196e-05, 2.8374e-05, 2.1008e-05, 1.8043e-05,\n",
      "        3.6224e-05, 3.8146e-05, 2.8107e-05, 2.9115e-05, 3.2248e-05, 5.4889e-05,\n",
      "        3.1834e-05, 3.1496e-05, 3.5267e-05, 2.8256e-05, 3.4770e-05, 8.6589e-05,\n",
      "        2.4818e-05, 2.0960e-05, 2.1109e-05, 3.9285e-05, 3.6542e-05, 3.1271e-05,\n",
      "        3.7522e-05, 3.9554e-05, 4.8060e-05, 2.6272e-05, 4.4381e-05, 3.1185e-05,\n",
      "        3.4544e-05, 3.9368e-05, 2.3567e-05, 4.0947e-05, 3.8063e-05, 2.7213e-05,\n",
      "        2.9950e-05, 5.0001e-05, 3.0384e-05, 5.7313e-05, 3.2998e-05, 3.7890e-05,\n",
      "        3.2636e-05, 3.3841e-05, 1.6880e-05, 2.6992e-05, 2.8389e-05, 7.1538e-05,\n",
      "        3.2820e-05, 4.0087e-05, 2.9927e-05, 4.2689e-05, 4.2273e-05, 6.1999e-05,\n",
      "        3.4460e-05, 4.3121e-05, 3.4264e-05, 3.1141e-05, 3.9794e-05, 3.9152e-05,\n",
      "        3.5142e-05, 3.0959e-05, 3.8686e-05, 4.6579e-05, 3.6877e-05, 2.7397e-05,\n",
      "        4.8234e-05, 6.6383e-05, 2.9763e-05, 3.4689e-05, 4.9709e-05, 2.7463e-05,\n",
      "        3.1992e-05, 6.6799e-05, 3.9722e-05, 3.8469e-05, 4.3709e-05, 3.2262e-05,\n",
      "        3.0689e-05, 2.8733e-05, 3.3727e-05, 3.6034e-05, 5.3366e-05, 3.4719e-05,\n",
      "        4.1667e-05, 3.9555e-05, 5.8309e-05, 2.4199e-05])}, 11: {'step': tensor(11460.), 'exp_avg': tensor([-2.3984e-11,  1.3974e-11,  1.3356e-11,  1.8941e-11, -6.8006e-13,\n",
      "        -1.3224e-11,  1.0503e-10,  4.7709e-11, -1.2050e-11, -1.4401e-11,\n",
      "        -2.6138e-11,  3.2925e-11,  3.7670e-11, -1.0730e-10, -8.0900e-11,\n",
      "         5.9959e-12,  2.2971e-11,  1.0481e-11,  7.9758e-11, -2.1374e-12,\n",
      "         3.5563e-11, -6.6296e-11,  4.6273e-11,  9.5115e-12, -7.6911e-12,\n",
      "         1.5422e-11,  3.8096e-12,  4.0606e-11, -1.4776e-11,  3.4173e-12,\n",
      "        -3.5108e-11,  2.1086e-11, -2.2951e-11, -3.9123e-11,  2.1444e-11,\n",
      "         7.1251e-11,  2.4889e-11,  4.4919e-13, -4.3075e-11,  2.1907e-11,\n",
      "         4.7946e-11,  1.4179e-10,  5.0565e-11, -3.9134e-12, -1.8810e-10,\n",
      "        -3.4431e-11,  2.4466e-13, -1.0498e-10, -3.5544e-11,  3.5643e-11,\n",
      "         1.7526e-11,  1.7079e-11, -1.4258e-11,  9.0602e-11, -2.8263e-11,\n",
      "         1.0324e-12, -9.8884e-12, -3.4759e-12,  6.4924e-12,  5.4532e-12,\n",
      "        -3.5680e-11,  6.5033e-11, -3.8236e-13, -2.6540e-12, -7.0830e-11,\n",
      "         2.9420e-11,  2.0911e-11, -1.9161e-12,  1.7824e-11, -4.6742e-12,\n",
      "        -3.8886e-11,  1.5504e-10,  1.3385e-11,  2.7104e-12,  5.0465e-11,\n",
      "         3.8495e-11, -3.8911e-11, -8.6343e-12,  5.0428e-11,  5.3261e-11,\n",
      "         7.6914e-11, -1.4236e-11, -8.9725e-13, -2.4287e-11, -4.1277e-11,\n",
      "        -1.1709e-11,  6.3291e-12,  3.0311e-11,  1.1146e-11, -4.7513e-11,\n",
      "        -2.2845e-11,  2.0384e-11,  2.1022e-11,  3.5578e-12,  6.6290e-12,\n",
      "        -2.0978e-10, -3.4928e-11, -2.3784e-12, -1.3714e-10, -5.2305e-12]), 'exp_avg_sq': tensor([1.4372e-18, 9.0189e-19, 9.2395e-19, 1.1322e-18, 1.0719e-18, 7.3909e-19,\n",
      "        8.5022e-19, 1.6207e-18, 1.3309e-18, 1.0442e-18, 1.1680e-18, 1.0641e-18,\n",
      "        1.3450e-18, 1.8143e-18, 7.2892e-19, 1.3941e-18, 8.7380e-19, 7.5026e-19,\n",
      "        8.5788e-19, 1.1468e-18, 1.0066e-18, 1.2868e-18, 1.2382e-18, 1.4550e-18,\n",
      "        3.7926e-18, 8.7509e-19, 1.2381e-18, 9.3265e-19, 1.0127e-18, 1.9115e-18,\n",
      "        8.2447e-19, 1.0358e-18, 9.1657e-19, 2.5953e-18, 1.3074e-18, 1.1211e-18,\n",
      "        1.3873e-18, 1.1347e-18, 1.1929e-18, 7.1343e-19, 1.4004e-18, 2.3031e-18,\n",
      "        1.2978e-18, 8.0097e-19, 1.0542e-18, 1.1430e-18, 1.3027e-18, 1.3859e-18,\n",
      "        8.8777e-19, 1.3804e-18, 1.1889e-18, 1.1475e-18, 7.6607e-19, 1.1290e-18,\n",
      "        1.2127e-18, 7.3759e-19, 1.4283e-18, 1.7534e-18, 1.0329e-18, 2.8162e-18,\n",
      "        9.2922e-19, 1.4503e-18, 9.5070e-19, 1.5585e-18, 1.3655e-18, 2.1949e-18,\n",
      "        1.1677e-18, 1.0089e-18, 1.2910e-18, 1.3326e-18, 1.2357e-18, 1.0415e-18,\n",
      "        9.1522e-19, 1.3088e-18, 1.1046e-18, 1.7955e-18, 1.8285e-18, 7.8995e-19,\n",
      "        1.0256e-18, 1.8366e-18, 1.0604e-18, 1.4423e-18, 1.2092e-18, 1.2108e-18,\n",
      "        1.0035e-18, 1.8432e-18, 1.2309e-18, 1.1581e-18, 1.3276e-18, 8.9481e-19,\n",
      "        1.2736e-18, 7.4837e-19, 1.0931e-18, 1.2673e-18, 1.2807e-18, 1.8012e-18,\n",
      "        1.0558e-18, 2.3516e-18, 7.0535e-18, 7.3451e-19])}, 12: {'step': tensor(11460.), 'exp_avg': tensor([ 0.0816, -0.2637, -0.0660,  0.1185,  0.3156, -0.0088, -0.0608, -0.1164]), 'exp_avg_sq': tensor([ 4.2092, 39.9286,  5.5388,  7.2540, 28.9292,  5.2296,  0.9237,  8.9357])}, 13: {'step': tensor(11460.), 'exp_avg': tensor([[-0.0101, -0.0083,  0.0036],\n",
      "        [-0.0077,  0.0367, -0.0871],\n",
      "        [ 0.0058, -0.0030,  0.0732],\n",
      "        [ 0.0195, -0.0015, -0.0612],\n",
      "        [-0.0300, -0.0300,  0.0493],\n",
      "        [ 0.0299, -0.0023, -0.0153],\n",
      "        [ 0.0064,  0.0076, -0.0209],\n",
      "        [-0.0141,  0.0008,  0.0583]]), 'exp_avg_sq': tensor([[5.3582e-02, 2.2710e-03, 4.4627e-01],\n",
      "        [4.5593e-01, 5.5109e-02, 3.8380e+00],\n",
      "        [1.7815e-01, 8.3541e-03, 1.1394e+00],\n",
      "        [3.7746e-02, 6.3761e-03, 4.0089e-01],\n",
      "        [2.5320e-01, 2.3448e-02, 2.7613e+00],\n",
      "        [3.6147e-02, 5.4496e-03, 3.9674e-01],\n",
      "        [1.1195e-02, 7.4708e-04, 1.5640e-01],\n",
      "        [3.8347e-02, 3.4259e-03, 3.2184e-01]])}, 14: {'step': tensor(11460.), 'exp_avg': tensor([-4.6550e-04,  2.8798e-04,  8.3898e-05,  2.7620e-04, -1.3066e-04,\n",
      "        -2.9401e-04, -1.8336e-04, -2.8977e-06,  1.7180e-04,  3.6991e-04,\n",
      "        -3.3716e-04,  5.2482e-06, -2.3150e-04,  1.4203e-04,  3.8900e-04,\n",
      "        -6.7307e-04, -4.6285e-04, -2.0412e-04, -3.7872e-04,  2.2007e-04,\n",
      "        -2.9127e-05,  2.3521e-05,  7.6939e-05,  1.2837e-04,  2.1033e-06,\n",
      "        -3.1763e-04,  6.5805e-05,  2.1144e-04,  3.5445e-04, -1.4096e-05,\n",
      "         8.7644e-05,  1.0915e-04, -2.6249e-04, -4.7472e-04, -2.6716e-05,\n",
      "        -5.1013e-04, -2.5615e-05, -2.1040e-04,  8.7971e-04, -1.7212e-04,\n",
      "        -5.0966e-04, -2.7255e-04, -6.0673e-05, -3.3697e-05, -3.9009e-04,\n",
      "         1.7756e-04,  7.8867e-05, -8.1888e-05, -7.0668e-05,  2.4481e-04,\n",
      "        -1.6542e-05, -2.1813e-04,  7.6561e-06, -1.2028e-04,  7.4684e-06,\n",
      "        -2.5164e-04,  5.2483e-04,  3.8749e-04, -1.8128e-04, -3.4855e-04,\n",
      "         1.5351e-04, -4.2280e-04,  6.3280e-05, -5.9620e-04,  5.3910e-04,\n",
      "        -1.0962e-04, -3.9465e-05, -6.1849e-04, -5.1944e-04, -1.0362e-04,\n",
      "        -1.5110e-04, -2.8143e-04,  1.7230e-04, -1.7016e-04,  1.6400e-04,\n",
      "        -1.6839e-04, -3.2270e-04,  8.5317e-05, -1.9895e-04, -7.1461e-05,\n",
      "         3.1839e-05,  1.6981e-04, -2.7473e-04, -1.7354e-04, -5.8717e-04,\n",
      "         6.2214e-05,  3.8824e-04, -2.0995e-04, -2.5552e-04, -2.3275e-04,\n",
      "         3.3734e-04, -8.2279e-05, -1.5186e-04, -4.1933e-04, -2.7011e-04,\n",
      "         5.4464e-05, -4.4164e-04,  4.0458e-04,  2.3932e-04,  2.1385e-04]), 'exp_avg_sq': tensor([2.7549e-05, 3.1329e-05, 1.4110e-05, 1.2507e-05, 1.5874e-05, 3.4315e-05,\n",
      "        1.4319e-05, 1.1076e-05, 3.4076e-05, 1.8828e-05, 1.4514e-05, 1.6837e-05,\n",
      "        3.2373e-05, 1.7790e-05, 1.2874e-05, 1.6602e-05, 1.3671e-05, 3.0785e-05,\n",
      "        1.2176e-05, 1.6021e-05, 1.2838e-05, 2.0808e-05, 2.2715e-05, 1.9241e-05,\n",
      "        1.0752e-05, 1.4431e-05, 2.7463e-05, 2.0737e-05, 1.6663e-05, 2.1828e-05,\n",
      "        1.9625e-05, 1.7038e-05, 1.4210e-04, 2.0952e-05, 1.3065e-05, 1.2952e-05,\n",
      "        1.3935e-05, 3.5956e-05, 2.8063e-05, 1.0463e-04, 1.5301e-05, 3.4702e-05,\n",
      "        1.9810e-05, 2.7577e-05, 3.0637e-05, 2.3948e-05, 1.3334e-05, 2.3721e-05,\n",
      "        1.4745e-05, 1.9410e-05, 1.5498e-05, 1.9420e-05, 2.8984e-05, 2.8232e-05,\n",
      "        1.0349e-05, 4.1255e-05, 1.1443e-05, 1.9659e-05, 2.5298e-05, 2.8697e-05,\n",
      "        1.8026e-05, 2.6594e-05, 2.1481e-05, 3.3669e-05, 2.0813e-05, 2.2520e-05,\n",
      "        1.3021e-05, 3.8557e-05, 3.7798e-05, 2.0468e-05, 1.7954e-05, 1.3405e-05,\n",
      "        3.6087e-05, 1.9412e-05, 3.0477e-05, 1.5250e-05, 2.2375e-05, 1.3573e-05,\n",
      "        2.8538e-05, 2.9816e-05, 1.5550e-05, 5.4714e-05, 2.6018e-05, 1.4453e-05,\n",
      "        2.1942e-05, 2.1326e-05, 2.3322e-05, 4.2276e-05, 1.8684e-05, 1.7528e-05,\n",
      "        1.1474e-05, 2.2113e-05, 2.5386e-05, 2.0440e-05, 7.4672e-05, 1.3052e-05,\n",
      "        1.5614e-05, 5.0563e-05, 5.6355e-05, 1.4837e-05])}, 15: {'step': tensor(11460.), 'exp_avg': tensor([-8.1191e-04, -2.7044e-04, -1.6125e-03, -9.6898e-04, -3.5238e-04,\n",
      "        -8.3360e-04, -4.5278e-04, -1.0268e-03, -1.4955e-03, -1.4275e-04,\n",
      "        -1.4834e-03, -6.7386e-04, -1.4366e-03, -1.2347e-04, -5.1025e-04,\n",
      "        -2.4876e-03, -7.3758e-04, -1.3382e-03, -1.6116e-03, -6.3581e-04,\n",
      "        -3.2930e-04, -7.8407e-04, -1.2088e-03, -9.2612e-04, -5.9017e-04,\n",
      "        -6.1659e-04, -7.6354e-04,  1.6867e-04, -3.7934e-04, -8.2179e-04,\n",
      "        -7.9777e-04, -1.3855e-03, -1.3915e-03, -1.4711e-03, -1.2586e-03,\n",
      "        -1.5754e-03, -2.0529e-03, -1.5850e-03, -1.3748e-03, -1.4410e-03,\n",
      "        -1.4372e-03, -9.8138e-04, -9.1033e-04, -6.1422e-04, -9.9210e-04,\n",
      "        -2.9023e-04, -1.6846e-03, -1.0208e-03, -1.0274e-03, -1.2155e-03,\n",
      "        -1.6984e-03, -1.7919e-03, -1.5291e-03, -1.4067e-03, -1.7291e-03,\n",
      "        -8.4781e-04, -1.3922e-03, -9.3379e-04, -1.2172e-03, -1.5503e-03,\n",
      "         2.1894e-04, -1.0130e-03, -1.1053e-03, -1.1376e-03, -1.0753e-03,\n",
      "        -1.2467e-03, -9.2214e-04, -9.0336e-04, -1.6641e-03, -1.8141e-03,\n",
      "        -8.5619e-04, -8.0540e-04, -1.1436e-03, -1.8467e-03, -1.1437e-03,\n",
      "        -8.0113e-04, -1.0472e-03, -7.6806e-04, -1.0083e-03, -1.2770e-03,\n",
      "         2.8411e-05,  6.2697e-05, -1.7532e-03, -3.6141e-04, -4.1830e-04,\n",
      "         9.9755e-05, -5.1382e-04, -1.2842e-03, -1.4663e-04, -5.5631e-04,\n",
      "        -8.4625e-04, -1.0379e-03, -1.1815e-03, -7.8639e-04, -1.5017e-03,\n",
      "        -3.8184e-04, -8.7115e-04, -4.1466e-04, -9.0618e-04, -1.6281e-03]), 'exp_avg_sq': tensor([0.0004, 0.0005, 0.0003, 0.0004, 0.0003, 0.0008, 0.0005, 0.0004, 0.0004,\n",
      "        0.0004, 0.0004, 0.0004, 0.0007, 0.0004, 0.0003, 0.0004, 0.0004, 0.0004,\n",
      "        0.0004, 0.0004, 0.0003, 0.0004, 0.0004, 0.0006, 0.0006, 0.0005, 0.0004,\n",
      "        0.0005, 0.0004, 0.0005, 0.0005, 0.0004, 0.0010, 0.0004, 0.0005, 0.0004,\n",
      "        0.0004, 0.0004, 0.0005, 0.0008, 0.0004, 0.0007, 0.0005, 0.0006, 0.0007,\n",
      "        0.0004, 0.0006, 0.0004, 0.0004, 0.0004, 0.0004, 0.0006, 0.0005, 0.0005,\n",
      "        0.0004, 0.0004, 0.0004, 0.0005, 0.0004, 0.0009, 0.0005, 0.0006, 0.0004,\n",
      "        0.0006, 0.0005, 0.0004, 0.0004, 0.0007, 0.0004, 0.0004, 0.0004, 0.0004,\n",
      "        0.0005, 0.0005, 0.0005, 0.0005, 0.0006, 0.0004, 0.0005, 0.0005, 0.0004,\n",
      "        0.0005, 0.0006, 0.0003, 0.0005, 0.0005, 0.0008, 0.0004, 0.0006, 0.0005,\n",
      "        0.0004, 0.0005, 0.0005, 0.0006, 0.0007, 0.0004, 0.0005, 0.0007, 0.0005,\n",
      "        0.0005])}, 16: {'step': tensor(11460.), 'exp_avg': tensor([-0.0170, -0.0390,  0.0293, -0.0156, -0.0382,  0.0399,  0.0270,  0.0136]), 'exp_avg_sq': tensor([0.4895, 0.3883, 0.7349, 0.0314, 1.6174, 0.3852, 0.3522, 0.4324])}, 17: {'step': tensor(11460.), 'exp_avg': tensor([[ 0.0380, -0.0203, -0.0051, -0.0070, -0.0289,  0.0058,  0.0026,  0.0174],\n",
      "        [-0.0082,  0.0127,  0.0222,  0.0044,  0.0146, -0.0108, -0.0092, -0.0194],\n",
      "        [ 0.0318, -0.0148, -0.0219, -0.0144, -0.0184,  0.0002, -0.0094,  0.0421],\n",
      "        [ 0.0288, -0.0100, -0.0043, -0.0097, -0.0158, -0.0024, -0.0078,  0.0240],\n",
      "        [-0.0270,  0.0089,  0.0207,  0.0148,  0.0088,  0.0055,  0.0173, -0.0429],\n",
      "        [-0.0273,  0.0004, -0.0132,  0.0074,  0.0032,  0.0137,  0.0206, -0.0113],\n",
      "        [ 0.0075, -0.0031, -0.0096, -0.0045, -0.0012, -0.0016, -0.0064,  0.0145],\n",
      "        [-0.0436,  0.0261,  0.0112,  0.0090,  0.0377, -0.0105, -0.0076, -0.0244]]), 'exp_avg_sq': tensor([[0.5330, 0.0658, 0.0144, 0.0329, 0.1186, 0.0353, 0.1125, 0.1726],\n",
      "        [0.4923, 0.0707, 0.0134, 0.0255, 0.1262, 0.0272, 0.0853, 0.1358],\n",
      "        [0.8770, 0.1302, 0.0263, 0.0457, 0.2355, 0.0500, 0.1510, 0.2442],\n",
      "        [0.0238, 0.0042, 0.0017, 0.0015, 0.0083, 0.0036, 0.0088, 0.0077],\n",
      "        [1.4427, 0.2186, 0.0497, 0.0728, 0.3937, 0.0897, 0.2650, 0.3905],\n",
      "        [0.3942, 0.0490, 0.0088, 0.0232, 0.0804, 0.0219, 0.0754, 0.1234],\n",
      "        [0.3404, 0.0539, 0.0127, 0.0160, 0.0936, 0.0211, 0.0614, 0.0867],\n",
      "        [0.2851, 0.0339, 0.0072, 0.0156, 0.0609, 0.0176, 0.0604, 0.0820]])}, 18: {'step': tensor(11460.), 'exp_avg': tensor([-1.9427e-04,  8.7565e-05,  7.9105e-05,  1.9704e-04,  1.0502e-06,\n",
      "         1.0705e-05, -1.7384e-04,  1.7370e-04,  1.4189e-04,  2.5024e-04,\n",
      "        -2.6327e-04,  9.6550e-05, -7.2055e-06, -4.0773e-05,  3.0840e-04,\n",
      "        -1.9372e-04, -1.5897e-04, -1.2200e-04, -8.0226e-05,  8.3621e-05,\n",
      "        -8.3113e-05, -5.1747e-05,  6.2577e-05,  8.1363e-05, -4.5743e-05,\n",
      "        -2.4713e-04,  6.6024e-05,  2.1054e-05,  1.9955e-04, -9.4038e-06,\n",
      "         2.7156e-04,  6.4840e-06, -5.8295e-05, -2.8486e-04, -1.5900e-04,\n",
      "        -2.4420e-04, -3.0895e-05,  9.3772e-05,  3.6768e-04, -1.2893e-04,\n",
      "        -3.0730e-04, -3.0503e-04, -3.9183e-05, -2.6915e-05, -2.3057e-04,\n",
      "         4.9547e-05,  5.4383e-05,  7.2234e-05, -1.1214e-04, -9.4819e-05,\n",
      "        -2.5638e-05, -2.9574e-04, -2.3401e-05, -1.4278e-04, -9.1397e-05,\n",
      "        -2.7659e-04,  3.0219e-04,  9.1732e-05, -4.8867e-05, -8.2242e-05,\n",
      "        -1.4506e-04, -3.9280e-05,  5.9985e-06, -1.2557e-04,  8.4767e-05,\n",
      "        -1.6607e-04,  2.3996e-05, -3.1141e-04, -2.1835e-04, -5.4538e-05,\n",
      "         9.0468e-05, -2.4289e-04,  5.2444e-05, -1.6604e-05,  7.7170e-05,\n",
      "        -2.4285e-05, -2.3796e-04, -1.2437e-04, -1.8531e-04, -8.2083e-05,\n",
      "         1.1297e-04,  1.2989e-04, -4.7780e-07, -3.5143e-04, -3.3199e-04,\n",
      "         8.3218e-05,  2.3616e-04, -2.3098e-04, -4.2397e-04, -3.8444e-05,\n",
      "         2.8881e-04, -9.6187e-05, -2.4949e-04, -3.0828e-04, -6.0749e-05,\n",
      "        -1.0628e-04, -2.0166e-04,  5.0716e-04,  2.1419e-04,  1.6134e-04]), 'exp_avg_sq': tensor([8.4531e-06, 7.3873e-06, 1.0815e-05, 4.4471e-06, 4.7933e-06, 1.1002e-05,\n",
      "        6.7371e-06, 4.3403e-06, 8.1760e-06, 6.4342e-06, 1.4399e-05, 6.1627e-06,\n",
      "        1.9490e-05, 6.9018e-06, 5.5513e-06, 5.9473e-06, 5.3950e-06, 7.7192e-06,\n",
      "        5.4860e-06, 5.1080e-06, 4.5758e-06, 8.1458e-06, 1.2996e-05, 8.2559e-06,\n",
      "        3.6688e-06, 6.8884e-06, 8.0692e-06, 9.0678e-06, 6.0242e-06, 7.0898e-06,\n",
      "        1.0990e-05, 5.5258e-06, 1.2426e-05, 1.1778e-05, 6.1352e-06, 6.6562e-06,\n",
      "        4.3583e-06, 9.4649e-06, 1.1863e-05, 2.4177e-05, 7.0026e-06, 7.0863e-06,\n",
      "        1.3247e-05, 7.6559e-06, 6.9972e-06, 7.5941e-06, 8.6659e-06, 9.9585e-06,\n",
      "        8.2124e-06, 6.3445e-06, 7.3395e-06, 8.3085e-06, 6.0759e-06, 6.6686e-06,\n",
      "        5.0944e-06, 1.3673e-05, 4.3862e-06, 1.0201e-05, 7.6891e-06, 1.9412e-05,\n",
      "        7.4440e-06, 1.2934e-05, 9.6639e-06, 1.2940e-05, 1.7101e-05, 1.1446e-05,\n",
      "        1.0567e-05, 1.6060e-05, 1.0459e-05, 6.5125e-06, 8.4180e-06, 4.6284e-06,\n",
      "        8.5701e-06, 6.7908e-06, 8.7430e-06, 6.9479e-06, 9.4734e-06, 1.1808e-05,\n",
      "        9.8013e-06, 1.2020e-05, 7.1669e-06, 1.7335e-05, 9.0739e-06, 6.9415e-06,\n",
      "        1.4421e-05, 5.7678e-06, 1.0313e-05, 1.1966e-05, 9.6369e-06, 1.1670e-05,\n",
      "        9.0520e-06, 1.0933e-05, 9.7678e-06, 1.3243e-05, 2.8578e-05, 5.4462e-06,\n",
      "        6.1482e-06, 2.2446e-05, 2.0495e-05, 8.4297e-06])}, 19: {'step': tensor(11460.), 'exp_avg': tensor([ 1.1221e-03, -1.7348e-04,  3.6155e-05,  9.4742e-04,  4.8494e-04,\n",
      "         2.3022e-04,  2.3647e-03, -2.0472e-04,  2.0712e-04,  3.1127e-04,\n",
      "         9.8157e-04,  6.8521e-04,  2.5544e-04,  2.0087e-03, -1.9244e-04,\n",
      "         4.6975e-04,  7.3326e-04, -5.6226e-05, -6.8971e-04, -9.2147e-04,\n",
      "         7.7154e-04,  1.4939e-03,  6.4493e-04,  7.1122e-05,  1.2694e-03,\n",
      "         1.0762e-03,  9.5649e-04,  8.2755e-04,  7.1942e-04,  1.4719e-03,\n",
      "         7.1217e-04,  1.4252e-04,  3.9242e-04,  1.2659e-03,  1.8625e-03,\n",
      "         1.3518e-03, -1.1926e-03,  9.3473e-04,  5.8011e-04,  1.2758e-03,\n",
      "        -2.6386e-04,  5.1861e-04,  3.4605e-04,  1.9989e-04,  9.9391e-04,\n",
      "         9.4795e-04, -1.5034e-05, -7.5761e-04,  1.2458e-03, -3.0561e-04,\n",
      "         2.6160e-04,  1.1388e-04, -2.8934e-04, -3.3495e-04, -2.5960e-04,\n",
      "         8.9638e-04, -1.0058e-03,  1.5722e-03, -6.5495e-04,  1.4352e-04,\n",
      "         1.6483e-03, -3.3124e-05,  1.4545e-03,  8.8643e-04,  9.5270e-04,\n",
      "        -2.3716e-04,  1.0229e-04,  1.6646e-04,  5.7709e-04,  2.9121e-04,\n",
      "         4.4499e-04,  1.0541e-03, -1.0176e-04, -1.2064e-03,  1.5000e-04,\n",
      "         1.8370e-03,  2.9074e-04,  1.3485e-03,  5.0991e-04,  6.9544e-04,\n",
      "         1.9859e-03,  1.3697e-03,  1.0523e-04,  1.5123e-03,  1.8107e-03,\n",
      "         2.9950e-03,  1.8548e-04, -1.9768e-04,  2.0602e-03,  9.9175e-04,\n",
      "        -9.5682e-05,  2.0046e-03,  3.5735e-04,  1.3088e-03,  9.8393e-04,\n",
      "         1.3897e-03,  8.7945e-04,  1.1085e-03,  1.1806e-03,  5.0797e-04]), 'exp_avg_sq': tensor([0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0005, 0.0004, 0.0004, 0.0004,\n",
      "        0.0004, 0.0004, 0.0004, 0.0004, 0.0005, 0.0004, 0.0004, 0.0005, 0.0004,\n",
      "        0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0005, 0.0005, 0.0005, 0.0004,\n",
      "        0.0005, 0.0005, 0.0005, 0.0004, 0.0005, 0.0006, 0.0005, 0.0004, 0.0005,\n",
      "        0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005,\n",
      "        0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005,\n",
      "        0.0005, 0.0004, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005,\n",
      "        0.0005, 0.0005, 0.0005, 0.0004, 0.0005, 0.0004, 0.0005, 0.0005, 0.0005,\n",
      "        0.0005, 0.0005, 0.0006, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005,\n",
      "        0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0006, 0.0005, 0.0006, 0.0006,\n",
      "        0.0005, 0.0006, 0.0006, 0.0006, 0.0005, 0.0005, 0.0006, 0.0005, 0.0006,\n",
      "        0.0005])}, 20: {'step': tensor(11460.), 'exp_avg': tensor([-0.0215,  0.0100, -0.0404,  0.0033,  0.0078,  0.0393,  0.0140, -0.0125]), 'exp_avg_sq': tensor([1.1799, 0.0615, 0.4606, 0.0714, 0.2005, 0.8285, 0.3474, 0.3015])}, 21: {'step': tensor(11460.), 'exp_avg': tensor([[-0.0178,  0.0420, -0.0561, -0.0993, -0.0063,  0.0025,  0.1578, -0.0266],\n",
      "        [ 0.0200, -0.0117,  0.0160,  0.0290, -0.0079, -0.0256, -0.0620,  0.0441],\n",
      "        [ 0.0349, -0.0235,  0.0690,  0.1111, -0.0115, -0.0105, -0.2012,  0.0245],\n",
      "        [ 0.0021, -0.0029, -0.0011,  0.0007,  0.0004, -0.0052, -0.0022,  0.0088],\n",
      "        [-0.0240,  0.0251, -0.0436, -0.0770,  0.0027,  0.0126,  0.1353, -0.0297],\n",
      "        [ 0.0131, -0.0324,  0.0321,  0.0599,  0.0047, -0.0107, -0.0949,  0.0353],\n",
      "        [-0.0397,  0.0256, -0.0583, -0.0961,  0.0146,  0.0297,  0.1825, -0.0558],\n",
      "        [ 0.0115, -0.0223,  0.0420,  0.0719,  0.0033,  0.0072, -0.1153, -0.0007]]), 'exp_avg_sq': tensor([[1.9146e-01, 4.1730e-02, 4.6136e-01, 7.4137e-01, 1.0559e-01, 4.1610e-01,\n",
      "         2.7081e+00, 8.6524e-01],\n",
      "        [9.1821e-03, 2.1024e-03, 2.0579e-02, 3.4711e-02, 4.3175e-03, 2.3007e-02,\n",
      "         1.2095e-01, 4.9725e-02],\n",
      "        [8.1428e-02, 2.1023e-02, 2.6247e-01, 4.4598e-01, 3.9223e-02, 2.3169e-01,\n",
      "         1.4378e+00, 5.1076e-01],\n",
      "        [1.0096e-02, 1.3351e-03, 1.7353e-02, 3.1821e-02, 4.2630e-03, 2.2747e-02,\n",
      "         1.1916e-01, 4.8539e-02],\n",
      "        [4.0604e-02, 7.4628e-03, 8.9191e-02, 1.5400e-01, 2.0171e-02, 8.7658e-02,\n",
      "         5.7307e-01, 1.9139e-01],\n",
      "        [9.1490e-02, 2.0922e-02, 2.4948e-01, 4.1044e-01, 5.6600e-02, 1.9570e-01,\n",
      "         1.4955e+00, 4.2141e-01],\n",
      "        [6.3952e-02, 1.7258e-02, 1.8769e-01, 3.1294e-01, 3.2046e-02, 1.8045e-01,\n",
      "         1.0193e+00, 3.9483e-01],\n",
      "        [6.1714e-02, 1.1990e-02, 1.5664e-01, 2.5300e-01, 3.1723e-02, 1.3451e-01,\n",
      "         9.0187e-01, 2.7353e-01]])}, 22: {'step': tensor(11460.), 'exp_avg': tensor([-2.1597e-04,  4.9547e-04, -1.2065e-04,  1.3837e-04, -1.8575e-04,\n",
      "         1.1091e-04, -1.5105e-04,  6.6894e-04,  2.2480e-04, -2.5918e-05,\n",
      "        -2.2678e-04,  1.9835e-04,  1.6067e-05,  3.5843e-04,  1.6387e-04,\n",
      "        -2.5337e-04, -5.1066e-04, -8.2693e-05, -5.0854e-04, -3.4580e-04,\n",
      "         5.2420e-04, -4.2053e-04,  2.3440e-04,  2.0082e-05, -1.4077e-04,\n",
      "        -1.1987e-04,  7.2946e-05,  2.7431e-04,  6.2109e-04,  1.1441e-04,\n",
      "         2.1315e-04, -1.9613e-05, -1.4869e-04, -4.8837e-04,  8.9322e-05,\n",
      "        -1.1043e-04,  3.8319e-04, -1.5598e-04,  2.2357e-04, -3.8131e-04,\n",
      "        -6.1391e-04, -6.7519e-04,  2.2417e-05,  2.3767e-04, -6.3011e-04,\n",
      "         2.9874e-04,  3.3763e-04, -9.7940e-05, -4.7220e-04, -2.6477e-04,\n",
      "        -3.0006e-04,  1.3678e-04, -4.5030e-05, -4.8706e-04, -2.9500e-04,\n",
      "        -1.3114e-04,  2.8423e-04,  2.2946e-04,  4.0568e-04,  3.4787e-04,\n",
      "         4.8734e-04,  3.9137e-04,  4.0751e-04,  2.7442e-05,  1.8914e-04,\n",
      "        -1.7978e-04,  4.5233e-04, -6.0993e-04, -5.2217e-04, -2.1487e-04,\n",
      "         4.3385e-04, -4.4504e-04, -2.0033e-04, -3.2100e-04, -1.5315e-04,\n",
      "         3.4438e-04,  6.5044e-05, -1.8365e-04, -2.3056e-05,  4.3773e-05,\n",
      "        -4.9970e-05,  2.6017e-04, -1.4249e-04, -5.2624e-04, -6.8513e-04,\n",
      "        -7.7239e-05,  4.5552e-04,  1.5383e-04, -2.3759e-04, -3.3849e-04,\n",
      "         4.5722e-04, -1.4429e-04, -9.9272e-05,  6.5490e-05, -4.0423e-04,\n",
      "         5.4980e-04,  1.3533e-04,  9.4336e-04,  1.9808e-04,  1.5560e-04]), 'exp_avg_sq': tensor([5.1650e-05, 5.5767e-05, 7.2820e-05, 3.1856e-05, 4.0921e-05, 3.1406e-05,\n",
      "        5.4241e-05, 4.0965e-05, 5.9623e-05, 4.4359e-05, 7.5579e-05, 4.8117e-05,\n",
      "        3.4777e-05, 5.2236e-05, 3.4514e-05, 7.1246e-05, 4.0801e-05, 3.6455e-05,\n",
      "        4.3530e-05, 4.2226e-05, 4.0334e-05, 4.2529e-05, 5.0702e-05, 3.7242e-05,\n",
      "        4.5060e-05, 4.4074e-05, 3.8384e-05, 5.6478e-05, 5.8495e-05, 5.7412e-05,\n",
      "        4.5300e-05, 4.1691e-05, 4.1610e-05, 4.6921e-05, 3.3897e-05, 4.6417e-05,\n",
      "        4.4515e-05, 4.7297e-05, 3.9625e-05, 4.5007e-05, 4.5133e-05, 4.2418e-05,\n",
      "        4.5241e-05, 2.9009e-05, 2.9550e-05, 3.6826e-05, 3.5710e-05, 5.2002e-05,\n",
      "        3.8876e-05, 3.7688e-05, 4.0329e-05, 3.7411e-05, 4.2733e-05, 4.2941e-05,\n",
      "        4.9069e-05, 3.1747e-05, 3.9733e-05, 4.8663e-05, 3.3074e-05, 7.2250e-05,\n",
      "        2.9647e-05, 6.1724e-05, 3.0881e-05, 6.0786e-05, 5.2020e-05, 3.6913e-05,\n",
      "        4.0362e-05, 3.6145e-05, 4.2497e-05, 3.6984e-05, 5.3224e-05, 2.5419e-05,\n",
      "        4.2222e-05, 4.2569e-05, 4.2559e-05, 2.8412e-05, 4.1245e-05, 4.1034e-05,\n",
      "        3.7847e-05, 4.3438e-05, 4.5816e-05, 4.9124e-05, 3.3211e-05, 2.9506e-05,\n",
      "        4.9573e-05, 3.3603e-05, 4.5685e-05, 2.9663e-05, 4.2324e-05, 4.9018e-05,\n",
      "        3.2802e-05, 3.2022e-05, 4.1795e-05, 5.7879e-05, 5.3820e-05, 2.2544e-05,\n",
      "        3.0446e-05, 3.5469e-05, 6.6317e-05, 3.4623e-05])}, 23: {'step': tensor(11460.), 'exp_avg': tensor([ 3.7393e-04, -8.7696e-04,  5.2894e-04, -2.1088e-03, -1.3512e-03,\n",
      "        -5.2493e-04, -1.8676e-03,  2.9225e-04, -1.7824e-03, -1.3567e-03,\n",
      "         3.1664e-04, -2.8890e-03, -2.5141e-03, -3.0346e-03, -8.8151e-04,\n",
      "        -2.2242e-03, -2.1914e-03, -4.7156e-04, -1.3927e-03, -6.4463e-05,\n",
      "        -2.0250e-03, -1.9767e-03, -1.7632e-03, -2.7636e-04, -2.2209e-03,\n",
      "        -2.3178e-03, -4.8230e-04, -2.2588e-03, -6.9634e-04, -1.2711e-03,\n",
      "        -2.4057e-03, -1.7262e-03, -1.4393e-03, -2.0806e-03, -1.9603e-03,\n",
      "        -1.9720e-03, -8.0886e-04, -2.3064e-03, -1.7210e-03, -1.6167e-03,\n",
      "        -4.0235e-04, -9.7447e-04, -1.4252e-03,  3.1639e-04, -7.5082e-04,\n",
      "        -2.9267e-03, -2.6244e-03, -1.9186e-04, -6.3920e-05, -3.6375e-04,\n",
      "        -1.5316e-03, -9.7013e-04, -1.4462e-03,  2.3112e-04, -5.7531e-04,\n",
      "        -2.2341e-03, -6.0821e-05, -1.5937e-03, -1.8425e-03,  1.7183e-04,\n",
      "        -2.9837e-03,  4.9987e-04, -1.9733e-03, -8.1208e-04, -2.5148e-03,\n",
      "        -5.5211e-04, -6.9346e-04, -2.9655e-03, -1.1687e-03, -2.6193e-03,\n",
      "        -9.5839e-04, -1.8201e-03, -1.7634e-03,  3.3489e-04, -7.5105e-04,\n",
      "        -3.0554e-03, -2.6576e-03, -1.2799e-03, -8.4742e-04, -1.3731e-03,\n",
      "        -1.4033e-03, -1.8892e-03, -8.6156e-04,  3.9109e-04, -2.3724e-03,\n",
      "        -2.5006e-03, -1.7886e-03,  4.1819e-04, -1.4571e-03, -2.5259e-03,\n",
      "        -2.2631e-03, -2.0872e-03, -1.7391e-03, -1.7782e-03, -2.3374e-04,\n",
      "        -9.3991e-04, -8.2648e-04, -2.9493e-03, -7.6533e-04, -2.6765e-03]), 'exp_avg_sq': tensor([0.0010, 0.0010, 0.0010, 0.0009, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
      "        0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0010, 0.0009,\n",
      "        0.0010, 0.0010, 0.0009, 0.0010, 0.0009, 0.0010, 0.0010, 0.0010, 0.0009,\n",
      "        0.0010, 0.0010, 0.0009, 0.0010, 0.0009, 0.0009, 0.0010, 0.0009, 0.0010,\n",
      "        0.0010, 0.0010, 0.0009, 0.0009, 0.0010, 0.0010, 0.0009, 0.0009, 0.0010,\n",
      "        0.0009, 0.0009, 0.0010, 0.0009, 0.0010, 0.0009, 0.0009, 0.0009, 0.0009,\n",
      "        0.0010, 0.0010, 0.0010, 0.0010, 0.0009, 0.0010, 0.0010, 0.0008, 0.0010,\n",
      "        0.0010, 0.0010, 0.0009, 0.0010, 0.0008, 0.0009, 0.0010, 0.0008, 0.0009,\n",
      "        0.0010, 0.0009, 0.0010, 0.0009, 0.0009, 0.0009, 0.0009, 0.0008, 0.0010,\n",
      "        0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0008, 0.0010, 0.0010,\n",
      "        0.0009, 0.0009, 0.0010, 0.0010, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009,\n",
      "        0.0009])}, 24: {'step': tensor(11460.), 'exp_avg': tensor([-1.1868e-04, -2.1416e-04,  1.1840e-04,  1.7778e-05,  2.0953e-04,\n",
      "        -4.3148e-05,  1.6638e-04, -1.3610e-04]), 'exp_avg_sq': tensor([2.2905e-06, 2.3502e-06, 3.6627e-07, 1.1132e-06, 2.7026e-06, 4.4549e-07,\n",
      "        1.6892e-06, 2.1803e-06])}, 25: {'step': tensor(11460.), 'exp_avg': tensor([[ 4.8601e-05, -7.8770e-05,  3.6021e-04,  7.7547e-04,  2.1001e-04,\n",
      "         -1.5397e-03, -5.4916e-04,  7.9024e-04],\n",
      "        [ 5.2876e-04,  4.1520e-06,  1.9268e-04,  1.2474e-03, -4.6544e-04,\n",
      "         -1.5982e-03, -8.4315e-04,  9.5622e-04],\n",
      "        [-2.2546e-04,  5.0591e-06, -1.7682e-04, -5.4758e-04,  1.6001e-04,\n",
      "          8.0927e-04,  3.9277e-04, -4.3019e-04],\n",
      "        [-3.8734e-05,  2.1727e-05, -2.3147e-05, -2.9539e-04,  7.9192e-05,\n",
      "          4.3251e-04,  1.3660e-04, -3.1659e-04],\n",
      "        [-3.7289e-04,  6.4570e-05, -3.7078e-04, -1.4694e-03,  1.5501e-04,\n",
      "          2.2901e-03,  9.8375e-04, -1.3072e-03],\n",
      "        [ 1.1353e-04, -7.2013e-06,  3.7104e-05,  3.6472e-04, -7.0311e-05,\n",
      "         -4.8876e-04, -2.4306e-04,  2.9898e-04],\n",
      "        [-3.9067e-04, -1.9823e-05, -1.2563e-04, -7.8966e-04,  2.6951e-04,\n",
      "          9.6931e-04,  5.9816e-04, -5.2579e-04],\n",
      "        [ 3.3686e-04,  1.0287e-05,  1.0637e-04,  7.1442e-04, -3.3799e-04,\n",
      "         -8.7454e-04, -4.7590e-04,  5.3432e-04]]), 'exp_avg_sq': tensor([[1.6434e-05, 8.1494e-07, 7.4115e-06, 2.2464e-05, 4.2115e-05, 5.7304e-05,\n",
      "         6.2673e-06, 2.3659e-05],\n",
      "        [9.6094e-06, 2.6766e-07, 3.3108e-06, 1.4457e-05, 2.9455e-05, 1.3247e-05,\n",
      "         3.9971e-06, 8.3694e-06],\n",
      "        [3.0415e-06, 1.0570e-07, 1.0781e-06, 4.1115e-06, 8.1621e-06, 6.8810e-06,\n",
      "         1.4383e-06, 2.9622e-06],\n",
      "        [2.2720e-06, 1.0670e-07, 3.0087e-06, 9.4220e-06, 1.6628e-05, 1.0019e-05,\n",
      "         8.3472e-07, 1.2214e-05],\n",
      "        [5.2854e-06, 2.9465e-07, 2.8311e-06, 1.0178e-05, 1.1540e-05, 2.8981e-05,\n",
      "         3.3631e-06, 1.2273e-05],\n",
      "        [8.6662e-07, 5.4177e-08, 6.2503e-07, 1.3398e-06, 2.0903e-06, 4.3198e-06,\n",
      "         5.7114e-07, 1.8350e-06],\n",
      "        [5.0940e-06, 2.3760e-07, 4.0435e-06, 9.1772e-06, 1.7664e-05, 2.0002e-05,\n",
      "         2.4016e-06, 8.7638e-06],\n",
      "        [9.1581e-06, 2.0908e-07, 3.8516e-06, 1.6470e-05, 3.5366e-05, 8.1284e-06,\n",
      "         3.1825e-06, 1.1170e-05]])}, 26: {'step': tensor(11460.), 'exp_avg': tensor([ 1.8097e-06, -8.6987e-08, -7.3322e-06,  5.8207e-06, -1.4476e-05,\n",
      "        -4.3650e-06, -9.8851e-06,  4.2726e-07,  4.0108e-06,  8.5266e-07,\n",
      "         2.9730e-05, -3.3533e-07, -1.9352e-05, -1.7431e-06,  9.7261e-06,\n",
      "        -3.5687e-06,  4.8933e-06, -6.0341e-06,  1.0889e-05, -2.0222e-06,\n",
      "        -2.9883e-06,  9.4306e-07,  4.5722e-06, -9.6433e-06, -4.6255e-06]), 'exp_avg_sq': tensor([2.4739e-09, 1.0685e-08, 1.8744e-08, 1.0147e-08, 1.7217e-08, 2.1125e-09,\n",
      "        1.5963e-08, 5.3669e-09, 1.1054e-08, 1.2694e-08, 1.4026e-07, 1.8973e-09,\n",
      "        2.2589e-08, 5.5760e-09, 2.3864e-08, 6.1597e-09, 1.4296e-08, 8.3800e-09,\n",
      "        2.7388e-08, 4.6896e-09, 1.0760e-08, 2.0536e-09, 4.9618e-09, 1.0499e-07,\n",
      "        1.5549e-08])}, 27: {'step': tensor(11460.), 'exp_avg': tensor([5.4737e-05, 7.0285e-05, 7.3657e-05, 5.6358e-05, 1.3509e-04, 4.8600e-05,\n",
      "        4.4228e-05, 6.0772e-05, 5.5788e-05, 5.9163e-05, 5.0324e-05, 4.8495e-05,\n",
      "        5.7463e-04, 5.5878e-05, 2.4607e-05, 6.1019e-05, 5.5593e-05, 4.3830e-05,\n",
      "        1.8258e-05, 5.2217e-05, 5.0861e-05, 5.1801e-05, 6.2602e-05, 6.0325e-04,\n",
      "        4.6985e-05]), 'exp_avg_sq': tensor([8.0992e-08, 2.0466e-07, 2.2227e-07, 1.4664e-07, 4.0851e-07, 6.7076e-08,\n",
      "        4.0998e-07, 1.0569e-07, 2.2221e-07, 2.2626e-07, 1.7705e-05, 7.1137e-08,\n",
      "        2.4031e-06, 8.5116e-08, 4.1687e-07, 9.7503e-08, 2.2097e-07, 1.4465e-07,\n",
      "        5.8509e-07, 8.3574e-08, 1.9217e-07, 7.4904e-08, 1.3264e-07, 1.2084e-05,\n",
      "        2.2608e-07])}, 28: {'step': tensor(11460.), 'exp_avg': tensor([ 0.0001,  0.0017,  0.0003, -0.0003, -0.0008, -0.0001, -0.0003, -0.0005]), 'exp_avg_sq': tensor([7.1202e-06, 2.5873e-05, 8.0811e-06, 4.3322e-06, 1.8558e-05, 1.6223e-05,\n",
      "        1.7453e-05, 2.4835e-05])}, 29: {'step': tensor(11460.), 'exp_avg': tensor([[ 6.4653e-05, -2.4787e-05, -4.1321e-04, -3.2511e-05,  1.2436e-04,\n",
      "          3.3771e-05,  4.3625e-05,  2.0876e-04],\n",
      "        [ 5.9668e-04,  1.1382e-04, -3.9022e-03, -4.1796e-04,  1.6808e-03,\n",
      "          2.1644e-04,  5.0634e-04,  1.2641e-03],\n",
      "        [ 5.0193e-05, -1.1043e-04, -2.1678e-04,  8.2349e-05, -9.7349e-05,\n",
      "          1.1400e-04,  1.9159e-04, -3.9598e-06],\n",
      "        [-1.0267e-04,  4.9017e-05,  6.4294e-04, -9.4592e-06, -2.5849e-04,\n",
      "         -4.1626e-05, -1.7208e-04, -1.1813e-04],\n",
      "        [-2.8818e-04, -5.9305e-05,  1.8133e-03,  2.8236e-04, -5.0860e-04,\n",
      "         -2.3543e-04, -1.6605e-04, -8.7022e-04],\n",
      "        [-2.7829e-05, -1.6851e-05,  1.2692e-04,  9.7898e-05,  1.7336e-04,\n",
      "         -1.1975e-04,  5.4288e-05, -2.9526e-04],\n",
      "        [-7.2420e-05,  7.9033e-05,  4.6166e-04, -1.0032e-04, -2.9785e-04,\n",
      "          2.2588e-05, -2.2605e-04,  1.2625e-04],\n",
      "        [-2.2043e-04, -3.0501e-05,  1.4873e-03,  9.7650e-05, -8.1620e-04,\n",
      "          1.0015e-05, -2.3166e-04, -3.1153e-04]]), 'exp_avg_sq': tensor([[3.1424e-07, 3.9327e-06, 1.8150e-05, 4.4409e-06, 2.5978e-05, 2.6490e-06,\n",
      "         7.4782e-06, 1.0313e-05],\n",
      "        [1.5167e-06, 9.3909e-06, 8.3273e-05, 1.1096e-05, 5.4697e-05, 4.7143e-06,\n",
      "         8.9122e-06, 1.9704e-05],\n",
      "        [2.9689e-07, 3.0350e-06, 1.5650e-05, 3.7042e-06, 2.1968e-05, 3.2197e-06,\n",
      "         5.3157e-06, 1.0692e-05],\n",
      "        [1.4912e-07, 7.0246e-07, 7.3225e-06, 8.9172e-07, 7.8747e-06, 9.0396e-07,\n",
      "         1.9301e-06, 3.0339e-06],\n",
      "        [1.0153e-06, 8.2040e-06, 5.5542e-05, 1.1007e-05, 4.5275e-05, 4.3787e-06,\n",
      "         1.0895e-05, 2.6156e-05],\n",
      "        [5.5730e-07, 3.3193e-06, 3.1193e-05, 5.0052e-06, 3.4572e-05, 3.3918e-06,\n",
      "         6.9853e-06, 1.6286e-05],\n",
      "        [6.4781e-07, 3.3425e-06, 3.7448e-05, 5.9622e-06, 5.3046e-05, 4.5920e-06,\n",
      "         1.1758e-05, 2.3471e-05],\n",
      "        [3.7757e-07, 4.2096e-06, 3.3868e-05, 2.8959e-06, 6.4779e-05, 7.3965e-06,\n",
      "         4.1815e-06, 1.0017e-05]])}, 30: {'step': tensor(11460.), 'exp_avg': tensor([ 6.8574e-07, -1.6697e-06, -6.8673e-06,  5.2328e-06, -1.0712e-05,\n",
      "        -3.0346e-06, -6.0256e-06, -8.9511e-07,  5.1634e-06,  4.3017e-06,\n",
      "         3.9031e-05, -3.4460e-07, -7.7962e-06, -2.1945e-06,  8.0437e-06,\n",
      "        -3.7852e-06,  5.5782e-06, -5.4860e-06,  1.0321e-05, -2.8808e-06,\n",
      "        -5.6272e-07,  3.2945e-07,  2.1241e-06, -4.7859e-06, -1.6287e-06]), 'exp_avg_sq': tensor([2.0858e-09, 6.5098e-09, 2.6316e-08, 9.3321e-09, 1.7360e-08, 2.2442e-09,\n",
      "        1.3788e-08, 4.1797e-09, 1.2990e-08, 1.2205e-08, 1.6240e-07, 2.0740e-09,\n",
      "        2.2629e-08, 4.6449e-09, 2.2456e-08, 5.1490e-09, 1.3774e-08, 8.3628e-09,\n",
      "        2.7212e-08, 4.9051e-09, 9.5324e-09, 2.0437e-09, 3.1936e-09, 1.1641e-07,\n",
      "        1.4105e-08])}, 31: {'step': tensor(11460.), 'exp_avg': tensor([-5.9498e-05, -9.3940e-05, -1.1302e-04, -4.6173e-05, -2.0854e-04,\n",
      "        -6.1095e-05, -7.4900e-05, -7.8373e-05, -4.8599e-05, -5.5949e-05,\n",
      "        -8.8721e-05, -5.3024e-05, -6.4180e-04, -7.6542e-05, -1.9897e-05,\n",
      "        -8.9261e-05, -5.1461e-05, -7.1573e-05, -8.3336e-06, -7.0241e-05,\n",
      "        -5.3120e-05, -5.5185e-05, -6.6493e-05, -6.9064e-04, -5.9485e-05]), 'exp_avg_sq': tensor([1.7995e-07, 5.0690e-07, 4.9586e-07, 4.3859e-07, 1.5640e-06, 1.4201e-07,\n",
      "        2.2948e-07, 2.8924e-07, 4.0992e-07, 3.7424e-07, 4.9628e-06, 1.3421e-07,\n",
      "        4.2521e-06, 2.4388e-07, 5.4035e-07, 2.9067e-07, 4.7353e-07, 3.5530e-07,\n",
      "        7.1338e-07, 2.2604e-07, 3.4908e-07, 1.4857e-07, 3.0829e-07, 1.9781e-05,\n",
      "        2.0442e-07])}, 32: {'step': tensor(11460.), 'exp_avg': tensor([-0.0004, -0.0002,  0.0005,  0.0004, -0.0002, -0.0001,  0.0004,  0.0008,\n",
      "         0.0005, -0.0016]), 'exp_avg_sq': tensor([2.8473e-05, 3.0791e-05, 6.6413e-06, 5.2590e-06, 1.8052e-05, 1.9690e-06,\n",
      "        2.5044e-06, 4.1349e-05, 1.3343e-05, 2.4837e-05])}, 33: {'step': tensor(11460.), 'exp_avg': tensor([[-5.1030e-04,  3.9472e-05,  2.1465e-04,  8.7398e-06, -1.2051e-04,\n",
      "          1.8214e-04, -8.3716e-05,  2.5210e-04],\n",
      "        [-1.0276e-03,  4.1981e-04,  5.4093e-04, -3.4813e-04,  1.8786e-04,\n",
      "          3.8975e-04, -3.3489e-04,  1.6186e-04],\n",
      "        [ 9.9425e-04, -3.5559e-04, -4.0409e-04,  1.6226e-04,  4.0615e-06,\n",
      "         -3.6630e-04,  2.6764e-04, -2.8050e-04],\n",
      "        [ 8.0872e-04, -3.2375e-04, -3.7008e-04,  2.0085e-04, -7.5040e-05,\n",
      "         -3.1150e-04,  2.5119e-04, -1.6528e-04],\n",
      "        [-2.1308e-04,  1.4794e-04,  1.3075e-05, -7.1049e-06, -1.9191e-05,\n",
      "          6.3039e-05, -5.2936e-05,  6.0146e-05],\n",
      "        [-3.0943e-04,  7.1138e-05,  1.1565e-04, -1.2663e-05, -4.8744e-05,\n",
      "          1.0528e-04, -5.9260e-05,  1.3134e-04],\n",
      "        [ 7.8216e-04, -3.3474e-04, -2.8471e-04,  1.3068e-04, -7.7122e-06,\n",
      "         -2.8172e-04,  2.1675e-04, -2.0406e-04],\n",
      "        [ 1.6833e-03, -7.1786e-05, -9.1392e-04,  1.6746e-04,  2.1137e-04,\n",
      "         -6.0934e-04,  3.1173e-04, -7.4226e-04],\n",
      "        [ 1.1526e-03, -5.5810e-04, -3.2697e-04,  1.4094e-04,  3.5719e-05,\n",
      "         -3.8796e-04,  2.9765e-04, -3.2804e-04],\n",
      "        [-3.3606e-03,  9.6561e-04,  1.4155e-03, -4.4304e-04, -1.6781e-04,\n",
      "          1.2166e-03, -8.1415e-04,  1.1147e-03]]), 'exp_avg_sq': tensor([[9.6987e-05, 2.5964e-05, 7.5932e-05, 2.8380e-05, 2.9518e-05, 1.9845e-05,\n",
      "         9.7173e-06, 3.5660e-05],\n",
      "        [6.9062e-05, 2.8167e-05, 6.9443e-05, 1.2829e-05, 1.1207e-05, 1.3895e-05,\n",
      "         4.5001e-06, 2.2930e-05],\n",
      "        [2.2150e-05, 1.0177e-05, 9.9770e-06, 4.4502e-06, 3.7988e-06, 4.9259e-06,\n",
      "         3.9141e-06, 2.9936e-06],\n",
      "        [1.5810e-05, 7.4022e-06, 7.1546e-06, 3.4096e-06, 3.0521e-06, 3.4569e-06,\n",
      "         2.9152e-06, 2.3742e-06],\n",
      "        [3.7848e-05, 1.4588e-05, 4.5573e-05, 6.3758e-06, 3.6149e-06, 7.8468e-06,\n",
      "         1.6713e-06, 1.1151e-05],\n",
      "        [3.5039e-06, 1.0541e-06, 3.3886e-06, 9.3459e-07, 6.0648e-07, 7.4574e-07,\n",
      "         3.5708e-07, 6.9909e-07],\n",
      "        [8.4676e-06, 3.5783e-06, 5.1135e-06, 2.2815e-06, 2.4574e-06, 1.7908e-06,\n",
      "         1.3084e-06, 2.5962e-06],\n",
      "        [9.7310e-05, 4.5172e-05, 5.1661e-05, 1.2516e-05, 3.6365e-05, 1.4956e-05,\n",
      "         3.4944e-06, 7.0597e-05],\n",
      "        [3.9791e-05, 1.6532e-05, 1.9122e-05, 4.2549e-06, 1.1533e-05, 6.6376e-06,\n",
      "         1.9714e-06, 2.3232e-05],\n",
      "        [8.3470e-05, 2.4675e-05, 2.6559e-05, 1.1318e-05, 1.0094e-05, 1.6479e-05,\n",
      "         1.1777e-05, 1.0991e-05]])}, 34: {'step': tensor(11460.), 'exp_avg': tensor([-8.0068e-05, -6.4963e-05, -9.7805e-05, -6.6750e-05, -1.7028e-04,\n",
      "        -9.6287e-05, -1.0721e-04, -7.5424e-05, -7.1037e-05, -7.9166e-05,\n",
      "        -5.1204e-05, -7.7985e-05, -4.1828e-04, -7.3291e-05, -9.5906e-06,\n",
      "        -7.7736e-05, -6.9857e-05, -7.6777e-05, -1.8865e-05, -8.3879e-05,\n",
      "        -9.0519e-05, -7.9998e-05, -7.6016e-05, -3.1507e-04, -1.0259e-04]), 'exp_avg_sq': tensor([3.9540e-07, 1.1487e-06, 1.1371e-06, 7.3631e-07, 1.8306e-06, 3.5415e-07,\n",
      "        4.6382e-07, 7.3519e-07, 5.4845e-07, 5.6327e-07, 3.4408e-05, 3.5418e-07,\n",
      "        3.2361e-06, 6.6721e-07, 4.2505e-06, 7.7416e-07, 3.8098e-07, 6.8560e-07,\n",
      "        5.8207e-06, 5.4193e-07, 4.0052e-07, 3.6173e-07, 6.3698e-07, 1.0490e-05,\n",
      "        4.2399e-07])}, 35: {'step': tensor(11460.), 'exp_avg': tensor([ 3.6505e-11,  5.0097e-12, -1.3360e-11, -6.2539e-13, -7.1168e-11,\n",
      "         6.2019e-11,  4.6215e-11,  9.1702e-12,  1.6123e-11, -1.5143e-11,\n",
      "         6.1499e-11,  1.0377e-11, -8.4530e-11, -4.4717e-11,  9.1196e-13,\n",
      "        -6.9447e-11,  1.1299e-11, -4.8009e-11,  2.5623e-11, -8.9433e-12,\n",
      "         3.7575e-11, -1.1724e-11,  7.2987e-13,  1.3957e-10,  2.3828e-11]), 'exp_avg_sq': tensor([6.8816e-20, 3.5507e-19, 6.9217e-19, 1.0002e-18, 1.5372e-18, 1.3619e-19,\n",
      "        1.7376e-19, 3.7244e-19, 2.2709e-18, 9.4446e-19, 7.5350e-18, 1.2725e-19,\n",
      "        1.6866e-18, 2.6500e-19, 2.0436e-18, 6.0427e-19, 3.6946e-19, 6.3690e-19,\n",
      "        4.3672e-18, 2.1335e-19, 5.8828e-19, 1.1431e-19, 1.4329e-19, 2.9835e-18,\n",
      "        6.4280e-19])}, 36: {'step': tensor(11460.), 'exp_avg': tensor([-4.7374e-05, -9.1673e-03, -8.2332e-04, -3.2998e-03, -4.2449e-04,\n",
      "        -4.4806e-03,  2.4553e-03, -5.8584e-03,  8.8833e-03,  2.0621e-04,\n",
      "         1.1179e-02,  1.3776e-03]), 'exp_avg_sq': tensor([0.0025, 0.0089, 0.0244, 0.0318, 0.0047, 0.0024, 0.0299, 0.0232, 0.0202,\n",
      "        0.0015, 0.0344, 0.0011])}, 37: {'step': tensor(11460.), 'exp_avg': tensor([[ 1.0008e-03, -1.9357e-03, -1.0298e-02,  2.6429e-02, -1.1119e-02,\n",
      "         -2.7369e-02, -7.1528e-03,  3.0414e-02],\n",
      "        [ 3.8636e-02,  2.9464e-04, -2.3098e-02,  1.0566e-01, -6.8982e-02,\n",
      "         -9.6033e-02, -4.7978e-02,  9.2413e-02],\n",
      "        [-2.5971e-02, -1.3575e-03,  3.9352e-02, -7.2624e-02,  5.5224e-02,\n",
      "          4.0701e-02,  2.6918e-02, -6.2186e-02],\n",
      "        [-8.3878e-02, -2.7324e-02,  1.4904e-02,  6.9508e-02,  9.7741e-02,\n",
      "         -2.0620e-01, -1.2781e-02,  1.4846e-01],\n",
      "        [ 8.8611e-03,  1.6575e-04, -9.6061e-03,  2.0471e-02, -2.4045e-02,\n",
      "         -1.0616e-02, -4.1431e-03,  1.8874e-02],\n",
      "        [ 2.5296e-02,  1.9011e-03, -1.4642e-02,  5.5853e-02, -3.5794e-02,\n",
      "         -4.4071e-02, -3.0206e-02,  4.2180e-02],\n",
      "        [-1.6272e-02, -3.6435e-03, -5.0899e-03,  1.0974e-02,  2.7104e-02,\n",
      "         -2.9167e-02, -5.9941e-03,  2.2104e-02],\n",
      "        [ 3.7223e-02, -1.9572e-03, -4.5354e-02,  1.3373e-01, -8.4839e-02,\n",
      "         -1.1467e-01, -5.0365e-02,  1.2674e-01],\n",
      "        [-2.4333e-02,  1.0574e-02,  5.4424e-02, -1.9917e-01,  7.8311e-02,\n",
      "          2.1731e-01,  7.4173e-02, -2.1218e-01],\n",
      "        [ 8.7008e-03,  2.4644e-03, -2.2525e-03, -6.1968e-03, -1.5093e-02,\n",
      "          2.1237e-02,  3.7368e-03, -1.2683e-02],\n",
      "        [ 1.6329e-02,  1.5414e-02,  5.7228e-03, -1.3090e-01, -7.1959e-03,\n",
      "          2.0992e-01,  5.3929e-02, -1.6456e-01],\n",
      "        [ 1.4407e-02,  5.4045e-03, -4.0627e-03, -1.3728e-02, -1.1313e-02,\n",
      "          3.8945e-02, -1.3735e-04, -2.9578e-02]]), 'exp_avg_sq': tensor([[5.9706e-02, 2.8778e-03, 1.2354e-02, 3.1499e-02, 1.2430e-01, 6.1670e-02,\n",
      "         1.1758e-02, 3.7252e-02],\n",
      "        [2.0059e-01, 8.4456e-03, 3.2538e-02, 1.3528e-01, 4.3049e-01, 1.8380e-01,\n",
      "         5.0123e-02, 1.0752e-01],\n",
      "        [5.9848e-01, 2.8176e-02, 1.3565e-01, 3.4245e-01, 1.3217e+00, 6.8381e-01,\n",
      "         1.1775e-01, 3.7734e-01],\n",
      "        [2.0906e+00, 9.1880e-02, 3.9284e-01, 1.2376e+00, 4.4967e+00, 1.6857e+00,\n",
      "         4.1783e-01, 1.0219e+00],\n",
      "        [3.0000e-01, 1.3010e-02, 5.8399e-02, 1.7869e-01, 6.5753e-01, 2.3889e-01,\n",
      "         5.9180e-02, 1.4223e-01],\n",
      "        [6.0339e-02, 2.2602e-03, 8.0420e-03, 5.2919e-02, 1.4651e-01, 5.9384e-02,\n",
      "         1.6265e-02, 3.9453e-02],\n",
      "        [9.9584e-01, 3.8170e-02, 1.4348e-01, 6.9706e-01, 2.1979e+00, 6.0127e-01,\n",
      "         2.3346e-01, 4.0062e-01],\n",
      "        [7.8463e-01, 3.6298e-02, 1.5236e-01, 4.4456e-01, 1.6224e+00, 8.2274e-01,\n",
      "         1.7850e-01, 4.5728e-01],\n",
      "        [6.1335e-01, 2.6649e-02, 1.0748e-01, 4.2194e-01, 1.3545e+00, 6.6930e-01,\n",
      "         1.4671e-01, 3.9928e-01],\n",
      "        [6.3188e-02, 2.6880e-03, 1.0553e-02, 4.1624e-02, 1.3362e-01, 5.6791e-02,\n",
      "         1.5384e-02, 3.2513e-02],\n",
      "        [1.8430e+00, 8.0878e-02, 3.4118e-01, 1.1278e+00, 3.9673e+00, 1.5837e+00,\n",
      "         3.7547e-01, 9.5744e-01],\n",
      "        [2.0294e-02, 8.3005e-04, 2.8658e-03, 1.4833e-02, 4.2275e-02, 2.2799e-02,\n",
      "         5.7217e-03, 1.3292e-02]])}, 38: {'step': tensor(11460.), 'exp_avg': tensor([ 3.0314e-05,  7.5345e-05,  2.5099e-04, -1.2226e-05,  4.4658e-04,\n",
      "         8.5804e-05,  1.1931e-04,  5.0107e-05, -3.7895e-05, -7.6825e-05,\n",
      "        -8.2824e-04,  7.7543e-05,  1.6953e-03,  1.1029e-04, -1.3363e-04,\n",
      "         1.6200e-04, -1.3935e-05,  2.8334e-04, -7.1566e-05,  1.2227e-04,\n",
      "        -1.4295e-05,  6.8805e-05, -3.9555e-05,  1.1932e-03,  1.2378e-05]), 'exp_avg_sq': tensor([6.1119e-06, 3.2357e-05, 1.8216e-05, 1.4450e-05, 4.5782e-05, 4.2307e-06,\n",
      "        1.2116e-05, 1.3868e-05, 1.3169e-05, 1.2209e-05, 3.2707e-04, 5.3494e-06,\n",
      "        8.5456e-05, 1.2868e-05, 4.1540e-05, 1.5194e-05, 1.1039e-05, 3.0797e-05,\n",
      "        5.4927e-05, 1.2493e-05, 9.9870e-06, 5.6113e-06, 1.5540e-05, 4.8798e-04,\n",
      "        8.0650e-06])}, 39: {'step': tensor(11460.), 'exp_avg': tensor([-0.0033, -0.0044, -0.0051, -0.0030, -0.0102, -0.0039, -0.0036, -0.0036,\n",
      "        -0.0033, -0.0039,  0.0151, -0.0031, -0.0475, -0.0034, -0.0026, -0.0038,\n",
      "        -0.0031, -0.0024, -0.0017, -0.0024, -0.0037, -0.0029, -0.0036, -0.0311,\n",
      "        -0.0037]), 'exp_avg_sq': tensor([0.0015, 0.0045, 0.0022, 0.0012, 0.0080, 0.0011, 0.0032, 0.0024, 0.0011,\n",
      "        0.0011, 0.0354, 0.0012, 0.0248, 0.0018, 0.0016, 0.0018, 0.0011, 0.0020,\n",
      "        0.0022, 0.0016, 0.0011, 0.0013, 0.0036, 0.1257, 0.0013])}, 40: {'step': tensor(11460.), 'exp_avg': tensor([-7.4757e-04, -4.0962e-02,  2.2394e-02, -6.3804e-02,  5.7523e-05,\n",
      "        -6.9149e-03, -2.0109e-02,  6.0162e-02, -6.1815e-03,  4.0056e-02,\n",
      "         3.8388e-02, -2.2337e-02]), 'exp_avg_sq': tensor([0.0334, 0.0489, 0.0849, 0.3181, 0.0690, 0.0613, 0.2236, 0.2024, 0.3548,\n",
      "        0.1693, 0.0435, 0.2745])}, 41: {'step': tensor(11460.), 'exp_avg': tensor([[-2.0177e-03,  2.9447e-03,  1.9837e-03, -4.6413e-03,  7.8560e-03,\n",
      "         -9.9779e-04,  2.3856e-03,  1.2752e-03,  1.1987e-03, -5.2682e-03,\n",
      "         -4.8764e-03, -1.7246e-04],\n",
      "        [-5.5665e-02,  5.4809e-02,  3.6422e-02, -4.5306e-02,  1.1900e-01,\n",
      "         -4.8274e-02,  4.3920e-02, -2.5602e-02, -3.6212e-03, -4.4825e-03,\n",
      "         -4.4810e-02, -3.6188e-02],\n",
      "        [ 1.1145e-01, -8.4576e-02,  6.7599e-03,  5.9391e-02, -1.3914e-01,\n",
      "         -2.0002e-02, -7.0128e-02,  6.0179e-02, -2.1120e-02, -2.5477e-02,\n",
      "          4.2410e-02,  8.5647e-02],\n",
      "        [-1.2637e-01,  1.0771e-01,  2.5125e-02, -7.4104e-02,  1.9448e-01,\n",
      "         -2.6632e-02,  7.6833e-02, -6.6170e-02,  1.3966e-02,  2.2021e-02,\n",
      "         -6.5402e-02, -9.6988e-02],\n",
      "        [-2.7056e-02,  1.8623e-02, -1.5606e-02, -8.7853e-03,  1.7783e-02,\n",
      "          2.7680e-02,  7.1815e-03, -1.3677e-02,  1.4629e-02,  9.9716e-03,\n",
      "         -5.1610e-03, -2.5828e-02],\n",
      "        [-5.2364e-02,  4.2733e-02,  8.6782e-03, -3.7690e-02,  8.3797e-02,\n",
      "         -6.2959e-03,  4.2832e-02, -2.5107e-02,  5.2663e-03,  3.8550e-04,\n",
      "         -2.9314e-02, -3.4390e-02],\n",
      "        [ 1.0483e-02,  2.9482e-03,  5.0933e-02, -1.7777e-02,  4.9393e-02,\n",
      "         -7.8789e-02,  2.1361e-02,  7.9833e-03, -2.8423e-02, -2.4401e-02,\n",
      "         -2.1789e-02,  2.3840e-02],\n",
      "        [ 8.9931e-02, -8.9082e-02, -7.3928e-02,  8.3996e-02, -2.1239e-01,\n",
      "          1.0197e-01, -9.0417e-02,  4.1556e-02,  1.8100e-02,  1.6516e-02,\n",
      "          7.9053e-02,  4.8558e-02],\n",
      "        [-1.5963e-02,  4.6042e-03, -3.5562e-02,  1.7597e-02, -3.1156e-02,\n",
      "          5.1301e-02, -1.9263e-02, -1.5305e-02,  1.9617e-02,  3.3101e-02,\n",
      "          1.8290e-02, -2.9291e-02],\n",
      "        [ 7.5879e-02, -6.5006e-02, -2.0131e-02,  4.5561e-02, -1.2153e-01,\n",
      "          2.4890e-02, -4.9713e-02,  4.0902e-02, -4.2872e-03, -1.3662e-02,\n",
      "          3.9991e-02,  5.6704e-02],\n",
      "        [ 1.0083e-01, -8.8296e-02, -3.7614e-02,  7.4427e-02, -1.8184e-01,\n",
      "          4.6031e-02, -8.2432e-02,  4.9850e-02, -6.6034e-04, -1.4343e-03,\n",
      "          6.3843e-02,  6.6088e-02],\n",
      "        [-1.0914e-01,  9.2592e-02,  5.2938e-02, -9.2669e-02,  2.1375e-01,\n",
      "         -7.0876e-02,  1.1744e-01, -5.5885e-02, -1.4665e-02, -7.2689e-03,\n",
      "         -7.2235e-02, -5.7979e-02]]), 'exp_avg_sq': tensor([[0.0596, 0.0331, 0.0339, 0.0195, 0.1100, 0.0696, 0.0206, 0.0199, 0.0091,\n",
      "         0.0243, 0.0219, 0.0463],\n",
      "        [0.0925, 0.0543, 0.0476, 0.0329, 0.1834, 0.0969, 0.0314, 0.0297, 0.0137,\n",
      "         0.0367, 0.0360, 0.0709],\n",
      "        [0.4029, 0.1767, 0.1905, 0.1056, 0.4775, 0.4257, 0.1578, 0.1427, 0.0697,\n",
      "         0.1542, 0.0786, 0.3250],\n",
      "        [1.2367, 0.5823, 0.6224, 0.3404, 1.6546, 1.3594, 0.4545, 0.4329, 0.2155,\n",
      "         0.4929, 0.2922, 1.0123],\n",
      "        [0.1878, 0.0959, 0.0707, 0.0528, 0.2675, 0.1563, 0.0637, 0.0614, 0.0297,\n",
      "         0.0644, 0.0453, 0.1487],\n",
      "        [0.1913, 0.0841, 0.1157, 0.0522, 0.2497, 0.2522, 0.0720, 0.0709, 0.0369,\n",
      "         0.0904, 0.0472, 0.1618],\n",
      "        [0.5892, 0.3000, 0.2279, 0.1663, 0.8444, 0.5046, 0.1920, 0.1930, 0.0931,\n",
      "         0.2081, 0.1444, 0.4652],\n",
      "        [0.3960, 0.2267, 0.2087, 0.1412, 0.7712, 0.4282, 0.1372, 0.1296, 0.0589,\n",
      "         0.1656, 0.1521, 0.3017],\n",
      "        [1.6835, 0.7737, 0.8059, 0.4369, 2.0711, 1.7872, 0.6178, 0.5886, 0.2940,\n",
      "         0.6412, 0.3469, 1.3851],\n",
      "        [0.4564, 0.2218, 0.2984, 0.1398, 0.7204, 0.6318, 0.1648, 0.1659, 0.0854,\n",
      "         0.2232, 0.1452, 0.3815],\n",
      "        [0.1604, 0.0822, 0.0696, 0.0498, 0.2420, 0.1514, 0.0605, 0.0532, 0.0263,\n",
      "         0.0614, 0.0420, 0.1286],\n",
      "        [1.2988, 0.6344, 0.4503, 0.3483, 1.6329, 1.0243, 0.4653, 0.4256, 0.2047,\n",
      "         0.4119, 0.2500, 1.0312]])}, 42: {'step': tensor(11460.), 'exp_avg': tensor([-1.1958e-04, -8.0025e-06,  3.2676e-05, -1.9705e-04,  1.9067e-06,\n",
      "        -1.2112e-04, -1.6654e-04, -6.5658e-05, -2.7897e-04, -3.9709e-04,\n",
      "        -1.4418e-04, -1.1771e-04, -1.0696e-04, -3.6361e-05, -3.6357e-04,\n",
      "        -9.7534e-08, -2.5946e-04,  6.3537e-05, -2.7271e-04, -4.4050e-05,\n",
      "        -2.8606e-04, -1.1792e-04, -1.2416e-04, -2.8497e-04, -3.1712e-04]), 'exp_avg_sq': tensor([7.5042e-06, 2.5650e-05, 2.1490e-05, 1.5895e-05, 5.6459e-05, 5.7234e-06,\n",
      "        1.4017e-05, 1.3339e-05, 1.4511e-05, 1.3873e-05, 3.4631e-04, 6.7924e-06,\n",
      "        7.1429e-05, 1.3430e-05, 4.9766e-05, 1.5945e-05, 1.2933e-05, 3.5445e-05,\n",
      "        6.7201e-05, 1.3197e-05, 1.1631e-05, 7.0608e-06, 1.2935e-05, 3.0864e-04,\n",
      "        9.2859e-06])}, 43: {'step': tensor(11460.), 'exp_avg': tensor([ 5.2467e-04,  1.7198e-03,  6.1366e-04, -1.7547e-05, -2.0599e-04,\n",
      "         1.3010e-04, -5.3713e-04,  9.7966e-04, -5.5786e-04, -1.3889e-03,\n",
      "        -7.2427e-03,  2.1083e-06,  6.2100e-03,  5.8520e-04, -8.9829e-04,\n",
      "         6.9436e-04, -5.8203e-04, -4.7451e-04, -1.2670e-03, -7.1383e-05,\n",
      "        -8.4605e-04,  4.6381e-05,  1.2376e-03, -2.2056e-03, -1.4770e-03]), 'exp_avg_sq': tensor([0.0015, 0.0022, 0.0019, 0.0014, 0.0055, 0.0014, 0.0030, 0.0017, 0.0014,\n",
      "        0.0016, 0.0206, 0.0015, 0.0078, 0.0016, 0.0016, 0.0016, 0.0015, 0.0023,\n",
      "        0.0018, 0.0017, 0.0016, 0.0015, 0.0021, 0.0342, 0.0019])}, 44: {'step': tensor(11460.), 'exp_avg': tensor([-0.0610,  0.0385, -0.0037, -0.0360,  0.0199, -0.0453,  0.0404,  0.0162,\n",
      "         0.0280, -0.0033, -0.0059, -0.0033,  0.0279, -0.0253,  0.0234, -0.0104]), 'exp_avg_sq': tensor([0.4001, 0.0585, 0.1208, 0.1916, 0.0446, 0.0518, 0.0987, 0.1686, 0.0918,\n",
      "        0.2523, 0.2045, 0.0413, 0.1682, 0.0166, 0.1910, 0.0514])}, 45: {'step': tensor(11460.), 'exp_avg': tensor([[ 0.0784,  0.0478, -0.0067,  0.0041, -0.1112,  0.1211,  0.0172, -0.0050,\n",
      "          0.0092,  0.0233, -0.0521, -0.1033],\n",
      "        [-0.1311, -0.0759, -0.0084,  0.0198,  0.1446, -0.1073, -0.0277,  0.0080,\n",
      "         -0.0360, -0.0306,  0.1036,  0.1271],\n",
      "        [ 0.0804,  0.0356, -0.0099, -0.0039, -0.1083,  0.0815,  0.0380,  0.0024,\n",
      "          0.0146,  0.0083, -0.0530, -0.0851],\n",
      "        [ 0.0444,  0.0273, -0.0032,  0.0017, -0.0619,  0.0667,  0.0104, -0.0025,\n",
      "          0.0054,  0.0128, -0.0301, -0.0576],\n",
      "        [ 0.0568,  0.0269,  0.0253, -0.0316, -0.0244, -0.0341, -0.0051, -0.0100,\n",
      "          0.0416,  0.0194, -0.0596, -0.0130],\n",
      "        [ 0.1193,  0.0718, -0.0017, -0.0089, -0.1474,  0.1299,  0.0333, -0.0042,\n",
      "          0.0215,  0.0240, -0.0882, -0.1330],\n",
      "        [-0.0564, -0.0322,  0.0269, -0.0194,  0.1122, -0.1366, -0.0403, -0.0069,\n",
      "          0.0148, -0.0014,  0.0235,  0.1012],\n",
      "        [-0.0712, -0.0300, -0.0012,  0.0091,  0.0835, -0.0553, -0.0164,  0.0048,\n",
      "         -0.0250, -0.0197,  0.0517,  0.0639],\n",
      "        [-0.1431, -0.0762, -0.0167,  0.0297,  0.1450, -0.0857, -0.0225,  0.0121,\n",
      "         -0.0520, -0.0383,  0.1171,  0.1207],\n",
      "        [-0.0661, -0.0235,  0.0183, -0.0035,  0.1033, -0.0833, -0.0435, -0.0062,\n",
      "         -0.0060, -0.0012,  0.0363,  0.0777],\n",
      "        [-0.0025, -0.0118, -0.0353,  0.0287, -0.0515,  0.0807,  0.0361,  0.0130,\n",
      "         -0.0284, -0.0158,  0.0269, -0.0386],\n",
      "        [-0.0562, -0.0304, -0.0152,  0.0209,  0.0412, -0.0030, -0.0037,  0.0064,\n",
      "         -0.0284, -0.0153,  0.0526,  0.0325],\n",
      "        [-0.0195, -0.0014,  0.0368, -0.0302,  0.0828, -0.1160, -0.0393, -0.0109,\n",
      "          0.0251,  0.0075, -0.0124,  0.0677],\n",
      "        [ 0.1562,  0.0811,  0.0075, -0.0248, -0.1736,  0.1156,  0.0376, -0.0084,\n",
      "          0.0473,  0.0346, -0.1209, -0.1437],\n",
      "        [ 0.0035, -0.0163, -0.0189,  0.0095, -0.0285,  0.0178,  0.0278,  0.0089,\n",
      "         -0.0053, -0.0112,  0.0115, -0.0084],\n",
      "        [ 0.0070,  0.0072,  0.0025, -0.0013, -0.0058,  0.0081, -0.0021, -0.0016,\n",
      "          0.0017,  0.0036, -0.0070, -0.0082]]), 'exp_avg_sq': tensor([[1.0392, 0.3721, 0.3878, 0.4267, 0.7865, 2.0736, 0.3135, 0.0684, 0.7273,\n",
      "         0.2211, 1.1528, 0.7549],\n",
      "        [0.2945, 0.1020, 0.0829, 0.0884, 0.1791, 0.2675, 0.0679, 0.0143, 0.1499,\n",
      "         0.0531, 0.3060, 0.1337],\n",
      "        [0.5927, 0.2007, 0.1927, 0.2082, 0.3540, 0.7151, 0.1498, 0.0334, 0.3477,\n",
      "         0.1173, 0.6465, 0.2847],\n",
      "        [0.5469, 0.1846, 0.2056, 0.2251, 0.3833, 0.9621, 0.1640, 0.0358, 0.3750,\n",
      "         0.1167, 0.6217, 0.3406],\n",
      "        [0.1014, 0.0393, 0.0261, 0.0317, 0.0720, 0.1532, 0.0201, 0.0042, 0.0584,\n",
      "         0.0173, 0.1053, 0.0730],\n",
      "        [0.1567, 0.0637, 0.0427, 0.0450, 0.1008, 0.1577, 0.0384, 0.0076, 0.0773,\n",
      "         0.0287, 0.1630, 0.0863],\n",
      "        [0.2950, 0.1129, 0.0948, 0.1056, 0.2011, 0.4732, 0.0810, 0.0172, 0.1782,\n",
      "         0.0578, 0.3186, 0.1946],\n",
      "        [0.2349, 0.0900, 0.1058, 0.1208, 0.2165, 0.7307, 0.0885, 0.0190, 0.2092,\n",
      "         0.0569, 0.2790, 0.2432],\n",
      "        [0.2951, 0.1012, 0.1110, 0.1206, 0.1905, 0.4924, 0.0860, 0.0197, 0.1996,\n",
      "         0.0637, 0.3358, 0.1695],\n",
      "        [1.3061, 0.4493, 0.4112, 0.4447, 0.7543, 1.4661, 0.3123, 0.0711, 0.7418,\n",
      "         0.2536, 1.4170, 0.6071],\n",
      "        [1.2981, 0.4458, 0.3917, 0.4161, 0.7623, 1.2685, 0.3085, 0.0672, 0.6938,\n",
      "         0.2453, 1.3848, 0.5747],\n",
      "        [0.1049, 0.0413, 0.0360, 0.0391, 0.0817, 0.1896, 0.0318, 0.0064, 0.0661,\n",
      "         0.0214, 0.1141, 0.0785],\n",
      "        [0.6377, 0.2466, 0.1797, 0.1932, 0.4168, 0.7157, 0.1496, 0.0308, 0.3329,\n",
      "         0.1177, 0.6726, 0.3632],\n",
      "        [0.0525, 0.0197, 0.0160, 0.0173, 0.0366, 0.0728, 0.0153, 0.0031, 0.0295,\n",
      "         0.0100, 0.0552, 0.0321],\n",
      "        [1.1684, 0.4175, 0.3555, 0.3678, 0.6880, 1.0591, 0.2868, 0.0613, 0.6083,\n",
      "         0.2246, 1.2552, 0.5106],\n",
      "        [0.1977, 0.0652, 0.0775, 0.0817, 0.1270, 0.3015, 0.0617, 0.0136, 0.1317,\n",
      "         0.0438, 0.2280, 0.1008]])}, 46: {'step': tensor(11460.), 'exp_avg': tensor([-1.1981e-04, -1.1320e-07,  1.1456e-04, -2.5844e-04,  1.5130e-04,\n",
      "        -1.4080e-04, -2.1696e-04, -4.3611e-05, -3.9166e-04, -5.1451e-04,\n",
      "         3.3632e-04, -1.4454e-04,  1.2312e-04, -3.6221e-06, -6.0762e-04,\n",
      "         4.6240e-05, -3.7540e-04,  7.1515e-05, -4.3847e-04, -2.9513e-05,\n",
      "        -3.8236e-04, -1.3760e-04, -1.1357e-04,  1.0983e-04, -4.1248e-04]), 'exp_avg_sq': tensor([1.2839e-05, 5.7563e-05, 8.0899e-05, 5.9880e-05, 1.3711e-04, 1.3155e-05,\n",
      "        2.0987e-05, 3.0393e-05, 9.2106e-05, 7.9686e-05, 3.5892e-04, 1.2719e-05,\n",
      "        1.4268e-04, 3.9688e-05, 2.3010e-04, 5.3186e-05, 6.5135e-05, 6.6733e-05,\n",
      "        2.6230e-04, 3.5531e-05, 5.5606e-05, 1.2945e-05, 1.4689e-05, 1.7429e-04,\n",
      "        3.4829e-05])}, 47: {'step': tensor(11460.), 'exp_avg': tensor([-0.0060, -0.0061, -0.0062, -0.0055, -0.0063, -0.0061, -0.0061, -0.0061,\n",
      "        -0.0054, -0.0053, -0.0032, -0.0059, -0.0063, -0.0061, -0.0032, -0.0062,\n",
      "        -0.0054, -0.0062, -0.0032, -0.0061, -0.0057, -0.0059, -0.0059, -0.0063,\n",
      "        -0.0058]), 'exp_avg_sq': tensor([0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "        0.0020, 0.0019, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020,\n",
      "        0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020, 0.0020])}, 48: {'step': tensor(11460.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 49: {'step': tensor(11460.), 'exp_avg': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'exp_avg_sq': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])}, 50: {'step': tensor(11460.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 51: {'step': tensor(11460.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 52: {'step': tensor(11460.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 53: {'step': tensor(11460.), 'exp_avg': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'exp_avg_sq': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])}, 54: {'step': tensor(11460.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 55: {'step': tensor(11460.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 56: {'step': tensor(11460.), 'exp_avg': tensor([0.]), 'exp_avg_sq': tensor([0.])}, 57: {'step': tensor(11460.), 'exp_avg': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'exp_avg_sq': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])}, 60: {'step': tensor(11460.), 'exp_avg': tensor([-0.0279,  0.0130, -0.0021,  0.0045, -0.0008,  0.0063, -0.0137,  0.0084,\n",
      "         0.0096, -0.0108,  0.0126, -0.0019,  0.0134,  0.0116,  0.0076, -0.0299]), 'exp_avg_sq': tensor([0.0139, 0.0187, 0.0101, 0.0208, 0.0043, 0.0104, 0.0079, 0.0145, 0.0158,\n",
      "        0.0148, 0.0159, 0.0085, 0.0271, 0.0073, 0.0471, 0.0345])}, 61: {'step': tensor(11460.), 'exp_avg': tensor([[-0.1733, -0.2368, -0.0821,  0.3212, -0.4940,  0.0451,  0.3544,  0.3861,\n",
      "          0.0516,  0.0978, -0.1688,  0.1618, -0.2519,  0.3538,  0.0678, -0.4123],\n",
      "        [ 0.0730,  0.0884,  0.0495, -0.1184,  0.1850, -0.0210, -0.1361, -0.1597,\n",
      "         -0.0217, -0.0463,  0.0546, -0.0633,  0.1111, -0.1486, -0.0170,  0.1628],\n",
      "        [-0.0269, -0.0429, -0.0069,  0.0601, -0.0892,  0.0058,  0.0643,  0.0619,\n",
      "          0.0098,  0.0129, -0.0354,  0.0268, -0.0406,  0.0554,  0.0170, -0.0704],\n",
      "        [ 0.0621,  0.0710,  0.1171, -0.1180,  0.1737, -0.0195, -0.1519, -0.1820,\n",
      "         -0.0539, -0.0449,  0.0618, -0.0415,  0.1716, -0.1838, -0.0278,  0.1658],\n",
      "        [ 0.0127,  0.0194,  0.0251, -0.0338,  0.0485, -0.0032, -0.0416, -0.0438,\n",
      "         -0.0148, -0.0073,  0.0226, -0.0096,  0.0410, -0.0440, -0.0127,  0.0422],\n",
      "        [ 0.0827,  0.1114,  0.0954, -0.1696,  0.2502, -0.0225, -0.1991, -0.2188,\n",
      "         -0.0530, -0.0506,  0.0936, -0.0674,  0.1816, -0.2117, -0.0438,  0.2187],\n",
      "        [-0.0731, -0.1064,  0.0043,  0.1345, -0.2125,  0.0175,  0.1400,  0.1452,\n",
      "          0.0056,  0.0365, -0.0728,  0.0765, -0.0692,  0.1253,  0.0279, -0.1675],\n",
      "        [ 0.0270,  0.0149,  0.0444, -0.0172,  0.0372, -0.0111, -0.0315, -0.0603,\n",
      "         -0.0075, -0.0243, -0.0018, -0.0175,  0.0473, -0.0606,  0.0099,  0.0467],\n",
      "        [ 0.0645,  0.1050, -0.0229, -0.1343,  0.2069, -0.0132, -0.1343, -0.1261,\n",
      "         -0.0036, -0.0274,  0.0779, -0.0719,  0.0539, -0.1050, -0.0343,  0.1554],\n",
      "        [-0.0474, -0.0525, -0.0389,  0.0684, -0.1153,  0.0147,  0.0838,  0.1074,\n",
      "          0.0119,  0.0311, -0.0326,  0.0416, -0.0692,  0.1011,  0.0077, -0.1041],\n",
      "        [ 0.0910,  0.1223,  0.0646, -0.1730,  0.2575, -0.0243, -0.1932, -0.2112,\n",
      "         -0.0386, -0.0541,  0.0876, -0.0790,  0.1574, -0.1980, -0.0371,  0.2204],\n",
      "        [-0.0420, -0.0486, -0.0781,  0.0806, -0.1179,  0.0131,  0.1031,  0.1223,\n",
      "          0.0365,  0.0302, -0.0420,  0.0280, -0.1161,  0.1233,  0.0190, -0.1122],\n",
      "        [ 0.0215,  0.0263, -0.0524, -0.0118,  0.0343, -0.0055, -0.0009, -0.0052,\n",
      "          0.0292, -0.0092, -0.0018, -0.0306, -0.0439,  0.0078,  0.0105,  0.0199],\n",
      "        [ 0.0626,  0.0874,  0.0066, -0.1112,  0.1768, -0.0158, -0.1185, -0.1276,\n",
      "         -0.0071, -0.0330,  0.0590, -0.0634,  0.0658, -0.1123, -0.0217,  0.1425],\n",
      "        [ 0.0188,  0.0268, -0.0228, -0.0246,  0.0523, -0.0045, -0.0240, -0.0282,\n",
      "          0.0130, -0.0070,  0.0168, -0.0264, -0.0129, -0.0192, -0.0030,  0.0364],\n",
      "        [-0.1531, -0.1856, -0.1029,  0.2470, -0.3935,  0.0443,  0.2855,  0.3399,\n",
      "          0.0426,  0.0957, -0.1186,  0.1358, -0.2258,  0.3166,  0.0374, -0.3444]]), 'exp_avg_sq': tensor([[8.3216e-02, 1.3081e-01, 2.0821e-01, 2.0079e-01, 3.9200e-01, 8.1899e-03,\n",
      "         1.7894e-01, 2.3556e-01, 4.0347e-02, 4.0073e-02, 6.0398e-02, 7.9239e-02,\n",
      "         1.5993e-01, 2.1649e-01, 3.8554e-02, 2.6329e-01],\n",
      "        [9.7140e-02, 1.5785e-01, 2.1615e-01, 1.9992e-01, 4.4322e-01, 7.9385e-03,\n",
      "         1.6256e-01, 2.1950e-01, 3.6601e-02, 4.0397e-02, 4.1961e-02, 1.0463e-01,\n",
      "         1.2466e-01, 1.8378e-01, 2.3534e-02, 2.8203e-01],\n",
      "        [7.3136e-02, 1.0925e-01, 2.7668e-01, 1.8111e-01, 3.4585e-01, 8.0875e-03,\n",
      "         1.8066e-01, 2.7175e-01, 3.7836e-02, 3.9745e-02, 5.7535e-02, 5.9219e-02,\n",
      "         2.1270e-01, 2.7598e-01, 3.1931e-02, 2.5020e-01],\n",
      "        [1.1402e-01, 1.8362e-01, 2.2770e-01, 2.4070e-01, 5.3105e-01, 9.4074e-03,\n",
      "         2.0357e-01, 2.8163e-01, 3.5316e-02, 4.6548e-02, 4.5715e-02, 1.1449e-01,\n",
      "         1.5064e-01, 2.3695e-01, 2.3057e-02, 3.4617e-01],\n",
      "        [1.6392e-02, 3.3551e-02, 6.3603e-02, 4.4081e-02, 8.8517e-02, 1.2489e-03,\n",
      "         3.2776e-02, 4.0797e-02, 8.5331e-03, 7.2785e-03, 1.0504e-02, 1.9684e-02,\n",
      "         3.1020e-02, 3.8845e-02, 4.9688e-03, 5.3839e-02],\n",
      "        [5.6588e-02, 9.7575e-02, 1.5950e-01, 1.2918e-01, 2.7247e-01, 5.0049e-03,\n",
      "         1.0453e-01, 1.4531e-01, 2.1934e-02, 2.4216e-02, 2.9260e-02, 5.8835e-02,\n",
      "         9.3005e-02, 1.2965e-01, 1.4909e-02, 1.7197e-01],\n",
      "        [4.3209e-02, 7.4894e-02, 8.9848e-02, 1.0188e-01, 2.1396e-01, 3.4777e-03,\n",
      "         8.1476e-02, 1.0659e-01, 1.3617e-02, 1.7556e-02, 2.0233e-02, 4.4341e-02,\n",
      "         5.5671e-02, 8.9331e-02, 1.0685e-02, 1.3565e-01],\n",
      "        [1.1295e-01, 1.7929e-01, 3.6501e-01, 3.2353e-01, 5.8125e-01, 1.2891e-02,\n",
      "         3.0730e-01, 4.2801e-01, 4.5804e-02, 6.3220e-02, 1.0532e-01, 8.3142e-02,\n",
      "         3.0073e-01, 4.2493e-01, 5.8267e-02, 4.1223e-01],\n",
      "        [1.1563e-01, 1.9558e-01, 4.0956e-01, 3.1270e-01, 5.9718e-01, 1.1929e-02,\n",
      "         2.8338e-01, 4.0025e-01, 5.3879e-02, 5.7981e-02, 8.8369e-02, 1.0203e-01,\n",
      "         3.0156e-01, 3.9484e-01, 4.7077e-02, 4.0316e-01],\n",
      "        [1.0647e-01, 2.2493e-01, 4.7760e-01, 3.8441e-01, 6.7149e-01, 1.1434e-02,\n",
      "         3.2134e-01, 3.9113e-01, 5.4999e-02, 5.5281e-02, 1.2436e-01, 9.8597e-02,\n",
      "         3.1277e-01, 3.9354e-01, 6.1676e-02, 4.1389e-01],\n",
      "        [7.9594e-02, 1.3748e-01, 1.8240e-01, 1.6928e-01, 3.7977e-01, 6.1346e-03,\n",
      "         1.2983e-01, 1.7117e-01, 2.8470e-02, 3.0855e-02, 3.0950e-02, 8.9593e-02,\n",
      "         9.4284e-02, 1.3973e-01, 1.5888e-02, 2.3262e-01],\n",
      "        [4.0667e-02, 6.9086e-02, 9.4911e-02, 8.8677e-02, 1.9538e-01, 3.2252e-03,\n",
      "         7.2729e-02, 9.9027e-02, 1.3578e-02, 1.6655e-02, 1.6857e-02, 4.3082e-02,\n",
      "         5.3920e-02, 8.4766e-02, 8.0363e-03, 1.2582e-01],\n",
      "        [1.8331e-01, 3.4761e-01, 6.9580e-01, 5.6335e-01, 1.0337e+00, 1.8807e-02,\n",
      "         4.8472e-01, 6.1860e-01, 8.4948e-02, 9.0719e-02, 1.7523e-01, 1.6830e-01,\n",
      "         4.6040e-01, 6.0759e-01, 8.6616e-02, 6.5847e-01],\n",
      "        [4.3636e-02, 8.5894e-02, 1.2584e-01, 1.2977e-01, 2.4959e-01, 3.8405e-03,\n",
      "         1.0486e-01, 1.2455e-01, 1.6305e-02, 1.8574e-02, 3.3333e-02, 4.4020e-02,\n",
      "         7.9163e-02, 1.1252e-01, 1.5932e-02, 1.5296e-01],\n",
      "        [2.4870e-01, 5.2794e-01, 8.3417e-01, 7.1052e-01, 1.4354e+00, 1.9696e-02,\n",
      "         5.1662e-01, 6.0705e-01, 9.5273e-02, 9.6349e-02, 1.5954e-01, 2.8931e-01,\n",
      "         4.0028e-01, 5.3195e-01, 6.4064e-02, 8.1987e-01],\n",
      "        [3.0053e-01, 5.5245e-01, 1.2678e+00, 1.0122e+00, 1.7393e+00, 3.5600e-02,\n",
      "         9.1047e-01, 1.1963e+00, 1.5128e-01, 1.7065e-01, 3.5483e-01, 2.3583e-01,\n",
      "         9.3467e-01, 1.2239e+00, 1.8912e-01, 1.1519e+00]])}, 62: {'step': tensor(11460.), 'exp_avg': tensor([ 5.3892e-04,  5.9936e-04, -6.3870e-05, -1.0806e-04,  2.5303e-04,\n",
      "         1.1956e-04, -1.3209e-05,  8.7065e-04,  3.8275e-05, -5.3836e-04]), 'exp_avg_sq': tensor([3.4993e-05, 1.3691e-04, 2.0775e-05, 4.7151e-05, 5.5465e-05, 1.2893e-05,\n",
      "        2.1484e-05, 8.2105e-05, 2.4864e-05, 7.4272e-05])}, 63: {'step': tensor(11460.), 'exp_avg': tensor([-0.0247, -0.0328, -0.0023, -0.0016, -0.0157, -0.0083, -0.0046, -0.0261,\n",
      "        -0.0058,  0.0337]), 'exp_avg_sq': tensor([0.0091, 0.0163, 0.0094, 0.0103, 0.0077, 0.0072, 0.0082, 0.0213, 0.0090,\n",
      "        0.0298])}, 64: {'step': tensor(11460.), 'exp_avg': tensor([ 0.0005,  0.0165, -0.0030, -0.0394,  0.0175, -0.0018,  0.0305, -0.0522,\n",
      "        -0.0080,  0.0389,  0.0104, -0.0105,  0.0257, -0.0238, -0.0026,  0.0012]), 'exp_avg_sq': tensor([0.0569, 0.3351, 0.0425, 0.1568, 0.0848, 0.0817, 0.2021, 0.2465, 0.0370,\n",
      "        0.2594, 0.0247, 0.0506, 0.0523, 0.2066, 0.0474, 0.2859])}, 65: {'step': tensor(11460.), 'exp_avg': tensor([[-7.9832e-02, -2.4808e-01,  4.0155e-02,  3.6949e-02, -1.3192e-01,\n",
      "         -4.1566e-02, -2.6212e-02,  1.2985e-01,  4.0131e-02, -8.3233e-02,\n",
      "          1.8806e-01,  5.5848e-02,  1.0865e-02, -2.5429e-03, -2.0439e-02,\n",
      "          1.2956e-01],\n",
      "        [ 3.7206e-02,  1.7280e-01, -2.6899e-02, -3.6120e-02,  1.1914e-01,\n",
      "          1.4497e-02,  3.4121e-02, -7.7051e-02, -3.0955e-02,  6.8385e-02,\n",
      "         -1.2572e-01, -5.1494e-02, -6.6669e-03, -5.5360e-03,  9.3898e-03,\n",
      "         -9.4928e-02],\n",
      "        [-1.4906e-01, -4.0876e-01,  6.6179e-02,  6.3386e-02, -1.7429e-01,\n",
      "         -8.1967e-02, -2.9424e-02,  2.1013e-01,  6.4118e-02, -1.3505e-01,\n",
      "          3.0406e-01,  8.5308e-02,  2.7000e-02, -1.2995e-02, -4.1013e-02,\n",
      "          2.0905e-01],\n",
      "        [ 2.3650e-01,  5.5863e-01, -9.9229e-02, -4.3836e-02,  2.2611e-01,\n",
      "          1.4001e-01,  2.0906e-02, -3.3792e-01, -8.0506e-02,  1.4705e-01,\n",
      "         -4.5201e-01, -8.8553e-02, -2.1637e-02,  3.2210e-02,  5.3181e-02,\n",
      "         -2.8217e-01],\n",
      "        [ 9.7240e-02,  3.3873e-01, -4.9763e-02, -6.7016e-02,  1.8017e-01,\n",
      "          4.7400e-02,  3.6935e-02, -1.6051e-01, -5.6422e-02,  1.2873e-01,\n",
      "         -2.4015e-01, -8.4879e-02, -2.1349e-02, -2.4134e-03,  3.1361e-02,\n",
      "         -1.7644e-01],\n",
      "        [ 7.5767e-02,  2.4009e-01, -3.9998e-02, -3.1338e-02,  1.3742e-01,\n",
      "          3.9614e-02,  2.7764e-02, -1.3078e-01, -3.8570e-02,  7.7449e-02,\n",
      "         -1.8702e-01, -5.3616e-02, -6.8719e-03,  1.9471e-03,  1.7211e-02,\n",
      "         -1.2655e-01],\n",
      "        [-3.1199e-01, -8.1160e-01,  1.4066e-01,  8.4814e-02, -3.7026e-01,\n",
      "         -1.7777e-01, -5.5015e-02,  4.6487e-01,  1.2256e-01, -2.3478e-01,\n",
      "          6.4303e-01,  1.5047e-01,  3.2408e-02, -3.2887e-02, -7.1371e-02,\n",
      "          4.1659e-01],\n",
      "        [-1.1685e-01, -4.3323e-01,  5.8644e-02,  1.1288e-01, -2.0833e-01,\n",
      "         -5.3203e-02, -4.9984e-02,  1.7206e-01,  7.5058e-02, -1.8540e-01,\n",
      "          2.8159e-01,  1.2097e-01,  4.2645e-02,  5.5768e-03, -4.6462e-02,\n",
      "          2.2499e-01],\n",
      "        [ 1.4557e-01,  3.7632e-01, -6.4047e-02, -4.5723e-02,  1.6051e-01,\n",
      "          8.2651e-02,  2.4040e-02, -2.0762e-01, -5.7251e-02,  1.1326e-01,\n",
      "         -2.9156e-01, -7.1493e-02, -1.9794e-02,  1.5833e-02,  3.5685e-02,\n",
      "         -1.9229e-01],\n",
      "        [ 9.9666e-03,  1.0124e-01, -9.9008e-03, -4.8780e-02,  5.6016e-02,\n",
      "         -2.1980e-03,  2.3983e-02, -1.2591e-02, -2.1353e-02,  6.2467e-02,\n",
      "         -4.7640e-02, -4.3872e-02, -1.7821e-02, -8.3059e-03,  1.1247e-02,\n",
      "         -5.5265e-02],\n",
      "        [-9.0405e-02, -2.2866e-01,  3.8852e-02,  2.4537e-02, -9.7100e-02,\n",
      "         -5.1930e-02, -1.1574e-02,  1.3103e-01,  3.4134e-02, -6.6506e-02,\n",
      "          1.7914e-01,  4.0796e-02,  1.0706e-02, -9.9619e-03, -2.2139e-02,\n",
      "          1.1601e-01],\n",
      "        [ 7.7930e-02,  1.8448e-01, -3.1910e-02, -2.0717e-02,  6.7080e-02,\n",
      "          4.5095e-02,  7.8063e-03, -1.0309e-01, -2.7631e-02,  5.3074e-02,\n",
      "         -1.4360e-01, -3.1760e-02, -1.1301e-02,  1.0564e-02,  1.9376e-02,\n",
      "         -9.2861e-02],\n",
      "        [-1.2888e-01, -2.7100e-01,  5.1038e-02,  1.2079e-02, -9.1907e-02,\n",
      "         -7.9442e-02, -2.8736e-03,  1.7332e-01,  3.6853e-02, -6.1219e-02,\n",
      "          2.2676e-01,  3.4757e-02,  1.0134e-02, -2.2844e-02, -2.6770e-02,\n",
      "          1.3524e-01],\n",
      "        [-1.4693e-01, -4.7790e-01,  7.3420e-02,  8.9541e-02, -2.4176e-01,\n",
      "         -7.4496e-02, -5.1265e-02,  2.2912e-01,  7.8720e-02, -1.7477e-01,\n",
      "          3.4456e-01,  1.1606e-01,  3.0577e-02, -2.5647e-03, -4.3595e-02,\n",
      "          2.4908e-01],\n",
      "        [ 2.3302e-02,  6.9629e-02, -1.0238e-02, -1.0532e-02,  3.3775e-02,\n",
      "          1.2353e-02,  3.8029e-03, -3.7645e-02, -1.0908e-02,  2.3910e-02,\n",
      "         -5.1149e-02, -1.4300e-02, -3.6733e-03,  3.6727e-04,  7.3687e-03,\n",
      "         -3.5136e-02],\n",
      "        [ 3.2047e-01,  8.3729e-01, -1.3697e-01, -1.2013e-01,  3.3536e-01,\n",
      "          1.8096e-01,  4.6989e-02, -4.4317e-01, -1.2798e-01,  2.6664e-01,\n",
      "         -6.2836e-01, -1.6425e-01, -5.5222e-02,  3.3553e-02,  8.6968e-02,\n",
      "         -4.2489e-01]]), 'exp_avg_sq': tensor([[0.1745, 0.6037, 0.0228, 0.0853, 0.2311, 0.0723, 0.0158, 0.2351, 0.0146,\n",
      "         0.1214, 0.4091, 0.0399, 0.0262, 0.0179, 0.0128, 0.1526],\n",
      "        [0.7051, 1.5925, 0.0943, 0.1533, 0.3385, 0.3021, 0.0231, 0.9464, 0.0284,\n",
      "         0.1601, 1.5234, 0.0528, 0.0344, 0.0724, 0.0187, 0.4058],\n",
      "        [0.0790, 0.2067, 0.0108, 0.0386, 0.0775, 0.0360, 0.0051, 0.1207, 0.0048,\n",
      "         0.0465, 0.1791, 0.0145, 0.0088, 0.0104, 0.0037, 0.0555],\n",
      "        [0.4261, 0.9516, 0.0470, 0.1006, 0.2024, 0.1841, 0.0186, 0.4482, 0.0184,\n",
      "         0.1271, 0.7395, 0.0416, 0.0321, 0.0405, 0.0165, 0.2200],\n",
      "        [0.1653, 0.4030, 0.0220, 0.0762, 0.1215, 0.0769, 0.0111, 0.2556, 0.0092,\n",
      "         0.0798, 0.3731, 0.0292, 0.0178, 0.0195, 0.0072, 0.1010],\n",
      "        [0.2166, 0.7574, 0.0296, 0.0969, 0.2747, 0.0881, 0.0178, 0.2998, 0.0176,\n",
      "         0.1387, 0.5336, 0.0452, 0.0303, 0.0212, 0.0150, 0.1921],\n",
      "        [0.5762, 1.9506, 0.0741, 0.3067, 0.6104, 0.2341, 0.0406, 0.7592, 0.0484,\n",
      "         0.4090, 1.3133, 0.1333, 0.0926, 0.0550, 0.0443, 0.4831],\n",
      "        [0.6333, 1.6961, 0.0780, 0.2463, 0.5405, 0.2720, 0.0367, 0.7949, 0.0357,\n",
      "         0.3085, 1.3044, 0.0997, 0.0712, 0.0656, 0.0339, 0.4150],\n",
      "        [0.0890, 0.2800, 0.0119, 0.0460, 0.0847, 0.0378, 0.0059, 0.1254, 0.0072,\n",
      "         0.0582, 0.2058, 0.0198, 0.0128, 0.0094, 0.0059, 0.0706],\n",
      "        [0.6334, 1.3912, 0.0761, 0.1382, 0.3483, 0.2760, 0.0257, 0.7560, 0.0237,\n",
      "         0.1617, 1.2150, 0.0521, 0.0388, 0.0644, 0.0204, 0.3356],\n",
      "        [0.0648, 0.1472, 0.0074, 0.0173, 0.0369, 0.0283, 0.0033, 0.0734, 0.0030,\n",
      "         0.0214, 0.1176, 0.0071, 0.0051, 0.0066, 0.0026, 0.0351],\n",
      "        [0.1261, 0.4103, 0.0173, 0.0508, 0.1398, 0.0527, 0.0085, 0.1787, 0.0096,\n",
      "         0.0705, 0.3043, 0.0235, 0.0158, 0.0128, 0.0076, 0.1046],\n",
      "        [0.1082, 0.2822, 0.0145, 0.0488, 0.0931, 0.0499, 0.0080, 0.1633, 0.0065,\n",
      "         0.0573, 0.2404, 0.0196, 0.0114, 0.0131, 0.0049, 0.0728],\n",
      "        [0.3986, 0.8256, 0.0530, 0.1138, 0.2004, 0.1780, 0.0149, 0.5636, 0.0147,\n",
      "         0.1072, 0.8558, 0.0372, 0.0217, 0.0450, 0.0102, 0.2105],\n",
      "        [0.1018, 0.2253, 0.0129, 0.0299, 0.0639, 0.0460, 0.0050, 0.1393, 0.0042,\n",
      "         0.0327, 0.2092, 0.0111, 0.0070, 0.0117, 0.0033, 0.0564],\n",
      "        [0.7312, 2.2195, 0.0943, 0.3509, 0.8447, 0.3190, 0.0635, 1.0156, 0.0530,\n",
      "         0.4506, 1.6636, 0.1554, 0.0992, 0.0789, 0.0459, 0.5527]])}, 66: {'step': tensor(11460.), 'exp_avg': tensor([-0.0003, -0.0004, -0.0004, -0.0004, -0.0004, -0.0004, -0.0004, -0.0006,\n",
      "        -0.0004, -0.0007]), 'exp_avg_sq': tensor([3.5928e-05, 6.5317e-05, 3.0646e-05, 3.8495e-05, 3.7949e-05, 2.6789e-05,\n",
      "        3.0708e-05, 8.4529e-05, 3.4562e-05, 5.8270e-05])}, 67: {'step': tensor(11460.), 'exp_avg': tensor([ 0.0160,  0.0214, -0.0018, -0.0019,  0.0086,  0.0033,  0.0003,  0.0118,\n",
      "         0.0012, -0.0333]), 'exp_avg_sq': tensor([0.0162, 0.0175, 0.0151, 0.0155, 0.0140, 0.0140, 0.0147, 0.0371, 0.0161,\n",
      "        0.0240])}, 68: {'step': tensor(11460.), 'exp_avg': tensor([ 0.0465, -0.0296,  0.0392,  0.0310,  0.0111, -0.0210, -0.0445, -0.0132,\n",
      "         0.0529,  0.0030,  0.0176, -0.0023,  0.0068,  0.0264,  0.0348,  0.0231,\n",
      "        -0.0138, -0.0122,  0.0098, -0.0250, -0.0163, -0.0130, -0.0011, -0.0056,\n",
      "        -0.0222, -0.0205, -0.0037,  0.0091,  0.0427, -0.0298, -0.0443, -0.0359]), 'exp_avg_sq': tensor([0.1442, 0.1665, 0.1121, 0.0802, 0.1065, 0.0672, 0.1786, 0.1289, 0.1598,\n",
      "        0.0849, 0.2065, 0.1398, 0.0830, 0.0633, 0.1495, 0.1330, 0.1416, 0.0805,\n",
      "        0.0501, 0.0889, 0.0455, 0.0915, 0.1025, 0.1164, 0.0568, 0.1231, 0.1221,\n",
      "        0.1546, 0.1424, 0.0997, 0.1587, 0.1230])}, 69: {'step': tensor(11460.), 'exp_avg': tensor([[ 2.8697e-01, -3.1303e-01,  2.1496e-01, -6.3245e-02,  1.6007e-01,\n",
      "          1.0350e-01, -3.6836e-01, -7.1126e-02,  1.8873e-01,  4.1525e-02,\n",
      "          2.8534e-01, -4.3066e-01,  7.2639e-02, -1.4416e-02,  1.4194e-02,\n",
      "         -1.0270e-01],\n",
      "        [-1.3183e-01,  1.4704e-01, -9.2009e-02,  3.0934e-02, -8.1398e-02,\n",
      "         -3.3664e-02,  1.7357e-01,  2.5732e-02, -8.3033e-02, -1.3537e-02,\n",
      "         -1.3804e-01,  1.9763e-01, -5.0175e-02,  1.2907e-02, -1.0702e-02,\n",
      "          4.4022e-02],\n",
      "        [ 2.1831e-01, -2.4998e-01,  1.5484e-01, -4.3664e-02,  1.2915e-01,\n",
      "          7.5833e-02, -2.7632e-01, -4.5069e-02,  1.5545e-01,  2.8946e-02,\n",
      "          2.3400e-01, -3.3503e-01,  6.1063e-02, -3.4126e-02,  1.5449e-02,\n",
      "         -8.5158e-02],\n",
      "        [ 1.1850e-02, -2.0434e-02, -1.5516e-02, -7.8813e-03,  1.9781e-02,\n",
      "         -3.6195e-02, -2.8950e-02,  1.5174e-02, -1.3187e-02, -1.1400e-02,\n",
      "          2.8294e-02, -1.0626e-02,  5.1147e-02, -5.2625e-03,  1.1676e-02,\n",
      "          1.3440e-02],\n",
      "        [ 2.5832e-01, -2.8281e-01,  2.1182e-01, -4.7717e-02,  1.3425e-01,\n",
      "          1.3355e-01, -3.1482e-01, -7.6443e-02,  2.0004e-01,  4.9301e-02,\n",
      "          2.5225e-01, -3.9983e-01,  1.8961e-02, -2.4243e-02,  4.6930e-03,\n",
      "         -1.1505e-01],\n",
      "        [-2.3323e-01,  2.5152e-01, -1.8691e-01,  4.8446e-02, -1.2478e-01,\n",
      "         -1.0433e-01,  2.9229e-01,  6.6195e-02, -1.6580e-01, -3.9851e-02,\n",
      "         -2.2511e-01,  3.5468e-01, -3.5177e-02,  1.2293e-02, -6.4016e-03,\n",
      "          9.3561e-02],\n",
      "        [ 2.1085e-01, -2.4217e-01,  2.0271e-01, -1.6386e-02,  9.3357e-02,\n",
      "          1.9063e-01, -2.1811e-01, -8.1252e-02,  2.3282e-01,  6.4048e-02,\n",
      "          2.0896e-01, -3.5652e-01, -7.6435e-02, -5.8777e-02, -9.6619e-03,\n",
      "         -1.4514e-01],\n",
      "        [-2.8740e-01,  3.0946e-01, -2.4057e-01,  5.5076e-02, -1.4703e-01,\n",
      "         -1.5094e-01,  3.5095e-01,  8.9228e-02, -2.1868e-01, -5.6292e-02,\n",
      "         -2.7298e-01,  4.4262e-01, -1.7429e-02,  1.7890e-02, -2.8633e-03,\n",
      "          1.2650e-01],\n",
      "        [ 7.1659e-02, -7.3759e-02,  3.0778e-02, -3.0346e-02,  5.4101e-02,\n",
      "         -3.1666e-02, -1.1737e-01, -1.9449e-03,  2.5561e-03, -6.9045e-03,\n",
      "          7.3952e-02, -8.9193e-02,  8.3730e-02,  1.6333e-02,  1.4177e-02,\n",
      "          7.2645e-03],\n",
      "        [ 1.9556e-01, -2.2034e-01,  1.5939e-01, -3.1795e-02,  1.0268e-01,\n",
      "          1.0827e-01, -2.3277e-01, -5.5976e-02,  1.6346e-01,  3.8738e-02,\n",
      "          1.9864e-01, -3.0874e-01,  7.3186e-03, -3.2105e-02,  4.2008e-03,\n",
      "         -9.5034e-02],\n",
      "        [-2.3729e-01,  2.8443e-01, -2.0127e-01,  2.2341e-02, -1.2241e-01,\n",
      "         -1.7290e-01,  2.5734e-01,  6.9786e-02, -2.4631e-01, -5.7755e-02,\n",
      "         -2.5800e-01,  3.9766e-01,  3.5495e-02,  8.0660e-02, -1.9263e-03,\n",
      "          1.4941e-01],\n",
      "        [-2.7782e-01,  3.2656e-01, -2.2366e-01,  3.6150e-02, -1.4796e-01,\n",
      "         -1.6842e-01,  3.1840e-01,  7.5166e-02, -2.5638e-01, -5.8199e-02,\n",
      "         -2.9814e-01,  4.5106e-01,  3.6930e-03,  7.3291e-02, -7.2204e-03,\n",
      "          1.5136e-01],\n",
      "        [-1.2863e-01,  1.5168e-01, -1.0824e-01,  1.4679e-02, -6.7575e-02,\n",
      "         -8.7114e-02,  1.4342e-01,  3.7312e-02, -1.2687e-01, -2.9299e-02,\n",
      "         -1.3757e-01,  2.1249e-01,  1.2098e-02,  3.8410e-02, -1.6709e-03,\n",
      "          7.6336e-02],\n",
      "        [-6.2136e-02,  7.2587e-02, -6.6859e-02,  3.7020e-04, -2.3000e-02,\n",
      "         -7.3908e-02,  5.6593e-02,  2.8920e-02, -8.2209e-02, -2.4196e-02,\n",
      "         -6.0591e-02,  1.1058e-01,  4.2787e-02,  2.3192e-02,  6.1559e-03,\n",
      "          5.2758e-02],\n",
      "        [ 2.1280e-01, -2.5022e-01,  1.4831e-01, -3.8321e-02,  1.2642e-01,\n",
      "          7.9352e-02, -2.6452e-01, -4.1384e-02,  1.6171e-01,  2.9299e-02,\n",
      "          2.3625e-01, -3.3163e-01,  5.4480e-02, -4.5894e-02,  1.6126e-02,\n",
      "         -8.9292e-02],\n",
      "        [ 4.2317e-02, -4.8581e-02,  1.9637e-02, -1.3576e-02,  3.2073e-02,\n",
      "         -8.9251e-03, -6.3400e-02, -9.2041e-04,  1.4474e-02, -1.9833e-03,\n",
      "          4.9248e-02, -5.8829e-02,  3.9152e-02, -2.6694e-03,  8.0956e-03,\n",
      "         -4.5001e-03],\n",
      "        [ 9.0365e-02, -1.0347e-01,  8.4558e-02, -9.7875e-03,  4.5891e-02,\n",
      "          7.1458e-02, -9.7644e-02, -3.1385e-02,  9.5247e-02,  2.3382e-02,\n",
      "          9.1134e-02, -1.5175e-01, -2.0830e-02, -2.6178e-02, -1.9177e-03,\n",
      "         -5.9232e-02],\n",
      "        [ 8.3682e-03, -1.1843e-02,  1.2591e-02,  2.7599e-03,  2.7390e-03,\n",
      "          1.9128e-02, -3.0730e-03, -5.3771e-03,  2.0993e-02,  5.4021e-03,\n",
      "          9.9006e-03, -1.9472e-02, -1.5909e-02, -1.0576e-02, -1.9457e-03,\n",
      "         -1.4275e-02],\n",
      "        [ 3.5997e-02, -4.1430e-02,  2.4218e-02, -7.3283e-03,  2.0889e-02,\n",
      "          1.1221e-02, -4.5894e-02, -6.9511e-03,  2.3994e-02,  4.6770e-03,\n",
      "          3.8811e-02, -5.4480e-02,  1.1584e-02, -4.4939e-03,  2.7749e-03,\n",
      "         -1.2797e-02],\n",
      "        [-2.1930e-01,  2.4942e-01, -1.6445e-01,  4.0101e-02, -1.2179e-01,\n",
      "         -9.5620e-02,  2.7061e-01,  5.2942e-02, -1.6637e-01, -3.5674e-02,\n",
      "         -2.2955e-01,  3.3968e-01, -3.8415e-02,  3.3102e-02, -1.0800e-02,\n",
      "          9.3212e-02],\n",
      "        [-1.0746e-01,  1.1187e-01, -8.4568e-02,  2.6810e-02, -6.0294e-02,\n",
      "         -3.6439e-02,  1.4113e-01,  2.9288e-02, -6.5255e-02, -1.4808e-02,\n",
      "         -1.0015e-01,  1.5856e-01, -2.8922e-02, -2.7197e-03, -4.1262e-03,\n",
      "          3.5551e-02],\n",
      "        [ 2.5141e-01, -2.7454e-01,  2.2278e-01, -3.9633e-02,  1.2250e-01,\n",
      "          1.6366e-01, -2.9255e-01, -8.5705e-02,  2.1844e-01,  5.8183e-02,\n",
      "          2.3950e-01, -3.9880e-01, -2.0509e-02, -3.0660e-02, -2.7600e-03,\n",
      "         -1.3048e-01],\n",
      "        [-3.2838e-01,  3.6633e-01, -2.7559e-01,  5.3264e-02, -1.6988e-01,\n",
      "         -1.9135e-01,  3.8798e-01,  9.9394e-02, -2.7824e-01, -6.8121e-02,\n",
      "         -3.2692e-01,  5.1975e-01, -6.8044e-04,  5.0244e-02, -3.7226e-03,\n",
      "          1.6372e-01],\n",
      "        [-2.3264e-01,  2.6545e-01, -1.8683e-01,  3.6433e-02, -1.2337e-01,\n",
      "         -1.2824e-01,  2.7575e-01,  6.4222e-02, -1.9722e-01, -4.5616e-02,\n",
      "         -2.4081e-01,  3.6893e-01, -9.9995e-03,  4.3706e-02, -6.1926e-03,\n",
      "          1.1451e-01],\n",
      "        [-3.1057e-02,  2.6382e-02, -1.6074e-02,  1.6134e-02, -2.1579e-02,\n",
      "          1.6315e-02,  5.4520e-02,  3.7793e-03,  6.5796e-03,  3.2462e-03,\n",
      "         -2.4817e-02,  3.4386e-02, -3.8130e-02, -1.8056e-02, -4.8660e-03,\n",
      "         -8.1418e-03],\n",
      "        [-3.4306e-02,  2.8518e-02, -1.9285e-02,  1.6521e-02, -1.9610e-02,\n",
      "          1.2299e-02,  5.8415e-02,  6.6971e-03,  5.9555e-03,  1.1439e-03,\n",
      "         -2.5422e-02,  3.7716e-02, -3.5233e-02, -2.2500e-02, -3.8839e-03,\n",
      "         -8.3193e-03],\n",
      "        [ 1.0150e-02, -1.6527e-02,  8.6567e-03,  3.3613e-03,  2.2409e-03,\n",
      "          1.7292e-02, -5.0951e-03, -3.5009e-03,  1.9921e-02,  5.6965e-03,\n",
      "          1.5030e-02, -2.1056e-02, -1.2176e-02, -1.0814e-02, -7.2228e-04,\n",
      "         -1.2551e-02],\n",
      "        [ 2.2680e-01, -2.4428e-01,  1.8870e-01, -4.3260e-02,  1.1464e-01,\n",
      "          1.1863e-01, -2.7755e-01, -7.0375e-02,  1.7126e-01,  4.4501e-02,\n",
      "          2.1552e-01, -3.4825e-01,  1.4191e-02, -1.2708e-02,  2.4091e-03,\n",
      "         -9.8328e-02],\n",
      "        [-7.2929e-03,  1.3983e-02, -2.9627e-02, -1.4352e-02,  9.3865e-03,\n",
      "         -6.3858e-02, -1.8252e-02,  1.7656e-02, -5.4592e-02, -1.8964e-02,\n",
      "         -6.3032e-03,  3.1899e-02,  6.7661e-02,  2.5152e-02,  1.0477e-02,\n",
      "          3.9307e-02],\n",
      "        [ 6.3160e-02, -7.6670e-02,  6.9623e-02,  1.6833e-03,  2.5478e-02,\n",
      "          8.0119e-02, -5.3979e-02, -2.8864e-02,  9.1970e-02,  2.5243e-02,\n",
      "          6.5016e-02, -1.1690e-01, -4.8550e-02, -3.2358e-02, -6.2805e-03,\n",
      "         -5.9894e-02],\n",
      "        [ 3.0310e-02, -2.5418e-02,  5.9445e-02,  3.3563e-03, -2.7420e-04,\n",
      "          7.4642e-02, -1.5808e-02, -3.3071e-02,  5.9389e-02,  2.3834e-02,\n",
      "          1.0348e-02, -6.0415e-02, -6.7252e-02, -4.4269e-03, -1.4344e-02,\n",
      "         -4.2694e-02],\n",
      "        [ 9.3573e-02, -1.0973e-01,  9.8432e-02, -1.1267e-03,  3.5305e-02,\n",
      "          1.0767e-01, -8.6513e-02, -4.2149e-02,  1.2117e-01,  3.5433e-02,\n",
      "          9.2203e-02, -1.6546e-01, -6.0178e-02, -3.4198e-02, -8.4209e-03,\n",
      "         -7.7366e-02]]), 'exp_avg_sq': tensor([[0.2736, 0.2746, 0.2262, 0.0486, 0.1348, 0.1006, 0.6180, 0.0489, 0.0783,\n",
      "         0.0118, 0.2578, 0.4997, 0.2641, 0.0881, 0.0137, 0.0328],\n",
      "        [0.2706, 0.3253, 0.2482, 0.0450, 0.1332, 0.2087, 0.6231, 0.0742, 0.1282,\n",
      "         0.0239, 0.3465, 0.4970, 0.4282, 0.1192, 0.0262, 0.0575],\n",
      "        [0.2934, 0.3304, 0.4078, 0.0483, 0.1065, 0.2532, 0.5587, 0.1260, 0.1970,\n",
      "         0.0341, 0.3317, 0.5881, 0.3419, 0.2107, 0.0303, 0.0813],\n",
      "        [0.1955, 0.2116, 0.2584, 0.0343, 0.0727, 0.1466, 0.3872, 0.0780, 0.1113,\n",
      "         0.0200, 0.2135, 0.3786, 0.2144, 0.1336, 0.0191, 0.0467],\n",
      "        [0.2264, 0.2680, 0.2774, 0.0397, 0.0946, 0.1926, 0.4626, 0.0827, 0.1506,\n",
      "         0.0230, 0.2697, 0.4488, 0.3003, 0.1502, 0.0230, 0.0658],\n",
      "        [0.1412, 0.1630, 0.1477, 0.0252, 0.0647, 0.0889, 0.3080, 0.0390, 0.0748,\n",
      "         0.0100, 0.1613, 0.2733, 0.1664, 0.0770, 0.0115, 0.0324],\n",
      "        [0.2629, 0.3346, 0.2646, 0.0477, 0.1408, 0.2548, 0.6313, 0.0858, 0.1360,\n",
      "         0.0281, 0.3713, 0.4802, 0.5132, 0.1373, 0.0321, 0.0669],\n",
      "        [0.2858, 0.2943, 0.2822, 0.0479, 0.1349, 0.1181, 0.6115, 0.0657, 0.1037,\n",
      "         0.0149, 0.2767, 0.5528, 0.2455, 0.1167, 0.0167, 0.0434],\n",
      "        [0.3070, 0.3468, 0.3345, 0.0549, 0.1340, 0.2282, 0.6632, 0.0997, 0.1677,\n",
      "         0.0289, 0.3500, 0.5770, 0.4052, 0.1777, 0.0274, 0.0692],\n",
      "        [0.1507, 0.1741, 0.1428, 0.0272, 0.0697, 0.1028, 0.3323, 0.0401, 0.0788,\n",
      "         0.0118, 0.1762, 0.2792, 0.2037, 0.0779, 0.0128, 0.0333],\n",
      "        [0.4701, 0.5405, 0.4918, 0.0850, 0.1995, 0.3135, 1.0106, 0.1390, 0.2759,\n",
      "         0.0374, 0.5361, 0.8998, 0.5525, 0.2881, 0.0377, 0.1114],\n",
      "        [0.3362, 0.3755, 0.3989, 0.0595, 0.1346, 0.2467, 0.6944, 0.1155, 0.2008,\n",
      "         0.0306, 0.3720, 0.6492, 0.3935, 0.2164, 0.0300, 0.0839],\n",
      "        [0.1477, 0.1469, 0.1116, 0.0293, 0.0705, 0.0584, 0.3466, 0.0264, 0.0486,\n",
      "         0.0070, 0.1401, 0.2574, 0.1561, 0.0601, 0.0074, 0.0187],\n",
      "        [0.1170, 0.1349, 0.1309, 0.0214, 0.0516, 0.0965, 0.2520, 0.0404, 0.0707,\n",
      "         0.0120, 0.1389, 0.2203, 0.1681, 0.0736, 0.0115, 0.0294],\n",
      "        [0.3924, 0.4159, 0.5129, 0.0670, 0.1442, 0.2831, 0.7623, 0.1517, 0.2245,\n",
      "         0.0387, 0.4084, 0.7663, 0.4000, 0.2580, 0.0353, 0.0925],\n",
      "        [0.2336, 0.2407, 0.1915, 0.0428, 0.1003, 0.1234, 0.5283, 0.0502, 0.0830,\n",
      "         0.0144, 0.2343, 0.4030, 0.2760, 0.0884, 0.0156, 0.0357],\n",
      "        [0.2325, 0.2514, 0.1520, 0.0420, 0.1218, 0.0868, 0.5562, 0.0334, 0.0712,\n",
      "         0.0097, 0.2471, 0.4140, 0.2635, 0.0755, 0.0117, 0.0267],\n",
      "        [0.1363, 0.1407, 0.0822, 0.0257, 0.0679, 0.0397, 0.3307, 0.0166, 0.0365,\n",
      "         0.0043, 0.1350, 0.2336, 0.1411, 0.0448, 0.0056, 0.0127],\n",
      "        [0.0982, 0.1061, 0.0791, 0.0183, 0.0422, 0.0398, 0.2221, 0.0199, 0.0399,\n",
      "         0.0049, 0.1022, 0.1746, 0.0964, 0.0481, 0.0055, 0.0145],\n",
      "        [0.1887, 0.1649, 0.2098, 0.0393, 0.0714, 0.1035, 0.4012, 0.0565, 0.0674,\n",
      "         0.0135, 0.1517, 0.3291, 0.1837, 0.0988, 0.0127, 0.0327],\n",
      "        [0.0721, 0.0848, 0.0640, 0.0135, 0.0343, 0.0540, 0.1733, 0.0184, 0.0333,\n",
      "         0.0056, 0.0907, 0.1268, 0.1163, 0.0343, 0.0069, 0.0162],\n",
      "        [0.2306, 0.2687, 0.3158, 0.0409, 0.0909, 0.1959, 0.4523, 0.0968, 0.1602,\n",
      "         0.0253, 0.2702, 0.4653, 0.2767, 0.1789, 0.0243, 0.0671],\n",
      "        [0.1696, 0.1968, 0.1741, 0.0308, 0.0875, 0.1330, 0.3899, 0.0495, 0.0820,\n",
      "         0.0147, 0.2029, 0.3182, 0.2631, 0.0840, 0.0164, 0.0390],\n",
      "        [0.1953, 0.2257, 0.1899, 0.0334, 0.0951, 0.1364, 0.4355, 0.0524, 0.0893,\n",
      "         0.0153, 0.2284, 0.3672, 0.2709, 0.0854, 0.0171, 0.0414],\n",
      "        [0.0905, 0.1079, 0.0658, 0.0172, 0.0438, 0.0517, 0.2201, 0.0176, 0.0380,\n",
      "         0.0053, 0.1104, 0.1575, 0.1287, 0.0399, 0.0068, 0.0162],\n",
      "        [0.2744, 0.3198, 0.2892, 0.0463, 0.1154, 0.1732, 0.5616, 0.0803, 0.1659,\n",
      "         0.0215, 0.3126, 0.5412, 0.2904, 0.1622, 0.0212, 0.0648],\n",
      "        [0.2039, 0.1929, 0.1441, 0.0446, 0.0905, 0.0898, 0.5032, 0.0362, 0.0553,\n",
      "         0.0097, 0.1898, 0.3223, 0.2505, 0.0857, 0.0115, 0.0257],\n",
      "        [0.3508, 0.3699, 0.4053, 0.0656, 0.1396, 0.2266, 0.7101, 0.1145, 0.1986,\n",
      "         0.0298, 0.3546, 0.6736, 0.3580, 0.2226, 0.0274, 0.0816],\n",
      "        [0.2667, 0.2921, 0.2593, 0.0480, 0.1192, 0.1649, 0.5866, 0.0730, 0.1277,\n",
      "         0.0207, 0.2880, 0.4921, 0.3214, 0.1371, 0.0200, 0.0509],\n",
      "        [0.1583, 0.1639, 0.0924, 0.0309, 0.0846, 0.0448, 0.3890, 0.0182, 0.0402,\n",
      "         0.0051, 0.1588, 0.2715, 0.1717, 0.0508, 0.0066, 0.0135],\n",
      "        [0.4135, 0.4304, 0.4992, 0.0734, 0.1510, 0.2569, 0.8265, 0.1439, 0.2296,\n",
      "         0.0357, 0.4103, 0.7880, 0.3856, 0.2750, 0.0323, 0.0881],\n",
      "        [0.1982, 0.2429, 0.2310, 0.0363, 0.0936, 0.1966, 0.4421, 0.0753, 0.1217,\n",
      "         0.0235, 0.2621, 0.3728, 0.3474, 0.1247, 0.0237, 0.0556]])}, 70: {'step': tensor(11460.), 'exp_avg': tensor([-0.0021, -0.0021, -0.0021, -0.0021, -0.0021, -0.0020, -0.0021, -0.0021,\n",
      "        -0.0021, -0.0023]), 'exp_avg_sq': tensor([0.0078, 0.0076, 0.0077, 0.0077, 0.0077, 0.0077, 0.0077, 0.0077, 0.0077,\n",
      "        0.0077])}, 71: {'step': tensor(11460.), 'exp_avg': tensor([0.0194, 0.0194, 0.0194, 0.0194, 0.0194, 0.0194, 0.0194, 0.0194, 0.0194,\n",
      "        0.0194]), 'exp_avg_sq': tensor([0.0688, 0.0688, 0.0688, 0.0688, 0.0688, 0.0688, 0.0688, 0.0688, 0.0688,\n",
      "        0.0688])}, 72: {'step': tensor(11460.), 'exp_avg': tensor([[-5.6052e-45, -5.6052e-45,  5.6052e-45,  ...,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45],\n",
      "        [ 5.6052e-45,  4.7644e-44,  1.2191e-43,  ..., -6.8664e-44,\n",
      "          6.4460e-44,  3.5032e-44],\n",
      "        [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  ..., -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45],\n",
      "        ...,\n",
      "        [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  ..., -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45,  ..., -5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45,  ...,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45]]), 'exp_avg_sq': tensor([[2.4580e-04, 5.9691e-04, 1.0035e-04,  ..., 1.3318e-04, 7.8959e-04,\n",
      "         1.2248e-04],\n",
      "        [1.9300e-04, 5.1302e-04, 7.7550e-04,  ..., 7.0054e-04, 4.7309e-04,\n",
      "         6.8697e-04],\n",
      "        [1.1688e-04, 2.1178e-04, 6.8601e-05,  ..., 1.7009e-04, 1.1482e-04,\n",
      "         2.3729e-04],\n",
      "        ...,\n",
      "        [2.2813e-03, 4.8002e-03, 1.8212e-03,  ..., 2.8019e-03, 2.0697e-03,\n",
      "         3.7804e-03],\n",
      "        [1.2441e-03, 2.2077e-03, 4.0942e-04,  ..., 1.1541e-03, 1.4059e-03,\n",
      "         1.7799e-03],\n",
      "        [1.4094e-04, 1.3852e-04, 1.2131e-04,  ..., 2.8919e-04, 2.8323e-04,\n",
      "         4.6913e-04]])}, 73: {'step': tensor(11460.), 'exp_avg': tensor([ 5.6052e-45,  7.0065e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,  3.1207e-42,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  2.4795e-32,  5.6052e-45,  5.6052e-45,  4.4834e-03,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  1.3602e-10,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         1.6230e-02,  3.9710e-17,  1.0965e-35,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  1.5798e-20, -1.0545e-02,  5.6052e-45,  5.6052e-45,\n",
      "         1.7870e-16, -5.6052e-45,  5.6052e-45,  5.6052e-45,  4.1671e-03,\n",
      "         5.6052e-45,  5.6052e-45,  9.8091e-45, -1.1856e-02,  5.6052e-45,\n",
      "         5.6052e-45,  3.9293e-16,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -5.6052e-45,  3.5594e-31,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -9.1763e-08,  5.6052e-45,  5.6052e-45,  5.6052e-45]), 'exp_avg_sq': tensor([2.8246e-06, 5.7572e-06, 1.4316e-06, 4.0676e-04, 1.9650e-06, 6.3795e-06,\n",
      "        5.6103e-06, 9.4115e-06, 2.5527e-06, 1.0936e-04, 5.5969e-07, 1.9447e-05,\n",
      "        1.6420e-05, 2.8204e-06, 2.1757e-05, 6.6330e-05, 2.0302e-03, 1.0727e-05,\n",
      "        2.6632e-05, 1.5288e-02, 6.6588e-06, 7.6371e-06, 6.7537e-07, 1.7644e-05,\n",
      "        5.1747e-05, 5.6500e-07, 5.1277e-07, 9.3764e-07, 6.5470e-04, 1.0671e-06,\n",
      "        3.2040e-02, 3.2570e-05, 1.9914e-05, 4.4880e-05, 4.1030e-05, 2.4295e-06,\n",
      "        1.8398e-05, 1.9158e-02, 1.7698e-04, 5.0730e-06, 6.0450e-04, 2.8299e-05,\n",
      "        1.4079e-05, 4.1548e-06, 6.4805e-03, 4.2979e-06, 1.4766e-06, 3.9845e-06,\n",
      "        2.3811e-02, 4.0799e-06, 4.9731e-06, 2.8589e-04, 1.6069e-05, 2.4753e-04,\n",
      "        8.6895e-05, 1.3681e-05, 6.3227e-06, 1.9440e-05, 1.0772e-05, 1.2467e-05,\n",
      "        2.0877e-03, 3.1224e-05, 1.4613e-05, 2.0621e-06])}}\n",
      "param_groups \t [{'lr': 0.0001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]}]\n"
     ]
    }
   ],
   "source": [
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'{model_name}_state_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, model_name+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([22.329017639160156,\n",
       "  10.219109535217285,\n",
       "  5.376471996307373,\n",
       "  32.74656677246094,\n",
       "  39.740692138671875,\n",
       "  160.8426971435547,\n",
       "  108.23917388916016,\n",
       "  151.3341064453125,\n",
       "  25.837430953979492,\n",
       "  46.920467376708984,\n",
       "  39.1378059387207,\n",
       "  151.56512451171875,\n",
       "  34.71755599975586,\n",
       "  5.639667510986328,\n",
       "  41.822940826416016,\n",
       "  79.52281951904297,\n",
       "  18.758127212524414,\n",
       "  133.33250427246094,\n",
       "  66.47709655761719,\n",
       "  43.0785026550293,\n",
       "  84.30027770996094,\n",
       "  96.66808319091797,\n",
       "  44.6859016418457,\n",
       "  44.002933502197266,\n",
       "  8.093339920043945,\n",
       "  115.54039001464844,\n",
       "  31.010759353637695,\n",
       "  47.83892059326172,\n",
       "  149.17892456054688,\n",
       "  122.85252380371094,\n",
       "  63.60088348388672,\n",
       "  84.79488372802734,\n",
       "  22.039491653442383,\n",
       "  2.315373659133911,\n",
       "  1.2500079870224,\n",
       "  95.49724578857422,\n",
       "  8.544754981994629,\n",
       "  83.22979736328125,\n",
       "  4.910249710083008,\n",
       "  40.343963623046875,\n",
       "  132.6938934326172,\n",
       "  80.48320007324219,\n",
       "  44.710689544677734,\n",
       "  97.19412994384766,\n",
       "  36.20174026489258,\n",
       "  97.12845611572266,\n",
       "  193.5986785888672,\n",
       "  0.9599950313568115,\n",
       "  4.76561164855957,\n",
       "  7.250548839569092,\n",
       "  9.034016609191895,\n",
       "  71.84165954589844,\n",
       "  76.3934326171875,\n",
       "  31.792861938476562,\n",
       "  20.243972778320312,\n",
       "  48.899147033691406,\n",
       "  103.52481842041016,\n",
       "  52.098758697509766,\n",
       "  17.48418426513672,\n",
       "  15.074132919311523,\n",
       "  124.87866973876953,\n",
       "  13.31289005279541,\n",
       "  37.44230270385742,\n",
       "  181.81422424316406,\n",
       "  25.79769515991211,\n",
       "  2.82537841796875,\n",
       "  108.43873596191406,\n",
       "  196.4098663330078,\n",
       "  11.472606658935547,\n",
       "  38.51408767700195,\n",
       "  29.13383674621582,\n",
       "  8.886550903320312,\n",
       "  69.62898254394531,\n",
       "  59.22583770751953,\n",
       "  27.316516876220703,\n",
       "  167.17611694335938,\n",
       "  10.98212718963623,\n",
       "  11.216303825378418,\n",
       "  37.521202087402344,\n",
       "  168.26275634765625,\n",
       "  3.8531789779663086,\n",
       "  128.22821044921875,\n",
       "  40.87168502807617,\n",
       "  39.496036529541016,\n",
       "  12.094539642333984,\n",
       "  80.95346069335938,\n",
       "  32.44213104248047,\n",
       "  37.9345588684082,\n",
       "  4.355545520782471,\n",
       "  105.18943786621094,\n",
       "  162.89492797851562,\n",
       "  58.83170700073242,\n",
       "  51.376094818115234,\n",
       "  25.351619720458984,\n",
       "  0.9785680770874023,\n",
       "  188.7066192626953,\n",
       "  42.74552917480469,\n",
       "  15.52173137664795,\n",
       "  44.03056716918945,\n",
       "  111.69952392578125,\n",
       "  190.78228759765625,\n",
       "  37.96725082397461,\n",
       "  88.76061248779297,\n",
       "  9.259263038635254,\n",
       "  1.9162044525146484,\n",
       "  89.8063735961914,\n",
       "  82.72269439697266,\n",
       "  28.79828643798828,\n",
       "  1.923178791999817,\n",
       "  3.0736958980560303,\n",
       "  130.18096923828125,\n",
       "  211.1922607421875,\n",
       "  74.82051086425781,\n",
       "  0.9990746974945068,\n",
       "  34.75615692138672,\n",
       "  11.882963180541992,\n",
       "  10.229155540466309,\n",
       "  32.06182861328125,\n",
       "  4.754492282867432,\n",
       "  17.93170738220215,\n",
       "  115.0500717163086,\n",
       "  33.89601135253906,\n",
       "  11.188539505004883,\n",
       "  95.1670913696289,\n",
       "  9.468375205993652,\n",
       "  40.36681365966797,\n",
       "  31.62261390686035,\n",
       "  175.1454315185547,\n",
       "  29.177431106567383,\n",
       "  23.755489349365234,\n",
       "  156.39068603515625,\n",
       "  139.43296813964844,\n",
       "  221.9644317626953,\n",
       "  67.1456527709961,\n",
       "  1.189122200012207,\n",
       "  34.593231201171875,\n",
       "  47.229488372802734,\n",
       "  63.75847244262695,\n",
       "  31.34701156616211,\n",
       "  4.584005832672119,\n",
       "  43.122127532958984,\n",
       "  96.0254135131836,\n",
       "  57.491065979003906,\n",
       "  1.3529527187347412,\n",
       "  116.54752349853516,\n",
       "  2.0118954181671143,\n",
       "  26.770769119262695,\n",
       "  119.34942626953125,\n",
       "  151.6846466064453,\n",
       "  26.40955924987793,\n",
       "  55.690521240234375,\n",
       "  145.6708984375,\n",
       "  108.76336669921875,\n",
       "  1.9231114387512207,\n",
       "  9.452539443969727,\n",
       "  207.0744171142578,\n",
       "  86.08312225341797,\n",
       "  55.769012451171875,\n",
       "  97.17948913574219,\n",
       "  5.619045257568359,\n",
       "  3.25775146484375,\n",
       "  32.95686721801758,\n",
       "  29.992271423339844,\n",
       "  14.011678695678711,\n",
       "  167.69105529785156,\n",
       "  41.33531188964844,\n",
       "  117.1151351928711,\n",
       "  65.80184936523438,\n",
       "  128.53797912597656,\n",
       "  19.771867752075195,\n",
       "  127.94840240478516,\n",
       "  15.191327095031738,\n",
       "  17.52058982849121,\n",
       "  1.8309880495071411,\n",
       "  159.20619201660156,\n",
       "  114.59650421142578,\n",
       "  10.86783504486084,\n",
       "  2.288106918334961,\n",
       "  51.90361785888672,\n",
       "  95.43501281738281,\n",
       "  89.20662689208984,\n",
       "  15.963663101196289,\n",
       "  2.065305709838867,\n",
       "  34.7758674621582,\n",
       "  11.515750885009766,\n",
       "  171.0571746826172,\n",
       "  21.062761306762695,\n",
       "  58.311439514160156,\n",
       "  43.289981842041016,\n",
       "  12.922585487365723,\n",
       "  24.619590759277344],\n",
       " [0.749350368976593,\n",
       "  53.30064392089844,\n",
       "  65.67085266113281,\n",
       "  6.729006767272949,\n",
       "  0.40462201833724976,\n",
       "  103.54654693603516,\n",
       "  0.6639126539230347,\n",
       "  6.52174711227417,\n",
       "  2.2145025730133057,\n",
       "  30.345869064331055,\n",
       "  5.330595970153809,\n",
       "  23.511869430541992,\n",
       "  37.803443908691406,\n",
       "  4.574239730834961,\n",
       "  12.670663833618164,\n",
       "  4.755915641784668,\n",
       "  6.918300151824951,\n",
       "  4.304458141326904,\n",
       "  1.6842342615127563,\n",
       "  13.12236213684082,\n",
       "  6.349308490753174,\n",
       "  2.020275831222534,\n",
       "  2.375408887863159,\n",
       "  4.260676383972168,\n",
       "  9.660327911376953,\n",
       "  3.935779333114624,\n",
       "  3.3256170749664307,\n",
       "  79.53652954101562,\n",
       "  4.72757625579834,\n",
       "  3.011620044708252,\n",
       "  0.5840482711791992,\n",
       "  12.940979957580566,\n",
       "  0.6686633825302124,\n",
       "  46.78738021850586,\n",
       "  11.199475288391113,\n",
       "  5.0061540603637695,\n",
       "  8.049978256225586,\n",
       "  2.1801564693450928,\n",
       "  1.8022854328155518,\n",
       "  3.0582966804504395,\n",
       "  20.038333892822266,\n",
       "  13.908061027526855,\n",
       "  25.440725326538086,\n",
       "  27.645797729492188,\n",
       "  2.39375376701355,\n",
       "  8.038067817687988,\n",
       "  2.7616424560546875,\n",
       "  107.52037048339844,\n",
       "  2.155510187149048,\n",
       "  11.959942817687988,\n",
       "  3.550853729248047,\n",
       "  94.47760009765625,\n",
       "  2.023333787918091,\n",
       "  9.853554725646973,\n",
       "  91.68812561035156,\n",
       "  1.4367413520812988,\n",
       "  6.758801460266113,\n",
       "  8.679044723510742,\n",
       "  8.747459411621094,\n",
       "  7.17531156539917,\n",
       "  4.367994785308838,\n",
       "  26.185991287231445,\n",
       "  2.936070442199707,\n",
       "  2.5638175010681152,\n",
       "  95.18944549560547,\n",
       "  5.805807590484619,\n",
       "  6.797974586486816,\n",
       "  189.84304809570312,\n",
       "  143.95420837402344,\n",
       "  2.5472075939178467,\n",
       "  73.87689971923828,\n",
       "  9.549199104309082,\n",
       "  1.9222171306610107,\n",
       "  2.909740924835205,\n",
       "  4.929283618927002,\n",
       "  27.079172134399414,\n",
       "  8.721028327941895,\n",
       "  44.7623291015625,\n",
       "  74.10359954833984,\n",
       "  75.64981079101562,\n",
       "  0.6421579122543335,\n",
       "  9.280427932739258,\n",
       "  30.615074157714844,\n",
       "  133.77740478515625,\n",
       "  7.2613630294799805,\n",
       "  4.8068156242370605,\n",
       "  1.1747081279754639,\n",
       "  2.0439391136169434,\n",
       "  3.0868723392486572,\n",
       "  46.379364013671875,\n",
       "  51.22119903564453,\n",
       "  4.96531343460083,\n",
       "  59.042884826660156,\n",
       "  41.466182708740234,\n",
       "  175.3900604248047,\n",
       "  10.739455223083496,\n",
       "  10.574990272521973,\n",
       "  5.764878273010254,\n",
       "  19.74810218811035,\n",
       "  3.5523183345794678,\n",
       "  12.655403137207031,\n",
       "  25.672746658325195,\n",
       "  16.313377380371094,\n",
       "  69.73020935058594,\n",
       "  123.42936706542969,\n",
       "  1.0023443698883057,\n",
       "  145.44622802734375,\n",
       "  12.160429954528809,\n",
       "  122.40998077392578,\n",
       "  52.67448806762695,\n",
       "  5.271979331970215,\n",
       "  12.360579490661621,\n",
       "  8.244735717773438,\n",
       "  8.44958782196045,\n",
       "  11.499189376831055,\n",
       "  100.28060150146484,\n",
       "  19.70419692993164,\n",
       "  102.7872314453125,\n",
       "  95.8541030883789,\n",
       "  3.462083339691162,\n",
       "  0.3004988431930542,\n",
       "  27.793663024902344,\n",
       "  8.14748764038086,\n",
       "  35.316593170166016,\n",
       "  1.2434386014938354,\n",
       "  144.4453125,\n",
       "  0.8541852235794067,\n",
       "  0.7507864236831665,\n",
       "  18.851112365722656,\n",
       "  157.74281311035156,\n",
       "  0.6965747475624084,\n",
       "  4.4337358474731445,\n",
       "  1.9164677858352661,\n",
       "  94.18720245361328,\n",
       "  1.5956941843032837,\n",
       "  39.81006622314453,\n",
       "  14.81474494934082,\n",
       "  2.913517951965332,\n",
       "  3.53434157371521,\n",
       "  111.161376953125,\n",
       "  1.8574451208114624,\n",
       "  1.0407793521881104,\n",
       "  1.4132883548736572,\n",
       "  1.3759199380874634,\n",
       "  6.724647521972656,\n",
       "  0.592155933380127,\n",
       "  37.509891510009766,\n",
       "  122.180419921875,\n",
       "  1.8284912109375,\n",
       "  95.98648071289062,\n",
       "  5.029109001159668,\n",
       "  3.289539337158203,\n",
       "  1.8790807723999023,\n",
       "  3.902236223220825,\n",
       "  9.993988037109375,\n",
       "  5.774125099182129,\n",
       "  11.268977165222168,\n",
       "  4.898857593536377,\n",
       "  0.796701192855835,\n",
       "  1.9923043251037598,\n",
       "  3.126495838165283,\n",
       "  80.78648376464844,\n",
       "  5.190101623535156,\n",
       "  142.86984252929688,\n",
       "  2.8031325340270996,\n",
       "  121.93600463867188,\n",
       "  2.41263484954834,\n",
       "  3.4417240619659424,\n",
       "  9.214637756347656,\n",
       "  3.9595253467559814,\n",
       "  7.258551120758057,\n",
       "  3.4741315841674805,\n",
       "  9.600262641906738,\n",
       "  15.990554809570312,\n",
       "  1.1329971551895142,\n",
       "  44.06437683105469,\n",
       "  39.63359069824219,\n",
       "  120.8331298828125,\n",
       "  23.24209213256836,\n",
       "  6.502928256988525,\n",
       "  8.513710975646973,\n",
       "  10.672268867492676,\n",
       "  7.581289291381836,\n",
       "  12.651252746582031,\n",
       "  1.235642433166504,\n",
       "  1.667627215385437,\n",
       "  7.275829792022705,\n",
       "  9.899859428405762,\n",
       "  3.7033028602600098,\n",
       "  1.0092109441757202,\n",
       "  1.0322049856185913],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.2807638943195343,\n",
       "  1420.4794921875,\n",
       "  0.0,\n",
       "  2156.329833984375,\n",
       "  22.639738082885742,\n",
       "  0.08185986429452896,\n",
       "  0.0,\n",
       "  5360.9443359375,\n",
       "  0.0,\n",
       "  0.22038964927196503,\n",
       "  21.266620635986328,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.4520139694213867,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  460.4356994628906,\n",
       "  0.0,\n",
       "  14.207633972167969,\n",
       "  0.0,\n",
       "  276.4040832519531,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  714.5504760742188,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  10.461845397949219,\n",
       "  80.27288818359375,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  11.309359550476074,\n",
       "  23.931468963623047,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  9.264163970947266,\n",
       "  1.418321132659912,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  86.09822082519531,\n",
       "  20.15685272216797,\n",
       "  2.040755271911621,\n",
       "  2.821272373199463,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  9.076677322387695,\n",
       "  0.0,\n",
       "  46.661014556884766,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  7.74518346786499,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  5.5298686027526855,\n",
       "  0.0,\n",
       "  3163.0302734375,\n",
       "  11.174979209899902,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  4.534926891326904,\n",
       "  0.0,\n",
       "  0.17055560648441315,\n",
       "  83.73440551757812,\n",
       "  0.22355559468269348,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1094.52978515625,\n",
       "  62.71405792236328,\n",
       "  0.0,\n",
       "  12.53079605102539,\n",
       "  32.40107345581055,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0008001463138498366,\n",
       "  2.3765432834625244,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.6241146326065063,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  4.676584720611572,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  200.76730346679688,\n",
       "  96.71711730957031,\n",
       "  323.6153869628906,\n",
       "  382.1448974609375,\n",
       "  0.0,\n",
       "  2.865030288696289,\n",
       "  0.0,\n",
       "  32.30522155761719,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  3.81333065032959,\n",
       "  5780.314453125,\n",
       "  2.3231096267700195,\n",
       "  0.0,\n",
       "  71.52005004882812,\n",
       "  6.3042826652526855,\n",
       "  0.0,\n",
       "  4463.00830078125,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.0469422340393066,\n",
       "  0.0,\n",
       "  48.546268463134766,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  4203.35693359375,\n",
       "  1.032111644744873,\n",
       "  0.0,\n",
       "  22.840707778930664,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  37.662899017333984,\n",
       "  0.0,\n",
       "  38.25904846191406,\n",
       "  25.742544174194336,\n",
       "  9.539690971374512,\n",
       "  342.85296630859375,\n",
       "  4.310258865356445,\n",
       "  3.2865843772888184,\n",
       "  4530.51513671875,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  16.853708267211914,\n",
       "  0.0,\n",
       "  23.10623550415039,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  18020.19140625,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  10361.4072265625,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  3.244130849838257,\n",
       "  0.0,\n",
       "  2728.897705078125,\n",
       "  45.59361267089844,\n",
       "  0.0,\n",
       "  1.847461462020874,\n",
       "  4.233299732208252,\n",
       "  12.14892578125,\n",
       "  366.64093017578125,\n",
       "  0.0,\n",
       "  38.02819061279297,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1001.8333740234375,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2745.671142578125,\n",
       "  2861.4462890625,\n",
       "  0.20618419349193573,\n",
       "  0.0,\n",
       "  0.00022964194067753851,\n",
       "  43.06315231323242,\n",
       "  0.0,\n",
       "  468.6412048339844,\n",
       "  8948.1953125,\n",
       "  26.363706588745117,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  11.55273151397705,\n",
       "  0.0,\n",
       "  0.6899712681770325,\n",
       "  2.0888469219207764,\n",
       "  4.764385223388672,\n",
       "  1075.5225830078125,\n",
       "  1311.8057861328125,\n",
       "  12.327173233032227,\n",
       "  0.0,\n",
       "  1743.0306396484375,\n",
       "  0.0,\n",
       "  859.7222900390625,\n",
       "  0.0,\n",
       "  15380.8388671875,\n",
       "  57.667999267578125,\n",
       "  55.91521072387695,\n",
       "  16.616918563842773,\n",
       "  194.99380493164062,\n",
       "  6.309476852416992,\n",
       "  80.07963562011719,\n",
       "  329.5447998046875,\n",
       "  133.06304931640625,\n",
       "  2431.151611328125,\n",
       "  0.0,\n",
       "  7617.40234375,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.5023452043533325,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  10577.30078125,\n",
       "  0.0,\n",
       "  73.93802642822266,\n",
       "  7492.1025390625,\n",
       "  0.0,\n",
       "  1387.3006591796875,\n",
       "  13.896875381469727,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  76.39197540283203,\n",
       "  33.987857818603516,\n",
       "  35.697776794433594,\n",
       "  66.11569213867188,\n",
       "  5028.09814453125,\n",
       "  4.255041403666837e-07,\n",
       "  194.1278076171875,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  5282.60693359375,\n",
       "  4594.00390625,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  5.993005752563477,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.04515008255839348,\n",
       "  0.0,\n",
       "  386.2436828613281,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  33.1907844543457,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  623.6311645507812,\n",
       "  0.0,\n",
       "  0.7730683088302612,\n",
       "  0.0,\n",
       "  10432.224609375,\n",
       "  0.36481496691703796,\n",
       "  0.0,\n",
       "  0.28184062242507935,\n",
       "  177.68211364746094,\n",
       "  0.0,\n",
       "  12441.3974609375,\n",
       "  0.242609441280365,\n",
       "  0.0,\n",
       "  9.828998565673828,\n",
       "  0.0,\n",
       "  1.836426019668579,\n",
       "  4435.61474609375,\n",
       "  1.2731198072433472,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  792.4208374023438,\n",
       "  109.7384033203125,\n",
       "  4.244290828704834,\n",
       "  0.0,\n",
       "  6.245781898498535,\n",
       "  0.0,\n",
       "  6178.4248046875,\n",
       "  1.7250475883483887,\n",
       "  0.5416125655174255,\n",
       "  0.998690664768219,\n",
       "  0.9465789794921875,\n",
       "  0.0,\n",
       "  22.610431671142578,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.1753251999616623,\n",
       "  0.0,\n",
       "  703.4956665039062,\n",
       "  7464.0283203125,\n",
       "  1.6716967821121216,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  4606.703125,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  12.645973205566406,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  5.410528182983398,\n",
       "  1.7654677629470825,\n",
       "  7.613718032836914,\n",
       "  0.0,\n",
       "  49.93990707397461,\n",
       "  16.670269012451172,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  63.49493408203125,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  11.999396324157715,\n",
       "  0.3173680901527405,\n",
       "  0.0,\n",
       "  1.9846422672271729,\n",
       "  4.887488842010498,\n",
       "  3263.228515625,\n",
       "  13.468585014343262,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  10205.8955078125,\n",
       "  3.928786039352417,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  7434.1962890625,\n",
       "  2.910400629043579,\n",
       "  5.922737121582031,\n",
       "  0.0,\n",
       "  42.4547233581543,\n",
       "  7.838926315307617,\n",
       "  0.0,\n",
       "  26.343305587768555,\n",
       "  6.034796714782715,\n",
       "  46.0825309753418,\n",
       "  127.84901428222656,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6418408751487732,\n",
       "  970.8346557617188,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  785.4104614257812,\n",
       "  7300.32080078125,\n",
       "  270.0973205566406,\n",
       "  21.144046783447266,\n",
       "  0.0,\n",
       "  36.24162292480469,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  56.94871139526367,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  28.737974166870117,\n",
       "  80.02710723876953,\n",
       "  0.7634077072143555,\n",
       "  0.0,\n",
       "  1.3904904127120972,\n",
       "  26.46881866455078,\n",
       "  49.00364685058594,\n",
       "  6.857232093811035,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.509251058101654,\n",
       "  0.0,\n",
       "  0.5327247977256775,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\AppData\\Local\\Temp\\ipykernel_14776\\3520072505.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tr_results = np.asarray(train_results)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "tr_results = np.asarray(train_results)\n",
    "tr_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [103], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tr_results[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mshape\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "tr_results[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(123)\n",
    "\n",
    "w = 0.8    # bar width\n",
    "x = [1, 2] # x-coordinates of your bars\n",
    "colors = [(0, 0, 1, 1), (1, 0, 0, 1)]    # corresponding colors\n",
    "y = [np.random.random(30) * 2 + 5,       # data series\n",
    "    np.random.random(10) * 3 + 8]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(x,\n",
    "       height=[np.mean(yi) for yi in y],\n",
    "       yerr=[np.std(yi) for yi in y],    # error bars\n",
    "       capsize=12, # error bar cap width in points\n",
    "       width=w,    # bar width\n",
    "       tick_label=[\"control\", \"test\"],\n",
    "       color=(0,0,0,0),  # face color transparent\n",
    "       edgecolor=colors,\n",
    "       #ecolor=colors,    # error bar colors; setting this raises an error for whatever reason.\n",
    "       )\n",
    "\n",
    "for i in range(len(x)):\n",
    "    # distribute scatter randomly across whole width of bar\n",
    "    ax.scatter(x[i] + np.random.random(y[i].size) * w - w / 2, y[i], color=colors[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save(f'{model_name}_training_loss.npy', tr_loss, allow_pickle=True)\n",
    "np.save(f'{model_name}_training_accuracy.npy', tr_acc, allow_pickle=True)\n",
    "\n",
    "np.save(f'{model_name}_validation_loss.npy', v_loss, allow_pickle=True)\n",
    "np.save(f'{model_name}_validation_accuracy.npy', v_acc, allow_pickle=True)\n",
    "\n",
    "np.save(f'{model_name}_test_loss.npy', tst_loss, allow_pickle=True)\n",
    "np.save(f'{model_name}_test_accuracy.npy', tst_acc, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "training_loss = np.load(f'{model_name}_training_loss.npy', allow_pickle=True)\n",
    "training_accuracy = np.load(f'{model_name}_training_accuracy.npy', allow_pickle=True)\n",
    "\n",
    "validation_loss = np.load(f'{model_name}_validation_loss.npy', allow_pickle=True)\n",
    "validation_accuracy = np.load(f'{model_name}_validation_accuracy.npy', allow_pickle=True)\n",
    "\n",
    "test_loss = np.load(f'{model_name}_test_loss.npy', allow_pickle=True)\n",
    "test_accuracy = np.load(f'{model_name}_test_accuracy.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a sequence of integers to represent the epoch numbers\n",
    "epochs = range(1, num_epochs+1)\n",
    " \n",
    "# Plot and label the training and validation loss values\n",
    "plt.plot(epochs, training_loss, label='Training Loss')\n",
    "plt.plot(epochs, validation_loss, label='Validation Loss')\n",
    " \n",
    "# Add in a title and axes labels\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    " \n",
    "# Set the tick locations\n",
    "plt.xticks(np.arange(0, num_epochs+1, num_epochs/10))\n",
    " \n",
    "# Display the plot\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(f'{model_name}_Training and Validation Loss.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a sequence of integers to represent the epoch numbers\n",
    "epochs = range(1, num_epochs+1)\n",
    " \n",
    "# Plot and label the training and validation loss values\n",
    "plt.plot(epochs, training_accuracy, label='Training Accuracy')\n",
    "plt.plot(epochs, validation_accuracy, label='Validation Accuracy')\n",
    "plt.plot(epochs, test_accuracy, label='Test Accuracy')\n",
    " \n",
    "# Add in a title and axes labels\n",
    "plt.title('Accuracy vs. Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    " \n",
    "# Set the tick locations\n",
    "plt.xticks(np.arange(0, num_epochs+1, num_epochs/10))\n",
    "plt.ylim(0,1)\n",
    " \n",
    "# Display the plot\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(f'{model_name}_Accuracy vs. Epochs.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_fraction = [0,0]\n",
    "\n",
    "train_fraction = [0,0]\n",
    "val_fraction = [0,0]\n",
    "test_fraction = [0,0]\n",
    "\n",
    "for grph in train_dataset: \n",
    "    if grph.y == 1: \n",
    "        train_fraction[1] +=1\n",
    "        dataset_fraction[1] +=1 \n",
    "    else: \n",
    "        train_fraction[0] +=1\n",
    "        dataset_fraction[0] +=1 \n",
    "\n",
    "for grph in val_dataset: \n",
    "    if grph.y == 1:\n",
    "         val_fraction[1] +=1\n",
    "         dataset_fraction[1] +=1  \n",
    "    else:\n",
    "         val_fraction[0] +=1\n",
    "         dataset_fraction[0] +=1\n",
    "\n",
    "for grph in test_dataset: \n",
    "    if grph.y == 1:\n",
    "         test_fraction[1] +=1\n",
    "         dataset_fraction[1] +=1 \n",
    "    else:\n",
    "         test_fraction[0] +=1\n",
    "         dataset_fraction[0] +=1\n",
    "\n",
    "print(f'Overall dataset percentage of label 1 = {dataset_fraction[1]/len(dataset)})')\n",
    "print(f'Training dataset percentage of label 1 = {train_fraction} = {train_fraction[1]/len(train_dataset)}')\n",
    "print(f'Validation dataset percentage of label 1 = {val_fraction} = {val_fraction[1]/len(val_dataset)}')\n",
    "print(f'Test dataset percentage of label 1 = {test_fraction} = {test_fraction[1]/len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Graph: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, pos0, adj0 = torch.load(f'{model_name}_img0_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Embedding GNN\n",
    "print(x0[0].shape)\n",
    "x0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pos0[0].shape)\n",
    "pos0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adj0[0].shape)\n",
    "adj0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index, _ = dense_to_sparse(adj0[0])\n",
    "visualize_points(pos0[0].cpu(), edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph After 1st Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_emb, x1_pool, pos1, adj1, s1= torch.load(f'{model_name}_img1_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Embedding GNN (adj0 @ x_0 @ w_gnn_emb)\n",
    "print(x1_emb[0].shape)\n",
    "x1_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Pooling GNN: adj_0 @ x_0 @ w_gnn_pool\n",
    "print(s1[0].shape)\n",
    "s1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Coordinate Matrix (pos_out = softmax(s).t() @ pos_in)\n",
    "print(pos1[0].shape)\n",
    "pos1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Feature Matrix (x_out = softmax(s).t() @ x_in)\n",
    "print(x1_pool[0].shape)\n",
    "x1_pool[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Adjacency Matrix = softmax(adj_out = softmax(s.t()) @ adj_in @ softmax(s))\n",
    "print(adj1[0].shape)\n",
    "adj1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index, _ = dense_to_sparse(adj1[0])\n",
    "visualize_points(pos1[0].cpu(), edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph after 2nd reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_emb, x2_pool, pos2, adj2, s2 = torch.load(f'{model_name}_img2_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Embedding GNN (adj1 @ x1_pool @ w_gnn_emb)\n",
    "print(x2_emb[0].shape)\n",
    "x2_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Pooling GNN: adj1 @ x1_pool @ w_gnn_pool), dim=1\n",
    "print(s2[0].shape)\n",
    "s2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Coordinate Matrix (pos_out = softmax(s.t()) @ pos_in)\n",
    "print(pos2[0].shape)\n",
    "pos2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Feature Matrix (x_out = softmax(s2).t() @ x2_emb)\n",
    "print(x2_pool[0].shape)\n",
    "x2_pool[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Adjacency Matrix (adj = softmax(s).T @ adj @ softmax(s)\n",
    "print(adj2[0].shape)\n",
    "adj2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index, _ = dense_to_sparse(adj2[0])\n",
    "visualize_points(pos2[0].cpu(), edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph after 3rd reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3_emb, x3_pool, pos3, adj3, s3 = torch.load(f'{model_name}_img3_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Embedding GNN (adj_0 @ x_0 @ w_gnn_emb)\n",
    "print(x3_emb[0].shape)\n",
    "x3_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Pooling GNN: torch.softmax(adj_0 @ x_0 @ w_gnn_pool), dim=1)\n",
    "print(s3[0].shape)\n",
    "s3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Coordinate Matrix (pos_out = softmax(s.t()) @ pos_in)\n",
    "print(pos3[0].shape)\n",
    "pos3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Feature Matrix (x_out = softmax(s.t()) @ x_0)\n",
    "print(x3_pool[0].shape)\n",
    "x3_pool[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Adjacency Matrix (adj = softmax(s.t()) @ adj @ softmax(s)\n",
    "print(adj3[0].shape)\n",
    "adj3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index, _ = dense_to_sparse(adj3[0])\n",
    "visualize_points(pos3[0].cpu(), edge_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3baeb0c3f97feb3023477fbaa09b9f4da769e45e64d8febc6957bb84d33ff77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
