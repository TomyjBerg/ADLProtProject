{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize features? \n",
    "## Invert h-bond and charge? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_siamese_071222'\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import DenseDataLoader #To make use of this data loader, all graph attributes in the dataset need to have the same shape. In particular, this data loader should only be used when working with dense adjacency matrices.\n",
    "from torch_geometric.nn import DenseGCNConv, dense_diff_pool\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dir_1 = 'C:/Users/david/pyproj/pyg/adl/patch_label_1'\n",
    "#data_dir_0 = 'C:/Users/david/pyproj/pyg/adl/patch_label_0'\n",
    "data_dir_1 = 'C:/Users/thoma/OneDrive - ZHAW/ProteinSurfaces/patch_label_1'\n",
    "data_dir_0 = 'C:/Users/thoma/OneDrive - ZHAW/ProteinSurfaces/patch_label_0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "572"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from c_PatchDataset import PatchDataset\n",
    "dataset = PatchDataset(data_dir_label_0 = data_dir_0,  data_dir_label_1=data_dir_1,  neg_pos_ratio=1)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: PatchDataset(572):\n",
      "====================\n",
      "Number of graphs pairs: 572\n",
      "\n",
      "PairData(adj1=[100, 100], x1=[100, 3], adj2=[100, 100], x2=[100, 3], y=0)\n",
      "=============================================================\n",
      "Number of nodes in each: None\n",
      "Number of node features: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thoma\\Desktop\\ZHAW MLS\\David prod\\ADLProtProject\\.venv\\lib\\site-packages\\torch_geometric\\data\\storage.py:271: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'x1', 'x2', 'adj1', 'y', 'adj2'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs pairs: {len(dataset)}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "print()\n",
    "print(data)\n",
    "print('=============================================================')\n",
    "\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes in each: {data.num_nodes}')\n",
    "print(f'Number of node features: {data.num_node_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.adj2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does not work we do not have pos\n",
    "#visualize_points(data.pos, data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs pairs: 382\n",
      "Number of validation graphs: 95\n",
      "Number of test graphs: 95\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader \n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "n_train = math.ceil((4/6) * len(dataset))\n",
    "n_val = math.ceil((len(dataset) - n_train)/2)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "print(f'Number of training graphs pairs: {len(train_dataset)}')\n",
    "print(f'Number of validation graphs: {len(val_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')\n",
    "\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size= batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset = val_dataset, batch_size= batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size= batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PairDataBatch(adj1=[100, 100], x1=[100, 3], adj2=[100, 100], x2=[100, 3], y=[1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "databatch = next(iter(train_loader))\n",
    "databatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_nodes, in_channels, hidden_channels, out_channels,\n",
    "                 normalize=False, lin=True):\n",
    "        super(GNN, self).__init__()\n",
    "\n",
    "        # Each instance of this GNN will have 3 convolutional layers and three batch norm layers        \n",
    "        self.conv1 = DenseGCNConv(in_channels, hidden_channels, normalize)\n",
    "        self.bns1 = torch.nn.BatchNorm1d(in_nodes)\n",
    "        \n",
    "        self.conv2 = DenseGCNConv(hidden_channels, hidden_channels, normalize)\n",
    "        self.bns2 = torch.nn.BatchNorm1d(in_nodes)\n",
    "        \n",
    "        self.conv3 = DenseGCNConv(hidden_channels, out_channels, normalize)\n",
    "        self.bns3 = torch.nn.BatchNorm1d(in_nodes)\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        \n",
    "        #Step 1\n",
    "        x = self.conv1(x, adj, mask)\n",
    "        x = self.bns1(x)\n",
    "        \n",
    "        #Step 2\n",
    "        x = self.conv2(x, adj, mask)\n",
    "        x = self.bns2(x)\n",
    "\n",
    "        #Step 3\n",
    "        x = self.conv3(x, adj, mask)\n",
    "        if x.shape[2] != 1: \n",
    "            x = self.bns3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class DiffPool(torch.nn.Module):\n",
    "    def __init__(self, num_nodes):\n",
    "        super(DiffPool, self).__init__()\n",
    "\n",
    "        #Hierarchical Step #1\n",
    "        in_nodes = num_nodes\n",
    "        out_nodes = 25 # Number of clusters / nodes in the next layer\n",
    "        self.gnn1_pool = GNN(in_nodes, dataset.num_features, 16, out_nodes) # PoolGNN --> Cluster Assignment Matrix to reduce to num_nodes\n",
    "        self.gnn1_embed = GNN(in_nodes, dataset.num_features, 8, 8) # EmbGNN --> Convolutions to create new node embedding\n",
    "\n",
    "        # Hierarchical Step #2\n",
    "        in_nodes = out_nodes\n",
    "        out_nodes = 10\n",
    "        self.gnn2_pool = GNN(in_nodes, 8, 8, out_nodes)\n",
    "        self.gnn2_embed = GNN(in_nodes, 8, 12, 16, lin=False)\n",
    "\n",
    "        # Hierarchical Step #3\n",
    "        in_nodes = out_nodes\n",
    "        out_nodes = 1\n",
    "        self.gnn3_pool = GNN(in_nodes, 16, 16, out_nodes)\n",
    "        self.gnn3_embed = GNN(in_nodes, 16, 16, 32, lin=False)\n",
    "\n",
    "        # Final Classifier\n",
    "        self.lin1 = torch.nn.Linear(32, 64) \n",
    "        #self.lin2 = torch.nn.Linear(64, 2)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, batch, mask=None):\n",
    "        \n",
    "        #if batch == 0: print('Shape of input data batch:')\n",
    "        #if batch == 0: print(f'Feature Matrix: {tuple(x.shape)}')\n",
    "        #if batch == 0: print(f'Adjacency Matrix: {tuple(adj.shape)}')\n",
    "       \n",
    "\n",
    "\n",
    "        #Hierarchical Step #1\n",
    "        #if batch == 0: print('Hierarchical Step #1')\n",
    "        x1 = self.gnn1_embed(x, adj, mask) # node feature embedding\n",
    "        s = self.gnn1_pool(x, adj, mask) # cluster assignment matrix\n",
    "\n",
    "        #if batch == 0: print(f'X1 = {tuple(x1.shape)}    S1: {tuple(s.shape)}')\n",
    "\n",
    "        x, adj, l1, e1 = dense_diff_pool(x1, adj, s, mask) # does the necessary matrix multiplications\n",
    "        adj = torch.softmax(adj, dim=-1)\n",
    "\n",
    "        #if batch == 0: print(f'---matmul---> New feature matrix (softmax(s_0.t()) @ z_0) = {tuple(x.shape)}')\n",
    "        #if batch == 0: print(f'---matmul---> New adjacency matrix (s_0.t() @ adj_0 @ s_0) = {tuple(adj.shape)}')\n",
    "   \n",
    "\n",
    "\n",
    "        # Hierarchical Step #2\n",
    "        #if batch == 0: print('Hierarchical Step #2')\n",
    "        x2 = self.gnn2_embed(x, adj)\n",
    "        s = self.gnn2_pool(x, adj)\n",
    "\n",
    "        #if batch == 0: print(f'X2: {tuple(x2.shape)}    S2: {tuple(s.shape)}')\n",
    "        \n",
    "        x, adj, l2, e2 = dense_diff_pool(x2, adj, s)\n",
    "        adj = torch.softmax(adj, dim=-1)\n",
    "\n",
    "        #if batch == 0: print(f'---matmul---> New feature matrix (softmax(s_0.t()) @ z_0) = {tuple(x.shape)}')\n",
    "        #if batch == 0: print(f'---matmul---> New adjacency matrix (s_0.t() @ adj_0 @ s_0) = {tuple(adj.shape)}')\n",
    "      \n",
    "        \n",
    "\n",
    "        # Hierarchical Step #3\n",
    "        #if batch == 0: print('Hierarchical Step #3')\n",
    "        x3 = self.gnn3_embed(x, adj)\n",
    "        s = self.gnn3_pool(x, adj)\n",
    "        \n",
    "        #if batch == 0: print(f'X3: {tuple(x3.shape)}    S3: {tuple(s.shape)}')\n",
    "\n",
    "        x, adj, l3, e3 = dense_diff_pool(x3, adj, s)\n",
    "        adj = torch.softmax(adj, dim=-1)\n",
    "\n",
    "        #if batch == 0: print(f'---matmul---> New feature matrix (softmax(s_0.t()) @ z_0) = {tuple(x.shape)}')\n",
    "        #if batch == 0: print(f'---matmul---> New adjacency matrix (s_0.t() @ adj_0 @ s_0) = {tuple(adj.shape)}')\n",
    "     \n",
    "        \n",
    "\n",
    "        # Final Classification\n",
    "        #if batch == 0: print('Final Output')\n",
    "        x = x.mean(dim=1) # Pool the features of all nodes (global mean pool)  dim = 1 refers to columns\n",
    "        #if batch == 0: print(f'---X Output after mean= {tuple(x.shape)}')\n",
    "\n",
    "        x = F.relu(self.lin1(x)) # Fully connected layer + relu\n",
    "        #if batch == 0: print(f'------ X Output 3 after lin= {tuple(x.shape)}')\n",
    "\n",
    "        \n",
    "        return x, l1 + l2 + l3, e1 + e2 + e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An attempt of a contrastive loss function\n",
    "#   pairs with label 1 --> should get small euclid dist = small loss\n",
    "#   pairs with label 0 --> should get large euclid dist = large loss\n",
    "\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, x0, x1, y):\n",
    "        # euclidian distance\n",
    "        #print(x0)\n",
    "        #print(x1)\n",
    "        #print(y)\n",
    "        diff = x0 - x1\n",
    "        #print(diff)\n",
    "        pow = torch.pow(diff, 2)\n",
    "        #print(pow)\n",
    "        dist_sq = torch.sum(pow, 1)\n",
    "        #print(dist_sq) # sum of squared distance = 0.5 = 9\n",
    "        dist = torch.sqrt(dist_sq)\n",
    "        #print(dist) # euclidean distance = 0.7 = 3\n",
    "\n",
    "        mdist = self.margin - dist #negative euclidean distance - margin = 0.3 = -2\n",
    "        #print(mdist)\n",
    "        dist_marg = torch.clamp(mdist, min=0.0) # only distances <margin will be still positive here = 0.3 = 0\n",
    "        #print(dist)\n",
    "        loss =  (1 - y) * torch.pow(dist, 2) + y * torch.pow(dist_marg,2)\n",
    "\n",
    "        # What happens to a pair with squared euclid dist (dist_sq) of 0.5\n",
    "        # if label = 0 --> 0 + squared clampled euclid distance --> loss = 0.3^2\n",
    "        # if label = 1 --> squared euclidean distance + 0 --> loss = 0.5\n",
    "\n",
    "        # What happens to a pair with squared euclid dist (dist_sq) of 9\n",
    "        # if label = 0 --> 0 + squared clampled euclid distance --> loss = 0\n",
    "        # if label = 1 --> squared euclidean distance + 0 --> loss = 9\n",
    "\n",
    "        #print(loss)\n",
    "        #loss = torch.sum(loss) / 2.0 \n",
    "        loss = torch.sum(loss) / 2.0 / x0.size()[0]\n",
    "        #print(loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch: 001, Train Loss: 28.854\n",
      "Epoch: 002, Train Loss: 0.300\n",
      "Epoch: 003, Train Loss: 0.199\n",
      "Epoch: 004, Train Loss: 0.182\n",
      "Epoch: 005, Train Loss: 0.180\n",
      "Epoch: 006, Train Loss: 0.228\n",
      "Epoch: 007, Train Loss: 0.246\n",
      "Epoch: 008, Train Loss: 0.214\n",
      "Epoch: 009, Train Loss: 0.269\n",
      "Epoch: 010, Train Loss: 0.292\n",
      "Epoch: 011, Train Loss: 0.275\n",
      "Epoch: 012, Train Loss: 1.405\n",
      "Epoch: 013, Train Loss: 0.180\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = DiffPool(num_nodes = 100).to(device)\n",
    "criterion = ContrastiveLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 30\n",
    "\n",
    "def train(epoch):\n",
    "    batch = 0\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output1, _, _ = model(data.x1, data.adj1, batch)\n",
    "        output2, _, _ = model(data.x2, data.adj2, batch = None)\n",
    "        \n",
    "        #Contrastive Loss\n",
    "        loss_contrastive = criterion(output1,output2,data.y)\n",
    "        loss_contrastive.backward()\n",
    "        loss_all += data.y.size(0) * loss_contrastive.item()\n",
    "        optimizer.step()\n",
    "        batch +=1\n",
    "\n",
    "    return loss_all / len(train_dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    distances_lab1 = []\n",
    "    distances_lab0 = []\n",
    "    labels = []\n",
    "    losses = []\n",
    "    \n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output1, _, _ = model(data.x1, data.adj2, batch=None)\n",
    "        output2, _, _ = model(data.x2, data.adj2, batch=None)\n",
    "\n",
    "        test_loss_contrastive = criterion(output1, output2, data.y)\n",
    "        \n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        label = data.y\n",
    "\n",
    "        if int(label) == 1: \n",
    "            distances_lab1.append(float(euclidean_distance))\n",
    "            labels.append(int(label))\n",
    "            losses.append(float(test_loss_contrastive))\n",
    "        else:\n",
    "            distances_lab0.append(float(euclidean_distance))\n",
    "            labels.append(int(label))\n",
    "            losses.append(float(test_loss_contrastive))\n",
    "\n",
    "    return  distances_lab0, distances_lab1, losses, labels\n",
    "\n",
    "\n",
    "\n",
    "train_distances_lab0 = []\n",
    "train_distances_lab1 = []\n",
    "train_losses = []\n",
    "train_labels = []\n",
    "\n",
    "validation_distances_lab0 = []\n",
    "validation_distances_lab1 = []\n",
    "validation_losses = []\n",
    "validation_labels = []\n",
    "\n",
    "test_distances_lab0 = []\n",
    "test_distances_lab1 = []\n",
    "test_losses = []\n",
    "test_labels = []\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    train_loss = train(epoch)\n",
    "\n",
    "    train_results = test(train_loader)\n",
    "    train_distances_lab0.append(train_results[0])\n",
    "    train_distances_lab1.append(train_results[1])\n",
    "    train_losses.append(train_results[2])\n",
    "    train_labels.append(train_results[3])\n",
    "\n",
    "\n",
    "    validation_results = test(val_loader)\n",
    "    validation_distances_lab0.append(validation_results[0])\n",
    "    validation_distances_lab1.append(validation_results[1])\n",
    "    validation_losses.append(validation_results[2])\n",
    "    validation_labels.append(validation_results[3])\n",
    "\n",
    "    test_results = test(test_loader)\n",
    "    test_distances_lab0.append(test_results[0])\n",
    "    test_distances_lab1.append(test_results[1])\n",
    "    test_losses.append(test_results[2])\n",
    "    test_labels.append(test_results[3])\n",
    "\n",
    "\n",
    "    print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.3f}')\n",
    "    #Train Acc: {train_acc:.3f}, f'Val Acc: {val_acc:.3f}, Test Acc: {test_acc:.3f}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compare_euclid_distances(distances_lab0, distances_lab1):\n",
    "\n",
    "    w = 0.8    # bar width\n",
    "    x = [1, 2] # x-coordinates of your bars\n",
    "    colors = [(0, 0, 1, 1), (1, 0, 0, 1)]    # corresponding colors\n",
    "\n",
    "    # Epoch 0\n",
    "    y = [distances_lab0, distances_lab1]\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(x,\n",
    "        height=[np.mean(yi) for yi in y],\n",
    "        yerr=[np.std(yi) for yi in y],    # error bars\n",
    "        capsize=12, # error bar cap width in points\n",
    "        width=w,    # bar width\n",
    "        tick_label=[\"Label 0\", \"Label 1\"],\n",
    "        color=(0,0,0,0),  # face color transparent\n",
    "        edgecolor=colors,\n",
    "        )\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        # distribute scatter randomly across whole width of bar\n",
    "        ax.scatter(x[i] + np.random.random(len(y[i])) * w - w / 2, y[i], color=colors[i])\n",
    "\n",
    "    plt.ylabel = 'Euclidean Distance'\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_euclid_distances(train_distances_lab0[15], train_distances_lab1[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "gnn1_pool.conv1.bias \t torch.Size([16])\n",
      "gnn1_pool.conv1.lin.weight \t torch.Size([16, 3])\n",
      "gnn1_pool.bns1.weight \t torch.Size([100])\n",
      "gnn1_pool.bns1.bias \t torch.Size([100])\n",
      "gnn1_pool.bns1.running_mean \t torch.Size([100])\n",
      "gnn1_pool.bns1.running_var \t torch.Size([100])\n",
      "gnn1_pool.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn1_pool.conv2.bias \t torch.Size([16])\n",
      "gnn1_pool.conv2.lin.weight \t torch.Size([16, 16])\n",
      "gnn1_pool.bns2.weight \t torch.Size([100])\n",
      "gnn1_pool.bns2.bias \t torch.Size([100])\n",
      "gnn1_pool.bns2.running_mean \t torch.Size([100])\n",
      "gnn1_pool.bns2.running_var \t torch.Size([100])\n",
      "gnn1_pool.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn1_pool.conv3.bias \t torch.Size([25])\n",
      "gnn1_pool.conv3.lin.weight \t torch.Size([25, 16])\n",
      "gnn1_pool.bns3.weight \t torch.Size([100])\n",
      "gnn1_pool.bns3.bias \t torch.Size([100])\n",
      "gnn1_pool.bns3.running_mean \t torch.Size([100])\n",
      "gnn1_pool.bns3.running_var \t torch.Size([100])\n",
      "gnn1_pool.bns3.num_batches_tracked \t torch.Size([])\n",
      "gnn1_embed.conv1.bias \t torch.Size([8])\n",
      "gnn1_embed.conv1.lin.weight \t torch.Size([8, 3])\n",
      "gnn1_embed.bns1.weight \t torch.Size([100])\n",
      "gnn1_embed.bns1.bias \t torch.Size([100])\n",
      "gnn1_embed.bns1.running_mean \t torch.Size([100])\n",
      "gnn1_embed.bns1.running_var \t torch.Size([100])\n",
      "gnn1_embed.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn1_embed.conv2.bias \t torch.Size([8])\n",
      "gnn1_embed.conv2.lin.weight \t torch.Size([8, 8])\n",
      "gnn1_embed.bns2.weight \t torch.Size([100])\n",
      "gnn1_embed.bns2.bias \t torch.Size([100])\n",
      "gnn1_embed.bns2.running_mean \t torch.Size([100])\n",
      "gnn1_embed.bns2.running_var \t torch.Size([100])\n",
      "gnn1_embed.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn1_embed.conv3.bias \t torch.Size([8])\n",
      "gnn1_embed.conv3.lin.weight \t torch.Size([8, 8])\n",
      "gnn1_embed.bns3.weight \t torch.Size([100])\n",
      "gnn1_embed.bns3.bias \t torch.Size([100])\n",
      "gnn1_embed.bns3.running_mean \t torch.Size([100])\n",
      "gnn1_embed.bns3.running_var \t torch.Size([100])\n",
      "gnn1_embed.bns3.num_batches_tracked \t torch.Size([])\n",
      "gnn2_pool.conv1.bias \t torch.Size([8])\n",
      "gnn2_pool.conv1.lin.weight \t torch.Size([8, 8])\n",
      "gnn2_pool.bns1.weight \t torch.Size([25])\n",
      "gnn2_pool.bns1.bias \t torch.Size([25])\n",
      "gnn2_pool.bns1.running_mean \t torch.Size([25])\n",
      "gnn2_pool.bns1.running_var \t torch.Size([25])\n",
      "gnn2_pool.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn2_pool.conv2.bias \t torch.Size([8])\n",
      "gnn2_pool.conv2.lin.weight \t torch.Size([8, 8])\n",
      "gnn2_pool.bns2.weight \t torch.Size([25])\n",
      "gnn2_pool.bns2.bias \t torch.Size([25])\n",
      "gnn2_pool.bns2.running_mean \t torch.Size([25])\n",
      "gnn2_pool.bns2.running_var \t torch.Size([25])\n",
      "gnn2_pool.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn2_pool.conv3.bias \t torch.Size([10])\n",
      "gnn2_pool.conv3.lin.weight \t torch.Size([10, 8])\n",
      "gnn2_pool.bns3.weight \t torch.Size([25])\n",
      "gnn2_pool.bns3.bias \t torch.Size([25])\n",
      "gnn2_pool.bns3.running_mean \t torch.Size([25])\n",
      "gnn2_pool.bns3.running_var \t torch.Size([25])\n",
      "gnn2_pool.bns3.num_batches_tracked \t torch.Size([])\n",
      "gnn2_embed.conv1.bias \t torch.Size([12])\n",
      "gnn2_embed.conv1.lin.weight \t torch.Size([12, 8])\n",
      "gnn2_embed.bns1.weight \t torch.Size([25])\n",
      "gnn2_embed.bns1.bias \t torch.Size([25])\n",
      "gnn2_embed.bns1.running_mean \t torch.Size([25])\n",
      "gnn2_embed.bns1.running_var \t torch.Size([25])\n",
      "gnn2_embed.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn2_embed.conv2.bias \t torch.Size([12])\n",
      "gnn2_embed.conv2.lin.weight \t torch.Size([12, 12])\n",
      "gnn2_embed.bns2.weight \t torch.Size([25])\n",
      "gnn2_embed.bns2.bias \t torch.Size([25])\n",
      "gnn2_embed.bns2.running_mean \t torch.Size([25])\n",
      "gnn2_embed.bns2.running_var \t torch.Size([25])\n",
      "gnn2_embed.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn2_embed.conv3.bias \t torch.Size([16])\n",
      "gnn2_embed.conv3.lin.weight \t torch.Size([16, 12])\n",
      "gnn2_embed.bns3.weight \t torch.Size([25])\n",
      "gnn2_embed.bns3.bias \t torch.Size([25])\n",
      "gnn2_embed.bns3.running_mean \t torch.Size([25])\n",
      "gnn2_embed.bns3.running_var \t torch.Size([25])\n",
      "gnn2_embed.bns3.num_batches_tracked \t torch.Size([])\n",
      "gnn3_pool.conv1.bias \t torch.Size([16])\n",
      "gnn3_pool.conv1.lin.weight \t torch.Size([16, 16])\n",
      "gnn3_pool.bns1.weight \t torch.Size([10])\n",
      "gnn3_pool.bns1.bias \t torch.Size([10])\n",
      "gnn3_pool.bns1.running_mean \t torch.Size([10])\n",
      "gnn3_pool.bns1.running_var \t torch.Size([10])\n",
      "gnn3_pool.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn3_pool.conv2.bias \t torch.Size([16])\n",
      "gnn3_pool.conv2.lin.weight \t torch.Size([16, 16])\n",
      "gnn3_pool.bns2.weight \t torch.Size([10])\n",
      "gnn3_pool.bns2.bias \t torch.Size([10])\n",
      "gnn3_pool.bns2.running_mean \t torch.Size([10])\n",
      "gnn3_pool.bns2.running_var \t torch.Size([10])\n",
      "gnn3_pool.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn3_pool.conv3.bias \t torch.Size([1])\n",
      "gnn3_pool.conv3.lin.weight \t torch.Size([1, 16])\n",
      "gnn3_pool.bns3.weight \t torch.Size([10])\n",
      "gnn3_pool.bns3.bias \t torch.Size([10])\n",
      "gnn3_pool.bns3.running_mean \t torch.Size([10])\n",
      "gnn3_pool.bns3.running_var \t torch.Size([10])\n",
      "gnn3_pool.bns3.num_batches_tracked \t torch.Size([])\n",
      "gnn3_embed.conv1.bias \t torch.Size([16])\n",
      "gnn3_embed.conv1.lin.weight \t torch.Size([16, 16])\n",
      "gnn3_embed.bns1.weight \t torch.Size([10])\n",
      "gnn3_embed.bns1.bias \t torch.Size([10])\n",
      "gnn3_embed.bns1.running_mean \t torch.Size([10])\n",
      "gnn3_embed.bns1.running_var \t torch.Size([10])\n",
      "gnn3_embed.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn3_embed.conv2.bias \t torch.Size([16])\n",
      "gnn3_embed.conv2.lin.weight \t torch.Size([16, 16])\n",
      "gnn3_embed.bns2.weight \t torch.Size([10])\n",
      "gnn3_embed.bns2.bias \t torch.Size([10])\n",
      "gnn3_embed.bns2.running_mean \t torch.Size([10])\n",
      "gnn3_embed.bns2.running_var \t torch.Size([10])\n",
      "gnn3_embed.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn3_embed.conv3.bias \t torch.Size([32])\n",
      "gnn3_embed.conv3.lin.weight \t torch.Size([32, 16])\n",
      "gnn3_embed.bns3.weight \t torch.Size([10])\n",
      "gnn3_embed.bns3.bias \t torch.Size([10])\n",
      "gnn3_embed.bns3.running_mean \t torch.Size([10])\n",
      "gnn3_embed.bns3.running_var \t torch.Size([10])\n",
      "gnn3_embed.bns3.num_batches_tracked \t torch.Size([])\n",
      "lin1.weight \t torch.Size([64, 32])\n",
      "lin1.bias \t torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer's state_dict:\n",
      "state \t {0: {'step': tensor(3820.), 'exp_avg': tensor([ 2.8445e-20, -6.9422e-20, -3.1782e-20,  5.2043e-20,  4.7987e-22,\n",
      "         1.2048e-20, -3.6965e-20,  3.2110e-20,  1.2917e-20, -1.1714e-20,\n",
      "         1.0632e-20,  3.9492e-20, -5.6435e-20,  2.1133e-21,  5.2675e-20,\n",
      "        -3.6637e-20]), 'exp_avg_sq': tensor([ 4.2446, 64.4574,  1.5525,  7.4734, 27.9939, 37.3418, 85.5606, 95.1106,\n",
      "        13.2425, 25.7589,  9.2820,  9.6957, 10.5717, 32.5673,  9.9329, 20.5714])}, 1: {'step': tensor(3820.), 'exp_avg': tensor([[ 2.3940e-20, -7.6265e-22, -5.5771e-20],\n",
      "        [-1.1371e-19, -1.5135e-20,  1.8058e-19],\n",
      "        [-4.7432e-20, -5.7289e-21,  9.6904e-20],\n",
      "        [ 7.8894e-20,  1.0673e-20, -1.6599e-19],\n",
      "        [ 9.7582e-21,  1.8193e-21,  2.7258e-20],\n",
      "        [ 3.0610e-20,  6.5959e-21, -2.6931e-20],\n",
      "        [-6.9400e-20, -1.0735e-20,  8.5243e-20],\n",
      "        [ 7.2120e-20,  1.3122e-20, -7.4682e-20],\n",
      "        [ 2.3193e-20,  2.2115e-21, -6.3141e-20],\n",
      "        [-3.5133e-20, -7.8863e-21,  2.6737e-20],\n",
      "        [ 1.0128e-20,  4.7213e-22, -1.3880e-21],\n",
      "        [ 7.1243e-20,  1.2274e-20, -1.6357e-19],\n",
      "        [-7.6299e-20, -9.6846e-21,  1.6129e-19],\n",
      "        [ 8.2907e-21,  1.6693e-22,  1.3315e-20],\n",
      "        [ 8.1818e-20,  1.2777e-20, -1.3957e-19],\n",
      "        [-6.8025e-20, -1.0180e-20,  9.9719e-20]]), 'exp_avg_sq': tensor([[7.2498e-01, 1.7505e-02, 2.8943e+00],\n",
      "        [2.5401e+00, 3.9681e-02, 2.1026e+01],\n",
      "        [5.9742e-01, 4.5880e-02, 1.8469e+00],\n",
      "        [9.7877e-02, 1.0490e-02, 2.7538e+00],\n",
      "        [1.7719e+00, 1.3275e-01, 7.8935e+00],\n",
      "        [7.5712e+00, 2.2491e-01, 5.3427e+00],\n",
      "        [2.5459e+00, 4.3272e-02, 2.6864e+01],\n",
      "        [2.2622e+00, 7.3817e-02, 3.8084e+01],\n",
      "        [3.5185e+00, 1.1245e-01, 1.3974e+00],\n",
      "        [9.8742e-01, 2.5151e-02, 9.7905e+00],\n",
      "        [1.9560e-01, 2.0613e-02, 3.3188e+00],\n",
      "        [1.9713e-01, 1.9056e-02, 3.3092e+00],\n",
      "        [1.3321e+00, 3.1392e-02, 1.8560e+00],\n",
      "        [3.3392e+00, 7.0811e-02, 6.0902e+00],\n",
      "        [3.4968e+00, 1.3287e-01, 1.6523e+00],\n",
      "        [1.0153e+00, 2.3514e-02, 5.1510e+00]])}, 2: {'step': tensor(3820.), 'exp_avg': tensor([ 5.9874e-23, -2.4423e-22,  3.3561e-22, -1.9214e-21, -7.7384e-23,\n",
      "         2.5921e-22, -3.0910e-23, -1.4572e-22, -9.4350e-23, -4.9252e-21,\n",
      "         1.5653e-22, -9.0766e-23, -2.3045e-22,  1.0941e-21, -1.3472e-22,\n",
      "         3.5810e-22, -1.3146e-22, -1.2275e-22, -1.9709e-22, -1.4744e-22,\n",
      "         1.4520e-22, -1.4873e-23,  2.4371e-22, -1.9033e-22, -1.7772e-22,\n",
      "        -1.2896e-22, -4.0118e-22, -1.4654e-22,  1.0423e-22, -4.4168e-22,\n",
      "        -1.2437e-22,  8.0043e-22,  3.4955e-22, -2.0946e-21, -1.1401e-23,\n",
      "         1.9329e-23, -4.1568e-21,  1.9024e-22,  9.8901e-23, -3.8664e-22,\n",
      "        -1.4711e-22,  1.7858e-22, -1.3909e-22,  7.8003e-23,  5.9563e-22,\n",
      "         6.8532e-22, -5.5730e-23,  3.6210e-22, -9.4456e-23, -2.5438e-22,\n",
      "        -6.9448e-22,  1.0874e-22, -1.1812e-21, -1.3190e-22, -4.1631e-23,\n",
      "         2.2817e-22,  1.0112e-22,  1.2646e-22, -3.3078e-22, -6.1787e-24,\n",
      "        -2.4818e-22, -2.9513e-22, -2.7223e-22, -3.4191e-22,  6.3324e-22,\n",
      "        -3.5244e-21, -2.2438e-22, -1.4714e-22,  2.5308e-22, -2.4295e-22,\n",
      "         3.2030e-22, -2.2886e-24,  3.6886e-23, -1.5836e-22, -1.8336e-21,\n",
      "        -1.8286e-22,  1.4398e-21,  4.2336e-22, -7.4274e-23,  1.1739e-22,\n",
      "         4.5226e-22,  1.2424e-21,  1.1111e-21,  7.7912e-22, -3.2238e-22,\n",
      "        -5.0509e-22, -7.5663e-22, -1.0012e-22, -1.3550e-22,  2.2223e-23,\n",
      "         6.8775e-22, -1.5166e-22,  3.8417e-22, -2.6292e-22,  1.1376e-21,\n",
      "         1.2716e-22,  5.5575e-22, -7.6631e-22, -1.2722e-22,  6.1013e-23]), 'exp_avg_sq': tensor([0.0016, 0.0006, 0.0012, 0.0013, 0.0005, 0.0010, 0.0032, 0.0014, 0.0015,\n",
      "        0.0017, 0.0044, 0.0013, 0.0002, 0.0004, 0.0008, 0.0007, 0.0008, 0.0007,\n",
      "        0.0027, 0.0002, 0.0007, 0.0023, 0.0025, 0.0010, 0.0025, 0.0012, 0.0004,\n",
      "        0.0011, 0.0027, 0.0005, 0.0004, 0.0030, 0.0004, 0.0010, 0.0033, 0.0003,\n",
      "        0.0004, 0.0009, 0.0001, 0.0009, 0.0005, 0.0039, 0.0008, 0.0004, 0.0009,\n",
      "        0.0003, 0.0023, 0.0010, 0.0013, 0.0014, 0.0003, 0.0045, 0.0004, 0.0004,\n",
      "        0.0019, 0.0019, 0.0003, 0.0025, 0.0023, 0.0012, 0.0004, 0.0009, 0.0016,\n",
      "        0.0004, 0.0003, 0.0018, 0.0016, 0.0003, 0.0017, 0.0004, 0.0008, 0.0010,\n",
      "        0.0025, 0.0010, 0.0003, 0.0003, 0.0008, 0.0037, 0.0011, 0.0006, 0.0015,\n",
      "        0.0018, 0.0011, 0.0010, 0.0039, 0.0006, 0.0008, 0.0023, 0.0004, 0.0023,\n",
      "        0.0021, 0.0004, 0.0015, 0.0010, 0.0027, 0.0005, 0.0003, 0.0006, 0.0008,\n",
      "        0.0043])}, 3: {'step': tensor(3820.), 'exp_avg': tensor([-2.7850e-22,  4.2932e-21, -5.4398e-21,  6.8783e-22,  6.6034e-22,\n",
      "        -5.9018e-21,  6.3367e-22,  3.5780e-21,  1.1077e-21,  4.7723e-21,\n",
      "        -5.2830e-22,  5.2215e-22,  2.9610e-21,  6.6525e-22,  1.5906e-21,\n",
      "        -5.4592e-21, -1.3159e-21,  3.8699e-21,  1.2501e-21,  1.2814e-21,\n",
      "         1.7730e-21,  1.5436e-21,  6.0674e-21,  1.8273e-21,  1.7471e-21,\n",
      "         1.8116e-21,  1.2066e-21,  8.1730e-23, -1.5290e-21,  4.5468e-21,\n",
      "         3.3962e-21, -5.1389e-21,  8.8180e-22,  4.7352e-21,  3.4314e-21,\n",
      "        -1.4705e-22,  1.8707e-21, -1.3318e-21, -7.2448e-22,  4.7030e-21,\n",
      "         1.6657e-21,  1.1957e-23,  1.0301e-21, -6.3320e-22,  7.8994e-22,\n",
      "        -4.7125e-21,  1.1944e-22,  5.1751e-21,  2.7999e-21,  2.5825e-21,\n",
      "        -2.1794e-22, -1.2871e-21,  7.1237e-21,  2.6062e-21,  3.3384e-22,\n",
      "        -6.5972e-22,  4.3150e-22, -1.3483e-21,  2.3625e-21,  5.6472e-21,\n",
      "         2.6544e-21,  2.2572e-21, -6.1209e-22,  4.6459e-21, -3.9232e-21,\n",
      "         2.1371e-21,  5.8360e-22,  8.7610e-23, -6.8720e-21,  2.4463e-21,\n",
      "         4.5825e-21, -7.0081e-24,  2.5264e-21,  3.5301e-21,  6.8563e-21,\n",
      "         1.7764e-21, -2.0918e-22, -2.1110e-21,  2.4170e-22,  8.2850e-23,\n",
      "         2.7063e-21,  4.0292e-21,  4.7523e-21, -1.8598e-21,  2.3262e-21,\n",
      "         4.6414e-21, -6.6112e-22,  9.1279e-22,  1.4201e-21,  6.6253e-22,\n",
      "        -4.2472e-21,  2.2532e-21,  4.3243e-21,  2.8908e-21,  3.1351e-21,\n",
      "        -2.9810e-22, -6.3575e-22,  8.1276e-21,  1.3467e-22, -1.6101e-21]), 'exp_avg_sq': tensor([0.0067, 0.0022, 0.0027, 0.0020, 0.0010, 0.0096, 0.0029, 0.0034, 0.0044,\n",
      "        0.0045, 0.0017, 0.0024, 0.0036, 0.0057, 0.0042, 0.0030, 0.0050, 0.0018,\n",
      "        0.0053, 0.0024, 0.0021, 0.0042, 0.0047, 0.0014, 0.0055, 0.0037, 0.0028,\n",
      "        0.0054, 0.0044, 0.0030, 0.0026, 0.0045, 0.0044, 0.0043, 0.0066, 0.0026,\n",
      "        0.0037, 0.0055, 0.0031, 0.0034, 0.0026, 0.0078, 0.0089, 0.0023, 0.0049,\n",
      "        0.0030, 0.0068, 0.0060, 0.0046, 0.0028, 0.0065, 0.0054, 0.0038, 0.0022,\n",
      "        0.0090, 0.0044, 0.0038, 0.0059, 0.0042, 0.0056, 0.0037, 0.0019, 0.0073,\n",
      "        0.0058, 0.0013, 0.0023, 0.0067, 0.0043, 0.0021, 0.0018, 0.0044, 0.0024,\n",
      "        0.0072, 0.0072, 0.0018, 0.0044, 0.0043, 0.0023, 0.0036, 0.0047, 0.0024,\n",
      "        0.0039, 0.0035, 0.0032, 0.0069, 0.0035, 0.0041, 0.0092, 0.0026, 0.0085,\n",
      "        0.0034, 0.0035, 0.0045, 0.0035, 0.0091, 0.0042, 0.0062, 0.0066, 0.0048,\n",
      "        0.0041])}, 4: {'step': tensor(3820.), 'exp_avg': tensor([-3.9813e-20,  3.1921e-20, -3.0261e-20,  4.3858e-20, -2.8193e-20,\n",
      "         4.7086e-20,  3.9406e-21, -1.0977e-20,  1.3828e-21, -4.6878e-20,\n",
      "        -4.6368e-20,  5.3476e-20,  1.9060e-20, -8.3100e-20,  8.8825e-20,\n",
      "        -3.9588e-21]), 'exp_avg_sq': tensor([ 0.7551, 11.5135,  3.3184,  3.3862,  7.3220, 16.0925,  5.0444,  2.0648,\n",
      "         0.4438,  3.6218,  5.2000,  2.4567,  1.0006,  2.3212,  1.7146,  0.7132])}, 5: {'step': tensor(3820.), 'exp_avg': tensor([[-6.7437e-20,  2.1696e-20,  2.0406e-20,  3.3545e-20, -4.0759e-20,\n",
      "          1.4288e-20, -9.0004e-21,  2.9996e-20, -4.8014e-20,  3.3489e-20,\n",
      "          2.8420e-20,  5.8006e-20, -3.3329e-20, -5.0923e-20, -4.2322e-20,\n",
      "          3.9812e-20],\n",
      "        [ 3.3751e-20,  3.6488e-21, -6.2848e-21, -3.0084e-20,  2.9784e-20,\n",
      "         -1.3041e-20,  1.6851e-20, -1.0215e-20, -1.7082e-21, -2.7507e-20,\n",
      "         -4.4941e-21, -4.4724e-20,  3.0911e-20,  2.3348e-20,  3.2361e-20,\n",
      "         -2.2087e-20],\n",
      "        [-3.9603e-20,  6.2124e-21,  9.5728e-21,  2.5478e-20, -2.7785e-20,\n",
      "          1.0934e-20, -1.0672e-20,  1.5134e-20, -1.6616e-20,  2.4414e-20,\n",
      "          1.2359e-20,  4.0870e-20, -2.6044e-20, -2.8321e-20, -2.9626e-20,\n",
      "          2.4268e-20],\n",
      "        [ 8.2967e-20, -2.1452e-20, -2.4859e-20, -4.6558e-20,  5.3713e-20,\n",
      "         -2.0050e-20,  1.5762e-20, -3.6091e-20,  4.9958e-20, -4.5024e-20,\n",
      "         -3.1739e-20, -7.7251e-20,  4.5801e-20,  6.2666e-20,  5.6250e-20,\n",
      "         -4.9801e-20],\n",
      "        [-4.9309e-20,  7.4421e-21,  1.5105e-20,  3.3089e-20, -3.6534e-20,\n",
      "          1.4336e-20, -1.4376e-20,  2.0490e-20, -2.0191e-20,  3.1021e-20,\n",
      "          1.5067e-20,  5.2459e-20, -3.2316e-20, -3.8263e-20, -3.8333e-20,\n",
      "          3.0672e-20],\n",
      "        [ 8.3453e-20, -2.0044e-20, -2.3897e-20, -4.7995e-20,  5.4648e-20,\n",
      "         -2.0658e-20,  1.6981e-20, -3.5425e-20,  4.7535e-20, -4.6329e-20,\n",
      "         -3.0922e-20, -7.9085e-20,  4.7655e-20,  6.2165e-20,  5.7501e-20,\n",
      "         -5.0228e-20],\n",
      "        [ 2.2761e-20, -1.3200e-20, -1.0511e-20, -6.6046e-21,  1.1160e-20,\n",
      "         -2.7839e-21, -1.4234e-21, -1.3079e-20,  2.6593e-20, -7.2635e-21,\n",
      "         -1.3372e-20, -1.4072e-20,  5.2911e-21,  2.0023e-20,  1.0592e-20,\n",
      "         -1.2853e-20],\n",
      "        [-2.3388e-20,  5.1183e-21,  6.3162e-21,  1.3875e-20, -1.5247e-20,\n",
      "          6.0187e-21, -5.0787e-21,  9.7999e-21, -1.2537e-20,  1.3202e-20,\n",
      "          8.5317e-21,  2.2472e-20, -1.3758e-20, -1.6944e-20, -1.6237e-20,\n",
      "          1.4055e-20],\n",
      "        [ 1.1488e-20, -1.9888e-21, -3.1456e-21, -7.4114e-21,  7.6774e-21,\n",
      "         -3.2767e-21,  2.9488e-21, -4.9029e-21,  5.3219e-21, -6.7856e-21,\n",
      "         -4.0174e-21, -1.1551e-20,  7.1400e-21,  8.2462e-21,  8.2859e-21,\n",
      "         -6.9470e-21],\n",
      "        [-7.7083e-20,  2.2467e-20,  2.2788e-20,  4.0551e-20, -4.8194e-20,\n",
      "          1.7314e-20, -1.2305e-20,  3.3546e-20, -5.0674e-20,  4.0086e-20,\n",
      "          3.0894e-20,  6.8944e-20, -4.0411e-20, -5.7957e-20, -5.0244e-20,\n",
      "          4.5910e-20],\n",
      "        [-8.0602e-20,  2.1320e-20,  2.3283e-20,  4.4443e-20, -5.1483e-20,\n",
      "          1.9070e-20, -1.4672e-20,  3.4596e-20, -4.9301e-20,  4.3345e-20,\n",
      "          3.1090e-20,  7.4243e-20, -4.4218e-20, -6.0110e-20, -5.4002e-20,\n",
      "          4.8231e-20],\n",
      "        [ 8.2730e-20, -2.5597e-20, -2.2861e-20, -4.1517e-20,  4.9553e-20,\n",
      "         -1.7651e-20,  1.1407e-20, -3.5519e-20,  5.7062e-20, -4.1610e-20,\n",
      "         -3.4334e-20, -7.1547e-20,  4.2096e-20,  6.0463e-20,  5.1942e-20,\n",
      "         -4.8764e-20],\n",
      "        [ 2.7567e-20, -8.1220e-21, -8.7139e-21, -1.4531e-20,  1.7713e-20,\n",
      "         -6.1710e-21,  4.5045e-21, -1.2150e-20,  1.8213e-20, -1.4425e-20,\n",
      "         -1.0900e-20, -2.4866e-20,  1.4400e-20,  2.1423e-20,  1.8260e-20,\n",
      "         -1.6516e-20],\n",
      "        [-1.4509e-19,  4.2220e-20,  4.3925e-20,  7.6742e-20, -9.1080e-20,\n",
      "          3.2847e-20, -2.3451e-20,  6.3828e-20, -9.5420e-20,  7.5473e-20,\n",
      "          5.8233e-20,  1.3006e-19, -7.5877e-20, -1.0992e-19, -9.4854e-20,\n",
      "          8.6463e-20],\n",
      "        [ 1.4689e-19, -4.2855e-20, -4.3421e-20, -7.7213e-20,  9.1700e-20,\n",
      "         -3.2978e-20,  2.3392e-20, -6.3992e-20,  9.6728e-20, -7.6268e-20,\n",
      "         -5.8971e-20, -1.3123e-19,  7.6907e-20,  1.1039e-19,  9.5635e-20,\n",
      "         -8.7425e-20],\n",
      "        [-9.0973e-21,  3.1360e-21,  2.2978e-21,  4.1902e-21, -4.8649e-21,\n",
      "          1.8014e-21, -8.6833e-22,  3.9853e-21, -6.9495e-21,  4.1812e-21,\n",
      "          4.1559e-21,  7.2664e-21, -4.2473e-21, -6.2798e-21, -5.2080e-21,\n",
      "          5.2094e-21]]), 'exp_avg_sq': tensor([[2.9770e-01, 1.3869e-01, 9.7673e-02, 9.4301e-02, 9.7330e-02, 1.8066e-02,\n",
      "         3.6603e-02, 1.1706e-01, 5.7172e-01, 7.6601e-02, 1.1409e-01, 2.0736e-01,\n",
      "         9.6627e-02, 2.3432e-01, 9.7952e-02, 9.1377e-02],\n",
      "        [1.3456e+01, 6.5106e+00, 3.9311e+00, 4.6543e-01, 2.0645e+00, 1.1796e-01,\n",
      "         3.6409e-01, 4.9655e+00, 2.6891e+01, 5.2462e-01, 5.5752e+00, 2.5593e+00,\n",
      "         2.2230e-01, 1.0060e+01, 1.2696e+00, 3.6143e+00],\n",
      "        [2.0518e+00, 1.4638e+00, 7.5927e-01, 7.5318e-02, 2.2014e-01, 1.4870e-02,\n",
      "         1.6939e-01, 9.1298e-01, 5.9016e+00, 6.2785e-02, 1.1232e+00, 2.4615e-01,\n",
      "         1.0959e-01, 1.6676e+00, 1.2048e-01, 4.9505e-01],\n",
      "        [2.2195e+00, 1.2891e+00, 7.1113e-01, 1.3789e-01, 2.9689e-01, 3.2928e-02,\n",
      "         1.3629e-01, 9.1613e-01, 5.3290e+00, 1.1310e-01, 1.0711e+00, 4.4189e-01,\n",
      "         1.4124e-01, 1.6658e+00, 1.9885e-01, 5.5424e-01],\n",
      "        [2.5648e+00, 3.1958e+00, 1.2075e+00, 3.4357e-01, 1.1770e-01, 5.4385e-02,\n",
      "         6.5649e-01, 1.4663e+00, 1.2520e+01, 1.8471e-01, 2.1699e+00, 2.5393e-01,\n",
      "         5.3663e-01, 2.2467e+00, 1.1608e-01, 4.8937e-01],\n",
      "        [4.7499e+00, 7.1631e+00, 2.7336e+00, 1.0164e+00, 1.8177e-01, 1.6572e-01,\n",
      "         1.6282e+00, 3.0716e+00, 2.7670e+01, 5.5613e-01, 4.6006e+00, 7.2447e-01,\n",
      "         1.5727e+00, 4.6042e+00, 3.0598e-01, 8.4177e-01],\n",
      "        [3.0624e+00, 2.3129e+00, 1.2340e+00, 7.0836e-02, 2.8565e-01, 1.6573e-02,\n",
      "         2.6506e-01, 1.4251e+00, 9.3268e+00, 4.6099e-02, 1.7449e+00, 2.3986e-01,\n",
      "         1.3035e-01, 2.5784e+00, 1.1760e-01, 7.1059e-01],\n",
      "        [3.7458e+00, 1.6445e+00, 1.2000e+00, 2.4333e-01, 7.5733e-01, 5.3601e-02,\n",
      "         8.7910e-02, 1.3933e+00, 6.7911e+00, 2.3997e-01, 1.4157e+00, 1.0027e+00,\n",
      "         1.3187e-01, 3.0162e+00, 5.0732e-01, 1.0622e+00],\n",
      "        [8.2933e-01, 3.3045e-01, 2.8875e-01, 8.6159e-02, 2.1218e-01, 1.6852e-02,\n",
      "         1.8834e-02, 3.0053e-01, 1.3387e+00, 8.2181e-02, 2.7887e-01, 2.9993e-01,\n",
      "         5.5230e-02, 7.1323e-01, 1.5451e-01, 2.5339e-01],\n",
      "        [1.0480e+00, 1.5750e+00, 4.3011e-01, 7.6957e-01, 3.0117e-01, 1.3720e-01,\n",
      "         5.7715e-01, 5.7747e-01, 6.0232e+00, 5.1295e-01, 9.9107e-01, 1.0672e+00,\n",
      "         8.8371e-01, 7.5692e-01, 4.7672e-01, 2.4264e-01],\n",
      "        [3.7070e+00, 2.9207e+00, 1.3571e+00, 1.4856e-01, 2.9779e-01, 2.6290e-02,\n",
      "         3.8945e-01, 1.6884e+00, 1.1792e+01, 1.0672e-01, 2.2157e+00, 3.4078e-01,\n",
      "         2.5782e-01, 2.8897e+00, 1.5825e-01, 8.4163e-01],\n",
      "        [1.3005e+00, 1.0809e+00, 5.2438e-01, 1.2934e-01, 1.5912e-01, 2.2062e-02,\n",
      "         1.6886e-01, 5.9995e-01, 4.2549e+00, 1.0236e-01, 7.6908e-01, 2.6209e-01,\n",
      "         1.8903e-01, 1.1000e+00, 1.2533e-01, 3.2120e-01],\n",
      "        [8.4778e-01, 5.6664e-01, 2.6941e-01, 1.1857e-01, 1.3930e-01, 2.2767e-02,\n",
      "         9.2189e-02, 3.4368e-01, 2.2566e+00, 9.2818e-02, 4.3256e-01, 2.7024e-01,\n",
      "         1.3400e-01, 6.4164e-01, 1.2400e-01, 2.2168e-01],\n",
      "        [4.9620e+00, 1.4546e+00, 1.0514e+00, 7.3713e-01, 1.2849e+00, 1.5207e-01,\n",
      "         1.0914e-01, 1.4253e+00, 6.0888e+00, 6.6240e-01, 1.4240e+00, 2.2573e+00,\n",
      "         5.1418e-01, 3.3633e+00, 1.0916e+00, 1.5455e+00],\n",
      "        [2.7962e+00, 5.2710e-01, 4.7583e-01, 5.9498e-01, 8.2709e-01, 1.2320e-01,\n",
      "         5.4240e-02, 6.9927e-01, 2.3856e+00, 5.1162e-01, 6.3764e-01, 1.6460e+00,\n",
      "         4.6131e-01, 1.6919e+00, 7.6912e-01, 9.0039e-01],\n",
      "        [2.1016e-01, 2.9128e-01, 9.1421e-02, 1.6531e-01, 7.2796e-02, 2.8885e-02,\n",
      "         1.1399e-01, 1.1502e-01, 1.1104e+00, 1.1422e-01, 1.8414e-01, 2.4188e-01,\n",
      "         1.9018e-01, 1.5858e-01, 1.0895e-01, 5.3593e-02]])}, 6: {'step': tensor(3820.), 'exp_avg': tensor([ 1.7156e-23, -3.9519e-23,  4.6198e-22, -2.2133e-22, -5.0871e-23,\n",
      "         4.2318e-22, -4.9205e-23,  2.2184e-22, -9.4835e-23, -2.8602e-21,\n",
      "         1.1791e-22, -5.2917e-23, -2.1785e-22, -5.4339e-22, -1.1492e-22,\n",
      "         4.9076e-22, -7.6241e-22, -5.1840e-24, -1.7722e-22,  3.4243e-22,\n",
      "         3.6069e-22, -6.2995e-23,  1.0837e-21, -1.3036e-22, -1.2316e-22,\n",
      "        -2.0532e-22, -1.7458e-22, -3.2519e-22,  1.6905e-22, -4.2740e-22,\n",
      "        -1.1926e-23,  7.9622e-22,  8.5731e-22, -1.8999e-21, -4.9311e-23,\n",
      "         8.3904e-23, -5.6026e-21,  2.4538e-22,  1.0595e-22, -3.8997e-22,\n",
      "        -1.5737e-22,  1.4404e-22, -6.5199e-23,  1.1415e-22,  7.6341e-23,\n",
      "         6.5835e-22, -1.1662e-21,  1.5552e-21, -1.4790e-22, -2.7202e-22,\n",
      "        -8.1856e-22,  2.5034e-22, -9.5969e-22,  1.6875e-22, -4.0522e-23,\n",
      "         2.4580e-22,  1.1157e-22,  1.6575e-22, -1.6687e-22,  3.3446e-22,\n",
      "        -2.2998e-22,  2.4644e-22, -1.2213e-22, -1.6496e-22,  7.1756e-22,\n",
      "        -3.2336e-21,  1.5498e-21, -3.2442e-22,  5.7012e-22, -1.8688e-22,\n",
      "         1.4664e-21,  6.0909e-23,  3.1107e-23, -2.7317e-22, -1.2099e-21,\n",
      "        -1.3462e-22,  4.2119e-21,  4.5849e-22, -6.3152e-24,  2.0715e-22,\n",
      "        -2.6099e-22,  6.7321e-22, -1.4400e-21,  7.3673e-22, -2.9072e-22,\n",
      "        -4.6504e-22, -1.3430e-21, -6.3480e-23, -1.1571e-22, -6.2082e-22,\n",
      "         5.7658e-22, -1.5807e-22,  2.1371e-22, -2.7338e-22,  9.6991e-22,\n",
      "         2.3979e-22,  5.5746e-22, -2.2544e-21, -4.0613e-22, -9.6768e-22]), 'exp_avg_sq': tensor([8.4730e-04, 6.9309e-04, 8.2127e-04, 6.8134e-04, 5.8233e-04, 7.8183e-04,\n",
      "        2.1507e-03, 1.0291e-03, 3.1588e-04, 1.6502e-03, 3.1922e-03, 5.3380e-04,\n",
      "        3.0675e-04, 7.9636e-04, 1.1744e-03, 4.4576e-04, 2.7142e-04, 1.1717e-03,\n",
      "        2.4218e-03, 6.2667e-04, 1.4172e-03, 1.2743e-03, 3.0194e-03, 9.1803e-04,\n",
      "        2.1719e-03, 3.1198e-04, 4.5262e-04, 1.0836e-03, 1.0016e-03, 6.9310e-04,\n",
      "        7.4721e-04, 1.2860e-03, 1.1585e-03, 2.9465e-04, 3.5383e-03, 7.5646e-04,\n",
      "        7.7867e-04, 1.3791e-03, 1.8530e-04, 4.6767e-04, 4.0429e-04, 1.7588e-03,\n",
      "        1.0643e-03, 1.1032e-03, 1.8206e-03, 3.9650e-04, 2.1662e-03, 1.3537e-03,\n",
      "        2.3140e-03, 1.3739e-03, 1.2188e-03, 3.3442e-03, 2.9522e-04, 1.0979e-03,\n",
      "        2.2817e-03, 1.9335e-03, 6.3284e-04, 3.8299e-03, 3.3237e-03, 8.6955e-04,\n",
      "        1.6870e-04, 2.6575e-04, 1.9911e-03, 6.0693e-04, 9.1563e-05, 1.9099e-03,\n",
      "        1.2184e-03, 8.2669e-04, 1.2866e-03, 7.3831e-04, 1.1819e-03, 2.7763e-03,\n",
      "        2.5686e-03, 1.5450e-03, 3.1567e-04, 2.9499e-04, 1.6462e-03, 5.8674e-03,\n",
      "        1.0895e-03, 4.7284e-04, 1.2028e-03, 8.3101e-04, 1.3681e-03, 8.0079e-04,\n",
      "        1.4916e-03, 6.5527e-04, 4.8156e-04, 2.2497e-03, 4.0541e-04, 2.2784e-03,\n",
      "        1.3987e-03, 6.0478e-04, 1.6492e-04, 4.9270e-04, 1.9354e-03, 7.1818e-04,\n",
      "        6.1812e-04, 9.5623e-04, 1.9426e-03, 4.0205e-03])}, 7: {'step': tensor(3820.), 'exp_avg': tensor([-1.7415e-22,  4.9776e-21, -7.1238e-21, -5.4440e-22,  6.0720e-22,\n",
      "        -8.5988e-21,  4.3906e-22,  3.5591e-21,  8.0596e-22,  2.9445e-21,\n",
      "        -7.5467e-22,  1.1206e-22,  2.2884e-21,  4.1878e-22,  1.1431e-21,\n",
      "        -7.7129e-21, -6.8926e-22,  3.4525e-21,  1.0676e-21,  1.1082e-21,\n",
      "         1.4038e-21,  8.8092e-22,  6.5078e-21,  1.3192e-21,  1.3553e-21,\n",
      "         1.6197e-21,  4.7195e-22, -2.4704e-22, -2.5696e-21,  4.9492e-21,\n",
      "         3.1521e-21, -6.8907e-21,  1.0175e-21,  3.2551e-21,  2.9499e-21,\n",
      "        -7.0285e-22,  5.8805e-22, -2.4684e-21, -1.1900e-21,  4.6001e-21,\n",
      "         1.4110e-21, -4.5186e-22,  6.6553e-22, -1.1555e-21,  1.5785e-23,\n",
      "        -6.3196e-21, -3.0516e-22,  5.0458e-21,  2.2090e-21,  2.6174e-21,\n",
      "        -6.7022e-22, -2.0741e-21,  6.5646e-21,  2.4534e-21, -3.7213e-23,\n",
      "        -1.5799e-21, -7.1032e-23, -2.4122e-21,  2.1754e-21,  5.1056e-21,\n",
      "         2.1633e-21,  2.1803e-21, -3.0127e-22,  5.1100e-21, -6.0027e-21,\n",
      "         2.6577e-22, -3.2190e-22, -2.3457e-22, -9.9706e-21,  2.1100e-21,\n",
      "         4.4894e-21, -8.1675e-22,  2.3138e-21,  3.5576e-21,  6.1537e-21,\n",
      "         1.4852e-21, -8.5759e-22, -3.0375e-21, -2.8587e-22, -1.2340e-21,\n",
      "         1.9547e-21,  2.7724e-21,  3.6278e-21, -2.2718e-21,  1.8146e-21,\n",
      "         4.7328e-21, -1.0862e-21,  3.1799e-22,  1.0627e-21,  3.3839e-22,\n",
      "        -5.6338e-21,  2.0574e-21,  3.9934e-21,  2.7348e-21,  2.3975e-21,\n",
      "        -1.1992e-21, -1.1314e-21,  6.9221e-21, -2.3565e-22, -8.5174e-22]), 'exp_avg_sq': tensor([0.0012, 0.0025, 0.0005, 0.0005, 0.0004, 0.0010, 0.0017, 0.0031, 0.0008,\n",
      "        0.0025, 0.0005, 0.0013, 0.0029, 0.0010, 0.0011, 0.0009, 0.0018, 0.0006,\n",
      "        0.0020, 0.0006, 0.0003, 0.0008, 0.0011, 0.0009, 0.0018, 0.0005, 0.0009,\n",
      "        0.0010, 0.0004, 0.0006, 0.0008, 0.0015, 0.0022, 0.0041, 0.0016, 0.0011,\n",
      "        0.0012, 0.0007, 0.0011, 0.0005, 0.0009, 0.0017, 0.0019, 0.0014, 0.0033,\n",
      "        0.0011, 0.0025, 0.0015, 0.0015, 0.0025, 0.0014, 0.0026, 0.0014, 0.0012,\n",
      "        0.0018, 0.0012, 0.0009, 0.0009, 0.0023, 0.0011, 0.0010, 0.0006, 0.0010,\n",
      "        0.0014, 0.0007, 0.0008, 0.0014, 0.0017, 0.0015, 0.0007, 0.0008, 0.0018,\n",
      "        0.0004, 0.0013, 0.0007, 0.0014, 0.0018, 0.0019, 0.0018, 0.0009, 0.0005,\n",
      "        0.0009, 0.0018, 0.0010, 0.0026, 0.0010, 0.0013, 0.0022, 0.0006, 0.0027,\n",
      "        0.0013, 0.0007, 0.0010, 0.0006, 0.0019, 0.0011, 0.0026, 0.0015, 0.0021,\n",
      "        0.0007])}, 8: {'step': tensor(3820.), 'exp_avg': tensor([ 1.4190e-20, -3.9941e-20, -9.1178e-21, -2.6558e-20,  1.4485e-20,\n",
      "        -2.2945e-20, -1.1665e-20,  1.0026e-20, -2.8976e-20,  1.3320e-20,\n",
      "         3.4118e-21, -2.1763e-20,  4.1855e-21, -2.3928e-20,  1.6756e-20,\n",
      "         7.3517e-21,  1.7725e-20, -5.1323e-20,  8.8147e-22, -2.7534e-20,\n",
      "         5.0057e-21,  1.2691e-19,  7.6379e-21,  1.6248e-20,  5.6211e-21]), 'exp_avg_sq': tensor([ 0.0479,  0.1578,  0.0546,  0.6597,  0.0674,  0.6318,  0.0678,  0.0969,\n",
      "         0.7711,  0.1261,  1.1861,  0.0649,  0.1532,  0.2280,  0.0707,  0.1679,\n",
      "        12.9480,  0.7802,  0.0260,  0.1805,  0.0410, 22.2419,  0.2269,  0.0223,\n",
      "         0.1492])}, 9: {'step': tensor(3820.), 'exp_avg': tensor([[ 4.6973e-21,  1.1195e-20, -1.3264e-20, -4.6179e-21,  1.1239e-20,\n",
      "          6.3034e-21, -1.2568e-20, -4.4008e-22,  1.1707e-20, -4.2423e-21,\n",
      "          4.2448e-21,  1.3915e-20, -1.3359e-20, -2.5137e-23, -4.5764e-21,\n",
      "         -7.4963e-21],\n",
      "        [-2.2267e-20, -5.3741e-20,  6.6701e-20,  2.3486e-20, -6.1652e-20,\n",
      "         -3.0579e-20,  6.1559e-20,  1.6532e-22, -5.7353e-20,  2.4091e-20,\n",
      "         -1.9597e-20, -6.9704e-20,  6.8806e-20, -3.0484e-21,  2.5026e-20,\n",
      "          3.8413e-20],\n",
      "        [-6.4592e-21, -1.6362e-20,  2.0995e-20,  7.4603e-21, -2.0662e-20,\n",
      "         -9.7809e-21,  1.9083e-20, -1.9186e-22, -1.8130e-20,  8.1127e-21,\n",
      "         -5.6846e-21, -2.2356e-20,  2.1712e-20, -6.8523e-22,  7.8207e-21,\n",
      "          1.2474e-20],\n",
      "        [-1.8916e-20, -3.7020e-20,  4.0877e-20,  1.3079e-20, -2.9139e-20,\n",
      "         -1.5332e-20,  3.9558e-20,  2.2315e-22, -3.1596e-20,  1.2054e-20,\n",
      "         -1.5957e-20, -3.6960e-20,  4.4304e-20, -1.1085e-20,  1.9176e-20,\n",
      "          1.9402e-20],\n",
      "        [ 6.4522e-21,  1.5280e-20, -1.8595e-20, -6.5381e-21,  1.6580e-20,\n",
      "          8.5467e-21, -1.7299e-20, -2.0597e-22,  1.6090e-20, -6.4081e-21,\n",
      "          5.6993e-21,  1.9361e-20, -1.9047e-20,  7.3533e-22, -6.8572e-21,\n",
      "         -1.0555e-20],\n",
      "        [-1.5771e-20, -3.1492e-20,  3.4768e-20,  1.0827e-20, -2.5218e-20,\n",
      "         -1.3302e-20,  3.3748e-20,  2.9680e-22, -2.6819e-20,  1.0535e-20,\n",
      "         -1.3469e-20, -3.1763e-20,  3.7766e-20, -9.2444e-21,  1.6084e-20,\n",
      "          1.6697e-20],\n",
      "        [-9.5836e-21, -1.8573e-20,  2.0442e-20,  6.4568e-21, -1.4481e-20,\n",
      "         -7.5066e-21,  1.9814e-20,  3.5171e-23, -1.5574e-20,  6.0614e-21,\n",
      "         -8.0498e-21, -1.8252e-20,  2.2339e-20, -6.0625e-21,  9.8351e-21,\n",
      "          9.5810e-21],\n",
      "        [ 6.7384e-21,  1.3048e-20, -1.4087e-20, -4.3288e-21,  9.5635e-21,\n",
      "          5.2053e-21, -1.3817e-20, -1.7683e-22,  1.0703e-20, -4.0261e-21,\n",
      "          5.7278e-21,  1.2522e-20, -1.5379e-20,  4.1914e-21, -6.7038e-21,\n",
      "         -6.5051e-21],\n",
      "        [-1.9619e-20, -3.9774e-20,  4.4620e-20,  1.4311e-20, -3.3427e-20,\n",
      "         -1.7458e-20,  4.2962e-20,  2.9810e-22, -3.5053e-20,  1.3734e-20,\n",
      "         -1.6729e-20, -4.1472e-20,  4.8053e-20, -1.0473e-20,  2.0167e-20,\n",
      "          2.1958e-20],\n",
      "        [ 7.2741e-21,  1.5363e-20, -1.7779e-20, -6.0600e-21,  1.4138e-20,\n",
      "          7.3799e-21, -1.6838e-20, -1.4542e-22,  1.4620e-20, -5.5989e-21,\n",
      "          6.2318e-21,  1.7258e-20, -1.8676e-20,  2.7137e-21, -7.4409e-21,\n",
      "         -9.2286e-21],\n",
      "        [ 7.2080e-21,  1.6448e-20, -1.9931e-20, -6.2807e-21,  1.8171e-20,\n",
      "          8.3116e-21, -1.8620e-20,  3.3505e-22,  1.5676e-20, -7.6398e-21,\n",
      "          6.2519e-21,  1.9661e-20, -2.1734e-20,  4.0058e-21, -8.7794e-21,\n",
      "         -1.0857e-20],\n",
      "        [-1.3822e-20, -3.1284e-20,  3.7655e-20,  1.2902e-20, -3.2879e-20,\n",
      "         -1.6408e-20,  3.5180e-20,  4.0597e-23, -3.1444e-20,  1.3028e-20,\n",
      "         -1.1973e-20, -3.7922e-20,  3.9458e-20, -4.1511e-21,  1.5170e-20,\n",
      "          2.0684e-20],\n",
      "        [ 7.3329e-21,  1.5005e-20, -1.7245e-20, -5.3362e-21,  1.3896e-20,\n",
      "          6.5041e-21, -1.6412e-20,  2.6143e-22,  1.3005e-20, -5.9516e-21,\n",
      "          6.1953e-21,  1.5880e-20, -1.9093e-20,  5.0712e-21, -8.2993e-21,\n",
      "         -8.5692e-21],\n",
      "        [-1.5985e-20, -3.3278e-20,  3.8082e-20,  1.2500e-20, -2.9828e-20,\n",
      "         -1.5362e-20,  3.6342e-20,  1.8552e-22, -3.0480e-20,  1.2096e-20,\n",
      "         -1.3664e-20, -3.6213e-20,  4.0671e-20, -7.5656e-21,  1.6692e-20,\n",
      "          1.9348e-20],\n",
      "        [ 5.1624e-21,  1.4867e-20, -1.9360e-20, -7.1166e-21,  1.9586e-20,\n",
      "          1.0064e-20, -1.7607e-20, -3.4329e-22,  1.7922e-20, -7.3421e-21,\n",
      "          4.8452e-21,  2.1973e-20, -1.9091e-20, -2.2714e-21, -5.8004e-21,\n",
      "         -1.2221e-20],\n",
      "        [ 7.6874e-21,  1.5335e-20, -1.7255e-20, -5.3946e-21,  1.3101e-20,\n",
      "          6.4429e-21, -1.6562e-20,  1.0371e-22,  1.3095e-20, -5.5558e-21,\n",
      "          6.4900e-21,  1.5692e-20, -1.8964e-20,  5.0395e-21, -8.2606e-21,\n",
      "         -8.3539e-21],\n",
      "        [ 3.9846e-21,  1.6305e-20, -2.3598e-20, -9.1267e-21,  2.7878e-20,\n",
      "          1.3645e-20, -2.0626e-20, -2.4025e-22,  2.3161e-20, -1.0327e-20,\n",
      "          4.1631e-21,  2.9196e-20, -2.2549e-20, -6.2918e-21, -5.5945e-21,\n",
      "         -1.6667e-20],\n",
      "        [-2.9721e-20, -6.8361e-20,  8.3098e-20,  2.9004e-20, -7.3597e-20,\n",
      "         -3.6833e-20,  7.7259e-20,  2.0584e-22, -7.0353e-20,  2.8885e-20,\n",
      "         -2.5825e-20, -8.4748e-20,  8.6343e-20, -6.9170e-21,  3.2549e-20,\n",
      "          4.6345e-20],\n",
      "        [-2.2111e-21, -3.8840e-21,  4.4100e-21,  1.4449e-21, -3.2458e-21,\n",
      "         -1.2866e-21,  4.1325e-21, -2.4482e-22, -3.0558e-21,  1.4420e-21,\n",
      "         -1.7308e-21, -3.5957e-21,  5.0682e-21, -2.0906e-21,  2.5565e-21,\n",
      "          1.9308e-21],\n",
      "        [-1.7088e-20, -3.7665e-20,  4.4836e-20,  1.5429e-20, -3.8020e-20,\n",
      "         -1.9188e-20,  4.2036e-20,  1.0235e-22, -3.7282e-20,  1.5028e-20,\n",
      "         -1.4694e-20, -4.4568e-20,  4.7008e-20, -5.5582e-21,  1.8362e-20,\n",
      "          2.4185e-20],\n",
      "        [ 6.8694e-21,  1.3319e-20, -1.4735e-20, -4.4588e-21,  1.0774e-20,\n",
      "          5.2399e-21, -1.4256e-20,  1.4083e-22,  1.0836e-20, -4.6771e-21,\n",
      "          5.7591e-21,  1.2981e-20, -1.6446e-20,  5.1197e-21, -7.4106e-21,\n",
      "         -6.8689e-21],\n",
      "        [ 8.7139e-20,  1.7904e-19, -2.0603e-19, -6.9693e-20,  1.6077e-19,\n",
      "          8.2293e-20, -1.9559e-19, -3.6729e-22,  1.6596e-19, -6.4443e-20,\n",
      "          7.3637e-20,  1.9526e-19, -2.1909e-19,  3.9961e-20, -9.0785e-20,\n",
      "         -1.0449e-19],\n",
      "        [ 8.0534e-21,  1.5762e-20, -1.7570e-20, -5.4837e-21,  1.2976e-20,\n",
      "          6.4124e-21, -1.6915e-20,  1.0775e-22,  1.3221e-20, -5.5253e-21,\n",
      "          6.7661e-21,  1.5745e-20, -1.9369e-20,  5.4651e-21, -8.5614e-21,\n",
      "         -8.3383e-21],\n",
      "        [ 6.0085e-21,  1.6502e-20, -2.1180e-20, -7.5820e-21,  2.1039e-20,\n",
      "          1.0642e-20, -1.9356e-20, -2.6135e-22,  1.9103e-20, -8.0401e-21,\n",
      "          5.5543e-21,  2.3510e-20, -2.1258e-20, -1.3247e-21, -6.8361e-21,\n",
      "         -1.3046e-20],\n",
      "        [ 6.8356e-21,  1.3964e-20, -1.5857e-20, -4.8835e-21,  1.2439e-20,\n",
      "          6.0455e-21, -1.5210e-20,  1.1551e-22,  1.2044e-20, -5.2905e-21,\n",
      "          5.8068e-21,  1.4596e-20, -1.7469e-20,  4.4923e-21, -7.5315e-21,\n",
      "         -7.8263e-21]]), 'exp_avg_sq': tensor([[1.4108e-02, 6.8529e-02, 1.6860e-01, 3.8424e-02, 5.0456e-01, 5.6969e-02,\n",
      "         1.4659e-01, 2.9205e-03, 2.0264e-01, 4.6400e-02, 7.8440e-03, 3.4948e-01,\n",
      "         2.8475e-01, 3.5359e-02, 2.0613e-02, 1.7234e-01],\n",
      "        [1.8133e-01, 2.9343e-01, 2.8510e-01, 7.5067e-02, 5.4000e-01, 4.0918e-02,\n",
      "         3.0818e-01, 5.8476e-03, 2.6797e-01, 3.2349e-02, 7.8892e-02, 3.5398e-01,\n",
      "         5.0588e-01, 2.3938e-01, 1.5570e-01, 1.8924e-01],\n",
      "        [2.2860e-02, 2.7502e-02, 9.2373e-02, 5.4315e-02, 3.8713e-01, 2.3092e-02,\n",
      "         6.0095e-02, 6.2905e-03, 1.4928e-01, 2.0945e-02, 7.6791e-03, 2.3294e-01,\n",
      "         1.6347e-01, 3.8864e-02, 2.1895e-02, 1.3025e-01],\n",
      "        [6.1144e-02, 2.3761e-01, 7.6066e-01, 2.1643e-01, 3.0384e+00, 2.7094e-01,\n",
      "         6.4239e-01, 3.3976e-02, 1.0356e+00, 2.4020e-01, 4.2813e-02, 1.9830e+00,\n",
      "         1.6839e+00, 1.9872e-01, 9.4294e-02, 1.0548e+00],\n",
      "        [9.9657e-02, 1.8292e-01, 2.5124e-01, 4.1739e-02, 6.1491e-01, 7.1247e-02,\n",
      "         2.5691e-01, 2.7629e-03, 2.4043e-01, 6.1813e-02, 4.6205e-02, 4.1803e-01,\n",
      "         4.4168e-01, 1.8222e-01, 9.8781e-02, 2.0113e-01],\n",
      "        [6.4211e-02, 2.0652e-01, 6.8648e-01, 1.9337e-01, 3.1765e+00, 2.5200e-01,\n",
      "         5.9090e-01, 3.5700e-02, 9.3067e-01, 2.5887e-01, 4.0175e-02, 1.9601e+00,\n",
      "         1.6696e+00, 1.8129e-01, 8.5118e-02, 1.0727e+00],\n",
      "        [2.3956e-02, 7.2259e-02, 2.0868e-01, 5.0904e-02, 7.7081e-01, 7.5258e-02,\n",
      "         1.8104e-01, 7.6499e-03, 2.6244e-01, 6.6254e-02, 1.4798e-02, 5.1310e-01,\n",
      "         4.4118e-01, 6.6621e-02, 3.4544e-02, 2.6422e-01],\n",
      "        [1.3560e-02, 2.7601e-02, 7.5178e-02, 2.6090e-02, 2.4119e-01, 1.3415e-02,\n",
      "         6.0388e-02, 3.7949e-03, 8.5055e-02, 1.7593e-02, 5.9276e-03, 1.4573e-01,\n",
      "         1.5820e-01, 1.0883e-02, 2.0232e-02, 7.9718e-02],\n",
      "        [5.2938e-02, 2.0663e-01, 7.3175e-01, 2.0499e-01, 3.3357e+00, 2.9414e-01,\n",
      "         6.1936e-01, 3.5360e-02, 1.0340e+00, 2.6788e-01, 3.3434e-02, 2.1079e+00,\n",
      "         1.6941e+00, 1.9205e-01, 6.8635e-02, 1.1469e+00],\n",
      "        [1.2037e-01, 1.3964e-01, 9.9717e-02, 1.3605e-02, 2.4515e-01, 1.9102e-02,\n",
      "         1.2914e-01, 2.1584e-03, 5.8872e-02, 2.0887e-02, 5.0008e-02, 1.2642e-01,\n",
      "         2.0482e-01, 1.9985e-01, 1.0506e-01, 7.2225e-02],\n",
      "        [1.2271e-01, 1.2256e-01, 7.5341e-01, 2.3115e-01, 5.3890e+00, 2.9651e-01,\n",
      "         5.6116e-01, 4.1935e-02, 1.0900e+00, 4.9481e-01, 1.1251e-02, 2.7667e+00,\n",
      "         2.0138e+00, 1.5215e-01, 5.5037e-02, 1.5918e+00],\n",
      "        [1.9522e-02, 4.4015e-02, 7.9735e-02, 1.9488e-02, 2.0581e-01, 2.1956e-02,\n",
      "         7.5668e-02, 2.1045e-03, 8.8494e-02, 1.8121e-02, 9.5052e-03, 1.4570e-01,\n",
      "         1.5190e-01, 2.6311e-02, 2.0029e-02, 7.4720e-02],\n",
      "        [3.4908e-02, 4.0133e-02, 5.7393e-02, 1.7328e-02, 2.7938e-01, 1.6380e-02,\n",
      "         5.2666e-02, 2.5711e-03, 6.8575e-02, 2.1577e-02, 1.2773e-02, 1.4796e-01,\n",
      "         1.2476e-01, 6.4017e-02, 3.0619e-02, 8.4804e-02],\n",
      "        [1.7286e-02, 8.5094e-02, 2.8002e-01, 8.2730e-02, 1.1858e+00, 9.1245e-02,\n",
      "         2.3365e-01, 1.3652e-02, 3.7895e-01, 9.1534e-02, 1.3405e-02, 7.4029e-01,\n",
      "         6.3660e-01, 4.1207e-02, 2.6730e-02, 4.0521e-01],\n",
      "        [8.2863e-02, 1.2001e-01, 1.1828e-01, 1.8000e-02, 2.6446e-01, 2.6024e-02,\n",
      "         1.3825e-01, 2.6852e-03, 9.1556e-02, 2.1855e-02, 3.7795e-02, 1.6737e-01,\n",
      "         2.4522e-01, 1.4503e-01, 8.0106e-02, 8.8416e-02],\n",
      "        [5.3724e-02, 5.4200e-02, 6.0387e-02, 1.7276e-02, 2.9336e-01, 1.9955e-02,\n",
      "         5.9637e-02, 2.4715e-03, 6.9620e-02, 2.2678e-02, 1.8699e-02, 1.5425e-01,\n",
      "         1.2413e-01, 9.4194e-02, 4.4165e-02, 8.9810e-02],\n",
      "        [9.4042e+00, 7.4064e+00, 1.5809e+00, 1.4136e-01, 1.6431e+01, 1.2271e+00,\n",
      "         3.5421e+00, 1.8977e-02, 9.6281e-01, 1.2561e+00, 3.1383e+00, 6.2551e+00,\n",
      "         2.2659e+00, 1.6325e+01, 6.6667e+00, 4.4266e+00],\n",
      "        [5.7267e-01, 4.5102e-01, 3.9328e-01, 1.4667e-01, 8.8725e-01, 7.2308e-02,\n",
      "         3.9443e-01, 1.4938e-02, 3.1806e-01, 1.0032e-01, 1.9073e-01, 4.5656e-01,\n",
      "         5.4199e-01, 5.0618e-01, 3.9745e-01, 2.6578e-01],\n",
      "        [1.9196e-02, 1.6751e-01, 6.7442e-01, 2.6102e-01, 2.5516e+00, 1.2794e-01,\n",
      "         5.0061e-01, 4.2333e-02, 8.8540e-01, 1.5227e-01, 3.0265e-02, 1.5421e+00,\n",
      "         1.5208e+00, 1.7997e-02, 9.3633e-02, 8.7423e-01],\n",
      "        [4.1510e-02, 7.6193e-02, 1.6624e-01, 5.5373e-02, 6.5495e-01, 4.7391e-02,\n",
      "         1.4101e-01, 7.4788e-03, 2.2372e-01, 4.8765e-02, 1.6011e-02, 4.0417e-01,\n",
      "         3.4312e-01, 4.7454e-02, 3.3005e-02, 2.2467e-01],\n",
      "        [4.6264e-03, 1.6398e-02, 4.5719e-02, 1.6860e-02, 1.9106e-01, 1.0110e-02,\n",
      "         3.7968e-02, 2.5633e-03, 5.7806e-02, 1.3861e-02, 3.7070e-03, 1.0910e-01,\n",
      "         1.0711e-01, 1.5196e-02, 9.0999e-03, 6.0771e-02],\n",
      "        [2.4900e+00, 6.9144e-01, 8.0398e+00, 3.4316e+00, 7.9361e+01, 5.4823e+00,\n",
      "         5.5013e+00, 7.1735e-01, 1.7157e+01, 6.4091e+00, 1.9773e-01, 4.3650e+01,\n",
      "         2.3289e+01, 6.1237e+00, 3.5854e-01, 2.5706e+01],\n",
      "        [6.6828e-02, 5.2707e-02, 4.7102e-02, 1.3817e-02, 3.4133e-01, 2.2627e-02,\n",
      "         4.7075e-02, 2.0625e-03, 6.2779e-02, 2.8413e-02, 2.0443e-02, 1.6774e-01,\n",
      "         9.7850e-02, 1.1471e-01, 4.7680e-02, 1.0064e-01],\n",
      "        [1.1148e-01, 3.9568e-01, 7.4843e-01, 1.6822e-01, 1.6500e+00, 9.5658e-02,\n",
      "         7.0499e-01, 2.6955e-02, 6.7941e-01, 1.1992e-01, 8.4489e-02, 1.0968e+00,\n",
      "         1.6501e+00, 1.0218e-01, 2.0976e-01, 5.8225e-01],\n",
      "        [3.0201e-02, 4.0677e-03, 6.7128e-02, 6.0919e-02, 7.7311e-01, 4.4532e-02,\n",
      "         2.6143e-02, 7.3738e-03, 1.8630e-01, 5.7512e-02, 9.8058e-03, 4.0084e-01,\n",
      "         1.4616e-01, 1.0110e-01, 5.1261e-03, 2.2559e-01]])}, 10: {'step': tensor(3820.), 'exp_avg': tensor([-2.6789e-21,  1.9456e-20, -3.6213e-20, -6.7439e-22, -2.9890e-21,\n",
      "        -4.7456e-20,  1.7143e-21,  7.8634e-21, -2.5075e-21,  1.1939e-20,\n",
      "        -6.3811e-21, -5.4664e-21,  6.4624e-21,  2.5628e-22, -1.9611e-21,\n",
      "        -4.2289e-20, -4.7800e-21,  8.1118e-21,  2.4347e-22,  2.1293e-21,\n",
      "         4.4666e-21, -1.4980e-21,  2.3517e-20, -1.0881e-21,  9.9743e-22,\n",
      "         2.9442e-21, -6.6801e-22, -3.1260e-21, -1.7376e-20,  1.6656e-20,\n",
      "         8.9340e-21, -2.4237e-20, -2.0023e-21,  1.2995e-20,  6.8128e-21,\n",
      "        -6.4430e-21, -1.8007e-21, -1.2598e-20, -9.2705e-21,  1.2663e-20,\n",
      "         2.6763e-21, -6.6411e-21, -9.0520e-22, -6.7860e-21, -3.4481e-21,\n",
      "        -3.0670e-20, -6.1454e-21,  2.1437e-20,  3.2373e-21,  5.5178e-21,\n",
      "        -3.7584e-21, -1.3343e-20,  2.7639e-20,  4.2020e-21, -3.4840e-21,\n",
      "        -8.3286e-21, -7.2181e-21, -1.5424e-20,  1.8227e-21,  2.0529e-20,\n",
      "         5.7351e-21,  5.7509e-21, -3.0031e-21,  1.7956e-20, -2.5565e-20,\n",
      "         2.6189e-24, -2.6013e-21, -3.0846e-21, -4.2659e-20,  2.3833e-21,\n",
      "         1.9291e-20, -4.1944e-21,  6.4978e-21,  1.0768e-20,  2.8164e-20,\n",
      "         1.4143e-21,  8.6091e-22, -1.0105e-20, -4.3538e-21, -3.3371e-21,\n",
      "         8.4926e-21,  1.3788e-20,  1.1262e-20, -1.0536e-20,  3.8608e-21,\n",
      "         1.6217e-20, -2.8907e-21, -1.3559e-21,  1.9848e-21, -1.6488e-22,\n",
      "        -2.4069e-20,  5.3653e-21,  1.3280e-20,  9.4131e-21,  1.1168e-20,\n",
      "        -4.3726e-21, -7.4526e-21,  2.4573e-20, -3.3677e-21, -9.7167e-21]), 'exp_avg_sq': tensor([0.0080, 0.0039, 0.0100, 0.0045, 0.0036, 0.0171, 0.0100, 0.0137, 0.0102,\n",
      "        0.0210, 0.0096, 0.0040, 0.0036, 0.0198, 0.0053, 0.0160, 0.0193, 0.0066,\n",
      "        0.0223, 0.0042, 0.0098, 0.0158, 0.0225, 0.0114, 0.0054, 0.0065, 0.0039,\n",
      "        0.0122, 0.0080, 0.0039, 0.0170, 0.0096, 0.0107, 0.0119, 0.0335, 0.0045,\n",
      "        0.0047, 0.0079, 0.0053, 0.0045, 0.0192, 0.0015, 0.0086, 0.0037, 0.0036,\n",
      "        0.0067, 0.0320, 0.0178, 0.0040, 0.0192, 0.0066, 0.0175, 0.0230, 0.0180,\n",
      "        0.0267, 0.0215, 0.0140, 0.0252, 0.0240, 0.0175, 0.0076, 0.0016, 0.0071,\n",
      "        0.0207, 0.0065, 0.0164, 0.0174, 0.0087, 0.0218, 0.0016, 0.0077, 0.0126,\n",
      "        0.0100, 0.0067, 0.0081, 0.0324, 0.0254, 0.0273, 0.0067, 0.0039, 0.0073,\n",
      "        0.0125, 0.0185, 0.0063, 0.0111, 0.0146, 0.0203, 0.0186, 0.0099, 0.0055,\n",
      "        0.0067, 0.0094, 0.0100, 0.0047, 0.0135, 0.0054, 0.0398, 0.0240, 0.0215,\n",
      "        0.0094])}, 11: {'step': tensor(3820.), 'exp_avg': tensor([ 2.8096e-29,  1.5776e-28,  2.3855e-27,  5.4026e-28, -2.6933e-28,\n",
      "         4.0259e-27, -1.1879e-28, -7.6313e-29,  3.3687e-28,  1.8707e-27,\n",
      "         1.0350e-29,  1.1945e-28, -6.0094e-28,  1.7562e-29,  9.8493e-29,\n",
      "        -1.5782e-27,  1.4926e-28,  1.2833e-27, -1.2075e-28, -5.2074e-28,\n",
      "         2.2481e-29, -9.3413e-28,  6.8965e-28,  1.2387e-28,  8.7961e-28,\n",
      "        -6.3321e-29,  7.0289e-28,  7.4037e-28,  2.3623e-28,  6.9987e-28,\n",
      "        -8.9068e-28, -1.7148e-27, -9.2147e-28,  9.7598e-28,  6.4562e-28,\n",
      "         1.4958e-28, -5.7266e-29,  2.5038e-28,  1.4563e-28, -3.9901e-28,\n",
      "         1.5180e-28, -2.3969e-28, -4.2355e-28,  1.3868e-28,  1.0855e-28,\n",
      "        -1.8481e-27, -1.1757e-28, -1.0913e-27, -1.1327e-28, -7.9915e-28,\n",
      "         1.5316e-27, -4.0116e-28,  2.6824e-27,  2.5442e-28,  3.7300e-29,\n",
      "         1.7963e-28,  2.0432e-29,  4.0157e-28,  7.2876e-28,  2.7820e-27,\n",
      "         1.0099e-29, -6.8530e-28, -8.7805e-28,  9.3071e-28, -1.1453e-28,\n",
      "         1.9140e-28,  5.8069e-28, -9.3712e-28,  1.4680e-27, -1.6861e-28,\n",
      "        -2.9497e-27,  3.0050e-29,  4.4577e-28, -5.9329e-28,  1.9352e-27,\n",
      "        -1.4751e-27,  1.0955e-27, -1.2438e-29, -9.0815e-29, -2.9725e-28,\n",
      "         1.0418e-27,  1.7910e-27, -1.2553e-27,  2.4882e-28,  2.3187e-27,\n",
      "        -3.6081e-28,  2.5636e-29,  4.2462e-28,  1.0728e-27, -2.0225e-28,\n",
      "        -6.7007e-28, -3.7629e-28,  9.3738e-28, -8.8545e-28, -1.6360e-27,\n",
      "         6.7879e-28, -1.8270e-29, -4.4702e-29,  9.7804e-28, -8.5353e-29]), 'exp_avg_sq': tensor([3.6411e-16, 2.5681e-16, 1.2912e-15, 1.2694e-16, 5.1425e-16, 9.6653e-16,\n",
      "        5.3117e-16, 6.6528e-16, 1.3255e-16, 1.0004e-15, 2.0709e-16, 4.3276e-16,\n",
      "        4.7438e-16, 4.9787e-16, 5.6943e-16, 3.0194e-16, 1.1719e-16, 8.9219e-17,\n",
      "        5.0165e-16, 8.9584e-17, 4.7559e-16, 6.2474e-16, 6.3232e-16, 2.7713e-16,\n",
      "        2.2671e-16, 1.2739e-15, 2.6356e-16, 6.3472e-16, 1.5852e-16, 1.6543e-16,\n",
      "        2.4217e-16, 4.6366e-16, 7.0496e-16, 7.2789e-16, 5.9648e-16, 1.5816e-16,\n",
      "        1.5561e-16, 5.7298e-16, 3.1427e-16, 3.8377e-16, 4.0485e-16, 2.2680e-16,\n",
      "        3.4221e-16, 5.0293e-16, 3.0195e-16, 2.0750e-16, 5.4844e-16, 3.2926e-16,\n",
      "        4.9048e-16, 2.4149e-16, 4.7171e-16, 6.7464e-16, 1.0885e-15, 9.8366e-16,\n",
      "        7.6356e-16, 6.5553e-16, 6.6109e-16, 5.6210e-16, 2.0122e-16, 7.7511e-16,\n",
      "        1.4441e-16, 2.2026e-16, 5.6048e-16, 2.9797e-16, 3.7116e-16, 1.2278e-15,\n",
      "        3.8390e-16, 5.4980e-16, 2.6682e-16, 2.1446e-16, 1.4976e-16, 1.2297e-15,\n",
      "        1.6017e-16, 5.1227e-16, 2.1819e-16, 2.4674e-16, 7.2456e-16, 5.8501e-16,\n",
      "        3.2991e-16, 3.7271e-16, 2.2451e-16, 1.0807e-16, 4.5925e-16, 1.0260e-15,\n",
      "        2.6578e-16, 2.1682e-16, 6.4872e-16, 1.0411e-15, 3.6288e-16, 2.1677e-16,\n",
      "        2.7017e-16, 3.0951e-16, 7.6990e-16, 1.1346e-16, 1.0645e-15, 1.0909e-15,\n",
      "        4.1442e-16, 3.6314e-16, 5.3277e-16, 1.1551e-15])}, 12: {'step': tensor(3820.), 'exp_avg': tensor([-5.8227e-18,  6.1375e-18,  5.5753e-18, -3.2442e-18, -2.2637e-18,\n",
      "        -4.6060e-18,  3.6975e-18,  5.2630e-19]), 'exp_avg_sq': tensor([ 69.3165, 126.8454, 159.5825,  20.3189,  55.0424,  81.0456,  55.2706,\n",
      "          8.9967])}, 13: {'step': tensor(3820.), 'exp_avg': tensor([[-4.0384e-18, -2.2885e-19,  1.4393e-17],\n",
      "        [ 4.4389e-18,  2.9200e-19, -1.5450e-17],\n",
      "        [ 3.8400e-18,  2.1901e-19, -1.3786e-17],\n",
      "        [-2.3537e-18, -1.6464e-19,  8.3618e-18],\n",
      "        [-1.6173e-18, -9.9058e-20,  5.4828e-18],\n",
      "        [-3.2453e-18, -1.9269e-19,  1.1429e-17],\n",
      "        [ 2.6376e-18,  1.6399e-19, -9.1905e-18],\n",
      "        [ 3.3819e-19,  1.0247e-20, -1.2400e-18]]), 'exp_avg_sq': tensor([[3.8233e+00, 1.3905e-01, 6.9921e+00],\n",
      "        [6.7905e+00, 1.5158e-01, 3.5361e+01],\n",
      "        [2.0641e+01, 4.4383e-01, 6.6584e+01],\n",
      "        [3.5631e+00, 1.0439e-01, 2.0905e+00],\n",
      "        [3.1813e+00, 8.5187e-02, 1.8001e+01],\n",
      "        [5.0743e+00, 1.9143e-01, 9.1912e+00],\n",
      "        [3.6334e+00, 2.5558e-02, 1.5305e+01],\n",
      "        [8.1666e-01, 5.4666e-02, 8.0209e-01]])}, 14: {'step': tensor(3820.), 'exp_avg': tensor([ 2.4389e-20,  2.0547e-20,  1.2298e-20, -5.7001e-21,  1.5500e-20,\n",
      "        -6.2335e-21,  2.4575e-20,  1.1831e-20,  5.1367e-21,  1.1915e-20,\n",
      "         9.6339e-21,  9.7731e-21,  1.2250e-20,  1.7911e-20,  8.2144e-21,\n",
      "        -3.0488e-21,  1.8274e-20,  1.4461e-20,  1.0987e-20,  1.3322e-20,\n",
      "         1.5050e-20,  6.1904e-21,  2.3882e-20,  1.1687e-20,  1.6972e-20,\n",
      "         1.0040e-20,  1.8205e-20,  1.9319e-21,  3.1862e-21,  2.0069e-20,\n",
      "         1.3083e-20,  1.7407e-20,  5.2529e-21,  1.2333e-20,  7.6248e-21,\n",
      "         1.2773e-20,  3.1722e-20,  8.5440e-21,  1.3629e-20,  1.4117e-20,\n",
      "         8.8735e-21,  1.5659e-20,  1.4047e-20,  1.5132e-20,  1.2111e-20,\n",
      "         8.4152e-21,  1.2141e-20,  1.9660e-20,  7.0539e-21,  1.4697e-20,\n",
      "        -1.4504e-21,  8.3564e-21,  1.8473e-20,  1.1993e-20,  1.1398e-20,\n",
      "         1.7827e-20,  1.8603e-20,  7.3274e-21,  6.3085e-21,  1.6920e-20,\n",
      "         1.6256e-20,  8.5532e-21, -1.2803e-21,  1.0861e-20,  1.0228e-20,\n",
      "         1.3814e-20, -8.9687e-22,  2.0005e-21, -1.7330e-21,  1.6165e-20,\n",
      "         2.2221e-20,  1.7670e-20,  9.3406e-21,  2.1964e-20,  1.9488e-20,\n",
      "         1.4376e-20,  3.9132e-21,  2.5921e-20,  1.0053e-20,  2.0933e-20,\n",
      "         2.1759e-20,  2.2950e-20,  2.7311e-20,  1.8441e-20,  2.4671e-20,\n",
      "         2.0662e-20,  1.5566e-20,  1.1150e-20,  1.2308e-20,  1.5333e-20,\n",
      "         1.9108e-20,  1.3661e-20,  1.1406e-20,  1.5858e-20,  1.6004e-20,\n",
      "         1.9696e-20,  2.1112e-20,  2.3866e-20,  1.3156e-21,  1.8342e-20]), 'exp_avg_sq': tensor([0.0046, 0.0014, 0.0023, 0.0055, 0.0052, 0.0009, 0.0055, 0.0067, 0.0076,\n",
      "        0.0084, 0.0015, 0.0058, 0.0013, 0.0024, 0.0021, 0.0012, 0.0013, 0.0156,\n",
      "        0.0100, 0.0013, 0.0094, 0.0145, 0.0048, 0.0092, 0.0068, 0.0079, 0.0025,\n",
      "        0.0013, 0.0035, 0.0039, 0.0010, 0.0043, 0.0010, 0.0116, 0.0265, 0.0041,\n",
      "        0.0100, 0.0022, 0.0034, 0.0045, 0.0014, 0.0491, 0.0509, 0.0102, 0.0106,\n",
      "        0.0011, 0.0012, 0.0019, 0.0112, 0.0101, 0.0118, 0.0112, 0.0060, 0.0013,\n",
      "        0.0041, 0.0036, 0.0029, 0.0016, 0.0041, 0.0031, 0.0016, 0.0005, 0.0024,\n",
      "        0.0089, 0.0138, 0.0031, 0.0101, 0.0058, 0.0081, 0.0038, 0.0017, 0.0007,\n",
      "        0.0172, 0.0059, 0.0010, 0.0014, 0.0026, 0.0046, 0.0093, 0.0031, 0.0043,\n",
      "        0.0030, 0.0112, 0.0028, 0.0197, 0.0030, 0.0032, 0.0282, 0.0060, 0.0368,\n",
      "        0.0050, 0.0023, 0.0059, 0.0052, 0.0125, 0.0060, 0.0017, 0.0018, 0.0101,\n",
      "        0.0012])}, 15: {'step': tensor(3820.), 'exp_avg': tensor([-1.3258e-19, -1.2785e-19, -1.5178e-19, -7.8655e-20, -1.3329e-19,\n",
      "        -1.5090e-19, -1.8341e-19, -1.4037e-19, -1.4998e-19, -1.2129e-19,\n",
      "        -1.5171e-19, -1.3877e-19, -1.5481e-19, -1.6424e-19, -1.4131e-19,\n",
      "        -1.5502e-19, -1.6485e-19, -1.6682e-19, -1.4746e-19, -1.6595e-19,\n",
      "        -1.5737e-19, -1.5723e-19, -1.6640e-19, -1.5273e-19, -1.5791e-19,\n",
      "        -1.4976e-19, -1.8363e-19, -2.8316e-20, -1.3780e-19, -1.6097e-19,\n",
      "        -1.4510e-19, -1.8661e-19, -1.4834e-19, -1.3472e-19, -1.4916e-19,\n",
      "        -1.3772e-19, -1.3184e-19, -1.5436e-19, -1.4325e-19, -1.7371e-19,\n",
      "        -1.6159e-19, -1.5353e-19, -1.5290e-19, -1.5981e-19, -1.4150e-19,\n",
      "        -1.6741e-19, -1.5424e-19, -1.5470e-19, -1.4987e-19, -1.4184e-19,\n",
      "        -6.4911e-20, -1.4981e-19, -1.3886e-19, -1.4310e-19, -1.4735e-19,\n",
      "        -1.5607e-19, -1.5907e-19, -1.3804e-19, -1.5121e-19, -1.5179e-19,\n",
      "        -1.7098e-19, -1.5304e-19, -4.7189e-20, -1.2844e-19, -1.8334e-19,\n",
      "        -1.2063e-19, -7.3418e-20, -2.8286e-20, -1.7401e-19, -1.6392e-19,\n",
      "        -1.6920e-19, -1.9347e-19, -1.4291e-19, -1.6622e-19, -1.2529e-19,\n",
      "        -1.4320e-19, -1.4264e-19, -1.7331e-19, -1.5510e-19, -2.0371e-19,\n",
      "        -1.7287e-19, -1.7812e-19, -1.5335e-19, -1.5244e-19, -2.0332e-19,\n",
      "        -1.6336e-19, -1.9447e-19, -1.4211e-19, -1.5369e-19, -1.7720e-19,\n",
      "        -1.5364e-19, -1.4136e-19, -1.5377e-19, -1.5571e-19, -1.6562e-19,\n",
      "        -1.8285e-19, -1.7370e-19, -1.9429e-19, -2.3278e-20, -1.4939e-19]), 'exp_avg_sq': tensor([0.0222, 0.0141, 0.0163, 0.0271, 0.0464, 0.0506, 0.0320, 0.0396, 0.0423,\n",
      "        0.0199, 0.0402, 0.0427, 0.0178, 0.0426, 0.0170, 0.0170, 0.0345, 0.0527,\n",
      "        0.0495, 0.0343, 0.0244, 0.0829, 0.0257, 0.0341, 0.0632, 0.0234, 0.0217,\n",
      "        0.0423, 0.0655, 0.0251, 0.0230, 0.0455, 0.0440, 0.0776, 0.0969, 0.0352,\n",
      "        0.0626, 0.0475, 0.0168, 0.0152, 0.0329, 0.1678, 0.1766, 0.0635, 0.0842,\n",
      "        0.0364, 0.0415, 0.0240, 0.0683, 0.0423, 0.0444, 0.0961, 0.0308, 0.0312,\n",
      "        0.0450, 0.0498, 0.0250, 0.0443, 0.0548, 0.0305, 0.0224, 0.0612, 0.0537,\n",
      "        0.0268, 0.0608, 0.0437, 0.0693, 0.0478, 0.0536, 0.0344, 0.0611, 0.0513,\n",
      "        0.0798, 0.0890, 0.0326, 0.0339, 0.0539, 0.0593, 0.0666, 0.0635, 0.0202,\n",
      "        0.0565, 0.0490, 0.0726, 0.1960, 0.0290, 0.0321, 0.1278, 0.0426, 0.1300,\n",
      "        0.0351, 0.0281, 0.0513, 0.0348, 0.1806, 0.0503, 0.0614, 0.0305, 0.0568,\n",
      "        0.0584])}, 16: {'step': tensor(3820.), 'exp_avg': tensor([ 2.1785e-18,  8.0416e-18,  2.8044e-18, -8.4695e-18, -9.1356e-18,\n",
      "         1.6971e-18,  4.9986e-18, -2.1150e-18]), 'exp_avg_sq': tensor([ 26.2346,  46.3506,  27.1869,  33.0519,  19.5386, 150.8792,  26.7634,\n",
      "         23.1831])}, 17: {'step': tensor(3820.), 'exp_avg': tensor([[-1.5942e-18, -3.1280e-18,  1.7354e-18,  2.0473e-18,  1.8895e-18,\n",
      "         -2.1609e-18,  3.9682e-19,  1.2571e-18],\n",
      "        [-5.8824e-18, -1.1584e-17,  6.4133e-18,  7.5798e-18,  6.9738e-18,\n",
      "         -7.9781e-18,  1.4638e-18,  4.6481e-18],\n",
      "        [-2.0707e-18, -4.0707e-18,  2.3012e-18,  2.6133e-18,  2.5056e-18,\n",
      "         -2.8207e-18,  5.0911e-19,  1.6041e-18],\n",
      "        [ 6.2307e-18,  1.2251e-17, -6.8363e-18, -7.9619e-18, -7.4384e-18,\n",
      "          8.4619e-18, -1.5439e-18, -4.8855e-18],\n",
      "        [ 6.7391e-18,  1.3221e-17, -7.2807e-18, -8.7066e-18, -7.9201e-18,\n",
      "          9.1182e-18, -1.6835e-18, -5.3442e-18],\n",
      "        [-1.3006e-18, -2.5302e-18,  1.3901e-18,  1.6734e-18,  1.5119e-18,\n",
      "         -1.7540e-18,  3.2554e-19,  1.0289e-18],\n",
      "        [-3.6638e-18, -7.1999e-18,  3.9720e-18,  4.7316e-18,  4.3208e-18,\n",
      "         -4.9619e-18,  9.1426e-19,  2.9033e-18],\n",
      "        [ 1.5419e-18,  3.0417e-18, -1.6950e-18, -1.9769e-18, -1.8432e-18,\n",
      "          2.0955e-18, -3.8219e-19, -1.2119e-18]]), 'exp_avg_sq': tensor([[  4.0386,   5.8094,   0.5378,  14.1958,   0.4259,   3.6679,   0.5382,\n",
      "           5.5559],\n",
      "        [  6.0239,   2.4859,  11.4264,  34.1718,  10.0076,   2.7122,   1.4105,\n",
      "          14.8441],\n",
      "        [  2.4259,   0.8820,   7.2608,  17.6596,   6.8892,   1.0551,   0.6930,\n",
      "           7.5209],\n",
      "        [  1.5675,   1.6025,   5.8359,  10.4067,   6.1788,   1.2132,   0.4116,\n",
      "           4.3594],\n",
      "        [  2.9037,   4.7281,   1.7172,   9.9166,   1.5821,   2.6703,   0.3910,\n",
      "           3.9977],\n",
      "        [ 18.6335,   8.4827,  25.2838, 104.6697,  20.6917,   8.6782,   4.2506,\n",
      "          44.7196],\n",
      "        [  3.3240,   1.7796,   4.2342,  15.5778,   3.8289,   1.8784,   0.6588,\n",
      "           6.7666],\n",
      "        [  2.5743,   1.6877,   3.7726,  14.9673,   3.2256,   1.3386,   0.5890,\n",
      "           6.2848]])}, 18: {'step': tensor(3820.), 'exp_avg': tensor([ 1.7741e-20,  1.3793e-20,  9.0389e-21, -1.1994e-22,  1.0804e-20,\n",
      "        -5.7801e-22,  1.9888e-20,  1.0021e-20,  8.5418e-21,  8.9085e-21,\n",
      "         1.0899e-20,  9.2700e-21,  1.0556e-20,  1.4627e-20,  8.2477e-21,\n",
      "         3.0887e-21,  1.2331e-20,  1.1435e-20,  1.0618e-20,  1.1441e-20,\n",
      "         1.4186e-20,  8.6957e-21,  1.9998e-20,  9.7365e-21,  1.3636e-20,\n",
      "         1.0637e-20,  1.3119e-20,  1.9976e-21,  6.0832e-21,  1.7765e-20,\n",
      "         1.0952e-20,  1.5412e-20,  9.0705e-21,  1.0493e-20,  8.3033e-21,\n",
      "         1.0808e-20,  8.3383e-21,  9.9422e-21,  9.8937e-21,  1.3842e-20,\n",
      "         1.2826e-20,  1.1671e-20,  1.1704e-20,  1.1492e-20,  6.5799e-21,\n",
      "         7.4542e-21,  1.1198e-20,  1.4242e-20,  8.2942e-21,  1.0206e-20,\n",
      "         8.8282e-22,  9.2216e-21,  1.4448e-20,  1.0807e-20,  9.3705e-21,\n",
      "         1.1773e-20,  1.1736e-20,  8.0669e-21,  9.1768e-21,  1.2270e-20,\n",
      "         1.4176e-20,  9.7784e-21,  6.7153e-22,  1.0256e-20,  1.1654e-20,\n",
      "         3.4177e-21, -1.6735e-21,  2.0255e-21,  4.3875e-21,  1.3145e-20,\n",
      "         1.7729e-20,  1.6316e-20,  8.9218e-21,  1.4399e-20,  1.2662e-20,\n",
      "         1.2221e-20, -2.3832e-21,  1.6831e-20,  7.8508e-21,  1.9783e-20,\n",
      "         1.6693e-20,  2.0441e-20,  2.3151e-20,  1.4528e-20,  1.9122e-20,\n",
      "         1.5078e-20,  1.7429e-20,  1.0529e-20,  1.2884e-20,  1.4512e-20,\n",
      "         1.4413e-20,  9.7297e-21,  1.0609e-20,  1.3560e-20,  1.5359e-20,\n",
      "         1.5377e-20,  1.4965e-20,  2.2299e-20,  1.3467e-21,  9.6843e-21]), 'exp_avg_sq': tensor([0.0015, 0.0012, 0.0012, 0.0030, 0.0047, 0.0005, 0.0024, 0.0051, 0.0033,\n",
      "        0.0018, 0.0009, 0.0036, 0.0011, 0.0016, 0.0012, 0.0010, 0.0011, 0.0094,\n",
      "        0.0034, 0.0013, 0.0097, 0.0033, 0.0015, 0.0043, 0.0042, 0.0010, 0.0009,\n",
      "        0.0012, 0.0074, 0.0020, 0.0013, 0.0015, 0.0012, 0.0064, 0.0034, 0.0032,\n",
      "        0.0087, 0.0008, 0.0023, 0.0042, 0.0010, 0.0067, 0.0139, 0.0038, 0.0210,\n",
      "        0.0007, 0.0022, 0.0010, 0.0050, 0.0054, 0.0074, 0.0043, 0.0024, 0.0029,\n",
      "        0.0017, 0.0019, 0.0032, 0.0012, 0.0024, 0.0017, 0.0008, 0.0004, 0.0032,\n",
      "        0.0053, 0.0208, 0.0048, 0.0082, 0.0055, 0.0077, 0.0010, 0.0009, 0.0007,\n",
      "        0.0042, 0.0078, 0.0007, 0.0005, 0.0037, 0.0049, 0.0097, 0.0025, 0.0051,\n",
      "        0.0024, 0.0135, 0.0027, 0.0087, 0.0021, 0.0029, 0.0120, 0.0069, 0.0051,\n",
      "        0.0051, 0.0014, 0.0008, 0.0024, 0.0026, 0.0044, 0.0006, 0.0012, 0.0083,\n",
      "        0.0028])}, 19: {'step': tensor(3820.), 'exp_avg': tensor([1.2397e-19, 1.1431e-19, 1.4607e-19, 3.6601e-20, 1.1890e-19, 1.5144e-19,\n",
      "        1.7557e-19, 1.2714e-19, 1.2774e-19, 9.5016e-20, 1.3430e-19, 1.2261e-19,\n",
      "        1.4639e-19, 1.1410e-19, 1.2889e-19, 1.5076e-19, 1.1758e-19, 1.4738e-19,\n",
      "        1.3089e-19, 1.3971e-19, 1.4857e-19, 1.3955e-19, 1.5110e-19, 1.3572e-19,\n",
      "        1.4966e-19, 1.3383e-19, 1.6478e-19, 2.7498e-20, 1.3306e-19, 1.4428e-19,\n",
      "        1.2816e-19, 1.7889e-19, 1.2270e-19, 1.0566e-19, 1.3349e-19, 1.2114e-19,\n",
      "        7.7277e-20, 1.4834e-19, 1.2872e-19, 1.6171e-19, 1.4967e-19, 1.3906e-19,\n",
      "        1.3433e-19, 1.4471e-19, 1.0363e-19, 1.5635e-19, 1.2840e-19, 1.3590e-19,\n",
      "        1.3797e-19, 1.2752e-19, 4.0863e-20, 1.4290e-19, 1.1092e-19, 1.3037e-19,\n",
      "        1.3217e-19, 1.4393e-19, 1.5032e-19, 1.3677e-19, 1.2935e-19, 1.2301e-19,\n",
      "        1.5635e-19, 1.2826e-19, 3.0736e-20, 1.1723e-19, 1.7980e-19, 7.5552e-20,\n",
      "        4.9820e-20, 2.7534e-20, 1.7534e-19, 1.4942e-19, 1.4671e-19, 1.7895e-19,\n",
      "        1.2590e-19, 1.4996e-19, 9.8260e-20, 1.3212e-19, 9.8076e-20, 1.6779e-19,\n",
      "        1.3848e-19, 2.0024e-19, 1.2965e-19, 1.4716e-19, 1.0952e-19, 1.3713e-19,\n",
      "        1.8755e-19, 1.4929e-19, 1.6519e-19, 1.3515e-19, 1.4194e-19, 1.4634e-19,\n",
      "        1.5017e-19, 1.2895e-19, 1.2861e-19, 1.4443e-19, 1.4068e-19, 1.7964e-19,\n",
      "        1.5824e-19, 1.5907e-19, 2.5290e-20, 1.0733e-19]), 'exp_avg_sq': tensor([0.0120, 0.0083, 0.0094, 0.0228, 0.0143, 0.0100, 0.0105, 0.0179, 0.0235,\n",
      "        0.0092, 0.0190, 0.0102, 0.0109, 0.0324, 0.0086, 0.0205, 0.0094, 0.0227,\n",
      "        0.0113, 0.0206, 0.0088, 0.0182, 0.0191, 0.0172, 0.0077, 0.0124, 0.0080,\n",
      "        0.0131, 0.0112, 0.0134, 0.0108, 0.0118, 0.0099, 0.0127, 0.0137, 0.0145,\n",
      "        0.0156, 0.0143, 0.0128, 0.0139, 0.0340, 0.0227, 0.0156, 0.0216, 0.0172,\n",
      "        0.0179, 0.0111, 0.0112, 0.0331, 0.0208, 0.0200, 0.0168, 0.0139, 0.0169,\n",
      "        0.0152, 0.0185, 0.0151, 0.0182, 0.0094, 0.0274, 0.0117, 0.0103, 0.0210,\n",
      "        0.0127, 0.0129, 0.0151, 0.0302, 0.0143, 0.0106, 0.0099, 0.0272, 0.0126,\n",
      "        0.0360, 0.0216, 0.0159, 0.0205, 0.0128, 0.0223, 0.0216, 0.0130, 0.0213,\n",
      "        0.0291, 0.0139, 0.0207, 0.0113, 0.0182, 0.0273, 0.0164, 0.0184, 0.0095,\n",
      "        0.0216, 0.0167, 0.0114, 0.0342, 0.0113, 0.0158, 0.0157, 0.0171, 0.0240,\n",
      "        0.0144])}, 20: {'step': tensor(3820.), 'exp_avg': tensor([ 7.9318e-19,  5.6021e-18,  8.2885e-18, -8.9394e-18, -4.2444e-18,\n",
      "        -2.8196e-18,  3.6186e-18, -2.2990e-18]), 'exp_avg_sq': tensor([ 16.6328,  28.7738,  43.6722,  14.1422,  33.1285,  10.3402, 112.1996,\n",
      "         12.7475])}, 21: {'step': tensor(3820.), 'exp_avg': tensor([[ 5.9339e-19,  6.3027e-19, -1.2798e-18,  9.3409e-19, -5.8270e-19,\n",
      "          1.7275e-20, -1.5039e-19, -1.8222e-19],\n",
      "        [ 4.3761e-18,  4.7803e-18, -9.5756e-18,  6.9714e-18, -4.4585e-18,\n",
      "          1.9152e-19, -1.0737e-18, -1.3449e-18],\n",
      "        [ 6.4476e-18,  7.0004e-18, -1.4064e-17,  1.0245e-17, -6.5398e-18,\n",
      "          2.6532e-19, -1.5749e-18, -1.9777e-18],\n",
      "        [-6.9590e-18, -7.3751e-18,  1.4992e-17, -1.0945e-17,  7.0226e-18,\n",
      "         -2.2970e-19,  1.6047e-18,  2.1018e-18],\n",
      "        [-3.2998e-18, -3.6522e-18,  7.2697e-18, -5.2864e-18,  3.3623e-18,\n",
      "         -1.5778e-19,  8.4195e-19,  1.0242e-18],\n",
      "        [-2.2070e-18, -2.4575e-18,  4.8770e-18, -3.5440e-18,  2.2567e-18,\n",
      "         -1.1147e-19,  5.6608e-19,  6.8757e-19],\n",
      "        [ 2.8551e-18,  3.0265e-18, -6.1512e-18,  4.4901e-18, -2.9014e-18,\n",
      "          9.8337e-20, -6.4219e-19, -8.5962e-19],\n",
      "        [-1.8064e-18, -1.9526e-18,  3.9311e-18, -2.8646e-18,  1.8408e-18,\n",
      "         -7.3507e-20,  4.2850e-19,  5.5095e-19]]), 'exp_avg_sq': tensor([[3.9853e+00, 5.4019e+00, 9.0542e-01, 4.3605e-01, 1.5104e+00, 1.6412e+00,\n",
      "         4.3129e+00, 7.2111e-02],\n",
      "        [2.5493e+00, 1.6652e+01, 1.0586e+01, 3.8712e+00, 1.8487e+00, 2.8587e+00,\n",
      "         1.1273e+01, 5.5448e-01],\n",
      "        [7.0342e+00, 2.1769e+01, 7.0740e+00, 1.9392e+00, 3.3763e+00, 5.0105e+00,\n",
      "         1.5295e+01, 5.2122e-01],\n",
      "        [3.3357e+00, 1.0040e+01, 4.5497e+00, 1.5711e+00, 1.9099e+00, 2.2501e+00,\n",
      "         6.9067e+00, 2.5593e-01],\n",
      "        [1.1410e+01, 2.4136e+01, 4.1246e+00, 8.8129e-01, 5.5379e+00, 6.3197e+00,\n",
      "         2.0784e+01, 3.4193e-01],\n",
      "        [1.5050e+00, 8.2194e+00, 5.7516e+00, 2.2218e+00, 8.9417e-01, 1.4928e+00,\n",
      "         4.7618e+00, 2.5383e-01],\n",
      "        [2.7907e+01, 1.2964e+02, 4.8820e+01, 1.3797e+01, 1.1976e+01, 2.6950e+01,\n",
      "         9.0289e+01, 3.0528e+00],\n",
      "        [5.7237e-01, 2.9668e+00, 1.7455e+00, 6.1879e-01, 6.2406e-01, 5.3297e-01,\n",
      "         2.2883e+00, 9.0068e-02]])}, 22: {'step': tensor(3820.), 'exp_avg': tensor([ 5.9361e-21,  2.0979e-20, -1.7789e-20, -5.4176e-21,  5.1725e-21,\n",
      "        -2.7500e-20,  9.7583e-21,  1.5313e-20,  5.6897e-21,  1.7205e-20,\n",
      "         1.9605e-21,  4.2196e-21,  1.0774e-20,  3.5354e-21,  6.2559e-21,\n",
      "        -2.3468e-20, -1.3151e-21,  1.4204e-20,  8.1008e-21,  7.8453e-21,\n",
      "         1.0902e-20,  6.4579e-21,  2.5338e-20,  8.2216e-21,  8.8712e-21,\n",
      "         9.8686e-21,  6.9190e-21, -8.5369e-21, -5.7714e-21,  1.9617e-20,\n",
      "         1.3804e-20, -9.3124e-21,  8.8090e-21,  1.7727e-20,  1.2402e-20,\n",
      "         4.9654e-22, -1.0343e-22, -2.2738e-21, -3.6962e-22,  1.6216e-20,\n",
      "         9.7384e-21,  4.2438e-21,  7.3339e-21,  7.7360e-22, -3.0845e-21,\n",
      "        -1.5183e-20,  1.3831e-21,  2.2670e-20,  9.6604e-21,  1.1925e-20,\n",
      "        -7.1510e-21, -1.2713e-21,  2.8099e-20,  1.2362e-20,  3.1252e-21,\n",
      "         5.5711e-22,  5.5695e-21, -4.2159e-21,  1.0151e-20,  2.1828e-20,\n",
      "         1.1601e-20,  1.1427e-20, -8.2596e-21,  1.9424e-20, -9.6181e-21,\n",
      "        -2.8852e-21, -7.4829e-21, -8.4557e-21, -2.3284e-20,  1.1167e-20,\n",
      "         2.0635e-20,  5.1959e-21,  1.1068e-20,  1.5350e-20,  2.8378e-20,\n",
      "         9.6184e-21, -5.0612e-21, -2.6637e-22,  2.3912e-21,  5.9002e-21,\n",
      "         1.0848e-20,  1.6735e-20,  1.5931e-20, -3.9144e-23,  1.1942e-20,\n",
      "         1.9154e-20,  4.0667e-21,  5.9760e-21,  8.3890e-21,  5.5059e-21,\n",
      "        -9.8509e-21,  1.0182e-20,  1.7106e-20,  1.3647e-20,  1.5095e-20,\n",
      "         4.9631e-21,  3.9239e-21,  2.5448e-20, -8.6647e-21, -5.0468e-21]), 'exp_avg_sq': tensor([0.0129, 0.0156, 0.0121, 0.0108, 0.0100, 0.0215, 0.0170, 0.0219, 0.0130,\n",
      "        0.0228, 0.0121, 0.0156, 0.0126, 0.0136, 0.0147, 0.0188, 0.0238, 0.0225,\n",
      "        0.0129, 0.0079, 0.0134, 0.0152, 0.0136, 0.0100, 0.0155, 0.0144, 0.0112,\n",
      "        0.0130, 0.0271, 0.0123, 0.0140, 0.0110, 0.0176, 0.0178, 0.0312, 0.0191,\n",
      "        0.0083, 0.0175, 0.0129, 0.0118, 0.0116, 0.0192, 0.0265, 0.0100, 0.0227,\n",
      "        0.0137, 0.0255, 0.0103, 0.0167, 0.0162, 0.0129, 0.0140, 0.0187, 0.0184,\n",
      "        0.0169, 0.0186, 0.0225, 0.0158, 0.0176, 0.0113, 0.0116, 0.0051, 0.0125,\n",
      "        0.0147, 0.0239, 0.0134, 0.0140, 0.0192, 0.0217, 0.0114, 0.0111, 0.0182,\n",
      "        0.0074, 0.0063, 0.0127, 0.0172, 0.0203, 0.0136, 0.0083, 0.0093, 0.0144,\n",
      "        0.0092, 0.0275, 0.0153, 0.0194, 0.0153, 0.0143, 0.0227, 0.0123, 0.0131,\n",
      "        0.0126, 0.0143, 0.0112, 0.0054, 0.0202, 0.0117, 0.0202, 0.0235, 0.0218,\n",
      "        0.0180])}, 23: {'step': tensor(3820.), 'exp_avg': tensor([-1.8382e-19, -1.7593e-19, -1.8916e-19, -2.6906e-20, -1.8287e-19,\n",
      "        -1.9440e-19, -1.7904e-19, -1.7525e-19, -1.7662e-19, -1.0631e-19,\n",
      "        -1.8405e-19, -1.7927e-19, -1.7886e-19, -1.0617e-19, -1.8175e-19,\n",
      "        -1.9440e-19, -1.1583e-19, -1.6818e-19, -1.7662e-19, -1.6225e-19,\n",
      "        -1.7714e-19, -1.7137e-19, -1.7583e-19, -1.7614e-19, -1.7624e-19,\n",
      "        -1.7942e-19, -1.6105e-19, -2.9988e-20, -1.8872e-19, -1.7963e-19,\n",
      "        -1.6623e-19, -1.8218e-19, -1.7040e-19, -1.1481e-19, -1.7174e-19,\n",
      "        -1.5583e-19, -2.6995e-20, -1.8618e-19, -1.7704e-19, -1.7871e-19,\n",
      "        -1.8340e-19, -1.7589e-19, -1.7093e-19, -1.7595e-19, -7.0429e-20,\n",
      "        -1.9109e-19, -1.4935e-19, -1.7729e-19, -1.7558e-19, -1.7506e-19,\n",
      "        -2.9225e-20, -1.8365e-19, -1.3379e-19, -1.7770e-19, -1.6319e-19,\n",
      "        -1.8313e-19, -1.7956e-19, -1.8927e-19, -1.6656e-19, -1.5143e-19,\n",
      "        -1.6825e-19, -1.7078e-19, -2.9599e-20, -1.7958e-19, -1.8882e-19,\n",
      "        -2.4463e-20, -2.8793e-20, -2.9879e-20, -1.9171e-19, -1.7805e-19,\n",
      "        -1.6809e-19, -1.6915e-19, -1.7281e-19, -1.7510e-19, -1.3075e-19,\n",
      "        -1.8141e-19, -2.4601e-20, -1.8512e-19, -1.7159e-19, -1.8047e-19,\n",
      "        -1.3238e-19, -1.5550e-19, -1.1177e-19, -1.7831e-19, -1.7464e-19,\n",
      "        -1.8118e-19, -1.6665e-19, -1.7469e-19, -1.7741e-19, -1.5019e-19,\n",
      "        -1.8872e-19, -1.7443e-19, -1.5728e-19, -1.8245e-19, -1.5261e-19,\n",
      "        -1.8502e-19, -1.7763e-19, -1.3027e-19, -2.9898e-20, -1.1682e-19]), 'exp_avg_sq': tensor([0.0092, 0.0068, 0.0070, 0.0093, 0.0087, 0.0071, 0.0088, 0.0089, 0.0093,\n",
      "        0.0089, 0.0095, 0.0079, 0.0098, 0.0096, 0.0087, 0.0090, 0.0082, 0.0084,\n",
      "        0.0091, 0.0100, 0.0082, 0.0092, 0.0093, 0.0107, 0.0061, 0.0068, 0.0062,\n",
      "        0.0098, 0.0070, 0.0081, 0.0086, 0.0086, 0.0048, 0.0048, 0.0097, 0.0061,\n",
      "        0.0099, 0.0060, 0.0103, 0.0113, 0.0097, 0.0066, 0.0073, 0.0094, 0.0059,\n",
      "        0.0090, 0.0091, 0.0107, 0.0082, 0.0058, 0.0087, 0.0086, 0.0093, 0.0099,\n",
      "        0.0100, 0.0092, 0.0084, 0.0118, 0.0058, 0.0099, 0.0105, 0.0090, 0.0104,\n",
      "        0.0104, 0.0074, 0.0101, 0.0110, 0.0085, 0.0079, 0.0052, 0.0080, 0.0112,\n",
      "        0.0098, 0.0104, 0.0100, 0.0101, 0.0070, 0.0060, 0.0099, 0.0093, 0.0096,\n",
      "        0.0100, 0.0068, 0.0085, 0.0064, 0.0105, 0.0116, 0.0080, 0.0113, 0.0081,\n",
      "        0.0077, 0.0107, 0.0085, 0.0117, 0.0070, 0.0074, 0.0096, 0.0116, 0.0085,\n",
      "        0.0063])}, 24: {'step': tensor(3820.), 'exp_avg': tensor([-4.1708e-21,  1.4928e-21, -1.0415e-21,  2.9191e-21, -2.0119e-22,\n",
      "        -7.3622e-22,  2.7733e-21, -1.0356e-21]), 'exp_avg_sq': tensor([0.0093, 0.0276, 0.0174, 0.0051, 0.0007, 0.0020, 0.0224, 0.0346])}, 25: {'step': tensor(3820.), 'exp_avg': tensor([[-3.0321e-19,  3.2969e-20, -1.9294e-19, -1.1303e-19,  1.9881e-19,\n",
      "          7.2277e-20,  3.8117e-19, -1.3446e-19],\n",
      "        [ 1.1645e-19, -1.2715e-20,  7.4099e-20,  4.3396e-20, -7.6315e-20,\n",
      "         -2.7874e-20, -1.4628e-19,  5.1605e-20],\n",
      "        [-8.3827e-20,  9.1656e-21, -5.3337e-20, -3.1248e-20,  5.4921e-20,\n",
      "          2.0083e-20,  1.0528e-19, -3.7138e-20],\n",
      "        [ 2.2274e-19, -2.4287e-20,  1.4173e-19,  8.3030e-20, -1.4599e-19,\n",
      "         -5.3229e-20, -2.7987e-19,  9.8729e-20],\n",
      "        [-2.5354e-20,  2.8248e-21, -1.6131e-20, -9.4530e-21,  1.6569e-20,\n",
      "          6.1790e-21,  3.1737e-20, -1.1196e-20],\n",
      "        [-5.1038e-20,  5.5306e-21, -3.2476e-20, -1.9025e-20,  3.3478e-20,\n",
      "          1.2128e-20,  6.4197e-20, -2.2647e-20],\n",
      "        [ 2.0060e-19, -2.1797e-20,  1.2764e-19,  7.4780e-20, -1.3154e-19,\n",
      "         -4.7786e-20, -2.5220e-19,  8.8968e-20],\n",
      "        [-7.6361e-20,  8.3092e-21, -4.8590e-20, -2.8453e-20,  5.0065e-20,\n",
      "          1.8222e-20,  9.5975e-20, -3.3860e-20]]), 'exp_avg_sq': tensor([[0.0552, 0.0066, 0.0204, 0.0303, 0.0354, 0.0114, 0.1332, 0.0180],\n",
      "        [0.0543, 0.0079, 0.0229, 0.0124, 0.0239, 0.0220, 0.0771, 0.0090],\n",
      "        [0.0149, 0.0021, 0.0068, 0.0045, 0.0091, 0.0054, 0.0305, 0.0037],\n",
      "        [0.0441, 0.0045, 0.0166, 0.0203, 0.0246, 0.0090, 0.0913, 0.0118],\n",
      "        [0.0086, 0.0014, 0.0027, 0.0034, 0.0022, 0.0035, 0.0078, 0.0007],\n",
      "        [0.0137, 0.0026, 0.0044, 0.0068, 0.0044, 0.0061, 0.0164, 0.0019],\n",
      "        [0.0347, 0.0041, 0.0140, 0.0143, 0.0218, 0.0064, 0.0772, 0.0103],\n",
      "        [0.0242, 0.0037, 0.0111, 0.0051, 0.0126, 0.0106, 0.0401, 0.0046]])}, 26: {'step': tensor(3820.), 'exp_avg': tensor([ 1.7288e-23,  2.3366e-23,  1.2445e-23, -9.2929e-25,  1.8236e-23,\n",
      "        -4.3431e-24,  1.0767e-24,  3.0579e-24,  1.2355e-24,  1.9420e-23,\n",
      "        -4.9656e-23,  6.9055e-24, -3.6565e-23,  3.2005e-24,  1.2851e-23,\n",
      "        -1.8376e-23, -1.2188e-23,  2.2205e-23,  1.0548e-23,  7.6668e-24,\n",
      "        -2.2755e-23, -5.5582e-21, -1.7800e-23,  1.4283e-23, -2.9200e-23]), 'exp_avg_sq': tensor([3.1753e-06, 1.7407e-05, 6.5867e-06, 5.0277e-06, 6.0841e-06, 5.1575e-06,\n",
      "        5.1885e-06, 5.8800e-06, 3.9008e-06, 5.3886e-06, 3.3049e-05, 1.3851e-05,\n",
      "        1.0495e-05, 2.3822e-06, 6.9718e-06, 9.9624e-06, 2.9502e-06, 1.3142e-05,\n",
      "        5.1826e-06, 1.4802e-05, 5.9613e-06, 5.6176e-05, 1.1345e-05, 5.8190e-06,\n",
      "        2.0050e-05])}, 27: {'step': tensor(3820.), 'exp_avg': tensor([-7.1065e-24, -2.8055e-22, -2.9383e-22, -5.5931e-22,  6.4284e-23,\n",
      "        -6.1039e-22, -4.1806e-22,  4.2073e-22, -5.0048e-22,  1.6158e-22,\n",
      "         5.8411e-22, -3.7859e-22,  6.5773e-22, -4.1716e-22, -1.0561e-22,\n",
      "         5.5540e-22, -4.9849e-22, -4.0690e-22, -2.4488e-22, -3.7223e-22,\n",
      "         5.3851e-22, -9.6910e-20,  5.3954e-22, -3.4151e-23,  4.8346e-22]), 'exp_avg_sq': tensor([2.8701e-04, 3.3704e-04, 1.2898e-03, 3.3989e-04, 3.2894e-04, 2.2555e-04,\n",
      "        1.5681e-04, 3.9086e-04, 1.3961e-04, 3.0112e-04, 2.1545e-03, 1.7118e-04,\n",
      "        4.5630e-04, 1.3769e-04, 2.5432e-04, 5.0345e-04, 1.1436e-04, 1.0538e-03,\n",
      "        4.3849e-04, 1.7999e-04, 3.5106e-04, 1.3154e-02, 5.4553e-04, 2.7052e-05,\n",
      "        1.4018e-03])}, 28: {'step': tensor(3820.), 'exp_avg': tensor([-1.1816e-20,  1.8396e-20, -7.7501e-20,  1.8839e-20,  7.3100e-20,\n",
      "        -2.2374e-20, -3.6027e-20,  3.7384e-20]), 'exp_avg_sq': tensor([0.0106, 0.0132, 0.0147, 0.0193, 0.0269, 0.0058, 0.0243, 0.0018])}, 29: {'step': tensor(3820.), 'exp_avg': tensor([[ 5.3081e-21,  7.1008e-21, -9.1212e-21,  1.7339e-20, -1.6260e-20,\n",
      "          5.4269e-21, -1.6813e-20,  7.9647e-21],\n",
      "        [-8.4860e-21, -1.1205e-20,  1.4373e-20, -2.7192e-20,  2.5540e-20,\n",
      "         -8.4444e-21,  2.6373e-20, -1.2441e-20],\n",
      "        [ 3.4727e-20,  4.6905e-20, -6.0329e-20,  1.1510e-19, -1.0785e-19,\n",
      "          3.6253e-20, -1.1153e-19,  5.3010e-20],\n",
      "        [-8.4817e-21, -1.1378e-20,  1.4619e-20, -2.7819e-20,  2.6079e-20,\n",
      "         -8.7215e-21,  2.6971e-20, -1.2788e-20],\n",
      "        [-3.3117e-20, -4.4364e-20,  5.7013e-20, -1.0844e-19,  1.0170e-19,\n",
      "         -3.3985e-20,  1.0512e-19, -4.9824e-20],\n",
      "        [ 1.0207e-20,  1.3621e-20, -1.7496e-20,  3.3232e-20, -3.1179e-20,\n",
      "          1.0390e-20, -3.2217e-20,  1.5251e-20],\n",
      "        [ 1.6555e-20,  2.1940e-20, -2.8162e-20,  5.3350e-20, -5.0092e-20,\n",
      "          1.6607e-20, -5.1740e-20,  2.4435e-20],\n",
      "        [-1.6712e-20, -2.2620e-20,  2.9104e-20, -5.5567e-20,  5.2063e-20,\n",
      "         -1.7527e-20,  5.3836e-20, -2.5607e-20]]), 'exp_avg_sq': tensor([[0.0167, 0.0014, 0.0021, 0.0056, 0.0042, 0.0041, 0.0035, 0.0053],\n",
      "        [0.0120, 0.0021, 0.0065, 0.0312, 0.0191, 0.0060, 0.0096, 0.0047],\n",
      "        [0.0094, 0.0052, 0.0064, 0.0210, 0.0089, 0.0031, 0.0205, 0.0051],\n",
      "        [0.0159, 0.0027, 0.0068, 0.0450, 0.0199, 0.0098, 0.0240, 0.0115],\n",
      "        [0.0220, 0.0079, 0.0078, 0.0138, 0.0070, 0.0040, 0.0207, 0.0068],\n",
      "        [0.0108, 0.0016, 0.0061, 0.0366, 0.0183, 0.0065, 0.0160, 0.0078],\n",
      "        [0.0280, 0.0047, 0.0037, 0.0063, 0.0021, 0.0073, 0.0092, 0.0083],\n",
      "        [0.0037, 0.0004, 0.0007, 0.0076, 0.0027, 0.0019, 0.0070, 0.0031]])}, 30: {'step': tensor(3820.), 'exp_avg': tensor([ 1.8194e-23,  1.4231e-23, -5.2926e-25, -3.4366e-23,  2.0558e-23,\n",
      "        -4.1514e-23, -1.8304e-23,  2.1588e-23, -2.7359e-23,  2.3916e-23,\n",
      "        -1.4468e-23, -9.4841e-24, -5.1138e-24, -1.8611e-23,  1.0927e-23,\n",
      "         6.4782e-24, -2.6926e-23,  9.2483e-26,  8.7903e-25, -9.9211e-24,\n",
      "         1.4024e-24, -3.9889e-21,  7.3671e-24,  1.3803e-23, -1.2546e-24]), 'exp_avg_sq': tensor([2.5057e-06, 1.6160e-05, 7.5484e-06, 5.0712e-06, 7.7357e-06, 3.7681e-06,\n",
      "        6.2692e-06, 5.6554e-06, 2.9691e-06, 4.2453e-06, 3.2178e-05, 1.2521e-05,\n",
      "        9.0994e-06, 3.4943e-06, 9.9997e-06, 9.1480e-06, 3.7413e-06, 1.0200e-05,\n",
      "        6.2043e-06, 1.4760e-05, 5.1776e-06, 1.0789e-04, 1.0060e-05, 6.4012e-06,\n",
      "        2.0821e-05])}, 31: {'step': tensor(3820.), 'exp_avg': tensor([-1.1191e-22, -5.2124e-22, -4.8452e-22, -8.2689e-22, -1.7996e-23,\n",
      "        -8.9392e-22, -6.4545e-22,  3.3514e-22, -7.5351e-22,  8.7964e-23,\n",
      "         4.6030e-22, -6.0507e-22,  5.4394e-22, -6.4562e-22, -2.2040e-22,\n",
      "         4.5833e-22, -7.0399e-22, -6.6823e-22, -4.0569e-22, -5.9579e-22,\n",
      "         4.3859e-22, -4.8714e-20,  4.4088e-22, -1.2869e-22,  3.7394e-22]), 'exp_avg_sq': tensor([1.0013e-04, 2.9995e-04, 5.7531e-04, 2.8327e-04, 6.9649e-05, 2.4169e-04,\n",
      "        1.9920e-04, 1.1552e-04, 2.2211e-04, 9.1415e-05, 4.5203e-04, 1.7947e-04,\n",
      "        1.2072e-04, 2.1109e-04, 8.1195e-05, 1.2984e-04, 1.5604e-04, 2.7989e-04,\n",
      "        1.6310e-04, 2.3012e-04, 9.4652e-05, 2.4091e-03, 1.4772e-04, 1.1177e-05,\n",
      "        2.7406e-04])}, 32: {'step': tensor(3820.), 'exp_avg': tensor([ 5.0378e-21, -4.3183e-23, -2.9681e-20, -9.8491e-21,  5.8183e-20,\n",
      "        -2.2705e-20,  1.3974e-20,  2.0469e-20, -5.4033e-20,  1.8648e-20]), 'exp_avg_sq': tensor([0.0004, 0.0025, 0.0030, 0.0011, 0.0214, 0.0080, 0.0033, 0.0018, 0.0082,\n",
      "        0.0007])}, 33: {'step': tensor(3820.), 'exp_avg': tensor([[-3.3654e-21,  9.2858e-21,  5.3614e-22,  4.1357e-22, -1.4618e-21,\n",
      "          7.3132e-21, -7.6263e-21, -4.8139e-21],\n",
      "        [-9.9361e-23,  2.4100e-22,  1.7430e-23,  1.4388e-23, -3.7366e-23,\n",
      "          1.9410e-22, -2.1457e-22, -1.2812e-22],\n",
      "        [ 1.9017e-20, -5.3438e-20, -3.0055e-21, -2.1409e-21,  8.5348e-21,\n",
      "         -4.1979e-20,  4.3370e-20,  2.7791e-20],\n",
      "        [ 6.1277e-21, -1.7475e-20, -9.6422e-22, -6.3215e-22,  2.8261e-21,\n",
      "         -1.3703e-20,  1.4046e-20,  9.1157e-21],\n",
      "        [-3.7469e-20,  1.0435e-19,  5.9230e-21,  4.4891e-21, -1.6503e-20,\n",
      "          8.2046e-20, -8.5212e-20, -5.4110e-20],\n",
      "        [ 1.4529e-20, -4.0540e-20, -2.2976e-21, -1.7179e-21,  6.4243e-21,\n",
      "         -3.1870e-20,  3.3060e-20,  2.1033e-20],\n",
      "        [-9.0101e-21,  2.4782e-20,  1.4234e-21,  1.1825e-21, -3.8548e-21,\n",
      "          1.9502e-20, -2.0412e-20, -1.2783e-20],\n",
      "        [-1.2988e-20,  3.6746e-20,  2.0534e-21,  1.3842e-21, -5.9157e-21,\n",
      "          2.8852e-20, -2.9683e-20, -1.9156e-20],\n",
      "        [ 3.5073e-20, -9.7468e-20, -5.5521e-21, -4.2327e-21,  1.5397e-20,\n",
      "         -7.6662e-20,  7.9701e-20,  5.0535e-20],\n",
      "        [-1.1816e-20,  3.3515e-20,  1.8660e-21,  1.2399e-21, -5.4090e-21,\n",
      "          2.6307e-20, -2.7030e-20, -1.7484e-20]]), 'exp_avg_sq': tensor([[2.0804e-04, 1.2261e-03, 6.4632e-05, 2.5569e-04, 7.1695e-04, 8.6136e-04,\n",
      "         4.0898e-04, 1.1873e-03],\n",
      "        [2.7380e-03, 2.9733e-02, 2.4546e-03, 2.8385e-03, 1.9006e-02, 2.6848e-02,\n",
      "         1.0547e-02, 2.4884e-02],\n",
      "        [2.9078e-03, 5.1312e-02, 8.0413e-04, 4.0313e-03, 3.0818e-02, 4.0011e-02,\n",
      "         1.1900e-02, 4.4669e-02],\n",
      "        [2.0315e-04, 1.7973e-03, 9.0535e-05, 2.7283e-04, 1.0789e-03, 1.3920e-03,\n",
      "         6.2554e-04, 1.6459e-03],\n",
      "        [5.0389e-03, 7.2519e-03, 5.9212e-04, 1.3195e-02, 4.6829e-03, 5.5353e-03,\n",
      "         1.9741e-02, 7.2519e-03],\n",
      "        [8.3875e-03, 1.1037e-02, 1.7724e-03, 7.9068e-03, 7.2536e-03, 6.7949e-03,\n",
      "         9.8993e-03, 1.3367e-02],\n",
      "        [1.7355e-03, 1.2762e-02, 1.7062e-04, 1.4429e-03, 8.5295e-03, 8.6852e-03,\n",
      "         2.2564e-03, 1.3016e-02],\n",
      "        [7.1064e-04, 9.8589e-03, 1.4809e-04, 7.2659e-04, 5.9322e-03, 7.3312e-03,\n",
      "         1.7488e-03, 9.0588e-03],\n",
      "        [5.5563e-03, 2.2157e-02, 6.2094e-04, 6.0631e-03, 1.2586e-02, 1.4932e-02,\n",
      "         1.0065e-02, 2.0508e-02],\n",
      "        [5.9818e-04, 2.0862e-03, 6.6813e-04, 5.1895e-04, 1.3127e-03, 2.2022e-03,\n",
      "         1.5146e-03, 1.7490e-03]])}, 34: {'step': tensor(3820.), 'exp_avg': tensor([-4.8738e-22,  3.7088e-21,  2.8337e-21,  5.6045e-21, -1.4375e-21,\n",
      "         6.1052e-21,  4.0720e-21, -4.8395e-21,  4.9725e-21, -2.4101e-21,\n",
      "        -6.9534e-21,  3.8842e-21, -7.6553e-21,  4.1688e-21,  3.2731e-22,\n",
      "        -6.5093e-21,  4.4249e-21,  4.9562e-21,  2.0106e-21,  3.8097e-21,\n",
      "        -6.1221e-21,  1.5349e-19, -6.3584e-21, -5.1888e-22, -5.5941e-21]), 'exp_avg_sq': tensor([3.5820e-04, 2.0339e-04, 2.3383e-04, 8.0988e-04, 2.0295e-04, 5.5326e-04,\n",
      "        2.6774e-04, 3.5917e-04, 5.5392e-04, 3.1727e-04, 7.1225e-04, 2.7719e-04,\n",
      "        3.8905e-04, 2.7107e-04, 2.4982e-04, 3.8595e-04, 3.0861e-04, 2.7247e-04,\n",
      "        7.6514e-05, 2.3361e-04, 3.1264e-04, 1.1570e-02, 3.7172e-04, 1.9635e-04,\n",
      "        4.5590e-04])}, 35: {'step': tensor(3820.), 'exp_avg': tensor([ 1.5321e-27,  1.3040e-27, -3.5124e-27,  4.8298e-27,  2.9616e-27,\n",
      "        -1.9655e-27, -1.1829e-29,  1.7794e-28,  3.3831e-27, -1.1804e-27,\n",
      "         8.2846e-28, -7.1131e-28,  6.2938e-28, -1.1073e-27, -1.9493e-27,\n",
      "        -7.1921e-28,  5.2850e-27,  2.1393e-28, -1.3937e-27,  3.1997e-27,\n",
      "         4.4489e-28, -8.8738e-27,  6.9254e-28,  4.7198e-28,  1.1187e-27]), 'exp_avg_sq': tensor([2.6360e-16, 8.1164e-16, 5.1295e-16, 7.9478e-16, 2.9984e-16, 1.8943e-15,\n",
      "        1.4984e-16, 8.5690e-16, 3.6711e-16, 1.6647e-16, 6.1708e-16, 4.4666e-16,\n",
      "        1.3128e-15, 1.6108e-15, 1.0743e-16, 9.7173e-16, 2.5217e-16, 5.6059e-16,\n",
      "        9.1578e-17, 4.4086e-16, 1.6204e-16, 1.1852e-15, 1.4538e-16, 1.1306e-16,\n",
      "        8.5632e-16])}, 36: {'step': tensor(3820.), 'exp_avg': tensor([ 5.7842e-20,  7.7568e-20, -2.2735e-19,  2.6774e-19,  1.7875e-19,\n",
      "         2.4757e-19, -2.9832e-19,  5.6917e-19, -2.5399e-21, -4.8324e-19,\n",
      "        -5.0230e-20, -3.3695e-19]), 'exp_avg_sq': tensor([5.4757, 0.6396, 0.4732, 1.2785, 1.6288, 2.0987, 1.1928, 3.5645, 0.3848,\n",
      "        4.8769, 6.2143, 0.8601])}, 37: {'step': tensor(3820.), 'exp_avg': tensor([[ 1.2356e-18, -1.1279e-19,  7.8718e-19,  4.5842e-19, -8.2784e-19,\n",
      "         -2.5276e-19, -1.5951e-18,  5.6331e-19],\n",
      "        [ 1.8326e-18, -1.7706e-19,  1.1673e-18,  6.7965e-19, -1.2203e-18,\n",
      "         -3.9454e-19, -2.3466e-18,  8.2863e-19],\n",
      "        [-5.8736e-18,  5.9149e-19, -3.7415e-18, -2.1681e-18,  3.8943e-18,\n",
      "          1.3199e-18,  7.4659e-18, -2.6399e-18],\n",
      "        [ 6.0037e-18, -5.5313e-19,  3.8244e-18,  2.2309e-18, -4.0179e-18,\n",
      "         -1.2359e-18, -7.7432e-18,  2.7333e-18],\n",
      "        [ 4.2816e-18, -4.1573e-19,  2.7271e-18,  1.5873e-18, -2.8494e-18,\n",
      "         -9.2638e-19, -5.4777e-18,  1.9346e-18],\n",
      "        [ 5.7600e-18, -5.4460e-19,  3.6691e-18,  2.1370e-18, -3.8446e-18,\n",
      "         -1.2158e-18, -7.3992e-18,  2.6128e-18],\n",
      "        [-7.0575e-18,  6.8039e-19, -4.4954e-18, -2.6161e-18,  4.7008e-18,\n",
      "          1.5175e-18,  9.0385e-18, -3.1923e-18],\n",
      "        [ 1.4315e-17, -1.4193e-18,  9.1183e-18,  5.2936e-18, -9.5065e-18,\n",
      "         -3.1655e-18, -1.8246e-17,  6.4486e-18],\n",
      "        [-4.3745e-20,  4.0878e-21, -2.7816e-20, -1.6754e-20,  2.9139e-20,\n",
      "          8.7496e-21,  5.6689e-20, -1.9827e-20],\n",
      "        [-1.1092e-17,  1.0410e-18, -7.0658e-18, -4.1156e-18,  7.4095e-18,\n",
      "          2.3257e-18,  1.4264e-17, -5.0369e-18],\n",
      "        [-1.3040e-18,  1.2947e-19, -8.3042e-19, -4.8413e-19,  8.6542e-19,\n",
      "          2.8737e-19,  1.6631e-18, -5.8714e-19],\n",
      "        [-8.0575e-18,  7.7618e-19, -5.1325e-18, -2.9862e-18,  5.3674e-18,\n",
      "          1.7318e-18,  1.0320e-17, -3.6452e-18]]), 'exp_avg_sq': tensor([[ 75.9146,  36.1687,  17.2282,  49.7952,   4.4778, 101.6360,   7.3682,\n",
      "           1.1327],\n",
      "        [  6.2175,   1.7849,   1.9277,   2.7983,   1.3151,   4.5944,   4.2687,\n",
      "           0.4739],\n",
      "        [  5.0167,   2.6144,   1.3200,   3.3106,   0.5198,   7.6067,   1.0195,\n",
      "           0.1843],\n",
      "        [  2.8583,   1.6142,   0.9770,   2.0190,   0.9827,   4.5344,   2.3910,\n",
      "           0.5332],\n",
      "        [ 12.1577,   5.8039,   3.3017,   7.0316,   1.2275,  16.7084,   3.1529,\n",
      "           0.4940],\n",
      "        [ 14.5572,   8.4924,   3.2642,  11.0389,   0.8147,  24.3549,   1.4173,\n",
      "           0.3883],\n",
      "        [ 21.9092,  10.7893,   4.9516,  14.3576,   1.8706,  30.8217,   3.7347,\n",
      "           0.7487],\n",
      "        [ 42.5875,  22.2473,  10.0376,  28.4779,   2.6045,  62.4980,   4.7710,\n",
      "           0.7895],\n",
      "        [  4.4629,   2.6752,   0.9792,   3.5837,   0.2769,   7.4474,   0.5507,\n",
      "           0.1388],\n",
      "        [ 56.8280,  28.4910,  12.9179,  37.4610,   3.1985,  82.9548,   5.1846,\n",
      "           0.9401],\n",
      "        [ 55.6443,  28.7243,  12.7299,  39.1475,   3.0076,  79.2789,   5.5200,\n",
      "           1.0561],\n",
      "        [  6.4208,   3.1486,   1.7274,   3.8145,   0.6862,   8.9008,   1.5715,\n",
      "           0.3087]])}, 38: {'step': tensor(3820.), 'exp_avg': tensor([3.6311e-20, 4.0154e-20, 3.3346e-20, 3.3689e-20, 3.7188e-20, 3.2250e-20,\n",
      "        3.2309e-20, 3.8991e-20, 3.4178e-20, 3.7555e-20, 3.6439e-20, 3.3593e-20,\n",
      "        3.8059e-20, 3.3386e-20, 3.5721e-20, 3.8295e-20, 3.3173e-20, 4.0121e-20,\n",
      "        3.2990e-20, 3.4134e-20, 3.8510e-20, 1.3206e-18, 3.7855e-20, 3.6224e-20,\n",
      "        3.7262e-20]), 'exp_avg_sq': tensor([0.0104, 0.0126, 0.0025, 0.0251, 0.0082, 0.0196, 0.0044, 0.0131, 0.0120,\n",
      "        0.0122, 0.0482, 0.0053, 0.0153, 0.0077, 0.0077, 0.0193, 0.0366, 0.0247,\n",
      "        0.0016, 0.0073, 0.0069, 0.1722, 0.0243, 0.0041, 0.0337])}, 39: {'step': tensor(3820.), 'exp_avg': tensor([-2.4554e-19, -2.7926e-19, -2.3357e-19, -2.4093e-19, -2.4859e-19,\n",
      "        -2.3516e-19, -2.2982e-19, -2.7091e-19, -2.4343e-19, -2.5195e-19,\n",
      "        -2.8096e-19, -2.3734e-19, -2.7503e-19, -2.3693e-19, -2.4167e-19,\n",
      "        -2.7226e-19, -2.3582e-19, -2.8215e-19, -2.2939e-19, -2.3900e-19,\n",
      "        -2.7602e-19, -9.0168e-18, -2.7062e-19, -2.4506e-19, -2.8181e-19]), 'exp_avg_sq': tensor([0.0729, 0.0993, 0.0629, 0.1758, 0.0638, 0.1974, 0.0577, 0.1011, 0.0708,\n",
      "        0.0744, 0.6772, 0.0526, 0.1166, 0.0557, 0.0618, 0.1289, 0.3198, 0.2295,\n",
      "        0.0604, 0.0520, 0.0784, 3.4604, 0.1378, 0.0524, 0.5205])}, 40: {'step': tensor(3820.), 'exp_avg': tensor([ 2.0947e-18,  6.0762e-19,  5.6335e-18, -7.7272e-18, -4.8108e-19,\n",
      "        -3.7479e-18, -4.1113e-18,  6.1541e-18,  5.7271e-18, -5.2993e-18,\n",
      "        -5.4885e-18,  6.6381e-18]), 'exp_avg_sq': tensor([ 5.2909, 10.2386, 16.4066,  6.6334,  4.9351,  4.2289,  4.9789,  8.7162,\n",
      "        16.3212,  5.0875,  2.8111, 12.3258])}, 41: {'step': tensor(3820.), 'exp_avg': tensor([[ 1.8339e-18,  1.1957e-19, -1.5407e-18,  7.2823e-19,  7.9635e-20,\n",
      "         -1.3150e-18, -3.4063e-18, -2.2859e-18,  3.9930e-18,  1.2434e-18,\n",
      "          3.6778e-18, -2.3164e-18],\n",
      "        [ 5.3955e-19, -2.4972e-20, -3.4667e-19,  1.8376e-19,  2.1260e-20,\n",
      "         -3.3717e-19, -8.0636e-19, -5.7427e-19,  9.4578e-19,  3.4246e-19,\n",
      "          8.8470e-19, -5.9225e-19],\n",
      "        [ 4.9353e-18,  2.7350e-19, -4.0604e-18,  1.9340e-18,  2.1353e-19,\n",
      "         -3.4999e-18, -9.0093e-18, -6.0744e-18,  1.0562e-17,  3.3279e-18,\n",
      "          9.7402e-18, -6.1624e-18],\n",
      "        [-6.7656e-18, -4.2221e-19,  5.6508e-18, -2.6768e-18, -2.9324e-19,\n",
      "          4.8364e-18,  1.2506e-17,  8.4032e-18, -1.4660e-17, -4.5799e-18,\n",
      "         -1.3507e-17,  8.5183e-18],\n",
      "        [-4.1852e-19, -3.7619e-20,  3.6947e-19, -1.7035e-19, -1.9328e-20,\n",
      "          3.0919e-19,  8.1026e-19,  5.3941e-19, -9.5020e-19, -2.8813e-19,\n",
      "         -8.7365e-19,  5.4386e-19],\n",
      "        [-3.2881e-18, -1.6023e-19,  2.6670e-18, -1.2786e-18, -1.4055e-19,\n",
      "          2.3132e-18,  5.9321e-18,  4.0104e-18, -6.9540e-18, -2.2083e-18,\n",
      "         -6.4170e-18,  4.0735e-18],\n",
      "        [-3.5929e-18, -2.5760e-19,  3.0589e-18, -1.4371e-18, -1.5795e-19,\n",
      "          2.5960e-18,  6.7480e-18,  4.5175e-18, -7.9109e-18, -2.4455e-18,\n",
      "         -7.2824e-18,  4.5723e-18],\n",
      "        [ 5.3886e-18,  3.5785e-19, -4.5402e-18,  2.1452e-18,  2.3267e-19,\n",
      "         -3.8690e-18, -1.0033e-17, -6.7267e-18,  1.1759e-17,  3.6554e-18,\n",
      "          1.0828e-17, -6.8171e-18],\n",
      "        [ 5.0037e-18,  3.5780e-19, -4.2583e-18,  2.0006e-18,  2.2016e-19,\n",
      "         -3.6149e-18, -9.3946e-18, -6.2902e-18,  1.1014e-17,  3.4055e-18,\n",
      "          1.0139e-17, -6.3664e-18],\n",
      "        [-4.6408e-18, -2.7153e-19,  3.8439e-18, -1.8273e-18, -2.0030e-19,\n",
      "          3.3022e-18,  8.5192e-18,  5.7341e-18, -9.9867e-18, -3.1344e-18,\n",
      "         -9.2054e-18,  5.8160e-18],\n",
      "        [-4.8036e-18, -3.0976e-19,  4.0294e-18, -1.9053e-18, -2.0883e-19,\n",
      "          3.4420e-18,  8.9110e-18,  5.9826e-18, -1.0446e-17, -3.2557e-18,\n",
      "         -9.6227e-18,  6.0624e-18],\n",
      "        [ 5.8086e-18,  3.7519e-19, -4.8733e-18,  2.3036e-18,  2.5295e-19,\n",
      "         -4.1630e-18, -1.0777e-17, -7.2358e-18,  1.2634e-17,  3.9373e-18,\n",
      "          1.1638e-17, -7.3318e-18]]), 'exp_avg_sq': tensor([[18.5922, 10.0833,  1.7657,  4.4588,  0.7634,  0.4957,  2.2587,  2.3661,\n",
      "          7.3079,  0.4463, 10.5099,  1.7832],\n",
      "        [25.9211, 15.6743,  2.8646,  7.3675,  1.4340,  0.9202,  3.3328,  4.7099,\n",
      "         12.6530,  0.3656, 18.5751,  1.7297],\n",
      "        [24.8471, 14.2960,  2.7249,  8.6641,  2.0588,  1.1750,  5.6040,  5.9739,\n",
      "         12.9967,  0.8818, 18.2514,  2.6387],\n",
      "        [11.0662,  6.6715,  1.5397,  3.5819,  0.8484,  0.5925,  3.2481,  2.9643,\n",
      "          7.2611,  0.4253,  9.4140,  1.2089],\n",
      "        [10.4575,  6.5533,  1.2022,  3.7768,  0.8082,  0.5192,  1.4654,  2.7109,\n",
      "          5.6070,  0.1898,  8.6975,  0.7682],\n",
      "        [11.5737,  5.8471,  1.3819,  2.5497,  0.5721,  0.5511,  3.4382,  2.6741,\n",
      "          6.4402,  0.6238,  8.0962,  1.8135],\n",
      "        [10.2935,  5.7847,  1.2079,  4.2637,  1.0800,  0.4416,  2.7938,  2.3131,\n",
      "          5.2780,  0.2477,  7.2529,  1.2830],\n",
      "        [11.5653,  7.6007,  1.9569,  4.6915,  1.2040,  0.9219,  3.8330,  4.4243,\n",
      "          8.9473,  0.5405, 12.2385,  1.0444],\n",
      "        [26.8339, 17.3033,  3.4695,  8.2724,  1.7053,  1.3087,  4.8297,  6.6683,\n",
      "         16.3658,  0.5904, 23.3868,  1.6920],\n",
      "        [12.1407,  6.7708,  1.5549,  2.6071,  0.5520,  0.3701,  3.1231,  1.6891,\n",
      "          6.3264,  0.4088,  7.8613,  1.2198],\n",
      "        [ 5.8248,  3.7402,  0.9803,  1.7707,  0.4915,  0.3814,  2.0531,  1.9338,\n",
      "          4.3614,  0.2776,  5.8886,  0.5168],\n",
      "        [15.2505, 10.1763,  2.7105,  5.6249,  1.4038,  1.2087,  5.7511,  6.0283,\n",
      "         13.2551,  0.7212, 17.2311,  1.6211]])}, 42: {'step': tensor(3820.), 'exp_avg': tensor([6.6655e-20, 7.5216e-20, 6.7180e-20, 6.8911e-20, 6.5509e-20, 6.8575e-20,\n",
      "        6.6791e-20, 6.8323e-20, 6.9877e-20, 6.5311e-20, 6.6034e-20, 6.8319e-20,\n",
      "        6.5555e-20, 6.8577e-20, 6.5678e-20, 6.5781e-20, 6.5345e-20, 7.7368e-20,\n",
      "        6.6449e-20, 6.8209e-20, 6.6107e-20, 9.1328e-19, 6.5493e-20, 6.6476e-20,\n",
      "        6.8893e-20]), 'exp_avg_sq': tensor([0.0102, 0.0069, 0.0028, 0.0376, 0.0086, 0.0347, 0.0040, 0.0127, 0.0171,\n",
      "        0.0121, 0.0396, 0.0031, 0.0142, 0.0065, 0.0084, 0.0165, 0.0189, 0.0143,\n",
      "        0.0019, 0.0045, 0.0086, 0.2422, 0.0191, 0.0021, 0.0284])}, 43: {'step': tensor(3820.), 'exp_avg': tensor([-4.5022e-19, -4.8581e-19, -4.3866e-19, -4.4633e-19, -4.5564e-19,\n",
      "        -4.4065e-19, -4.3367e-19, -4.7759e-19, -4.4925e-19, -4.5817e-19,\n",
      "        -4.8682e-19, -4.4197e-19, -4.8308e-19, -4.4121e-19, -4.4787e-19,\n",
      "        -4.7981e-19, -4.4325e-19, -4.9034e-19, -4.3645e-19, -4.4301e-19,\n",
      "        -4.8423e-19, -6.7101e-18, -4.7801e-19, -4.5569e-19, -4.8839e-19]), 'exp_avg_sq': tensor([0.0561, 0.0428, 0.0491, 0.0547, 0.0584, 0.0519, 0.0402, 0.0595, 0.0349,\n",
      "        0.0615, 0.2182, 0.0411, 0.0833, 0.0341, 0.0600, 0.0855, 0.1178, 0.0451,\n",
      "        0.0477, 0.0392, 0.0618, 0.8224, 0.0887, 0.0504, 0.1207])}, 44: {'step': tensor(3820.), 'exp_avg': tensor([ 5.8588e-18,  1.0498e-17, -4.7945e-18, -3.5902e-18,  1.5280e-18,\n",
      "        -1.2785e-18,  2.5104e-18, -1.9258e-18, -2.1266e-18, -3.1541e-18,\n",
      "         7.9177e-20,  8.4072e-19, -4.4812e-18,  1.2187e-18,  9.7081e-19,\n",
      "        -2.1541e-18]), 'exp_avg_sq': tensor([ 2.7806, 11.5159,  2.8751,  0.5943,  1.1385,  0.3095,  0.9943,  3.2004,\n",
      "         2.1813,  0.9166,  1.9072,  1.8646,  2.3961,  2.4932,  0.7468,  2.8517])}, 45: {'step': tensor(3820.), 'exp_avg': tensor([[-1.7342e-19,  5.3339e-18, -6.3934e-18,  9.3895e-18,  1.0444e-17,\n",
      "         -1.0047e-18, -2.7565e-18,  1.1796e-18,  7.4003e-18, -1.2395e-17,\n",
      "         -2.2723e-18, -4.8168e-18],\n",
      "        [-3.1606e-19,  9.5385e-18, -1.1419e-17,  1.6757e-17,  1.8648e-17,\n",
      "         -1.7562e-18, -4.9161e-18,  2.0966e-18,  1.3181e-17, -2.2135e-17,\n",
      "         -4.0270e-18, -8.5995e-18],\n",
      "        [ 1.5486e-19, -4.3121e-18,  5.1345e-18, -7.5086e-18, -8.3746e-18,\n",
      "          7.1551e-19,  2.1956e-18, -9.2421e-19, -5.8582e-18,  9.9495e-18,\n",
      "          1.7526e-18,  3.8597e-18],\n",
      "        [ 1.0240e-19, -3.2854e-18,  3.9481e-18, -5.8078e-18, -6.4531e-18,\n",
      "          6.4739e-19,  1.7078e-18, -7.3499e-19, -4.5944e-18,  7.6552e-18,\n",
      "          1.4240e-18,  2.9771e-18],\n",
      "        [-5.4332e-20,  1.3540e-18, -1.5990e-18,  2.3257e-18,  2.6029e-18,\n",
      "         -1.8700e-19, -6.7664e-19,  2.7874e-19,  1.7910e-18, -3.0965e-18,\n",
      "         -5.1742e-19, -1.1986e-18],\n",
      "        [ 4.0863e-20, -1.1519e-18,  1.3728e-18, -2.0089e-18, -2.2398e-18,\n",
      "          1.9490e-19,  5.8769e-19, -2.4814e-19, -1.5700e-18,  2.6609e-18,\n",
      "          4.7179e-19,  1.0323e-18],\n",
      "        [-7.5835e-20,  2.2810e-18, -2.7305e-18,  4.0068e-18,  4.4595e-18,\n",
      "         -4.1959e-19, -1.1753e-18,  5.0158e-19,  3.1524e-18, -5.2942e-18,\n",
      "         -9.6363e-19, -2.0563e-18],\n",
      "        [ 5.8751e-20, -1.7492e-18,  2.0932e-18, -3.0709e-18, -3.4190e-18,\n",
      "          3.1988e-19,  9.0024e-19, -3.8460e-19, -2.4164e-18,  4.0604e-18,\n",
      "          7.3888e-19,  1.5761e-18],\n",
      "        [ 6.1654e-20, -1.9447e-18,  2.3350e-18, -3.4331e-18, -3.8163e-18,\n",
      "          3.7787e-19,  1.0088e-18, -4.3375e-19, -2.7136e-18,  4.5286e-18,\n",
      "          8.3928e-19,  1.7602e-18],\n",
      "        [ 9.1019e-20, -2.8835e-18,  3.4632e-18, -5.0927e-18, -5.6605e-18,\n",
      "          5.6283e-19,  1.4966e-18, -6.4404e-19, -4.0270e-18,  6.7168e-18,\n",
      "          1.2468e-18,  2.6109e-18],\n",
      "        [-3.4137e-21,  6.6177e-20, -7.6312e-20,  1.0927e-19,  1.2350e-19,\n",
      "         -3.9851e-21, -3.1288e-20,  1.2097e-20,  8.0899e-20, -1.4740e-19,\n",
      "         -2.0780e-20, -5.6731e-20],\n",
      "        [-2.1243e-20,  7.8433e-19, -9.5060e-19,  1.4060e-18,  1.5575e-18,\n",
      "         -1.7763e-19, -4.1523e-19,  1.8287e-19,  1.1277e-18, -1.8462e-18,\n",
      "         -3.6139e-19, -7.1888e-19],\n",
      "        [ 1.3363e-19, -4.0811e-18,  4.8902e-18, -7.1803e-18, -7.9883e-18,\n",
      "          7.6418e-19,  2.1074e-18, -9.0136e-19, -5.6572e-18,  9.4820e-18,\n",
      "          1.7356e-18,  3.6839e-18],\n",
      "        [-3.5680e-20,  1.1141e-18, -1.3368e-18,  1.9646e-18,  2.1844e-18,\n",
      "         -2.1383e-19, -5.7712e-19,  2.4755e-19,  1.5509e-18, -2.5922e-18,\n",
      "         -4.7820e-19, -1.0075e-18],\n",
      "        [-3.1175e-20,  8.7738e-19, -1.0464e-18,  1.5319e-18,  1.7085e-18,\n",
      "         -1.5080e-19, -4.4796e-19,  1.9038e-19,  1.2007e-18, -2.0310e-18,\n",
      "         -3.6338e-19, -7.8706e-19],\n",
      "        [ 6.7980e-20, -1.9414e-18,  2.3150e-18, -3.3885e-18, -3.7762e-18,\n",
      "          3.3122e-19,  9.9203e-19, -4.1825e-19, -2.6475e-18,  4.4840e-18,\n",
      "          7.9519e-19,  1.7410e-18]]), 'exp_avg_sq': tensor([[ 0.3851,  1.6253,  0.9082,  1.9624,  2.6447,  5.9534,  0.4269,  0.1514,\n",
      "          2.0974, 14.3570,  1.7271,  0.3952],\n",
      "        [ 1.1637,  2.0319,  3.1916,  6.7969,  4.5962, 13.6317,  1.3824,  0.3705,\n",
      "          3.8050, 21.0952,  3.5955,  1.1572],\n",
      "        [ 0.4521,  3.4998,  1.2690,  2.5857,  4.4969,  9.3225,  0.3332,  0.1550,\n",
      "          2.1717, 23.7084,  1.5478,  0.6735],\n",
      "        [ 0.0759,  0.2323,  0.3935,  0.8021,  0.7660,  0.9500,  0.1418,  0.0264,\n",
      "          0.6309,  2.1955,  0.3362,  0.1855],\n",
      "        [ 0.1652,  1.2757,  0.7407,  1.1874,  2.2323,  2.5805,  0.2860,  0.0642,\n",
      "          0.9050,  8.7171,  0.7033,  0.3416],\n",
      "        [ 0.0733,  0.5111,  0.5097,  0.8105,  1.1287,  1.0682,  0.1872,  0.0263,\n",
      "          0.4588,  3.4204,  0.2694,  0.1972],\n",
      "        [ 0.1243,  0.4103,  0.5753,  1.0269,  0.8392,  1.7325,  0.1887,  0.0376,\n",
      "          0.6136,  2.9201,  0.3701,  0.1842],\n",
      "        [ 0.4604,  1.5324,  0.8295,  1.6869,  1.4695,  6.8949,  0.3879,  0.1243,\n",
      "          1.0917, 11.3416,  1.2516,  0.1907],\n",
      "        [ 0.2780,  0.6140,  0.4408,  1.1302,  0.8723,  3.5692,  0.2584,  0.0856,\n",
      "          0.7527,  6.2095,  0.8147,  0.1524],\n",
      "        [ 0.1241,  0.4144,  0.9081,  1.5335,  1.3395,  1.2042,  0.4618,  0.0702,\n",
      "          0.9869,  3.1761,  0.9380,  0.3478],\n",
      "        [ 0.2319,  1.2815,  0.4357,  1.0506,  1.6125,  4.3116,  0.1693,  0.0882,\n",
      "          1.0844, 10.1379,  0.8835,  0.2069],\n",
      "        [ 0.1702,  0.7037,  1.0690,  2.0023,  2.2815,  1.7759,  0.4879,  0.1130,\n",
      "          1.9000,  6.1840,  1.4312,  0.5500],\n",
      "        [ 0.2219,  0.7229,  0.8033,  1.6884,  1.8162,  2.8497,  0.3342,  0.0963,\n",
      "          1.8422,  6.5620,  1.4151,  0.4050],\n",
      "        [ 0.1665,  0.2951,  0.4150,  0.9573,  0.8280,  1.7976,  0.2864,  0.0864,\n",
      "          1.0620,  3.5599,  1.1859,  0.1986],\n",
      "        [ 0.0628,  0.2149,  0.2065,  0.3903,  0.5839,  0.6636,  0.1366,  0.0407,\n",
      "          0.4644,  2.3437,  0.5110,  0.1025],\n",
      "        [ 0.3185,  1.0277,  1.4937,  2.6236,  2.4128,  3.7779,  0.5440,  0.0968,\n",
      "          1.3090,  7.1881,  1.0386,  0.5561]])}, 46: {'step': tensor(3820.), 'exp_avg': tensor([ 1.0129e-20,  1.7188e-20,  1.8922e-20,  2.5589e-20,  8.3080e-21,\n",
      "         2.7493e-20,  2.2452e-20, -2.3822e-21,  2.3624e-20,  5.6244e-21,\n",
      "        -7.5496e-21,  2.1220e-20, -9.4869e-21,  2.2003e-20,  1.2965e-20,\n",
      "        -6.3346e-21,  2.4152e-20,  2.0118e-20,  1.7337e-20,  2.0864e-20,\n",
      "        -5.7914e-21,  9.4630e-22, -5.7644e-21,  1.0944e-20, -4.5383e-21]), 'exp_avg_sq': tensor([0.0695, 0.0599, 0.0369, 0.1451, 0.0493, 0.1350, 0.0629, 0.0895, 0.1338,\n",
      "        0.0698, 0.1169, 0.0422, 0.0926, 0.0885, 0.0445, 0.0977, 0.0516, 0.0741,\n",
      "        0.0216, 0.0653, 0.0681, 0.1606, 0.1038, 0.0123, 0.1117])}, 47: {'step': tensor(3820.), 'exp_avg': tensor([2.4281e-19, 2.4317e-19, 2.4148e-19, 2.4311e-19, 2.4392e-19, 2.4321e-19,\n",
      "        2.4222e-19, 2.4402e-19, 2.4358e-19, 2.4407e-19, 2.4389e-19, 2.4209e-19,\n",
      "        2.4508e-19, 2.4265e-19, 2.4354e-19, 2.4441e-19, 2.4303e-19, 2.4250e-19,\n",
      "        2.4207e-19, 2.4216e-19, 2.4591e-19, 2.4513e-19, 2.4428e-19, 2.4301e-19,\n",
      "        2.4427e-19]), 'exp_avg_sq': tensor([0.0387, 0.0412, 0.0412, 0.0402, 0.0386, 0.0407, 0.0413, 0.0389, 0.0403,\n",
      "        0.0387, 0.0390, 0.0413, 0.0390, 0.0409, 0.0384, 0.0390, 0.0414, 0.0409,\n",
      "        0.0417, 0.0410, 0.0388, 0.0405, 0.0390, 0.0417, 0.0390])}, 48: {'step': tensor(3820.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 49: {'step': tensor(3820.), 'exp_avg': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'exp_avg_sq': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])}, 50: {'step': tensor(3820.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 51: {'step': tensor(3820.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 52: {'step': tensor(3820.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 53: {'step': tensor(3820.), 'exp_avg': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'exp_avg_sq': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])}, 54: {'step': tensor(3820.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 55: {'step': tensor(3820.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 56: {'step': tensor(3820.), 'exp_avg': tensor([0.]), 'exp_avg_sq': tensor([0.])}, 57: {'step': tensor(3820.), 'exp_avg': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'exp_avg_sq': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])}, 60: {'step': tensor(3820.), 'exp_avg': tensor([-4.6967e-19, -5.6916e-19,  8.7930e-19, -2.1484e-18, -1.2002e-18,\n",
      "         1.8952e-18,  2.5913e-19,  8.6476e-19, -1.0416e-18,  2.9981e-19,\n",
      "         3.2476e-19,  1.0379e-18, -9.8083e-19,  2.5295e-19, -1.2905e-18,\n",
      "         1.8867e-18]), 'exp_avg_sq': tensor([0.2913, 0.2292, 0.5585, 0.0991, 0.2838, 0.3105, 0.2136, 0.1478, 0.2976,\n",
      "        0.4039, 0.0848, 0.2375, 0.0355, 0.3108, 0.1286, 1.0617])}, 61: {'step': tensor(3820.), 'exp_avg': tensor([[-3.5049e-18,  9.3770e-19,  1.0704e-19,  2.3595e-19,  1.0439e-18,\n",
      "          5.8218e-19, -3.6915e-19,  1.2462e-18, -1.3151e-18,  1.5994e-18,\n",
      "         -1.7195e-18,  1.6523e-18, -2.6913e-18,  2.8064e-18, -3.9022e-19,\n",
      "         -5.1068e-19],\n",
      "        [-4.2769e-18,  1.1309e-18,  1.2862e-19,  2.9288e-19,  1.2652e-18,\n",
      "          7.1265e-19, -4.5037e-19,  1.5174e-18, -1.5969e-18,  1.9483e-18,\n",
      "         -2.0896e-18,  2.0135e-18, -3.2766e-18,  3.4185e-18, -4.6557e-19,\n",
      "         -6.2296e-19],\n",
      "        [ 6.9130e-18, -1.7343e-18, -1.9255e-19, -5.0921e-19, -1.9839e-18,\n",
      "         -1.1690e-18,  7.2686e-19, -2.4293e-18,  2.5250e-18, -3.1238e-18,\n",
      "          3.3167e-18, -3.2364e-18,  5.2423e-18, -5.4825e-18,  6.7719e-19,\n",
      "          1.0058e-18],\n",
      "        [-1.6577e-17,  4.2422e-18,  4.7696e-19,  1.1882e-18,  4.8128e-18,\n",
      "          2.7865e-18, -1.7445e-18,  5.8461e-18, -6.1048e-18,  7.5147e-18,\n",
      "         -8.0073e-18,  7.7761e-18, -1.2620e-17,  1.3186e-17, -1.6917e-18,\n",
      "         -2.4124e-18],\n",
      "        [-9.3494e-18,  2.3677e-18,  2.6471e-19,  6.7982e-19,  2.6980e-18,\n",
      "          1.5763e-18, -9.8355e-19,  3.2910e-18, -3.4282e-18,  4.2314e-18,\n",
      "         -4.4999e-18,  4.3809e-18, -7.1030e-18,  7.4255e-18, -9.3398e-19,\n",
      "         -1.3603e-18],\n",
      "        [ 1.4972e-17, -3.7431e-18, -4.1715e-19, -1.1064e-18, -4.2896e-18,\n",
      "         -2.5319e-18,  1.5749e-18, -5.2578e-18,  5.4606e-18, -6.7639e-18,\n",
      "          7.1744e-18, -7.0053e-18,  1.1347e-17, -1.1869e-17,  1.4573e-18,\n",
      "          2.1775e-18],\n",
      "        [ 2.1252e-18, -5.0564e-19, -5.4927e-20, -1.6691e-19, -5.9208e-19,\n",
      "         -3.6415e-19,  2.2322e-19, -7.3994e-19,  7.5975e-19, -9.5313e-19,\n",
      "          1.0017e-18, -9.8942e-19,  1.5959e-18, -1.6729e-18,  1.8617e-19,\n",
      "          3.0879e-19],\n",
      "        [ 6.6752e-18, -1.7078e-18, -1.9048e-19, -4.7959e-19, -1.9367e-18,\n",
      "         -1.1235e-18,  7.0194e-19, -2.3541e-18,  2.4580e-18, -3.0245e-18,\n",
      "          3.2241e-18, -3.1320e-18,  5.0805e-18, -5.3085e-18,  6.8005e-19,\n",
      "          9.7179e-19],\n",
      "        [-8.2689e-18,  2.0527e-18,  2.2785e-19,  6.1674e-19,  2.3595e-18,\n",
      "          1.4012e-18, -8.6959e-19,  2.9003e-18, -3.0072e-18,  3.7317e-18,\n",
      "         -3.9530e-18,  3.8663e-18, -6.2586e-18,  6.5486e-18, -7.9304e-19,\n",
      "         -1.2025e-18],\n",
      "        [ 2.1568e-18, -5.8814e-19, -6.7605e-20, -1.4100e-19, -6.4955e-19,\n",
      "         -3.5630e-19,  2.2724e-19, -7.6964e-19,  8.1594e-19, -9.8709e-19,\n",
      "          1.0653e-18, -1.0190e-18,  1.6625e-18, -1.7320e-18,  2.4902e-19,\n",
      "          3.1440e-19],\n",
      "        [ 2.4637e-18, -6.4682e-19, -7.4265e-20, -1.6990e-19, -7.2638e-19,\n",
      "         -4.1049e-19,  2.5971e-19, -8.7283e-19,  9.1705e-19, -1.1219e-18,\n",
      "          1.2006e-18, -1.1585e-18,  1.8853e-18, -1.9677e-18,  2.6496e-19,\n",
      "          3.5856e-19],\n",
      "        [ 8.0560e-18, -2.0546e-18, -2.2984e-19, -5.8064e-19, -2.3338e-18,\n",
      "         -1.3562e-18,  8.4743e-19, -2.8393e-18,  2.9625e-18, -3.6493e-18,\n",
      "          3.8868e-18, -3.7780e-18,  6.1283e-18, -6.4044e-18,  8.1605e-19,\n",
      "          1.1725e-18],\n",
      "        [-7.7927e-18,  1.9338e-18,  2.1431e-19,  5.8168e-19,  2.2230e-18,\n",
      "          1.3209e-18, -8.1939e-19,  2.7331e-18, -2.8336e-18,  3.5163e-18,\n",
      "         -3.7250e-18,  3.6437e-18, -5.8976e-18,  6.1710e-18, -7.4669e-19,\n",
      "         -1.1333e-18],\n",
      "        [ 2.0773e-18, -4.9272e-19, -5.4673e-20, -1.6295e-19, -5.7852e-19,\n",
      "         -3.5507e-19,  2.1862e-19, -7.2278e-19,  7.4169e-19, -9.3237e-19,\n",
      "          9.7811e-19, -9.6614e-19,  1.5597e-18, -1.6354e-18,  1.8142e-19,\n",
      "          3.0152e-19],\n",
      "        [-1.0124e-17,  2.5524e-18,  2.8450e-19,  7.4061e-19,  2.9138e-18,\n",
      "          1.7092e-18, -1.0648e-18,  3.5607e-18, -3.7052e-18,  4.5784e-18,\n",
      "         -4.8652e-18,  4.7416e-18, -7.6844e-18,  8.0349e-18, -1.0020e-18,\n",
      "         -1.4729e-18],\n",
      "        [ 1.4455e-17, -3.7443e-18, -4.2250e-19, -1.0194e-18, -4.2257e-18,\n",
      "         -2.4223e-18,  1.5215e-18, -5.1090e-18,  5.3503e-18, -6.5642e-18,\n",
      "          7.0116e-18, -6.7898e-18,  1.1030e-17, -1.1518e-17,  1.5111e-18,\n",
      "          2.1044e-18]]), 'exp_avg_sq': tensor([[ 5.3859,  1.0565,  1.4540,  0.2057,  0.4260,  1.0788,  0.3446,  0.8197,\n",
      "          0.6261,  2.4948,  1.2133,  1.0861,  3.2582,  3.8035,  0.5357,  0.3548],\n",
      "        [ 4.0560,  0.8505,  1.4890,  0.2627,  1.0722,  0.7776,  0.1915,  0.6532,\n",
      "          0.6408,  2.3072,  1.5886,  0.6529,  3.1599,  3.6720,  1.0212,  0.2261],\n",
      "        [ 5.5879,  2.0829,  6.9508,  0.7611,  1.4826,  4.3126,  1.0786,  0.6570,\n",
      "          0.4875,  9.5030,  1.2238,  1.5386,  5.9180,  5.7371,  0.9856,  0.9779],\n",
      "        [ 1.9849,  0.2882,  0.5738,  0.0926,  0.1416,  0.4713,  0.1094,  0.3310,\n",
      "          0.2463,  0.9442,  0.3099,  0.4747,  1.2575,  1.3620,  0.1120,  0.1301],\n",
      "        [ 3.0548,  1.0250,  3.2623,  0.4941,  1.1981,  2.0581,  0.4233,  0.3798,\n",
      "          0.3900,  3.9450,  1.1505,  0.8402,  2.8272,  3.0902,  1.0360,  0.5677],\n",
      "        [ 9.5528,  1.4869,  3.8984,  0.4156,  1.0974,  1.9852,  0.6830,  1.1366,\n",
      "          0.7761,  6.3662,  1.7517,  1.3844,  6.6999,  7.5815,  0.8868,  0.6092],\n",
      "        [ 2.1831,  0.8809,  1.0463,  0.1823,  0.4444,  0.8547,  0.2947,  0.2293,\n",
      "          0.2766,  1.6210,  0.5661,  0.5414,  1.3146,  1.7462,  0.4759,  0.1855],\n",
      "        [ 4.1082,  0.3027,  2.1290,  0.2283,  0.5948,  1.0782,  0.2798,  0.6241,\n",
      "          0.3598,  3.1742,  0.7803,  0.6637,  3.3600,  3.4666,  0.3023,  0.3511],\n",
      "        [ 4.5286,  0.8211,  2.3617,  0.3558,  0.6574,  1.5183,  0.3820,  0.4624,\n",
      "          0.2951,  3.4071,  0.6629,  0.9318,  2.9296,  3.4099,  0.5361,  0.4346],\n",
      "        [ 3.9982,  1.2236,  3.9685,  0.5414,  0.7701,  2.9820,  0.5334,  0.5619,\n",
      "          0.4629,  5.1044,  0.6277,  1.4816,  3.3150,  3.3720,  0.3273,  0.6435],\n",
      "        [ 1.2018,  0.5068,  0.3536,  0.0804,  0.1052,  0.4228,  0.1622,  0.1830,\n",
      "          0.1836,  0.5704,  0.3577,  0.3909,  0.5998,  0.7304,  0.2719,  0.1140],\n",
      "        [ 3.1501,  0.8376,  1.1821,  0.2162,  0.2985,  1.1895,  0.2408,  0.4970,\n",
      "          0.4930,  1.6381,  0.7438,  0.9759,  1.7990,  2.1815,  0.3042,  0.2834],\n",
      "        [ 2.6082,  0.2999,  0.9183,  0.0829,  0.3200,  0.4360,  0.1468,  0.4159,\n",
      "          0.3165,  1.5832,  0.6619,  0.3568,  1.9909,  2.1133,  0.2032,  0.1234],\n",
      "        [ 3.3307,  1.4046,  1.2172,  0.2383,  0.2910,  1.4988,  0.3447,  0.4710,\n",
      "          0.5598,  1.8356,  0.7979,  1.1577,  1.6372,  2.1329,  0.4056,  0.2565],\n",
      "        [ 1.1258,  0.3736,  0.8402,  0.1161,  0.2342,  0.6004,  0.1862,  0.1193,\n",
      "          0.0952,  1.2894,  0.1953,  0.2729,  0.8781,  0.9662,  0.1741,  0.1252],\n",
      "        [10.5963,  4.1555,  3.7012,  0.6186,  0.9018,  3.9698,  1.1350,  1.6249,\n",
      "          1.6363,  5.9455,  2.7331,  3.0939,  5.7367,  7.1213,  1.4370,  0.8510]])}, 62: {'step': tensor(3820.), 'exp_avg': tensor([1.1557e-19, 1.1722e-19, 1.2903e-19, 1.2211e-19, 5.4210e-19, 1.2785e-19,\n",
      "        1.1231e-19, 1.0931e-19, 1.3703e-19, 1.1015e-19]), 'exp_avg_sq': tensor([0.0127, 0.0054, 0.0039, 0.0103, 0.0406, 0.0377, 0.0365, 0.0233, 0.0483,\n",
      "        0.0157])}, 63: {'step': tensor(3820.), 'exp_avg': tensor([6.6970e-19, 6.7344e-19, 6.8921e-19, 6.7751e-19, 2.7578e-18, 6.9368e-19,\n",
      "        6.6391e-19, 6.6268e-19, 7.2218e-19, 6.6353e-19]), 'exp_avg_sq': tensor([0.1384, 0.1405, 0.1347, 0.1360, 0.3038, 0.2425, 0.1980, 0.1610, 0.1934,\n",
      "        0.1672])}, 64: {'step': tensor(3820.), 'exp_avg': tensor([ 1.1075e-17,  9.3262e-19,  5.5277e-18,  4.5614e-18,  4.5624e-19,\n",
      "        -1.4034e-18, -5.9059e-18, -2.6126e-18,  2.8654e-18, -2.3129e-18,\n",
      "        -1.3318e-17,  3.2352e-18,  6.2574e-18,  1.6104e-18, -6.9620e-18,\n",
      "        -4.0075e-18]), 'exp_avg_sq': tensor([0.8837, 2.2931, 0.7829, 1.3823, 0.8006, 0.4437, 0.4091, 0.6333, 1.0186,\n",
      "        0.5386, 0.7940, 0.7088, 0.8889, 0.8925, 0.5643, 0.3855])}, 65: {'step': tensor(3820.), 'exp_avg': tensor([[ 6.6587e-18,  1.0726e-17,  7.1246e-18, -2.0472e-17, -1.0049e-17,\n",
      "         -1.4709e-17,  1.0041e-17,  6.4860e-18, -1.1147e-17,  1.8031e-17,\n",
      "         -9.8048e-18, -4.6762e-18,  7.2860e-18,  9.2357e-18,  1.2655e-17,\n",
      "         -1.1017e-17],\n",
      "        [ 6.1545e-19,  9.0963e-19,  6.8753e-19, -1.8334e-18, -9.7574e-19,\n",
      "         -1.3114e-18,  8.9026e-19,  6.3074e-19, -1.0226e-18,  1.6153e-18,\n",
      "         -9.2819e-19, -4.0077e-19,  7.0379e-19,  8.3185e-19,  1.0871e-18,\n",
      "         -9.6340e-19],\n",
      "        [ 3.3423e-18,  5.3552e-18,  3.5858e-18, -1.0255e-17, -5.0594e-18,\n",
      "         -7.3661e-18,  5.0266e-18,  3.2663e-18, -5.5920e-18,  9.0322e-18,\n",
      "         -4.9286e-18, -2.3366e-18,  3.6674e-18,  4.6281e-18,  6.3234e-18,\n",
      "         -5.5112e-18],\n",
      "        [ 2.7156e-18,  4.4151e-18,  2.8925e-18, -8.3796e-18, -4.0771e-18,\n",
      "         -6.0232e-18,  4.1145e-18,  2.6302e-18, -4.5512e-18,  7.3804e-18,\n",
      "         -3.9890e-18, -1.9216e-18,  2.9573e-18,  3.7778e-18,  5.2014e-18,\n",
      "         -4.5194e-18],\n",
      "        [ 2.3678e-19,  4.3746e-19,  2.3353e-19, -7.6825e-19, -3.2527e-19,\n",
      "         -5.5600e-19,  3.8301e-19,  2.0922e-19, -4.0170e-19,  6.7640e-19,\n",
      "         -3.3364e-19, -1.8773e-19,  2.3832e-19,  3.4337e-19,  5.0652e-19,\n",
      "         -4.2928e-19],\n",
      "        [-8.6771e-19, -1.3618e-18, -9.4102e-19,  2.6419e-18,  1.3298e-18,\n",
      "          1.8957e-18, -1.2918e-18, -8.5891e-19,  1.4492e-18, -2.3271e-18,\n",
      "          1.2873e-18,  5.9578e-19, -9.6268e-19, -1.1939e-18, -1.6130e-18,\n",
      "          1.4118e-18],\n",
      "        [-3.5501e-18, -5.7199e-18, -3.7989e-18,  1.0917e-17,  5.3583e-18,\n",
      "          7.8434e-18, -5.3544e-18, -3.4580e-18,  5.9441e-18, -9.6150e-18,\n",
      "          5.2280e-18,  2.4929e-18, -3.8847e-18, -4.9246e-18, -6.7479e-18,\n",
      "          5.8742e-18],\n",
      "        [-1.5009e-18, -2.5230e-18, -1.5702e-18,  4.6919e-18,  2.2075e-18,\n",
      "          3.3781e-18, -2.3127e-18, -1.4226e-18,  2.5241e-18, -4.1319e-18,\n",
      "          2.1834e-18,  1.0932e-18, -1.6045e-18, -2.1103e-18, -2.9579e-18,\n",
      "          2.5528e-18],\n",
      "        [ 1.7202e-18,  2.7748e-18,  1.8394e-18, -5.2919e-18, -2.5942e-18,\n",
      "         -3.8025e-18,  2.5959e-18,  1.6743e-18, -2.8804e-18,  4.6608e-18,\n",
      "         -2.5323e-18, -1.2095e-18,  1.8810e-18,  2.3870e-18,  3.2731e-18,\n",
      "         -2.8488e-18],\n",
      "        [-1.4561e-18, -2.2474e-18, -1.5925e-18,  4.4061e-18,  2.2533e-18,\n",
      "          3.1588e-18, -2.1503e-18, -1.4558e-18,  2.4282e-18, -3.8812e-18,\n",
      "          2.1702e-18,  9.8522e-19, -1.6295e-18, -1.9935e-18, -2.6685e-18,\n",
      "          2.3438e-18],\n",
      "        [-8.0140e-18, -1.2898e-17, -8.5782e-18,  2.4630e-17,  1.2099e-17,\n",
      "          1.7696e-17, -1.2079e-17, -7.8101e-18,  1.3414e-17, -2.1693e-17,\n",
      "          1.1803e-17,  5.6242e-18, -8.7727e-18, -1.1112e-17, -1.5219e-17,\n",
      "          1.3253e-17],\n",
      "        [ 1.9122e-18,  3.1291e-18,  2.0284e-18, -5.9137e-18, -2.8573e-18,\n",
      "         -4.2526e-18,  2.9060e-18,  1.8437e-18, -3.2055e-18,  5.2085e-18,\n",
      "         -2.8023e-18, -1.3618e-18,  2.0740e-18,  2.6652e-18,  3.6835e-18,\n",
      "         -3.1967e-18],\n",
      "        [ 3.7573e-18,  6.0599e-18,  4.0185e-18, -1.1558e-17, -5.6677e-18,\n",
      "         -8.3050e-18,  5.6698e-18,  3.6576e-18, -6.2918e-18,  1.0180e-17,\n",
      "         -5.5317e-18, -2.6409e-18,  4.1092e-18,  5.2137e-18,  7.1480e-18,\n",
      "         -6.2213e-18],\n",
      "        [ 9.4390e-19,  1.5573e-18,  9.9763e-19, -2.9291e-18, -1.4046e-18,\n",
      "         -2.1070e-18,  1.4407e-18,  9.0570e-19, -1.5843e-18,  2.5798e-18,\n",
      "         -1.3807e-18, -6.7632e-19,  1.0197e-18,  1.3192e-18,  1.8306e-18,\n",
      "         -1.5858e-18],\n",
      "        [-4.1395e-18, -6.7376e-18, -4.4058e-18,  1.2778e-17,  6.2094e-18,\n",
      "          9.1858e-18, -6.2750e-18, -4.0063e-18,  6.9377e-18, -1.1254e-17,\n",
      "          6.0780e-18,  2.9328e-18, -4.5047e-18, -5.7605e-18, -7.9368e-18,\n",
      "          6.8950e-18],\n",
      "        [-2.3739e-18, -3.8769e-18, -2.5213e-18,  7.3365e-18,  3.5523e-18,\n",
      "          5.2751e-18, -3.6043e-18, -2.2921e-18,  3.9791e-18, -6.4616e-18,\n",
      "          3.4813e-18,  1.6873e-18, -2.5779e-18, -3.3068e-18, -4.5650e-18,\n",
      "          3.9631e-18]]), 'exp_avg_sq': tensor([[0.3317, 0.4662, 0.6546, 1.7863, 1.3410, 1.0244, 0.3944, 0.4376, 0.7230,\n",
      "         0.9843, 0.6810, 0.6921, 0.5650, 0.2633, 1.3383, 1.1038],\n",
      "        [0.7559, 1.4943, 0.5815, 4.9085, 1.9717, 3.0712, 1.2364, 0.6747, 1.6391,\n",
      "         2.3249, 1.4183, 1.0803, 1.1952, 0.8582, 3.7639, 2.2346],\n",
      "        [0.4300, 1.1448, 0.2957, 2.6916, 0.7331, 1.5317, 0.8350, 0.3575, 0.8788,\n",
      "         1.3077, 0.5890, 0.4762, 0.5721, 0.4312, 1.8599, 1.0570],\n",
      "        [0.5492, 1.0733, 0.7224, 3.1493, 1.9135, 1.7178, 0.8324, 0.5332, 1.1342,\n",
      "         1.6828, 1.0335, 0.6954, 0.8694, 0.4996, 1.9825, 1.2534],\n",
      "        [0.7893, 2.1252, 1.3201, 6.9471, 3.3562, 2.8577, 2.3062, 0.6951, 1.8303,\n",
      "         4.3975, 1.7207, 1.3837, 1.1624, 0.7903, 2.0766, 1.4098],\n",
      "        [0.4521, 0.5510, 0.5117, 2.2577, 1.6323, 1.0201, 0.7321, 0.3711, 0.6167,\n",
      "         1.4565, 0.8517, 0.6314, 0.6306, 0.2995, 0.8159, 0.6576],\n",
      "        [0.2636, 0.7837, 0.3918, 2.2026, 0.9651, 1.0975, 0.5941, 0.2586, 0.6885,\n",
      "         1.2121, 0.5797, 0.1857, 0.4544, 0.3019, 0.9889, 0.5217],\n",
      "        [0.4345, 0.4486, 0.6817, 1.1984, 1.4626, 0.5702, 0.3904, 0.3101, 0.3606,\n",
      "         0.7261, 0.5896, 0.3938, 0.5365, 0.1621, 0.6086, 0.4799],\n",
      "        [0.8171, 0.5965, 1.3258, 2.2233, 3.8600, 0.9086, 1.0551, 0.6184, 0.7609,\n",
      "         1.7023, 1.3828, 1.9255, 0.8910, 0.2669, 1.4507, 1.6819],\n",
      "        [0.4765, 1.1092, 0.5605, 3.1353, 1.3208, 1.5201, 1.0345, 0.3747, 0.8756,\n",
      "         1.7423, 0.8306, 0.4162, 0.6885, 0.4188, 1.3350, 0.7115],\n",
      "        [0.4233, 1.5326, 0.7614, 3.2412, 1.5943, 1.4625, 1.1909, 0.3319, 0.9216,\n",
      "         1.7916, 0.7270, 0.2304, 0.5890, 0.3601, 1.2570, 0.5105],\n",
      "        [0.7279, 1.1316, 0.9461, 3.0807, 2.4824, 1.7012, 0.8015, 0.4333, 0.9586,\n",
      "         1.7031, 1.0261, 1.0137, 0.8084, 0.5833, 2.4093, 1.7254],\n",
      "        [0.5616, 0.4718, 0.6536, 2.1718, 2.0555, 1.0873, 0.5232, 0.5288, 0.7739,\n",
      "         1.3367, 1.0815, 0.6377, 0.8519, 0.3023, 0.9682, 0.8200],\n",
      "        [0.4604, 0.5626, 0.6364, 2.3235, 1.8292, 1.2970, 0.5802, 0.4723, 0.8404,\n",
      "         1.2924, 0.9713, 0.5776, 0.7685, 0.3846, 1.3842, 0.9911],\n",
      "        [0.4851, 0.7059, 0.6174, 1.9294, 1.6352, 1.0594, 0.5933, 0.3597, 0.6045,\n",
      "         1.0363, 0.7403, 0.5061, 0.6516, 0.3145, 1.2762, 0.8306],\n",
      "        [0.4658, 0.5631, 0.3869, 2.0148, 1.2872, 0.9621, 0.5188, 0.2482, 0.5213,\n",
      "         1.2343, 0.7116, 0.4214, 0.5215, 0.3125, 0.7931, 0.5828]])}, 66: {'step': tensor(3820.), 'exp_avg': tensor([2.3524e-19, 2.3435e-19, 2.4920e-19, 2.4081e-19, 5.9028e-19, 2.3715e-19,\n",
      "        2.3300e-19, 2.3076e-19, 2.5176e-19, 2.3029e-19]), 'exp_avg_sq': tensor([0.0046, 0.0015, 0.0013, 0.0039, 0.0118, 0.0142, 0.0127, 0.0083, 0.0179,\n",
      "        0.0056])}, 67: {'step': tensor(3820.), 'exp_avg': tensor([-1.3060e-18, -1.3041e-18, -1.3351e-18, -1.3170e-18, -3.1251e-18,\n",
      "        -1.3135e-18, -1.3006e-18, -1.2974e-18, -1.3436e-18, -1.2997e-18]), 'exp_avg_sq': tensor([0.2415, 0.2528, 0.2370, 0.2389, 0.3146, 0.3433, 0.2962, 0.2578, 0.2619,\n",
      "        0.2619])}, 68: {'step': tensor(3820.), 'exp_avg': tensor([-3.2925e-19, -4.7514e-19,  5.2323e-18, -4.5101e-18, -8.7191e-18,\n",
      "        -3.1646e-18, -4.7939e-18, -2.1774e-18, -1.7210e-18,  8.6168e-18,\n",
      "         2.8535e-18, -2.9974e-18, -2.5071e-18,  2.3960e-18,  6.8343e-18,\n",
      "         2.2475e-18, -4.3746e-18,  6.7231e-18, -2.8463e-19, -6.0917e-18,\n",
      "         2.1589e-19, -6.7505e-18,  1.1044e-17,  1.6543e-18, -9.2408e-18,\n",
      "         5.7752e-18,  9.5588e-18, -6.7669e-19,  9.9431e-18, -3.4166e-18,\n",
      "        -7.5140e-18, -3.3500e-18]), 'exp_avg_sq': tensor([0.8698, 0.2592, 0.4059, 1.0229, 0.6449, 0.7424, 0.4686, 1.0724, 0.9594,\n",
      "        1.4858, 2.0780, 0.3560, 0.4082, 0.3231, 0.6813, 0.3690, 0.8265, 0.3123,\n",
      "        0.3929, 0.3495, 0.3199, 0.4245, 0.4343, 0.5485, 0.8586, 0.6880, 0.3917,\n",
      "        0.6642, 0.4710, 0.4433, 0.3675, 0.4479])}, 69: {'step': tensor(3820.), 'exp_avg': tensor([[ 1.2471e-19, -4.6908e-19, -1.8955e-19, -3.9447e-19,  2.1206e-20,\n",
      "         -3.7897e-19, -2.9448e-20,  1.9010e-20,  8.9858e-19, -2.9435e-20,\n",
      "          4.1308e-19, -1.6596e-19,  5.7350e-19, -3.8496e-19, -2.0586e-19,\n",
      "          7.1128e-20],\n",
      "        [ 1.8711e-19, -6.7753e-19, -2.6466e-19, -5.6256e-19,  2.6584e-20,\n",
      "         -5.3272e-19, -4.3312e-20,  3.2532e-20,  1.2672e-18, -3.8160e-20,\n",
      "          5.8087e-19, -2.3068e-19,  8.1528e-19, -5.4539e-19, -2.8687e-19,\n",
      "          8.9672e-20],\n",
      "        [-2.2801e-18,  7.4825e-18,  2.6586e-18,  5.9973e-18, -1.5818e-19,\n",
      "          5.4348e-18,  4.9430e-19, -5.1763e-19, -1.3060e-17,  3.0074e-19,\n",
      "         -5.9424e-18,  2.2754e-18, -8.6163e-18,  5.7028e-18,  2.8441e-18,\n",
      "         -6.0637e-19],\n",
      "        [ 2.0314e-18, -6.4564e-18, -2.2136e-18, -5.1100e-18,  9.7179e-20,\n",
      "         -4.5553e-18, -4.3214e-19,  4.9384e-19,  1.0989e-17, -2.2222e-19,\n",
      "          4.9852e-18, -1.8815e-18,  7.3179e-18, -4.8244e-18, -2.3575e-18,\n",
      "          4.0685e-19],\n",
      "        [ 3.8284e-18, -1.2472e-17, -4.3961e-18, -9.9679e-18,  2.4650e-19,\n",
      "         -9.0001e-18, -8.2635e-19,  8.8336e-19,  2.1646e-17, -4.8497e-19,\n",
      "          9.8426e-18, -3.7569e-18,  1.4310e-17, -9.4633e-18, -4.6983e-18,\n",
      "          9.5985e-19],\n",
      "        [ 1.3895e-18, -4.5267e-18, -1.5956e-18, -3.6179e-18,  8.9548e-20,\n",
      "         -3.2667e-18, -2.9997e-19,  3.2060e-19,  7.8567e-18, -1.7600e-19,\n",
      "          3.5724e-18, -1.3636e-18,  5.1941e-18, -3.4348e-18, -1.7054e-18,\n",
      "          3.4839e-19],\n",
      "        [ 2.1290e-18, -6.8597e-18, -2.3890e-18, -5.4590e-18,  1.2107e-19,\n",
      "         -4.9014e-18, -4.5641e-19,  5.0308e-19,  1.1804e-17, -2.5343e-19,\n",
      "          5.3620e-18, -2.0367e-18,  7.8288e-18, -5.1700e-18, -2.5490e-18,\n",
      "          4.8591e-19],\n",
      "        [ 9.4272e-19, -3.1132e-18, -1.1134e-18, -2.5012e-18,  6.9649e-20,\n",
      "         -2.2737e-18, -2.0525e-19,  2.1093e-19,  5.4598e-18, -1.2841e-19,\n",
      "          2.4855e-18, -9.5428e-19,  3.5956e-18, -2.3816e-18, -1.1924e-18,\n",
      "          2.6290e-19],\n",
      "        [ 7.3269e-19, -2.4593e-18, -8.9536e-19, -1.9883e-18,  6.1788e-20,\n",
      "         -1.8214e-18, -1.6066e-19,  1.5786e-19,  4.3659e-18, -1.0903e-19,\n",
      "          1.9907e-18, -7.6948e-19,  2.8628e-18, -1.8997e-18, -9.5983e-19,\n",
      "          2.3027e-19],\n",
      "        [-3.7841e-18,  1.2326e-17,  4.3442e-18,  9.8506e-18, -2.4303e-19,\n",
      "          8.8934e-18,  8.1656e-19, -8.7351e-19, -2.1390e-17,  4.7921e-19,\n",
      "         -9.7262e-18,  3.7122e-18, -1.4142e-17,  9.3516e-18,  4.6423e-18,\n",
      "         -9.4788e-19],\n",
      "        [-1.2765e-18,  4.0842e-18,  1.4104e-18,  3.2409e-18, -6.7310e-20,\n",
      "          2.8995e-18,  2.7302e-19, -3.0600e-19, -6.9888e-18,  1.4500e-19,\n",
      "         -3.1721e-18,  1.2009e-18, -4.6444e-18,  3.0645e-18,  1.5044e-18,\n",
      "         -2.7222e-19],\n",
      "        [ 1.2976e-18, -4.2854e-18, -1.5338e-18, -3.4435e-18,  9.4969e-20,\n",
      "         -3.1301e-18, -2.8188e-19,  2.9046e-19,  7.5164e-18, -1.7771e-19,\n",
      "          3.4223e-18, -1.3141e-18,  4.9504e-18, -3.2788e-18, -1.6411e-18,\n",
      "          3.6314e-19],\n",
      "        [ 1.1264e-18, -3.5888e-18, -1.2343e-18, -2.8433e-18,  5.5388e-20,\n",
      "         -2.5378e-18, -2.3973e-19,  2.7253e-19,  6.1205e-18, -1.2547e-19,\n",
      "          2.7774e-18, -1.0495e-18,  4.0730e-18, -2.6859e-18, -1.3145e-18,\n",
      "          2.3160e-19],\n",
      "        [-1.0547e-18,  3.4274e-18,  1.2054e-18,  2.7369e-18, -6.5646e-20,\n",
      "          2.4679e-18,  2.2698e-19, -2.4478e-19, -5.9375e-18,  1.3224e-19,\n",
      "         -2.6995e-18,  1.0293e-18, -3.9284e-18,  2.5969e-18,  1.2871e-18,\n",
      "         -2.5965e-19],\n",
      "        [-3.0004e-18,  9.7755e-18,  3.4468e-18,  7.8136e-18, -1.9297e-19,\n",
      "          7.0553e-18,  6.4733e-19, -6.9217e-19, -1.6969e-17,  3.8083e-19,\n",
      "         -7.7160e-18,  2.9454e-18, -1.1218e-17,  7.4182e-18,  3.6831e-18,\n",
      "         -7.5367e-19],\n",
      "        [-1.0212e-18,  3.2183e-18,  1.0925e-18,  2.5384e-18, -4.3230e-20,\n",
      "          2.2526e-18,  2.1621e-19, -2.5250e-19, -5.4401e-18,  1.0570e-19,\n",
      "         -2.4658e-18,  9.2681e-19, -3.6320e-18,  2.3919e-18,  1.1622e-18,\n",
      "         -1.8710e-19],\n",
      "        [ 1.9202e-18, -6.2575e-18, -2.2068e-18, -5.0020e-18,  1.2384e-19,\n",
      "         -4.5171e-18, -4.1439e-19,  4.4279e-19,  1.0864e-17, -2.4398e-19,\n",
      "          4.9401e-18, -1.8859e-18,  7.1816e-18, -4.7492e-18, -2.3582e-18,\n",
      "          4.8311e-19],\n",
      "        [-3.0033e-18,  9.6220e-18,  3.3289e-18,  7.6398e-18, -1.5995e-19,\n",
      "          6.8394e-18,  6.4209e-19, -7.1809e-19, -1.6483e-17,  3.4498e-19,\n",
      "         -7.4829e-18,  2.8348e-18, -1.0950e-17,  7.2261e-18,  3.5500e-18,\n",
      "         -6.4992e-19],\n",
      "        [ 1.5480e-19, -4.1029e-19, -1.0813e-19, -2.9860e-19, -9.3948e-21,\n",
      "         -2.3553e-19, -2.9879e-20,  5.0315e-20,  5.8583e-19,  1.0359e-21,\n",
      "          2.5951e-19, -8.6576e-20,  4.1802e-19, -2.6784e-19, -1.1114e-19,\n",
      "         -2.1120e-20],\n",
      "        [ 2.7366e-18, -8.7200e-18, -2.9980e-18, -6.9086e-18,  1.3616e-19,\n",
      "         -6.1673e-18, -5.8339e-19,  6.6165e-19,  1.4873e-17, -3.0380e-19,\n",
      "          6.7485e-18, -2.5500e-18,  9.8962e-18, -6.5264e-18, -3.1950e-18,\n",
      "          5.6184e-19],\n",
      "        [-1.0597e-19,  3.0992e-19,  9.5639e-20,  2.3672e-19,  5.6019e-22,\n",
      "          2.0092e-19,  2.1468e-20, -2.9940e-20, -4.9049e-19,  5.7589e-21,\n",
      "         -2.2050e-19,  7.9503e-20, -3.3583e-19,  2.1885e-19,  1.0039e-19,\n",
      "         -4.1680e-21],\n",
      "        [ 2.9871e-18, -9.6582e-18, -3.3765e-18, -7.6966e-18,  1.7697e-19,\n",
      "         -6.9229e-18, -6.4175e-19,  7.0058e-19,  1.6665e-17, -3.6273e-19,\n",
      "          7.5726e-18, -2.8809e-18,  1.1041e-17, -7.2948e-18, -3.6046e-18,\n",
      "          7.0291e-19],\n",
      "        [-4.8856e-18,  1.5801e-17,  5.5255e-18,  1.2593e-17, -2.9081e-19,\n",
      "          1.1329e-17,  1.0501e-18, -1.1451e-18, -2.7271e-17,  5.9389e-19,\n",
      "         -1.2392e-17,  4.7148e-18, -1.8067e-17,  1.1937e-17,  5.8997e-18,\n",
      "         -1.1521e-18],\n",
      "        [-7.5596e-19,  2.3695e-18,  7.9845e-19,  1.8645e-18, -3.0010e-20,\n",
      "          1.6498e-18,  1.6003e-19, -1.8881e-19, -3.9872e-18,  7.4796e-20,\n",
      "         -1.8058e-18,  6.7686e-19, -2.6661e-18,  1.7546e-18,  8.4977e-19,\n",
      "         -1.2950e-19],\n",
      "        [ 4.0626e-18, -1.3219e-17, -4.6530e-18, -1.0560e-17,  2.5850e-19,\n",
      "         -9.5288e-18, -8.7643e-19,  9.3984e-19,  2.2921e-17, -5.1094e-19,\n",
      "          1.0421e-17, -3.9755e-18,  1.5158e-17, -1.0023e-17, -4.9724e-18,\n",
      "          1.0082e-18],\n",
      "        [-2.5285e-18,  8.2600e-18,  2.9207e-18,  6.6089e-18, -1.6730e-19,\n",
      "          5.9755e-18,  5.4648e-19, -5.7992e-19, -1.4367e-17,  3.2554e-19,\n",
      "         -6.5345e-18,  2.4973e-18, -9.4908e-18,  6.2782e-18,  3.1222e-18,\n",
      "         -6.4881e-19],\n",
      "        [-4.2343e-18,  1.3677e-17,  4.7760e-18,  1.0895e-17, -2.4780e-19,\n",
      "          9.7940e-18,  9.0909e-19, -9.9538e-19, -2.3580e-17,  5.1123e-19,\n",
      "         -1.0714e-17,  4.0739e-18, -1.5628e-17,  1.0323e-17,  5.0978e-18,\n",
      "         -9.8756e-19],\n",
      "        [ 3.3844e-19, -9.7219e-19, -2.9213e-19, -7.3634e-19, -5.1306e-21,\n",
      "         -6.1759e-19, -6.8094e-20,  9.8333e-20,  1.5122e-18, -1.4281e-20,\n",
      "          6.7809e-19, -2.4154e-19,  1.0423e-18, -6.7738e-19, -3.0597e-19,\n",
      "          1.7953e-21],\n",
      "        [-4.4019e-18,  1.4226e-17,  4.9712e-18,  1.1335e-17, -2.5928e-19,\n",
      "          1.0193e-17,  9.4535e-19, -1.0334e-18, -2.4539e-17,  5.3329e-19,\n",
      "         -1.1150e-17,  4.2409e-18, -1.6260e-17,  1.0742e-17,  5.3064e-18,\n",
      "         -1.0319e-18],\n",
      "        [ 1.5462e-18, -4.8918e-18, -1.6683e-18, -3.8645e-18,  6.9344e-20,\n",
      "         -3.4367e-18, -3.2805e-19,  3.7932e-19,  8.2955e-18, -1.6426e-19,\n",
      "          3.7615e-18, -1.4166e-18,  5.5317e-18, -3.6448e-18, -1.7757e-18,\n",
      "          2.9547e-19],\n",
      "        [ 3.2964e-18, -1.0748e-17, -3.7923e-18, -8.5929e-18,  2.1396e-19,\n",
      "         -7.7620e-18, -7.1172e-19,  7.5920e-19,  1.8667e-17, -4.1981e-19,\n",
      "          8.4885e-18, -3.2413e-18,  1.2338e-17, -8.1595e-18, -4.0531e-18,\n",
      "          8.3263e-19],\n",
      "        [ 1.5009e-18, -4.7949e-18, -1.6538e-18, -3.8028e-18,  7.6845e-20,\n",
      "         -3.3993e-18, -3.2017e-19,  3.6103e-19,  8.1951e-18, -1.6963e-19,\n",
      "          3.7196e-18, -1.4073e-18,  5.4488e-18, -3.5946e-18, -1.7625e-18,\n",
      "          3.1636e-19]]), 'exp_avg_sq': tensor([[ 0.8922,  1.5412,  0.3717,  0.5545,  0.2650,  0.3863,  0.0794,  0.1941,\n",
      "          2.0849,  0.4138,  0.3914,  0.1636,  0.5190,  0.3648,  0.2819,  2.4819],\n",
      "        [ 0.4099,  1.0658,  0.3056,  0.5974,  0.1419,  1.1320,  0.0847,  0.1026,\n",
      "          5.8677,  0.3218,  0.8112,  0.1328,  1.1685,  0.6606,  0.5056,  0.7020],\n",
      "        [ 0.3617,  0.9800,  0.2710,  0.5702,  0.0749,  0.6739,  0.0621,  0.0500,\n",
      "          3.6109,  0.2009,  0.6758,  0.0964,  1.0087,  0.3983,  0.2702,  0.4541],\n",
      "        [ 0.6583,  1.0239,  0.4371,  0.4008,  0.1332,  0.5948,  0.0562,  0.1141,\n",
      "          2.4823,  0.2433,  0.4974,  0.1680,  0.6380,  0.6547,  0.3299,  1.2225],\n",
      "        [ 0.6863,  1.6078,  0.5148,  0.8563,  0.3513,  1.5018,  0.1702,  0.2047,\n",
      "          7.6182,  0.5784,  1.0854,  0.1701,  1.5924,  1.0273,  0.6371,  1.4121],\n",
      "        [ 0.9033,  1.9746,  0.4059,  0.9403,  0.3138,  0.9506,  0.1390,  0.1465,\n",
      "          5.2990,  0.3679,  0.8299,  0.1486,  1.3821,  0.9823,  0.5017,  1.5682],\n",
      "        [ 0.6282,  1.3252,  0.2900,  0.5034,  0.3306,  0.3880,  0.1380,  0.1755,\n",
      "          2.0064,  0.4126,  0.5526,  0.1465,  0.6460,  0.3155,  0.2373,  1.2511],\n",
      "        [ 1.0110,  1.8635,  0.4854,  0.9987,  0.2719,  0.8313,  0.0729,  0.1086,\n",
      "          4.0418,  0.2739,  0.7213,  0.2432,  1.1227,  0.5629,  0.4653,  2.0822],\n",
      "        [ 0.6480,  1.3897,  0.3045,  0.7796,  0.1838,  1.0526,  0.1023,  0.1012,\n",
      "          5.4953,  0.3610,  0.7863,  0.1522,  1.1692,  0.5500,  0.4359,  1.1286],\n",
      "        [ 1.2665,  2.4175,  0.4092,  0.8586,  0.2351,  0.7492,  0.0670,  0.1967,\n",
      "          3.8650,  0.3457,  0.5931,  0.2446,  1.0081,  0.4629,  0.4815,  2.7185],\n",
      "        [ 2.0382,  3.6080,  1.0254,  1.8065,  0.3585,  2.0307,  0.1632,  0.3215,\n",
      "         10.7947,  0.7484,  1.5076,  0.4550,  2.4271,  2.2671,  1.1148,  4.3814],\n",
      "        [ 0.3122,  0.6747,  0.1434,  0.2552,  0.1010,  0.2776,  0.0339,  0.0648,\n",
      "          1.3527,  0.1258,  0.2811,  0.0806,  0.4250,  0.1940,  0.1619,  0.6565],\n",
      "        [ 0.6347,  1.2339,  0.3249,  0.5013,  0.3110,  0.5135,  0.1590,  0.1476,\n",
      "          2.3616,  0.3798,  0.5592,  0.1582,  0.6167,  0.3965,  0.2866,  1.0887],\n",
      "        [ 0.3252,  0.6647,  0.2174,  0.3492,  0.1643,  0.5356,  0.0888,  0.0915,\n",
      "          2.4302,  0.2607,  0.4764,  0.1112,  0.6030,  0.3775,  0.2443,  0.5032],\n",
      "        [ 0.8158,  1.5355,  0.6457,  0.6345,  0.8048,  1.1474,  0.3354,  0.3380,\n",
      "          4.8701,  0.9198,  1.0848,  0.1866,  1.1174,  0.7336,  0.5177,  1.8502],\n",
      "        [ 0.2584,  0.5786,  0.2963,  0.2960,  0.0452,  0.5545,  0.0275,  0.0530,\n",
      "          2.3555,  0.1967,  0.5672,  0.1311,  0.7504,  0.3271,  0.2481,  0.5101],\n",
      "        [ 0.7231,  1.4478,  0.2447,  0.6645,  0.2102,  0.3088,  0.0748,  0.1263,\n",
      "          1.5870,  0.2416,  0.3413,  0.1419,  0.5886,  0.3640,  0.1985,  1.3198],\n",
      "        [ 0.2517,  0.7089,  0.1641,  0.3370,  0.0582,  0.4548,  0.0276,  0.0621,\n",
      "          2.2867,  0.1390,  0.4062,  0.0887,  0.6587,  0.2976,  0.2049,  0.4589],\n",
      "        [ 0.4125,  0.8693,  0.2609,  0.3969,  0.2820,  0.4668,  0.1257,  0.1517,\n",
      "          2.2561,  0.3630,  0.4937,  0.0810,  0.5822,  0.3199,  0.1720,  0.8717],\n",
      "        [ 0.3111,  0.6717,  0.3605,  0.3806,  0.1380,  0.8287,  0.0699,  0.1054,\n",
      "          4.1096,  0.2974,  0.6179,  0.0863,  0.8590,  0.7739,  0.3802,  0.7062],\n",
      "        [ 0.8388,  1.9740,  0.3556,  1.0564,  0.2368,  0.9559,  0.1596,  0.1287,\n",
      "          5.2907,  0.4149,  0.9479,  0.1864,  1.3554,  0.5731,  0.4519,  1.0532],\n",
      "        [ 0.4259,  0.7149,  0.3258,  0.3472,  0.2566,  0.5256,  0.1159,  0.1100,\n",
      "          2.3289,  0.3216,  0.4917,  0.1102,  0.5016,  0.4642,  0.2604,  0.8205],\n",
      "        [ 0.5084,  1.1491,  0.2194,  0.5657,  0.0899,  0.3720,  0.0573,  0.0666,\n",
      "          2.0394,  0.1567,  0.4460,  0.1076,  0.6809,  0.2886,  0.1826,  0.7251],\n",
      "        [ 0.4838,  1.1736,  0.4912,  0.6144,  0.1895,  1.6233,  0.1311,  0.1390,\n",
      "          8.2035,  0.4324,  1.0821,  0.1643,  1.4098,  0.9299,  0.7191,  0.7469],\n",
      "        [ 0.8820,  1.7954,  0.4463,  0.8422,  0.3101,  0.9911,  0.1641,  0.1278,\n",
      "          4.5893,  0.4151,  0.9446,  0.2437,  1.3039,  0.6343,  0.5201,  1.2449],\n",
      "        [ 0.5039,  0.9869,  0.2401,  0.4195,  0.2602,  0.3899,  0.0846,  0.0938,\n",
      "          1.9290,  0.2640,  0.3890,  0.1216,  0.5401,  0.2978,  0.2360,  1.0907],\n",
      "        [ 0.4545,  0.8713,  0.2897,  0.3220,  0.2282,  0.5002,  0.0853,  0.1323,\n",
      "          2.1336,  0.2890,  0.4910,  0.1279,  0.6133,  0.3398,  0.2541,  1.0537],\n",
      "        [ 0.6298,  1.5465,  0.2719,  0.8103,  0.1576,  0.8994,  0.1123,  0.0866,\n",
      "          4.9465,  0.3064,  0.7745,  0.1370,  1.1053,  0.4572,  0.4244,  0.6734],\n",
      "        [ 0.5500,  1.2212,  0.6040,  0.6078,  0.5785,  1.3548,  0.2638,  0.3359,\n",
      "          6.3092,  0.8939,  1.1789,  0.1528,  1.3159,  0.7689,  0.4449,  1.5325],\n",
      "        [ 0.9488,  1.8964,  0.3584,  1.1625,  0.3967,  0.9143,  0.1960,  0.1479,\n",
      "          4.5076,  0.4911,  0.8138,  0.2393,  1.1617,  0.6341,  0.4292,  1.4403],\n",
      "        [ 0.2905,  0.6741,  0.3243,  0.3401,  0.4569,  0.7034,  0.1728,  0.2299,\n",
      "          3.1311,  0.6623,  0.6949,  0.1034,  0.8343,  0.5455,  0.2743,  1.0969],\n",
      "        [ 0.5083,  0.9669,  0.2919,  0.5001,  0.1571,  0.4022,  0.0638,  0.1032,\n",
      "          1.9526,  0.2397,  0.3730,  0.1157,  0.5354,  0.4466,  0.2044,  1.1054]])}, 70: {'step': tensor(3820.), 'exp_avg': tensor([3.4686e-20, 3.9850e-20, 4.8108e-20, 3.9990e-20, 6.0790e-20, 5.4451e-20,\n",
      "        3.1548e-20, 3.0382e-20, 7.2235e-20, 3.0134e-20]), 'exp_avg_sq': tensor([3.1031, 3.0264, 3.0692, 3.1033, 2.9567, 2.9525, 3.1234, 3.1165, 2.9266,\n",
      "        3.1066])}, 71: {'step': tensor(3820.), 'exp_avg': tensor([-4.9135e-18, -4.9135e-18, -4.9135e-18, -4.9135e-18, -4.9135e-18,\n",
      "        -4.9135e-18, -4.9135e-18, -4.9135e-18, -4.9135e-18, -4.9135e-18]), 'exp_avg_sq': tensor([0.1616, 0.1616, 0.1616, 0.1616, 0.1616, 0.1616, 0.1616, 0.1616, 0.1616,\n",
      "        0.1616])}, 72: {'step': tensor(3820.), 'exp_avg': tensor([[ 5.6052e-45, -5.6052e-45, -5.6052e-45,  ..., -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45,  5.6052e-45,  ..., -5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45],\n",
      "        [ 8.2906e-20, -8.3318e-21, -1.3558e-20,  ..., -4.0732e-20,\n",
      "          1.6865e-20, -2.6949e-20],\n",
      "        ...,\n",
      "        [ 8.7164e-17, -8.2927e-18, -1.3957e-17,  ..., -4.3646e-17,\n",
      "          1.9120e-17, -2.9034e-17],\n",
      "        [ 5.6052e-45, -5.6052e-45,  5.6052e-45,  ..., -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45, -5.6052e-45,  ..., -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45]]), 'exp_avg_sq': tensor([[7.0022e-01, 5.3823e-02, 5.7951e-02,  ..., 1.1084e-01, 2.1863e-01,\n",
      "         6.1785e-02],\n",
      "        [6.3196e+00, 1.7341e-01, 7.6307e-01,  ..., 1.8283e+00, 1.6642e+00,\n",
      "         1.4988e+00],\n",
      "        [6.5762e+00, 2.3861e-01, 8.1118e-01,  ..., 3.3723e+00, 2.0321e+00,\n",
      "         1.5865e+00],\n",
      "        ...,\n",
      "        [1.9279e+00, 2.3375e-02, 4.7966e-01,  ..., 1.4479e+00, 1.0572e+00,\n",
      "         2.8076e-01],\n",
      "        [1.5379e+00, 1.2562e-01, 3.1300e-01,  ..., 3.7731e-01, 8.0978e-01,\n",
      "         5.5486e-01],\n",
      "        [8.3291e-01, 5.5430e-03, 9.4226e-02,  ..., 1.2855e-01, 6.6398e-02,\n",
      "         1.2040e-01]])}, 73: {'step': tensor(3820.), 'exp_avg': tensor([ 5.6052e-45,  5.6052e-45,  4.0737e-21,  5.6052e-45,  9.5960e-35,\n",
      "         7.1063e-36,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  2.5199e-34,  5.6052e-45,  5.6052e-45,\n",
      "         5.4857e-31,  1.3284e-41,  5.6052e-45,  5.6052e-45,  7.0065e-45,\n",
      "         1.1101e-20,  5.6052e-45,  1.8217e-44,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         6.9606e-34,  2.9427e-44,  5.6052e-45,  3.1611e-23,  6.1657e-44,\n",
      "         5.6052e-45,  5.6052e-45,  1.6197e-33,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45,  1.2612e-44,  5.6052e-45,\n",
      "         5.6052e-45,  3.2722e-18,  5.6052e-45,  1.7690e-20,  5.6052e-45,\n",
      "         3.5651e-33,  5.6052e-45,  4.8359e-32,  5.6052e-45,  5.6052e-45,\n",
      "         1.4013e-44,  5.6052e-45,  6.0632e-40,  5.6052e-45,  5.6052e-45,\n",
      "         2.6662e-34,  4.3148e-18,  5.6052e-45,  5.6052e-45]), 'exp_avg_sq': tensor([1.2797e-03, 2.5815e-02, 2.9235e-02, 1.1689e-02, 3.2382e-03, 1.6776e-02,\n",
      "        9.9248e-04, 1.7504e-03, 6.5612e-04, 1.0435e-02, 1.1179e-03, 4.4961e-04,\n",
      "        5.1170e-04, 9.8027e-04, 1.7394e-03, 3.5674e-03, 2.5858e-03, 2.7669e-03,\n",
      "        1.0486e-03, 3.8352e-03, 2.2537e-03, 1.6981e-03, 3.5142e-04, 2.7582e-03,\n",
      "        4.9025e-04, 6.7623e-04, 2.3963e-02, 1.6171e-02, 2.7345e-03, 8.8751e-03,\n",
      "        1.6575e-02, 6.5168e-03, 1.1729e-03, 2.1161e-02, 2.3388e-02, 8.7486e-04,\n",
      "        1.0692e-03, 5.7504e-03, 4.9416e-03, 1.3131e-03, 1.6384e-03, 1.6564e-03,\n",
      "        3.8129e-02, 4.0943e-03, 1.1782e-02, 8.0578e-03, 3.0307e-02, 7.5701e-03,\n",
      "        2.6532e-03, 1.7998e-05, 1.7773e-03, 1.5655e-03, 1.8009e-03, 3.2968e-03,\n",
      "        1.7777e-03, 2.2284e-04, 1.2113e-03, 1.5474e-03, 1.1920e-03, 1.4500e-02,\n",
      "        5.2814e-03, 5.9126e-03, 7.3738e-03, 2.2238e-03])}}\n",
      "param_groups \t [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]}]\n"
     ]
    }
   ],
   "source": [
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'{model_name}_state_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, model_name+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2.704826593399048,\n",
       "  5.198240756988525,\n",
       "  13.315263748168945,\n",
       "  2.823438882827759,\n",
       "  3.2965333461761475,\n",
       "  16.09800910949707,\n",
       "  9.872518539428711,\n",
       "  1.0003350973129272,\n",
       "  0.7661793828010559,\n",
       "  6.772861480712891,\n",
       "  5.174842834472656,\n",
       "  9.828278541564941,\n",
       "  15.874943733215332,\n",
       "  53.55030059814453,\n",
       "  1.0800198316574097,\n",
       "  10.528260231018066,\n",
       "  53.853294372558594,\n",
       "  4.662607669830322,\n",
       "  4.270350933074951,\n",
       "  0.867901086807251,\n",
       "  1.5554147958755493,\n",
       "  2.229698896408081,\n",
       "  2.005354166030884,\n",
       "  3.3499433994293213,\n",
       "  15.229602813720703,\n",
       "  14.188955307006836,\n",
       "  16.699132919311523,\n",
       "  22.360225677490234,\n",
       "  22.466737747192383,\n",
       "  31.5380802154541,\n",
       "  1.7847511768341064,\n",
       "  2.5743556022644043,\n",
       "  53.521114349365234,\n",
       "  2.719676971435547,\n",
       "  2.6633896827697754,\n",
       "  18.13672637939453,\n",
       "  3.7198853492736816,\n",
       "  0.4871591627597809,\n",
       "  8.857869148254395,\n",
       "  45.62668991088867,\n",
       "  3.154035806655884,\n",
       "  4.935939311981201,\n",
       "  5.192224979400635,\n",
       "  9.803498268127441,\n",
       "  17.924827575683594,\n",
       "  9.848934173583984,\n",
       "  3.585824489593506,\n",
       "  86.6318130493164,\n",
       "  17.3171443939209,\n",
       "  2.581406354904175,\n",
       "  2.7631795406341553,\n",
       "  16.747119903564453,\n",
       "  3.547388792037964,\n",
       "  0.8788779377937317,\n",
       "  0.5995727181434631,\n",
       "  5.787005424499512,\n",
       "  2.118100166320801,\n",
       "  1.919079065322876,\n",
       "  11.341294288635254,\n",
       "  2.263032913208008,\n",
       "  0.6949743628501892,\n",
       "  4.012384414672852,\n",
       "  0.35861092805862427,\n",
       "  0.8392153978347778,\n",
       "  1.9523204565048218,\n",
       "  1.5161124467849731,\n",
       "  22.870882034301758,\n",
       "  9.66711711883545,\n",
       "  0.4888782203197479,\n",
       "  5.462646484375,\n",
       "  6.092201232910156,\n",
       "  1.016375184059143,\n",
       "  5.394891738891602,\n",
       "  0.7768035531044006,\n",
       "  17.16086196899414,\n",
       "  0.9088374376296997,\n",
       "  1.3090628385543823,\n",
       "  4.259058475494385,\n",
       "  0.8640763759613037,\n",
       "  1.96882963180542,\n",
       "  2.9054343700408936,\n",
       "  10.186197280883789,\n",
       "  8.666426658630371,\n",
       "  2.021890640258789,\n",
       "  37.51947021484375,\n",
       "  15.764997482299805,\n",
       "  2.097499132156372,\n",
       "  6.830977916717529,\n",
       "  3.6878957748413086,\n",
       "  19.14760971069336,\n",
       "  1.3249049186706543,\n",
       "  4.118762016296387,\n",
       "  7.989927768707275,\n",
       "  10.915167808532715,\n",
       "  29.659832000732422,\n",
       "  35.79417419433594,\n",
       "  16.774860382080078,\n",
       "  1.543757438659668,\n",
       "  110.32952880859375,\n",
       "  12.100777626037598,\n",
       "  0.5776466727256775,\n",
       "  10.142349243164062,\n",
       "  3.035236358642578,\n",
       "  13.713397979736328,\n",
       "  3.816195487976074,\n",
       "  9.482223510742188,\n",
       "  3.255971908569336,\n",
       "  24.57541275024414,\n",
       "  10.109694480895996,\n",
       "  12.866683959960938,\n",
       "  11.060444831848145,\n",
       "  20.535160064697266,\n",
       "  5.805521488189697,\n",
       "  9.43932056427002,\n",
       "  10.969657897949219,\n",
       "  14.198473930358887,\n",
       "  5.688391208648682,\n",
       "  20.013891220092773,\n",
       "  8.729480743408203,\n",
       "  1.674066185951233,\n",
       "  36.130615234375,\n",
       "  6.818122863769531,\n",
       "  3.175856351852417,\n",
       "  22.70490074157715,\n",
       "  5.9099812507629395,\n",
       "  0.4547455608844757,\n",
       "  1.45606529712677,\n",
       "  25.354225158691406,\n",
       "  9.80893325805664,\n",
       "  18.04686164855957,\n",
       "  8.206413269042969,\n",
       "  13.117918014526367,\n",
       "  20.550674438476562,\n",
       "  13.554835319519043,\n",
       "  1.045912265777588,\n",
       "  45.946327209472656,\n",
       "  0.7859334349632263,\n",
       "  42.173946380615234,\n",
       "  7.0339250564575195,\n",
       "  11.827227592468262,\n",
       "  4.80800724029541,\n",
       "  4.400030612945557,\n",
       "  3.5169429779052734,\n",
       "  42.460262298583984,\n",
       "  2.992161750793457,\n",
       "  61.76719665527344,\n",
       "  13.275609970092773,\n",
       "  41.199893951416016,\n",
       "  1.9388231039047241,\n",
       "  1.7367182970046997,\n",
       "  5.621242523193359,\n",
       "  7.279980659484863,\n",
       "  5.48419189453125,\n",
       "  49.14460372924805,\n",
       "  4.1668596267700195,\n",
       "  21.214513778686523,\n",
       "  3.4210243225097656,\n",
       "  24.54138946533203,\n",
       "  1.8284838199615479,\n",
       "  13.43665599822998,\n",
       "  1.6863292455673218,\n",
       "  0.40624549984931946,\n",
       "  16.733816146850586,\n",
       "  2.2687463760375977,\n",
       "  1.8972417116165161,\n",
       "  25.289302825927734,\n",
       "  4.335816860198975,\n",
       "  0.8518805503845215,\n",
       "  2.106466054916382,\n",
       "  1.0783138275146484,\n",
       "  1.1433900594711304,\n",
       "  18.154211044311523,\n",
       "  14.370222091674805,\n",
       "  6.093416213989258,\n",
       "  45.29472351074219,\n",
       "  0.9568530917167664,\n",
       "  5.3788676261901855,\n",
       "  5.844310283660889,\n",
       "  3.7407867908477783,\n",
       "  1.1640912294387817,\n",
       "  5.3128886222839355,\n",
       "  0.44115859270095825,\n",
       "  8.20824909210205,\n",
       "  4.9891581535339355,\n",
       "  2.888672113418579,\n",
       "  4.037245273590088,\n",
       "  0.322966068983078,\n",
       "  0.23082919418811798,\n",
       "  4.936459541320801,\n",
       "  39.93437957763672,\n",
       "  0.22667832672595978,\n",
       "  29.57611083984375,\n",
       "  62.06330108642578,\n",
       "  8.148748397827148],\n",
       " [27.181671142578125,\n",
       "  46.7053108215332,\n",
       "  0.5775931477546692,\n",
       "  18.145309448242188,\n",
       "  19.823272705078125,\n",
       "  1.222131609916687,\n",
       "  1.5900646448135376,\n",
       "  1.0873397588729858,\n",
       "  0.6155239343643188,\n",
       "  25.250816345214844,\n",
       "  0.21160487830638885,\n",
       "  23.210893630981445,\n",
       "  3.53255558013916,\n",
       "  0.49781733751296997,\n",
       "  6.42727518081665,\n",
       "  1.8676376342773438,\n",
       "  5.443838596343994,\n",
       "  35.25676727294922,\n",
       "  0.8407770991325378,\n",
       "  36.5833625793457,\n",
       "  1.2122560739517212,\n",
       "  25.440689086914062,\n",
       "  55.801753997802734,\n",
       "  3.1841704845428467,\n",
       "  1.1490204334259033,\n",
       "  1.726120114326477,\n",
       "  0.6069270968437195,\n",
       "  0.8175901174545288,\n",
       "  0.3303978741168976,\n",
       "  5.444737911224365,\n",
       "  0.7473751902580261,\n",
       "  20.440824508666992,\n",
       "  2.3824214935302734,\n",
       "  2.538160562515259,\n",
       "  1.1115511655807495,\n",
       "  2.5566086769104004,\n",
       "  4.197916507720947,\n",
       "  8.023086547851562,\n",
       "  2.8924777507781982,\n",
       "  25.886518478393555,\n",
       "  9.207832336425781,\n",
       "  3.2628908157348633,\n",
       "  4.177851676940918,\n",
       "  0.26979491114616394,\n",
       "  32.592506408691406,\n",
       "  5.443792343139648,\n",
       "  20.047550201416016,\n",
       "  1.6963348388671875,\n",
       "  1.475588083267212,\n",
       "  0.7018646001815796,\n",
       "  25.359506607055664,\n",
       "  29.34391975402832,\n",
       "  2.70133113861084,\n",
       "  0.5495991706848145,\n",
       "  12.431327819824219,\n",
       "  48.082149505615234,\n",
       "  0.529217541217804,\n",
       "  0.9486518502235413,\n",
       "  0.1961567997932434,\n",
       "  0.8649198412895203,\n",
       "  7.758583068847656,\n",
       "  3.615036725997925,\n",
       "  4.44827938079834,\n",
       "  9.91455078125,\n",
       "  9.520406723022461,\n",
       "  30.620840072631836,\n",
       "  32.2344856262207,\n",
       "  0.5394095778465271,\n",
       "  1.0339170694351196,\n",
       "  53.23109817504883,\n",
       "  9.778298377990723,\n",
       "  12.965744018554688,\n",
       "  12.68330192565918,\n",
       "  8.50987434387207,\n",
       "  0.4265194833278656,\n",
       "  24.38487434387207,\n",
       "  0.7621620297431946,\n",
       "  36.87624740600586,\n",
       "  0.7346929907798767,\n",
       "  5.7444353103637695,\n",
       "  16.96875,\n",
       "  4.063361167907715,\n",
       "  0.3896864354610443,\n",
       "  14.440710067749023,\n",
       "  2.7547202110290527,\n",
       "  0.3997734785079956,\n",
       "  6.123706817626953,\n",
       "  1.8189308643341064,\n",
       "  21.993806838989258,\n",
       "  5.953886032104492,\n",
       "  11.222068786621094,\n",
       "  0.7353714108467102,\n",
       "  0.11078941076993942,\n",
       "  15.505916595458984,\n",
       "  20.05398178100586,\n",
       "  58.98081588745117,\n",
       "  13.300873756408691,\n",
       "  29.598037719726562,\n",
       "  6.715970039367676,\n",
       "  3.714550018310547,\n",
       "  3.7526729106903076,\n",
       "  1.6419223546981812,\n",
       "  52.779850006103516,\n",
       "  0.3401187062263489,\n",
       "  7.360928058624268,\n",
       "  28.85964012145996,\n",
       "  6.290478229522705,\n",
       "  37.85420227050781,\n",
       "  9.8411865234375,\n",
       "  11.932409286499023,\n",
       "  0.6800362467765808,\n",
       "  49.429298400878906,\n",
       "  1.2473052740097046,\n",
       "  8.519445419311523,\n",
       "  5.326987266540527,\n",
       "  0.9189756512641907,\n",
       "  7.105715274810791,\n",
       "  1.892228364944458,\n",
       "  12.138153076171875,\n",
       "  6.111774921417236,\n",
       "  3.589543104171753,\n",
       "  1.2883989810943604,\n",
       "  1.7023115158081055,\n",
       "  3.8498706817626953,\n",
       "  2.908352851867676,\n",
       "  0.9184759855270386,\n",
       "  1.0212591886520386,\n",
       "  7.122376441955566,\n",
       "  6.732410907745361,\n",
       "  5.144501686096191,\n",
       "  4.854119777679443,\n",
       "  6.543369293212891,\n",
       "  0.3381232023239136,\n",
       "  9.557618141174316,\n",
       "  2.9639039039611816,\n",
       "  8.982439994812012,\n",
       "  53.80054473876953,\n",
       "  0.6904776692390442,\n",
       "  4.799500465393066,\n",
       "  1.9255938529968262,\n",
       "  0.45198413729667664,\n",
       "  0.38417744636535645,\n",
       "  25.38662338256836,\n",
       "  13.64249038696289,\n",
       "  10.207216262817383,\n",
       "  1.3610576391220093,\n",
       "  21.111278533935547,\n",
       "  24.605722427368164,\n",
       "  1.0504916906356812,\n",
       "  4.160204887390137,\n",
       "  18.85479736328125,\n",
       "  1.2725862264633179,\n",
       "  0.4366109073162079,\n",
       "  9.999670028686523,\n",
       "  46.153873443603516,\n",
       "  7.210074424743652,\n",
       "  2.3893697261810303,\n",
       "  7.822183132171631,\n",
       "  45.8588981628418,\n",
       "  3.8593175411224365,\n",
       "  1.6076730489730835,\n",
       "  1.328518271446228,\n",
       "  6.223233222961426,\n",
       "  1.3316060304641724,\n",
       "  5.251704692840576,\n",
       "  4.568398952484131,\n",
       "  5.108389854431152,\n",
       "  4.268512725830078,\n",
       "  1.5620540380477905,\n",
       "  30.523239135742188,\n",
       "  0.5821083188056946,\n",
       "  28.851144790649414,\n",
       "  3.05397367477417,\n",
       "  13.137351989746094,\n",
       "  86.47338104248047,\n",
       "  11.000306129455566,\n",
       "  0.7675381898880005,\n",
       "  0.8615167737007141,\n",
       "  1.1916416883468628,\n",
       "  13.696884155273438,\n",
       "  1.2448304891586304,\n",
       "  16.48255157470703,\n",
       "  0.9224311113357544,\n",
       "  0.48528560996055603,\n",
       "  64.15789794921875,\n",
       "  21.540653228759766,\n",
       "  6.004839897155762,\n",
       "  1.528403639793396],\n",
       " [369.4215087890625,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1090.693359375,\n",
       "  0.16680756211280823,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  164.62606811523438,\n",
       "  196.48118591308594,\n",
       "  0.746796727180481,\n",
       "  0.0,\n",
       "  1.2641557455062866,\n",
       "  0.0,\n",
       "  0.027335483580827713,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.5911548137664795,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.18943478167057037,\n",
       "  318.8017578125,\n",
       "  0.022387951612472534,\n",
       "  0.0,\n",
       "  269.3727111816406,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  6.239467144012451,\n",
       "  0.00872468389570713,\n",
       "  0.12391109764575958,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  20.654966354370117,\n",
       "  1.7440382242202759,\n",
       "  14.81767749786377,\n",
       "  0.0,\n",
       "  621.52001953125,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.3534511625766754,\n",
       "  669.17138671875,\n",
       "  0.7347842454910278,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  323.6144714355469,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1556.918212890625,\n",
       "  5.069479465484619,\n",
       "  0.0,\n",
       "  0.6601237058639526,\n",
       "  1.4897452592849731,\n",
       "  0.18417902290821075,\n",
       "  0.33422502875328064,\n",
       "  0.054580677300691605,\n",
       "  0.0,\n",
       "  14.822598457336426,\n",
       "  0.27928391098976135,\n",
       "  0.0,\n",
       "  208.91375732421875,\n",
       "  0.0,\n",
       "  2.837961435317993,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  3.2211248874664307,\n",
       "  0.6177758574485779,\n",
       "  0.0,\n",
       "  3.2681310176849365,\n",
       "  8.811262130737305,\n",
       "  0.13150343298912048,\n",
       "  32.1849250793457,\n",
       "  4.183220386505127,\n",
       "  335.0560607910156,\n",
       "  0.0,\n",
       "  42.39211654663086,\n",
       "  0.0,\n",
       "  5.323235034942627,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  8.727231979370117,\n",
       "  0.03639485687017441,\n",
       "  531.1358642578125,\n",
       "  0.0,\n",
       "  14.817427635192871,\n",
       "  200.9522705078125,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.438779354095459,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0886812210083008,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.2463073432445526,\n",
       "  321.5522155761719,\n",
       "  430.532958984375,\n",
       "  0.0,\n",
       "  3.6485891342163086,\n",
       "  0.15102963149547577,\n",
       "  77.26891326904297,\n",
       "  1155.94677734375,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.14003604650497437,\n",
       "  0.007335471920669079,\n",
       "  0.08017150312662125,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.4499712586402893,\n",
       "  0.0,\n",
       "  0.01923861913383007,\n",
       "  0.3740415871143341,\n",
       "  30.09784507751465,\n",
       "  0.046519555151462555,\n",
       "  6.534254550933838,\n",
       "  0.0,\n",
       "  0.20569008588790894,\n",
       "  9.893606185913086,\n",
       "  0.012925470247864723,\n",
       "  49.14921569824219,\n",
       "  0.0,\n",
       "  45.319091796875,\n",
       "  0.0,\n",
       "  468.81805419921875,\n",
       "  519.5311889648438,\n",
       "  0.14548057317733765,\n",
       "  0.5344939827919006,\n",
       "  0.0,\n",
       "  1416.775146484375,\n",
       "  47.807586669921875,\n",
       "  0.0,\n",
       "  0.13062375783920288,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  84.05532836914062,\n",
       "  0.0,\n",
       "  80.4331283569336,\n",
       "  36.20896530151367,\n",
       "  0.0909595862030983,\n",
       "  0.0,\n",
       "  297.3111572265625,\n",
       "  0.29044386744499207,\n",
       "  679.9290161132812,\n",
       "  0.2698877453804016,\n",
       "  0.024907981976866722,\n",
       "  0.0,\n",
       "  0.004155474714934826,\n",
       "  0.0,\n",
       "  16.499284744262695,\n",
       "  0.0,\n",
       "  0.009237494319677353,\n",
       "  143.96932983398438,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  8.255437850952148,\n",
       "  0.07592713832855225,\n",
       "  0.0,\n",
       "  104.26712799072266,\n",
       "  3.794236898422241,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.07990852743387222,\n",
       "  18.74992561340332,\n",
       "  0.0,\n",
       "  1.6542521715164185,\n",
       "  241.86387634277344,\n",
       "  17.724409103393555,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  62.96738815307617,\n",
       "  0.0,\n",
       "  0.27038389444351196,\n",
       "  0.006136915180832148,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  120.216796875,\n",
       "  201.08119201660156,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1739.36865234375,\n",
       "  88.45665740966797,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  438.0220947265625,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  22.55211067199707,\n",
       "  6.89896297454834,\n",
       "  7.041296005249023,\n",
       "  1.3479567766189575,\n",
       "  0.0,\n",
       "  1392.8565673828125,\n",
       "  0.08919113874435425,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.05784056335687637,\n",
       "  0.0,\n",
       "  27.091596603393555,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  416.43927001953125,\n",
       "  19.785079956054688,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  716.4700927734375,\n",
       "  48.42450714111328,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  71.19123077392578,\n",
       "  0.0,\n",
       "  0.23122519254684448,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1221.6280517578125,\n",
       "  0.0,\n",
       "  0.7778826951980591,\n",
       "  36.29043197631836,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  14.188423156738281,\n",
       "  0.0,\n",
       "  0.4222561717033386,\n",
       "  25.245635986328125,\n",
       "  0.0,\n",
       "  1.7902697324752808,\n",
       "  73.66743469238281,\n",
       "  0.0,\n",
       "  18.676931381225586,\n",
       "  0.14865238964557648,\n",
       "  0.0,\n",
       "  6.442417621612549,\n",
       "  0.8299885392189026,\n",
       "  0.0,\n",
       "  1.448937177658081,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  7.410762786865234,\n",
       "  0.0,\n",
       "  4.229274272918701,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.42179790139198303,\n",
       "  0.0,\n",
       "  0.022912221029400826,\n",
       "  0.5214875340461731,\n",
       "  25.36416244506836,\n",
       "  22.662694931030273,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  13.232925415039062,\n",
       "  11.78125286102295,\n",
       "  21.407855987548828,\n",
       "  0.0,\n",
       "  0.057163625955581665,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  45.674072265625,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  4.392370700836182,\n",
       "  0.0,\n",
       "  40.342079162597656,\n",
       "  1447.2496337890625,\n",
       "  0.0,\n",
       "  0.23837828636169434,\n",
       "  11.517620086669922,\n",
       "  1.8539519309997559,\n",
       "  0.10214409232139587,\n",
       "  0.0,\n",
       "  0.07379524409770966,\n",
       "  0.0,\n",
       "  322.24041748046875,\n",
       "  0.0,\n",
       "  93.05884552001953,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  52.09365463256836,\n",
       "  0.9262378215789795,\n",
       "  0.0,\n",
       "  222.84317016601562,\n",
       "  0.0,\n",
       "  0.17627356946468353,\n",
       "  302.72088623046875,\n",
       "  0.0,\n",
       "  0.5517711043357849,\n",
       "  8.653677940368652,\n",
       "  0.0,\n",
       "  177.7516326904297,\n",
       "  0.0,\n",
       "  0.8097395300865173,\n",
       "  0.0,\n",
       "  0.09531355649232864,\n",
       "  49.996742248535156,\n",
       "  0.0,\n",
       "  0.010969500057399273,\n",
       "  1065.09033203125,\n",
       "  25.992618560791016,\n",
       "  0.0,\n",
       "  2.854539632797241,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  30.593305587768555,\n",
       "  1051.51904296875,\n",
       "  7.44715690612793,\n",
       "  0.0,\n",
       "  1.2923084497451782,\n",
       "  0.8824797868728638,\n",
       "  0.0,\n",
       "  19.364330291748047,\n",
       "  0.8865857124328613,\n",
       "  13.790212631225586,\n",
       "  0.0,\n",
       "  0.0009307044092565775,\n",
       "  10.435123443603516,\n",
       "  13.047834396362305,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  9.110109329223633,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.15615229308605194,\n",
       "  1.220004677772522,\n",
       "  0.0,\n",
       "  465.8341979980469,\n",
       "  0.1694256216287613,\n",
       "  0.0,\n",
       "  416.1944274902344,\n",
       "  4.663385391235352,\n",
       "  86.2950439453125,\n",
       "  0.0,\n",
       "  3738.822509765625,\n",
       "  0.0,\n",
       "  60.50342559814453,\n",
       "  0.22918786108493805,\n",
       "  0.2958122491836548,\n",
       "  0.29455557465553284,\n",
       "  0.3711045980453491,\n",
       "  0.710006594657898,\n",
       "  93.80224609375,\n",
       "  0.7748044729232788,\n",
       "  0.0,\n",
       "  135.83729553222656,\n",
       "  0.42544129490852356,\n",
       "  0.11775003373622894,\n",
       "  2058.11865234375,\n",
       "  231.99996948242188,\n",
       "  18.02908706665039,\n",
       "  0.0,\n",
       "  0.299012154340744,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.1680129766464233,\n",
       "  0.0],\n",
       " [1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_16884\\3520072505.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tr_results = np.asarray(train_results)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "tr_results = np.asarray(train_results)\n",
    "tr_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [117], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tr_results[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mshape\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "tr_results[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(123)\n",
    "\n",
    "w = 0.8    # bar width\n",
    "x = [1, 2] # x-coordinates of your bars\n",
    "colors = [(0, 0, 1, 1), (1, 0, 0, 1)]    # corresponding colors\n",
    "y = [np.random.random(30) * 2 + 5,       # data series\n",
    "    np.random.random(10) * 3 + 8]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(x,\n",
    "       height=[np.mean(yi) for yi in y],\n",
    "       yerr=[np.std(yi) for yi in y],    # error bars\n",
    "       capsize=12, # error bar cap width in points\n",
    "       width=w,    # bar width\n",
    "       tick_label=[\"control\", \"test\"],\n",
    "       color=(0,0,0,0),  # face color transparent\n",
    "       edgecolor=colors,\n",
    "       #ecolor=colors,    # error bar colors; setting this raises an error for whatever reason.\n",
    "       )\n",
    "\n",
    "for i in range(len(x)):\n",
    "    # distribute scatter randomly across whole width of bar\n",
    "    ax.scatter(x[i] + np.random.random(y[i].size) * w - w / 2, y[i], color=colors[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save(f'{model_name}_training_loss.npy', tr_loss, allow_pickle=True)\n",
    "np.save(f'{model_name}_training_accuracy.npy', tr_acc, allow_pickle=True)\n",
    "\n",
    "np.save(f'{model_name}_validation_loss.npy', v_loss, allow_pickle=True)\n",
    "np.save(f'{model_name}_validation_accuracy.npy', v_acc, allow_pickle=True)\n",
    "\n",
    "np.save(f'{model_name}_test_loss.npy', tst_loss, allow_pickle=True)\n",
    "np.save(f'{model_name}_test_accuracy.npy', tst_acc, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "training_loss = np.load(f'{model_name}_training_loss.npy', allow_pickle=True)\n",
    "training_accuracy = np.load(f'{model_name}_training_accuracy.npy', allow_pickle=True)\n",
    "\n",
    "validation_loss = np.load(f'{model_name}_validation_loss.npy', allow_pickle=True)\n",
    "validation_accuracy = np.load(f'{model_name}_validation_accuracy.npy', allow_pickle=True)\n",
    "\n",
    "test_loss = np.load(f'{model_name}_test_loss.npy', allow_pickle=True)\n",
    "test_accuracy = np.load(f'{model_name}_test_accuracy.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a sequence of integers to represent the epoch numbers\n",
    "epochs = range(1, num_epochs+1)\n",
    " \n",
    "# Plot and label the training and validation loss values\n",
    "plt.plot(epochs, training_loss, label='Training Loss')\n",
    "plt.plot(epochs, validation_loss, label='Validation Loss')\n",
    " \n",
    "# Add in a title and axes labels\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    " \n",
    "# Set the tick locations\n",
    "plt.xticks(np.arange(0, num_epochs+1, num_epochs/10))\n",
    " \n",
    "# Display the plot\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(f'{model_name}_Training and Validation Loss.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a sequence of integers to represent the epoch numbers\n",
    "epochs = range(1, num_epochs+1)\n",
    " \n",
    "# Plot and label the training and validation loss values\n",
    "plt.plot(epochs, training_accuracy, label='Training Accuracy')\n",
    "plt.plot(epochs, validation_accuracy, label='Validation Accuracy')\n",
    "plt.plot(epochs, test_accuracy, label='Test Accuracy')\n",
    " \n",
    "# Add in a title and axes labels\n",
    "plt.title('Accuracy vs. Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    " \n",
    "# Set the tick locations\n",
    "plt.xticks(np.arange(0, num_epochs+1, num_epochs/10))\n",
    "plt.ylim(0,1)\n",
    " \n",
    "# Display the plot\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(f'{model_name}_Accuracy vs. Epochs.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_fraction = [0,0]\n",
    "\n",
    "train_fraction = [0,0]\n",
    "val_fraction = [0,0]\n",
    "test_fraction = [0,0]\n",
    "\n",
    "for grph in train_dataset: \n",
    "    if grph.y == 1: \n",
    "        train_fraction[1] +=1\n",
    "        dataset_fraction[1] +=1 \n",
    "    else: \n",
    "        train_fraction[0] +=1\n",
    "        dataset_fraction[0] +=1 \n",
    "\n",
    "for grph in val_dataset: \n",
    "    if grph.y == 1:\n",
    "         val_fraction[1] +=1\n",
    "         dataset_fraction[1] +=1  \n",
    "    else:\n",
    "         val_fraction[0] +=1\n",
    "         dataset_fraction[0] +=1\n",
    "\n",
    "for grph in test_dataset: \n",
    "    if grph.y == 1:\n",
    "         test_fraction[1] +=1\n",
    "         dataset_fraction[1] +=1 \n",
    "    else:\n",
    "         test_fraction[0] +=1\n",
    "         dataset_fraction[0] +=1\n",
    "\n",
    "print(f'Overall dataset percentage of label 1 = {dataset_fraction[1]/len(dataset)})')\n",
    "print(f'Training dataset percentage of label 1 = {train_fraction} = {train_fraction[1]/len(train_dataset)}')\n",
    "print(f'Validation dataset percentage of label 1 = {val_fraction} = {val_fraction[1]/len(val_dataset)}')\n",
    "print(f'Test dataset percentage of label 1 = {test_fraction} = {test_fraction[1]/len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Graph: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, pos0, adj0 = torch.load(f'{model_name}_img0_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Embedding GNN\n",
    "print(x0[0].shape)\n",
    "x0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pos0[0].shape)\n",
    "pos0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adj0[0].shape)\n",
    "adj0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index, _ = dense_to_sparse(adj0[0])\n",
    "visualize_points(pos0[0].cpu(), edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph After 1st Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_emb, x1_pool, pos1, adj1, s1= torch.load(f'{model_name}_img1_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Embedding GNN (adj0 @ x_0 @ w_gnn_emb)\n",
    "print(x1_emb[0].shape)\n",
    "x1_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Pooling GNN: adj_0 @ x_0 @ w_gnn_pool\n",
    "print(s1[0].shape)\n",
    "s1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Coordinate Matrix (pos_out = softmax(s).t() @ pos_in)\n",
    "print(pos1[0].shape)\n",
    "pos1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Feature Matrix (x_out = softmax(s).t() @ x_in)\n",
    "print(x1_pool[0].shape)\n",
    "x1_pool[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Adjacency Matrix = softmax(adj_out = softmax(s.t()) @ adj_in @ softmax(s))\n",
    "print(adj1[0].shape)\n",
    "adj1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index, _ = dense_to_sparse(adj1[0])\n",
    "visualize_points(pos1[0].cpu(), edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph after 2nd reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_emb, x2_pool, pos2, adj2, s2 = torch.load(f'{model_name}_img2_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Embedding GNN (adj1 @ x1_pool @ w_gnn_emb)\n",
    "print(x2_emb[0].shape)\n",
    "x2_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Pooling GNN: adj1 @ x1_pool @ w_gnn_pool), dim=1\n",
    "print(s2[0].shape)\n",
    "s2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Coordinate Matrix (pos_out = softmax(s.t()) @ pos_in)\n",
    "print(pos2[0].shape)\n",
    "pos2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Feature Matrix (x_out = softmax(s2).t() @ x2_emb)\n",
    "print(x2_pool[0].shape)\n",
    "x2_pool[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Adjacency Matrix (adj = softmax(s).T @ adj @ softmax(s)\n",
    "print(adj2[0].shape)\n",
    "adj2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index, _ = dense_to_sparse(adj2[0])\n",
    "visualize_points(pos2[0].cpu(), edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph after 3rd reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3_emb, x3_pool, pos3, adj3, s3 = torch.load(f'{model_name}_img3_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Embedding GNN (adj_0 @ x_0 @ w_gnn_emb)\n",
    "print(x3_emb[0].shape)\n",
    "x3_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Pooling GNN: torch.softmax(adj_0 @ x_0 @ w_gnn_pool), dim=1)\n",
    "print(s3[0].shape)\n",
    "s3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Coordinate Matrix (pos_out = softmax(s.t()) @ pos_in)\n",
    "print(pos3[0].shape)\n",
    "pos3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Feature Matrix (x_out = softmax(s.t()) @ x_0)\n",
    "print(x3_pool[0].shape)\n",
    "x3_pool[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Adjacency Matrix (adj = softmax(s.t()) @ adj @ softmax(s)\n",
    "print(adj3[0].shape)\n",
    "adj3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index, _ = dense_to_sparse(adj3[0])\n",
    "visualize_points(pos3[0].cpu(), edge_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3baeb0c3f97feb3023477fbaa09b9f4da769e45e64d8febc6957bb84d33ff77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
