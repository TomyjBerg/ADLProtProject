{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize features? \n",
    "## Invert h-bond and charge? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_siamese_071222'\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import DenseDataLoader #To make use of this data loader, all graph attributes in the dataset need to have the same shape. In particular, this data loader should only be used when working with dense adjacency matrices.\n",
    "from torch_geometric.nn import DenseGCNConv, dense_diff_pool\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dir_1 = 'C:/Users/david/pyproj/pyg/adl/patch_label_1'\n",
    "#data_dir_0 = 'C:/Users/david/pyproj/pyg/adl/patch_label_0'\n",
    "data_dir_1 = 'C:/Users/thoma/OneDrive - ZHAW/ProteinSurfaces-DESKTOP-AQ00763/patch_label_1'\n",
    "data_dir_0 = 'C:/Users/thoma/OneDrive - ZHAW/ProteinSurfaces-DESKTOP-AQ00763/patch_label_0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "572"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from c_PatchDataset import PatchDataset\n",
    "dataset = PatchDataset(data_dir_label_0 = data_dir_0,  data_dir_label_1=data_dir_1,  neg_pos_ratio=1)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: PatchDataset(572):\n",
      "====================\n",
      "Number of graphs pairs: 572\n",
      "\n",
      "PairData(adj1=[100, 100], x1=[100, 3], adj2=[100, 100], x2=[100, 3], y=1)\n",
      "=============================================================\n",
      "Number of nodes in each: None\n",
      "Number of node features: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thoma\\Desktop\\ZHAW MLS\\David prod\\ADLProtProject\\.venv\\lib\\site-packages\\torch_geometric\\data\\storage.py:271: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'adj1', 'y', 'x2', 'adj2', 'x1'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs pairs: {len(dataset)}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "print()\n",
    "print(data)\n",
    "print('=============================================================')\n",
    "\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes in each: {data.num_nodes}')\n",
    "print(f'Number of node features: {data.num_node_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3722e-01,  0.0000e+00, -9.9054e-01],\n",
       "        [-3.0243e-02,  0.0000e+00, -9.9954e-01],\n",
       "        [ 6.6998e-02,  0.0000e+00,  9.9775e-01],\n",
       "        [-8.0195e-02,  0.0000e+00,  9.9678e-01],\n",
       "        [-2.7805e-02,  0.0000e+00,  9.9961e-01],\n",
       "        [ 5.4906e-02,  0.0000e+00, -9.9849e-01],\n",
       "        [ 6.7535e-02,  0.0000e+00,  9.9772e-01],\n",
       "        [-3.7540e-02,  0.0000e+00, -9.9930e-01],\n",
       "        [-1.4162e-01,  0.0000e+00,  9.8992e-01],\n",
       "        [ 5.1660e-02,  0.0000e+00, -9.9866e-01],\n",
       "        [ 1.0746e-01,  0.0000e+00,  9.9421e-01],\n",
       "        [-3.7490e-02,  1.9489e-02, -9.9911e-01],\n",
       "        [ 4.1760e-02,  8.4647e-02, -9.9554e-01],\n",
       "        [-1.2137e-01,  0.0000e+00, -9.9261e-01],\n",
       "        [-1.4755e-04,  0.0000e+00, -1.0000e+00],\n",
       "        [ 2.0662e-02,  0.0000e+00,  9.9979e-01],\n",
       "        [-1.4473e-02,  2.3516e-01, -9.7185e-01],\n",
       "        [ 1.4049e-01,  0.0000e+00, -9.9008e-01],\n",
       "        [-1.6496e-01,  0.0000e+00,  9.8630e-01],\n",
       "        [ 2.8432e-02,  0.0000e+00, -9.9960e-01],\n",
       "        [-1.4237e-01,  0.0000e+00, -9.8981e-01],\n",
       "        [-9.4338e-03,  0.0000e+00,  9.9996e-01],\n",
       "        [-1.0466e-01,  0.0000e+00,  9.9451e-01],\n",
       "        [ 9.6129e-01,  0.0000e+00,  2.7555e-01],\n",
       "        [ 4.0802e-02,  0.0000e+00, -9.9917e-01],\n",
       "        [ 2.3648e-02,  0.0000e+00, -9.9972e-01],\n",
       "        [ 1.1634e-01,  0.0000e+00, -9.9321e-01],\n",
       "        [ 4.1715e-01,  0.0000e+00, -9.0884e-01],\n",
       "        [ 2.2562e-02,  0.0000e+00,  9.9975e-01],\n",
       "        [ 1.4863e-01,  0.0000e+00, -9.8889e-01],\n",
       "        [ 8.2292e-02,  0.0000e+00,  9.9661e-01],\n",
       "        [-2.7511e-02,  3.8024e-02, -9.9890e-01],\n",
       "        [ 5.1635e-02,  0.0000e+00, -9.9867e-01],\n",
       "        [-1.4561e-01,  0.0000e+00,  9.8934e-01],\n",
       "        [ 1.5751e-01,  3.9704e-02, -9.8672e-01],\n",
       "        [-2.2003e-01,  0.0000e+00, -9.7549e-01],\n",
       "        [ 1.9618e-01,  1.7923e-01, -9.6405e-01],\n",
       "        [-1.3546e-01,  0.0000e+00,  9.9078e-01],\n",
       "        [ 1.4994e-01,  4.5668e-03, -9.8868e-01],\n",
       "        [-2.4773e-02,  0.0000e+00, -9.9969e-01],\n",
       "        [ 7.4665e-02,  0.0000e+00, -9.9721e-01],\n",
       "        [-9.2391e-02,  0.0000e+00,  9.9572e-01],\n",
       "        [ 1.8657e-01,  2.0927e-01, -9.5990e-01],\n",
       "        [-6.5310e-02,  0.0000e+00, -9.9787e-01],\n",
       "        [ 1.0768e-01,  0.0000e+00, -9.9419e-01],\n",
       "        [ 4.7631e-02,  0.0000e+00, -9.9887e-01],\n",
       "        [ 6.8041e-02,  2.5526e-02, -9.9736e-01],\n",
       "        [ 3.8507e-02,  1.6256e-01, -9.8595e-01],\n",
       "        [-1.0885e-01,  0.0000e+00,  9.9406e-01],\n",
       "        [-4.8080e-01,  0.0000e+00,  8.7683e-01],\n",
       "        [-1.0085e-01,  0.0000e+00, -9.9490e-01],\n",
       "        [ 2.1457e-02,  0.0000e+00,  9.9977e-01],\n",
       "        [ 1.6160e-01,  1.0637e-01, -9.8111e-01],\n",
       "        [ 1.5271e-01,  1.3646e-01, -9.7880e-01],\n",
       "        [ 1.7950e-02,  0.0000e+00, -9.9984e-01],\n",
       "        [ 8.1329e-02,  0.0000e+00, -9.9669e-01],\n",
       "        [ 2.2112e-01,  5.5877e-02, -9.7364e-01],\n",
       "        [-1.2684e-01,  0.0000e+00, -9.9192e-01],\n",
       "        [-3.1117e-02,  0.0000e+00, -9.9952e-01],\n",
       "        [ 8.6217e-02,  0.0000e+00,  9.9628e-01],\n",
       "        [ 1.2129e-01,  0.0000e+00, -9.9262e-01],\n",
       "        [-2.3951e-01,  0.0000e+00, -9.7089e-01],\n",
       "        [ 1.9617e-01,  0.0000e+00, -9.8057e-01],\n",
       "        [-1.1740e-03,  0.0000e+00,  1.0000e+00],\n",
       "        [-5.4743e-01,  0.0000e+00,  8.3685e-01],\n",
       "        [ 3.9163e-02,  0.0000e+00,  9.9923e-01],\n",
       "        [ 1.9426e-01,  5.7132e-02, -9.7929e-01],\n",
       "        [ 1.0757e-01,  0.0000e+00, -9.9420e-01],\n",
       "        [-2.3411e-01,  0.0000e+00,  9.7221e-01],\n",
       "        [ 6.6706e-02,  0.0000e+00,  9.9777e-01],\n",
       "        [ 1.0694e-01,  0.0000e+00, -9.9427e-01],\n",
       "        [ 2.6065e-01,  0.0000e+00,  9.6543e-01],\n",
       "        [ 1.4082e-01,  0.0000e+00, -9.9003e-01],\n",
       "        [ 2.8029e-02,  0.0000e+00, -9.9961e-01],\n",
       "        [-9.5050e-03,  0.0000e+00,  9.9995e-01],\n",
       "        [ 1.8659e-01,  0.0000e+00, -9.8244e-01],\n",
       "        [ 8.6774e-01,  0.0000e+00, -4.9702e-01],\n",
       "        [ 3.5590e-02,  0.0000e+00,  9.9937e-01],\n",
       "        [-1.5661e-01,  0.0000e+00,  9.8766e-01],\n",
       "        [-3.1556e-02,  0.0000e+00,  9.9950e-01],\n",
       "        [ 1.6004e-01,  0.0000e+00, -9.8711e-01],\n",
       "        [ 1.8374e-01,  0.0000e+00, -9.8297e-01],\n",
       "        [ 1.7532e-02,  0.0000e+00,  9.9985e-01],\n",
       "        [ 7.9401e-02,  0.0000e+00,  9.9684e-01],\n",
       "        [ 8.2502e-03,  0.0000e+00,  9.9997e-01],\n",
       "        [ 5.8598e-02, -6.0216e-02, -9.9646e-01],\n",
       "        [-2.0654e-01, -3.5677e-01, -9.1107e-01],\n",
       "        [-1.6778e-02,  0.0000e+00,  9.9986e-01],\n",
       "        [ 2.2152e-01,  0.0000e+00, -9.7516e-01],\n",
       "        [ 1.1216e-01,  0.0000e+00, -9.9369e-01],\n",
       "        [ 1.2938e-02,  0.0000e+00, -9.9992e-01],\n",
       "        [ 1.5211e-01,  0.0000e+00, -9.8836e-01],\n",
       "        [-2.6816e-02,  0.0000e+00,  9.9964e-01],\n",
       "        [ 2.8064e-03,  0.0000e+00, -1.0000e+00],\n",
       "        [ 1.6781e-01,  8.9808e-02, -9.8172e-01],\n",
       "        [-1.8838e-02,  0.0000e+00,  9.9982e-01],\n",
       "        [ 5.2532e-02,  0.0000e+00,  9.9862e-01],\n",
       "        [-1.3212e-01,  0.0000e+00, -9.9123e-01],\n",
       "        [ 2.2156e-01,  9.4648e-02, -9.7054e-01],\n",
       "        [-3.3181e-01, -6.1474e-01, -7.1554e-01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does not work we do not have pos\n",
    "#visualize_points(data.pos, data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs pairs: 382\n",
      "Number of validation graphs: 95\n",
      "Number of test graphs: 95\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader \n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "n_train = math.ceil((4/6) * len(dataset))\n",
    "n_val = math.ceil((len(dataset) - n_train)/2)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "print(f'Number of training graphs pairs: {len(train_dataset)}')\n",
    "print(f'Number of validation graphs: {len(val_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')\n",
    "\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size= batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset = val_dataset, batch_size= batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size= batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PairDataBatch(adj1=[100, 100], x1=[100, 3], adj2=[100, 100], x2=[100, 3], y=[1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "databatch = next(iter(train_loader))\n",
    "databatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_nodes, in_channels, hidden_channels, out_channels,\n",
    "                 normalize=False, lin=True):\n",
    "        super(GNN, self).__init__()\n",
    "\n",
    "        # Each instance of this GNN will have 3 convolutional layers and three batch norm layers        \n",
    "        self.conv1 = DenseGCNConv(in_channels, hidden_channels, normalize)\n",
    "        self.bns1 = torch.nn.BatchNorm1d(in_nodes)\n",
    "        \n",
    "        self.conv2 = DenseGCNConv(hidden_channels, hidden_channels, normalize)\n",
    "        self.bns2 = torch.nn.BatchNorm1d(in_nodes)\n",
    "        \n",
    "        self.conv3 = DenseGCNConv(hidden_channels, out_channels, normalize)\n",
    "        self.bns3 = torch.nn.BatchNorm1d(in_nodes)\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        \n",
    "        #Step 1\n",
    "        x = self.conv1(x, adj, mask)\n",
    "        x = self.bns1(x)\n",
    "        \n",
    "        #Step 2\n",
    "        x = self.conv2(x, adj, mask)\n",
    "        x = self.bns2(x)\n",
    "\n",
    "        #Step 3\n",
    "        x = self.conv3(x, adj, mask)\n",
    "        if x.shape[2] != 1: \n",
    "            x = self.bns3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class DiffPool(torch.nn.Module):\n",
    "    def __init__(self, num_nodes):\n",
    "        super(DiffPool, self).__init__()\n",
    "\n",
    "        #Hierarchical Step #1\n",
    "        in_nodes = num_nodes\n",
    "        out_nodes = 25 # Number of clusters / nodes in the next layer\n",
    "        self.gnn1_pool = GNN(in_nodes, dataset.num_features, 16, out_nodes) # PoolGNN --> Cluster Assignment Matrix to reduce to num_nodes\n",
    "        self.gnn1_embed = GNN(in_nodes, dataset.num_features, 8, 8) # EmbGNN --> Convolutions to create new node embedding\n",
    "\n",
    "        # Hierarchical Step #2\n",
    "        in_nodes = out_nodes\n",
    "        out_nodes = 10\n",
    "        self.gnn2_pool = GNN(in_nodes, 8, 8, out_nodes)\n",
    "        self.gnn2_embed = GNN(in_nodes, 8, 12, 16, lin=False)\n",
    "\n",
    "        # Hierarchical Step #3\n",
    "        in_nodes = out_nodes\n",
    "        out_nodes = 1\n",
    "        self.gnn3_pool = GNN(in_nodes, 16, 16, out_nodes)\n",
    "        self.gnn3_embed = GNN(in_nodes, 16, 16, 32, lin=False)\n",
    "\n",
    "        # Final Classifier\n",
    "        self.lin1 = torch.nn.Linear(32, 64) \n",
    "        #self.lin2 = torch.nn.Linear(64, 2)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, batch, mask=None):\n",
    "        \n",
    "        #if batch == 0: print('Shape of input data batch:')\n",
    "        #if batch == 0: print(f'Feature Matrix: {tuple(x.shape)}')\n",
    "        #if batch == 0: print(f'Adjacency Matrix: {tuple(adj.shape)}')\n",
    "       \n",
    "\n",
    "\n",
    "        #Hierarchical Step #1\n",
    "        #if batch == 0: print('Hierarchical Step #1')\n",
    "        x1 = self.gnn1_embed(x, adj, mask) # node feature embedding\n",
    "        s = self.gnn1_pool(x, adj, mask) # cluster assignment matrix\n",
    "\n",
    "        #if batch == 0: print(f'X1 = {tuple(x1.shape)}    S1: {tuple(s.shape)}')\n",
    "\n",
    "        x, adj, l1, e1 = dense_diff_pool(x1, adj, s, mask) # does the necessary matrix multiplications\n",
    "        adj = torch.softmax(adj, dim=-1)\n",
    "\n",
    "        #if batch == 0: print(f'---matmul---> New feature matrix (softmax(s_0.t()) @ z_0) = {tuple(x.shape)}')\n",
    "        #if batch == 0: print(f'---matmul---> New adjacency matrix (s_0.t() @ adj_0 @ s_0) = {tuple(adj.shape)}')\n",
    "   \n",
    "\n",
    "\n",
    "        # Hierarchical Step #2\n",
    "        #if batch == 0: print('Hierarchical Step #2')\n",
    "        x2 = self.gnn2_embed(x, adj)\n",
    "        s = self.gnn2_pool(x, adj)\n",
    "\n",
    "        #if batch == 0: print(f'X2: {tuple(x2.shape)}    S2: {tuple(s.shape)}')\n",
    "        \n",
    "        x, adj, l2, e2 = dense_diff_pool(x2, adj, s)\n",
    "        adj = torch.softmax(adj, dim=-1)\n",
    "\n",
    "        #if batch == 0: print(f'---matmul---> New feature matrix (softmax(s_0.t()) @ z_0) = {tuple(x.shape)}')\n",
    "        #if batch == 0: print(f'---matmul---> New adjacency matrix (s_0.t() @ adj_0 @ s_0) = {tuple(adj.shape)}')\n",
    "      \n",
    "        \n",
    "\n",
    "        # Hierarchical Step #3\n",
    "        #if batch == 0: print('Hierarchical Step #3')\n",
    "        x3 = self.gnn3_embed(x, adj)\n",
    "        s = self.gnn3_pool(x, adj)\n",
    "        \n",
    "        #if batch == 0: print(f'X3: {tuple(x3.shape)}    S3: {tuple(s.shape)}')\n",
    "\n",
    "        x, adj, l3, e3 = dense_diff_pool(x3, adj, s)\n",
    "        adj = torch.softmax(adj, dim=-1)\n",
    "\n",
    "        #if batch == 0: print(f'---matmul---> New feature matrix (softmax(s_0.t()) @ z_0) = {tuple(x.shape)}')\n",
    "        #if batch == 0: print(f'---matmul---> New adjacency matrix (s_0.t() @ adj_0 @ s_0) = {tuple(adj.shape)}')\n",
    "     \n",
    "        \n",
    "\n",
    "        # Final Classification\n",
    "        #if batch == 0: print('Final Output')\n",
    "        x = x.mean(dim=1) # Pool the features of all nodes (global mean pool)  dim = 1 refers to columns\n",
    "        #if batch == 0: print(f'---X Output after mean= {tuple(x.shape)}')\n",
    "\n",
    "        x = F.relu(self.lin1(x)) # Fully connected layer + relu\n",
    "        #if batch == 0: print(f'------ X Output 3 after lin= {tuple(x.shape)}')\n",
    "\n",
    "        \n",
    "        return x, l1 + l2 + l3, e1 + e2 + e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An attempt of a contrastive loss function\n",
    "#   pairs with label 1 --> should get small euclid dist = small loss\n",
    "#   pairs with label 0 --> should get large euclid dist = small loss\n",
    "\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, margin=1.2):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, x0, x1, y,epochs):\n",
    "        # euclidian distance\n",
    "        #print(x0)\n",
    "        #print(x1)\n",
    "        #print(y)\n",
    "        diff = x0 - x1\n",
    "        #print(diff)\n",
    "        pow = torch.pow(diff, 2)\n",
    "        #print(pow)\n",
    "        dist_sq = torch.sum(pow, 1)\n",
    "        #print(dist_sq) # sum of squared distance = 0.5 = 9\n",
    "        dist = torch.sqrt(dist_sq)\n",
    "        #print(dist) # euclidean distance = 0.7 = 3\n",
    "\n",
    "        mdist = self.margin- dist #negative euclidean distance - margin = 0.3 = -2\n",
    "        #print(mdist)\n",
    "        dist_marg = torch.clamp(mdist, min=0.0) # only distances <margin will be still positive here = 0.3 = 0\n",
    "        #print(dist)\n",
    "        loss =  y * torch.pow(dist, 2) + (1-y) * torch.pow(dist_marg,2)\n",
    "\n",
    "        # What happens to a pair with squared euclid dist (dist_sq) of 0.5\n",
    "        # if label = 0 --> 0 + squared clampled euclid distance --> loss = 0.3^2\n",
    "        # if label = 1 --> squared euclidean distance + 0 --> loss = 0.5\n",
    "\n",
    "        # What happens to a pair with squared euclid dist (dist_sq) of 9\n",
    "        # if label = 0 --> 0 + squared clampled euclid distance --> loss = 0\n",
    "        # if label = 1 --> squared euclidean distance + 0 --> loss = 9\n",
    "\n",
    "        #print(loss)\n",
    "        #loss = torch.sum(loss) / 2.0 \n",
    "        #print(loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch: 001, Train Loss: 197.823\n",
      "Epoch: 002, Train Loss: 41.866\n",
      "Epoch: 003, Train Loss: 9.833\n",
      "Epoch: 004, Train Loss: 3.034\n",
      "Epoch: 005, Train Loss: 1.249\n",
      "Epoch: 006, Train Loss: 0.678\n",
      "Epoch: 007, Train Loss: 0.454\n",
      "Epoch: 008, Train Loss: 0.347\n",
      "Epoch: 009, Train Loss: 0.296\n",
      "Epoch: 010, Train Loss: 0.258\n",
      "Epoch: 011, Train Loss: 0.236\n",
      "Epoch: 012, Train Loss: 0.242\n",
      "Epoch: 013, Train Loss: 0.237\n",
      "Epoch: 014, Train Loss: 0.229\n",
      "Epoch: 015, Train Loss: 0.229\n",
      "Epoch: 016, Train Loss: 0.226\n",
      "Epoch: 017, Train Loss: 0.226\n",
      "Epoch: 018, Train Loss: 0.230\n",
      "Epoch: 019, Train Loss: 0.225\n",
      "Epoch: 020, Train Loss: 0.234\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = DiffPool(num_nodes = 100).to(device)\n",
    "criterion = ContrastiveLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "num_epochs = 20\n",
    "\n",
    "def train(epoch):\n",
    "    batch = 0\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output1, _, _ = model(data.x1, data.adj1, batch)\n",
    "        output2, _, _ = model(data.x2, data.adj2, batch = None)\n",
    "        \n",
    "        #Contrastive Loss\n",
    "        loss_contrastive = criterion(output1,output2,data.y,epoch)\n",
    "        loss_contrastive.backward()\n",
    "        loss_all += data.y.size(0) * loss_contrastive.item()\n",
    "        optimizer.step()\n",
    "        batch +=1\n",
    "\n",
    "    return loss_all / len(train_dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader,epochs):\n",
    "    model.eval()\n",
    "\n",
    "    distances_lab1 = []\n",
    "    distances_lab0 = []\n",
    "    labels = []\n",
    "    losses = []\n",
    "    \n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output1, _, _ = model(data.x1, data.adj1, batch=None)\n",
    "        output2, _, _ = model(data.x2, data.adj2, batch=None)\n",
    "\n",
    "        test_loss_contrastive = criterion(output1, output2, data.y,epochs)\n",
    "        #diff = output1 -output2\n",
    "        #print(diff)\n",
    "        #pow = torch.pow(diff, 2)\n",
    "        #print(pow)\n",
    "        #dist_sq = torch.sum(pow, 1)\n",
    "        #print(dist_sq) # sum of squared distance = 0.5 = 9\n",
    "        #euclidean_distance = torch.sqrt(dist_sq)\n",
    "        #print(dist) # euclidean distance = 0.7 = 3\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        label = data.y\n",
    "\n",
    "        if int(label) == 1: \n",
    "            distances_lab1.append(float(euclidean_distance))\n",
    "            labels.append(int(label))\n",
    "            losses.append(float(test_loss_contrastive))\n",
    "        else:\n",
    "            distances_lab0.append(float(euclidean_distance))\n",
    "            labels.append(int(label))\n",
    "            losses.append(float(test_loss_contrastive))\n",
    "\n",
    "    return  distances_lab0, distances_lab1, losses, labels\n",
    "\n",
    "\n",
    "\n",
    "train_distances_lab0 = []\n",
    "train_distances_lab1 = []\n",
    "train_losses = []\n",
    "train_labels = []\n",
    "\n",
    "validation_distances_lab0 = []\n",
    "validation_distances_lab1 = []\n",
    "validation_losses = []\n",
    "validation_labels = []\n",
    "\n",
    "test_distances_lab0 = []\n",
    "test_distances_lab1 = []\n",
    "test_losses = []\n",
    "test_labels = []\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    train_loss = train(epoch)\n",
    "\n",
    "    train_results = test(train_loader,epoch)\n",
    "    train_distances_lab0.append(train_results[0])\n",
    "    train_distances_lab1.append(train_results[1])\n",
    "    train_losses.append(train_results[2])\n",
    "    train_labels.append(train_results[3])\n",
    "\n",
    "\n",
    "    validation_results = test(val_loader,epoch)\n",
    "    validation_distances_lab0.append(validation_results[0])\n",
    "    validation_distances_lab1.append(validation_results[1])\n",
    "    validation_losses.append(validation_results[2])\n",
    "    validation_labels.append(validation_results[3])\n",
    "\n",
    "    test_results = test(test_loader,epoch)\n",
    "    test_distances_lab0.append(test_results[0])\n",
    "    test_distances_lab1.append(test_results[1])\n",
    "    test_losses.append(test_results[2])\n",
    "    test_labels.append(test_results[3])\n",
    "\n",
    "\n",
    "    print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.3f}')\n",
    "    #Train Acc: {train_acc:.3f}, f'Val Acc: {val_acc:.3f}, Test Acc: {test_acc:.3f}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compare_euclid_distances(distances_lab0, distances_lab1):\n",
    "\n",
    "    w = 0.8    # bar width\n",
    "    x = [1, 2] # x-coordinates of your bars\n",
    "    colors = [(0, 0, 1, 1), (1, 0, 0, 1)]    # corresponding colors\n",
    "\n",
    "    # Epoch 0\n",
    "    y = [distances_lab0, distances_lab1]\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(x,\n",
    "        height=[np.mean(yi) for yi in y],\n",
    "        yerr=[np.std(yi) for yi in y],    # error bars\n",
    "        capsize=12, # error bar cap width in points\n",
    "        width=w,    # bar width\n",
    "        tick_label=[\"Label 0\", \"Label 1\"],\n",
    "        color=(0,0,0,0),  # face color transparent\n",
    "        edgecolor=colors,\n",
    "        )\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        # distribute scatter randomly across whole width of bar\n",
    "        ax.scatter(x[i] + np.random.random(len(y[i])) * w - w / 2, y[i], color=colors[i])\n",
    "\n",
    "    plt.ylabel = 'Euclidean Distance'\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_euclid_distances(train_distances_lab0[0], train_distances_lab1[0])\n",
    "compare_euclid_distances(train_distances_lab0[15], train_distances_lab1[15])\n",
    "\n",
    "compare_euclid_distances(train_distances_lab0[18], train_distances_lab1[18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "gnn1_pool.conv1.bias \t torch.Size([16])\n",
      "gnn1_pool.conv1.lin.weight \t torch.Size([16, 3])\n",
      "gnn1_pool.bns1.weight \t torch.Size([100])\n",
      "gnn1_pool.bns1.bias \t torch.Size([100])\n",
      "gnn1_pool.bns1.running_mean \t torch.Size([100])\n",
      "gnn1_pool.bns1.running_var \t torch.Size([100])\n",
      "gnn1_pool.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn1_pool.conv2.bias \t torch.Size([16])\n",
      "gnn1_pool.conv2.lin.weight \t torch.Size([16, 16])\n",
      "gnn1_pool.bns2.weight \t torch.Size([100])\n",
      "gnn1_pool.bns2.bias \t torch.Size([100])\n",
      "gnn1_pool.bns2.running_mean \t torch.Size([100])\n",
      "gnn1_pool.bns2.running_var \t torch.Size([100])\n",
      "gnn1_pool.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn1_pool.conv3.bias \t torch.Size([25])\n",
      "gnn1_pool.conv3.lin.weight \t torch.Size([25, 16])\n",
      "gnn1_pool.bns3.weight \t torch.Size([100])\n",
      "gnn1_pool.bns3.bias \t torch.Size([100])\n",
      "gnn1_pool.bns3.running_mean \t torch.Size([100])\n",
      "gnn1_pool.bns3.running_var \t torch.Size([100])\n",
      "gnn1_pool.bns3.num_batches_tracked \t torch.Size([])\n",
      "gnn1_embed.conv1.bias \t torch.Size([8])\n",
      "gnn1_embed.conv1.lin.weight \t torch.Size([8, 3])\n",
      "gnn1_embed.bns1.weight \t torch.Size([100])\n",
      "gnn1_embed.bns1.bias \t torch.Size([100])\n",
      "gnn1_embed.bns1.running_mean \t torch.Size([100])\n",
      "gnn1_embed.bns1.running_var \t torch.Size([100])\n",
      "gnn1_embed.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn1_embed.conv2.bias \t torch.Size([8])\n",
      "gnn1_embed.conv2.lin.weight \t torch.Size([8, 8])\n",
      "gnn1_embed.bns2.weight \t torch.Size([100])\n",
      "gnn1_embed.bns2.bias \t torch.Size([100])\n",
      "gnn1_embed.bns2.running_mean \t torch.Size([100])\n",
      "gnn1_embed.bns2.running_var \t torch.Size([100])\n",
      "gnn1_embed.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn1_embed.conv3.bias \t torch.Size([8])\n",
      "gnn1_embed.conv3.lin.weight \t torch.Size([8, 8])\n",
      "gnn1_embed.bns3.weight \t torch.Size([100])\n",
      "gnn1_embed.bns3.bias \t torch.Size([100])\n",
      "gnn1_embed.bns3.running_mean \t torch.Size([100])\n",
      "gnn1_embed.bns3.running_var \t torch.Size([100])\n",
      "gnn1_embed.bns3.num_batches_tracked \t torch.Size([])\n",
      "gnn2_pool.conv1.bias \t torch.Size([8])\n",
      "gnn2_pool.conv1.lin.weight \t torch.Size([8, 8])\n",
      "gnn2_pool.bns1.weight \t torch.Size([25])\n",
      "gnn2_pool.bns1.bias \t torch.Size([25])\n",
      "gnn2_pool.bns1.running_mean \t torch.Size([25])\n",
      "gnn2_pool.bns1.running_var \t torch.Size([25])\n",
      "gnn2_pool.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn2_pool.conv2.bias \t torch.Size([8])\n",
      "gnn2_pool.conv2.lin.weight \t torch.Size([8, 8])\n",
      "gnn2_pool.bns2.weight \t torch.Size([25])\n",
      "gnn2_pool.bns2.bias \t torch.Size([25])\n",
      "gnn2_pool.bns2.running_mean \t torch.Size([25])\n",
      "gnn2_pool.bns2.running_var \t torch.Size([25])\n",
      "gnn2_pool.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn2_pool.conv3.bias \t torch.Size([10])\n",
      "gnn2_pool.conv3.lin.weight \t torch.Size([10, 8])\n",
      "gnn2_pool.bns3.weight \t torch.Size([25])\n",
      "gnn2_pool.bns3.bias \t torch.Size([25])\n",
      "gnn2_pool.bns3.running_mean \t torch.Size([25])\n",
      "gnn2_pool.bns3.running_var \t torch.Size([25])\n",
      "gnn2_pool.bns3.num_batches_tracked \t torch.Size([])\n",
      "gnn2_embed.conv1.bias \t torch.Size([12])\n",
      "gnn2_embed.conv1.lin.weight \t torch.Size([12, 8])\n",
      "gnn2_embed.bns1.weight \t torch.Size([25])\n",
      "gnn2_embed.bns1.bias \t torch.Size([25])\n",
      "gnn2_embed.bns1.running_mean \t torch.Size([25])\n",
      "gnn2_embed.bns1.running_var \t torch.Size([25])\n",
      "gnn2_embed.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn2_embed.conv2.bias \t torch.Size([12])\n",
      "gnn2_embed.conv2.lin.weight \t torch.Size([12, 12])\n",
      "gnn2_embed.bns2.weight \t torch.Size([25])\n",
      "gnn2_embed.bns2.bias \t torch.Size([25])\n",
      "gnn2_embed.bns2.running_mean \t torch.Size([25])\n",
      "gnn2_embed.bns2.running_var \t torch.Size([25])\n",
      "gnn2_embed.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn2_embed.conv3.bias \t torch.Size([16])\n",
      "gnn2_embed.conv3.lin.weight \t torch.Size([16, 12])\n",
      "gnn2_embed.bns3.weight \t torch.Size([25])\n",
      "gnn2_embed.bns3.bias \t torch.Size([25])\n",
      "gnn2_embed.bns3.running_mean \t torch.Size([25])\n",
      "gnn2_embed.bns3.running_var \t torch.Size([25])\n",
      "gnn2_embed.bns3.num_batches_tracked \t torch.Size([])\n",
      "gnn3_pool.conv1.bias \t torch.Size([16])\n",
      "gnn3_pool.conv1.lin.weight \t torch.Size([16, 16])\n",
      "gnn3_pool.bns1.weight \t torch.Size([10])\n",
      "gnn3_pool.bns1.bias \t torch.Size([10])\n",
      "gnn3_pool.bns1.running_mean \t torch.Size([10])\n",
      "gnn3_pool.bns1.running_var \t torch.Size([10])\n",
      "gnn3_pool.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn3_pool.conv2.bias \t torch.Size([16])\n",
      "gnn3_pool.conv2.lin.weight \t torch.Size([16, 16])\n",
      "gnn3_pool.bns2.weight \t torch.Size([10])\n",
      "gnn3_pool.bns2.bias \t torch.Size([10])\n",
      "gnn3_pool.bns2.running_mean \t torch.Size([10])\n",
      "gnn3_pool.bns2.running_var \t torch.Size([10])\n",
      "gnn3_pool.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn3_pool.conv3.bias \t torch.Size([1])\n",
      "gnn3_pool.conv3.lin.weight \t torch.Size([1, 16])\n",
      "gnn3_pool.bns3.weight \t torch.Size([10])\n",
      "gnn3_pool.bns3.bias \t torch.Size([10])\n",
      "gnn3_pool.bns3.running_mean \t torch.Size([10])\n",
      "gnn3_pool.bns3.running_var \t torch.Size([10])\n",
      "gnn3_pool.bns3.num_batches_tracked \t torch.Size([])\n",
      "gnn3_embed.conv1.bias \t torch.Size([16])\n",
      "gnn3_embed.conv1.lin.weight \t torch.Size([16, 16])\n",
      "gnn3_embed.bns1.weight \t torch.Size([10])\n",
      "gnn3_embed.bns1.bias \t torch.Size([10])\n",
      "gnn3_embed.bns1.running_mean \t torch.Size([10])\n",
      "gnn3_embed.bns1.running_var \t torch.Size([10])\n",
      "gnn3_embed.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn3_embed.conv2.bias \t torch.Size([16])\n",
      "gnn3_embed.conv2.lin.weight \t torch.Size([16, 16])\n",
      "gnn3_embed.bns2.weight \t torch.Size([10])\n",
      "gnn3_embed.bns2.bias \t torch.Size([10])\n",
      "gnn3_embed.bns2.running_mean \t torch.Size([10])\n",
      "gnn3_embed.bns2.running_var \t torch.Size([10])\n",
      "gnn3_embed.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn3_embed.conv3.bias \t torch.Size([32])\n",
      "gnn3_embed.conv3.lin.weight \t torch.Size([32, 16])\n",
      "gnn3_embed.bns3.weight \t torch.Size([10])\n",
      "gnn3_embed.bns3.bias \t torch.Size([10])\n",
      "gnn3_embed.bns3.running_mean \t torch.Size([10])\n",
      "gnn3_embed.bns3.running_var \t torch.Size([10])\n",
      "gnn3_embed.bns3.num_batches_tracked \t torch.Size([])\n",
      "lin1.weight \t torch.Size([64, 32])\n",
      "lin1.bias \t torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer's state_dict:\n",
      "state \t {0: {'step': tensor(11460.), 'exp_avg': tensor([ 0.0658,  0.0076,  0.0389, -0.0253,  0.0990,  0.0520,  0.0503, -0.0491,\n",
      "        -0.0395, -0.0155, -0.0820, -0.0177, -0.0692,  0.0048, -0.0068, -0.0135]), 'exp_avg_sq': tensor([ 22.0002,  45.0519,   6.4269,  26.2561,  17.3186,   3.3813,  12.4738,\n",
      "         43.8868, 125.1155,  12.9709,   8.3535,  14.4690,  51.9212,  53.7534,\n",
      "         68.8813,  13.8181])}, 1: {'step': tensor(11460.), 'exp_avg': tensor([[ 1.2526e-02, -2.1164e-03,  1.9209e-02],\n",
      "        [ 3.9082e-03, -1.6521e-03,  2.7305e-02],\n",
      "        [ 8.9222e-03, -7.6375e-04, -3.3584e-03],\n",
      "        [ 1.3559e-02, -1.7452e-03, -3.7313e-02],\n",
      "        [-9.5011e-04, -2.1945e-03,  2.7755e-02],\n",
      "        [ 5.5920e-03, -1.5507e-03,  1.8670e-03],\n",
      "        [ 1.2500e-02, -2.1825e-03, -1.9066e-02],\n",
      "        [-2.5711e-02,  2.4312e-03,  3.1771e-02],\n",
      "        [-2.2250e-02,  3.8344e-03,  9.9084e-03],\n",
      "        [ 4.5129e-03,  2.1123e-04,  1.5128e-02],\n",
      "        [-1.2023e-02,  1.7924e-03,  1.1589e-02],\n",
      "        [ 9.6230e-04, -1.7543e-05, -1.5216e-02],\n",
      "        [-1.9780e-02,  3.9446e-03,  1.3169e-02],\n",
      "        [ 1.3376e-02, -1.2508e-03, -7.2255e-03],\n",
      "        [-1.3821e-03, -3.2688e-04, -4.4219e-02],\n",
      "        [ 6.2377e-03,  1.5865e-03, -3.1305e-02]]), 'exp_avg_sq': tensor([[0.0541, 0.0115, 1.1394],\n",
      "        [0.0538, 0.0136, 1.3938],\n",
      "        [0.0383, 0.0044, 0.1888],\n",
      "        [0.0945, 0.0119, 0.3721],\n",
      "        [0.0364, 0.0062, 0.6299],\n",
      "        [0.0195, 0.0024, 0.4282],\n",
      "        [0.0923, 0.0061, 0.3629],\n",
      "        [0.3609, 0.0339, 0.6928],\n",
      "        [0.3177, 0.0492, 1.6510],\n",
      "        [0.0310, 0.0058, 0.1740],\n",
      "        [0.0311, 0.0039, 0.5122],\n",
      "        [0.0294, 0.0041, 0.8457],\n",
      "        [0.1603, 0.0257, 1.8455],\n",
      "        [0.1449, 0.0207, 0.7124],\n",
      "        [0.0952, 0.0245, 0.8485],\n",
      "        [0.0424, 0.0035, 1.7722]])}, 2: {'step': tensor(11460.), 'exp_avg': tensor([-8.2779e-04,  1.7618e-04,  3.9060e-04, -1.4781e-04,  6.3402e-04,\n",
      "        -4.4637e-04,  1.8933e-05,  5.2657e-06, -2.4699e-05,  1.6059e-05,\n",
      "         1.2148e-04,  5.5725e-04, -9.6230e-06, -2.6075e-04,  2.5390e-05,\n",
      "         4.1558e-04,  6.2128e-06,  6.4266e-05, -1.7935e-04, -5.4187e-04,\n",
      "        -1.6792e-04,  1.5172e-04,  1.2854e-04, -2.1070e-04, -1.6665e-04,\n",
      "         1.7031e-05,  1.8563e-04,  2.7759e-04, -1.7617e-04, -3.2815e-04,\n",
      "        -3.5996e-04,  2.0539e-04, -8.1343e-04, -9.3481e-05, -2.0492e-04,\n",
      "        -1.0161e-04, -2.6649e-04, -3.4039e-04, -2.3897e-04, -4.1123e-04,\n",
      "        -1.7199e-04,  9.0276e-05, -1.0308e-04,  3.3871e-04,  1.7086e-04,\n",
      "        -1.8052e-04, -1.9348e-04,  6.2550e-05,  6.3816e-05, -1.8816e-04,\n",
      "        -9.4895e-05, -1.2782e-04, -2.2214e-04, -1.9161e-04,  2.4425e-04,\n",
      "        -2.2640e-05,  5.5204e-05,  1.6937e-04, -5.7798e-04,  2.6771e-04,\n",
      "         1.9213e-05,  7.0640e-06,  4.4479e-04,  3.6010e-04,  5.9625e-04,\n",
      "         2.2343e-04, -1.0428e-04,  4.8755e-04, -2.5958e-04,  2.7176e-04,\n",
      "         1.2586e-04, -4.4892e-04, -2.9558e-05, -2.5335e-04,  5.4902e-04,\n",
      "         4.8611e-04, -9.0397e-05,  9.3985e-05, -1.0319e-04, -2.1262e-05,\n",
      "         8.4867e-05, -2.1487e-04, -1.0134e-05, -3.0263e-06,  7.7325e-05,\n",
      "         1.6771e-04,  2.5040e-04,  2.7373e-05, -9.5880e-05, -8.2451e-05,\n",
      "         1.0547e-05,  1.9458e-04,  1.4854e-04,  4.3639e-04, -2.0462e-04,\n",
      "        -4.0341e-04,  2.9280e-04,  2.5641e-04,  1.4026e-04, -9.8084e-05]), 'exp_avg_sq': tensor([1.5370e-04, 7.4700e-05, 1.4798e-04, 4.5443e-05, 1.1048e-04, 1.6148e-04,\n",
      "        1.5899e-04, 9.2448e-05, 7.3790e-05, 4.4079e-04, 1.6823e-04, 2.7002e-04,\n",
      "        5.3207e-04, 2.3063e-04, 1.7401e-04, 9.8808e-05, 8.8087e-05, 1.2231e-04,\n",
      "        9.9908e-05, 1.5374e-04, 2.3455e-04, 1.3633e-04, 1.8131e-04, 2.8581e-04,\n",
      "        1.6824e-04, 2.7280e-04, 2.1854e-04, 1.5339e-04, 9.9062e-05, 2.1507e-04,\n",
      "        2.4960e-04, 8.7648e-05, 2.1044e-04, 2.3277e-04, 1.8053e-04, 2.2169e-04,\n",
      "        1.0774e-04, 1.0601e-04, 1.8529e-04, 1.8087e-04, 2.0334e-04, 1.0040e-03,\n",
      "        1.0989e-04, 5.0792e-04, 2.3860e-04, 2.2159e-04, 1.6716e-04, 1.5085e-04,\n",
      "        6.1049e-05, 2.2196e-04, 1.8270e-04, 1.5353e-04, 1.3941e-04, 2.4331e-04,\n",
      "        9.9266e-05, 9.3178e-05, 6.8549e-05, 8.5442e-05, 1.2596e-04, 9.9547e-05,\n",
      "        1.3511e-04, 2.4843e-04, 1.4765e-04, 2.7763e-04, 1.6071e-04, 1.6350e-04,\n",
      "        1.5794e-04, 2.2077e-04, 7.2002e-05, 1.4654e-04, 1.1642e-04, 1.7998e-04,\n",
      "        3.8527e-04, 2.1516e-04, 1.4728e-04, 3.1852e-04, 2.1954e-04, 3.5895e-04,\n",
      "        3.4988e-04, 6.4822e-05, 1.8546e-04, 1.3261e-04, 2.6280e-04, 4.5877e-04,\n",
      "        2.3447e-04, 1.9088e-04, 2.0624e-04, 5.6453e-04, 7.9001e-05, 2.4897e-04,\n",
      "        1.4938e-04, 2.1684e-04, 2.4965e-04, 2.0701e-04, 2.5290e-04, 1.9148e-04,\n",
      "        1.5298e-04, 2.8733e-04, 2.1409e-04, 2.1001e-04])}, 3: {'step': tensor(11460.), 'exp_avg': tensor([ 6.0045e-04, -9.4185e-05, -2.0333e-04,  3.2730e-04, -4.9029e-04,\n",
      "        -3.2737e-04, -7.2943e-04,  2.0655e-05,  1.1811e-04, -4.6924e-04,\n",
      "         2.4339e-04, -9.9856e-05, -5.9515e-05,  1.2112e-03, -3.2882e-04,\n",
      "         1.2803e-03,  6.6798e-04, -1.8552e-05,  6.6016e-04, -8.7472e-05,\n",
      "        -4.5517e-04,  7.8167e-04, -2.7463e-04, -8.1051e-04,  6.7601e-04,\n",
      "        -1.1634e-03,  2.1238e-04,  7.8796e-04,  2.5067e-04,  8.6729e-05,\n",
      "        -6.4025e-04, -4.8151e-04, -5.0614e-05,  7.7118e-04, -3.6081e-04,\n",
      "        -5.4117e-04, -5.7789e-04,  8.4883e-04, -4.8508e-05,  7.5622e-04,\n",
      "         1.3978e-03, -2.3370e-04,  7.2866e-04,  4.0553e-04,  7.5816e-05,\n",
      "        -9.5120e-04,  8.7112e-04,  2.0299e-04,  5.7652e-04,  6.5464e-04,\n",
      "         4.3590e-04, -7.0554e-04,  3.6612e-05,  4.8370e-04, -5.5128e-04,\n",
      "         8.4047e-04, -5.7762e-04, -2.4379e-04, -7.1306e-04,  1.6414e-03,\n",
      "        -4.5655e-04,  6.4137e-04, -8.4633e-05,  9.5683e-05, -1.5526e-04,\n",
      "         1.9780e-04, -3.4081e-04, -1.7557e-04, -9.1874e-04, -9.4219e-05,\n",
      "        -5.6394e-04, -1.2067e-05, -3.1030e-04,  1.0425e-03,  4.4531e-04,\n",
      "         1.2562e-03, -7.5219e-04, -4.3759e-04, -4.9387e-05,  9.0168e-04,\n",
      "         5.6605e-04,  1.4474e-04,  7.5084e-05,  5.7898e-04,  6.9691e-04,\n",
      "        -5.9531e-05, -8.2292e-04, -2.3274e-04,  3.3121e-04,  1.1373e-03,\n",
      "        -2.8509e-04,  9.9330e-04,  9.3564e-04,  1.8502e-03, -1.0151e-04,\n",
      "        -1.3180e-04, -5.8762e-04,  8.0331e-05,  2.4063e-04,  2.1069e-04]), 'exp_avg_sq': tensor([0.0005, 0.0004, 0.0005, 0.0006, 0.0007, 0.0011, 0.0007, 0.0004, 0.0008,\n",
      "        0.0006, 0.0008, 0.0016, 0.0018, 0.0007, 0.0005, 0.0005, 0.0008, 0.0005,\n",
      "        0.0005, 0.0007, 0.0006, 0.0005, 0.0005, 0.0013, 0.0010, 0.0017, 0.0005,\n",
      "        0.0006, 0.0011, 0.0007, 0.0007, 0.0005, 0.0010, 0.0011, 0.0006, 0.0009,\n",
      "        0.0007, 0.0005, 0.0010, 0.0018, 0.0007, 0.0007, 0.0008, 0.0016, 0.0010,\n",
      "        0.0010, 0.0010, 0.0005, 0.0006, 0.0006, 0.0009, 0.0006, 0.0010, 0.0009,\n",
      "        0.0008, 0.0006, 0.0010, 0.0008, 0.0008, 0.0010, 0.0006, 0.0005, 0.0005,\n",
      "        0.0006, 0.0010, 0.0006, 0.0007, 0.0011, 0.0009, 0.0009, 0.0008, 0.0013,\n",
      "        0.0010, 0.0009, 0.0013, 0.0009, 0.0007, 0.0007, 0.0009, 0.0008, 0.0007,\n",
      "        0.0004, 0.0011, 0.0008, 0.0014, 0.0008, 0.0015, 0.0007, 0.0007, 0.0006,\n",
      "        0.0009, 0.0010, 0.0005, 0.0009, 0.0010, 0.0006, 0.0006, 0.0011, 0.0020,\n",
      "        0.0008])}, 4: {'step': tensor(11460.), 'exp_avg': tensor([-0.0053, -0.0040,  0.0040, -0.0035, -0.0044, -0.0067, -0.0142,  0.0011,\n",
      "        -0.0050,  0.0044,  0.0168,  0.0089, -0.0082, -0.0128,  0.0141,  0.0147]), 'exp_avg_sq': tensor([0.3986, 0.2024, 0.1966, 0.0596, 0.2521, 0.1091, 0.2743, 0.1900, 0.5790,\n",
      "        0.3531, 0.7412, 0.0524, 0.1582, 0.1209, 0.4973, 0.3021])}, 5: {'step': tensor(11460.), 'exp_avg': tensor([[ 1.2710e-03, -3.1265e-04, -5.5755e-04, -1.7825e-03,  2.3247e-03,\n",
      "         -3.6470e-03,  1.4918e-03,  3.2104e-03, -3.2458e-03, -5.2334e-04,\n",
      "          2.4671e-03,  2.5401e-03, -1.9053e-03, -4.2422e-03,  1.6328e-03,\n",
      "          1.3115e-03],\n",
      "        [-3.6939e-03, -5.3202e-04,  1.7357e-03,  7.8384e-03, -8.5997e-03,\n",
      "          1.4290e-02, -7.2633e-03, -1.2188e-02,  1.4670e-02,  2.3158e-03,\n",
      "         -9.1726e-03, -9.5626e-03,  7.6864e-03,  1.4414e-02, -6.7851e-03,\n",
      "         -5.3458e-03],\n",
      "        [ 2.7435e-03,  7.4831e-04, -1.5322e-03, -7.1102e-03,  8.4241e-03,\n",
      "         -1.3821e-02,  7.2639e-03,  1.1368e-02, -1.3904e-02, -2.3227e-03,\n",
      "          8.2377e-03,  8.5056e-03, -7.6879e-03, -1.3215e-02,  7.0310e-03,\n",
      "          5.4552e-03],\n",
      "        [-3.7655e-03, -1.7146e-04,  1.7916e-03,  7.8221e-03, -1.2367e-02,\n",
      "          1.8698e-02, -8.9846e-03, -1.4724e-02,  1.6865e-02,  2.5878e-03,\n",
      "         -1.0500e-02, -1.0094e-02,  1.1004e-02,  1.8569e-02, -9.5478e-03,\n",
      "         -7.4683e-03],\n",
      "        [-1.5683e-03,  1.9564e-04,  2.2982e-04,  1.9960e-03, -7.8186e-03,\n",
      "          9.9736e-03, -4.2590e-03, -6.6762e-03,  7.2169e-03,  6.0819e-04,\n",
      "         -4.4314e-03, -3.0851e-03,  6.9170e-03,  9.8368e-03, -5.2259e-03,\n",
      "         -4.1518e-03],\n",
      "        [ 3.4552e-03, -3.2519e-04, -2.2469e-03, -7.4952e-03,  8.9080e-03,\n",
      "         -1.4754e-02,  7.0451e-03,  1.2643e-02, -1.3824e-02, -2.7116e-03,\n",
      "          9.2191e-03,  9.8441e-03, -7.7400e-03, -1.5326e-02,  7.5283e-03,\n",
      "          5.8221e-03],\n",
      "        [-1.5096e-03, -3.3722e-03,  1.4213e-03,  8.6282e-03,  6.1468e-03,\n",
      "         -2.1373e-03, -2.3390e-03, -2.4604e-03,  7.9433e-03,  2.0082e-03,\n",
      "         -3.4839e-03, -7.3187e-03, -4.6716e-03, -3.4597e-03,  2.4627e-03,\n",
      "          1.9964e-03],\n",
      "        [-1.7342e-03, -7.8937e-04,  1.3343e-03,  5.0036e-03,  2.1549e-03,\n",
      "          4.4111e-04, -1.2662e-03, -2.8906e-03,  4.6669e-03,  1.3293e-03,\n",
      "         -3.0928e-03, -5.2240e-03, -1.8432e-03,  9.1724e-04,  6.4348e-04,\n",
      "          5.1690e-04],\n",
      "        [-3.6057e-03, -2.2608e-03,  2.8035e-03,  1.1966e-02, -8.3283e-04,\n",
      "          7.9995e-03, -6.3908e-03, -1.0468e-02,  1.5353e-02,  3.5029e-03,\n",
      "         -9.0163e-03, -1.2645e-02,  1.1822e-03,  7.5687e-03, -2.9772e-03,\n",
      "         -2.2228e-03],\n",
      "        [ 1.6884e-03,  1.0273e-04, -1.2352e-03, -5.6174e-03,  1.6455e-02,\n",
      "         -2.2517e-02,  1.0672e-02,  1.5406e-02, -1.7059e-02, -2.6934e-03,\n",
      "          9.6060e-03,  7.7619e-03, -1.4922e-02, -2.0570e-02,  1.3129e-02,\n",
      "          1.0068e-02],\n",
      "        [ 5.2166e-03,  3.3993e-03, -2.6809e-03, -1.3601e-02, -7.5034e-03,\n",
      "          1.3028e-03,  2.8466e-03,  5.9960e-03, -1.2569e-02, -2.6494e-03,\n",
      "          7.7151e-03,  1.3197e-02,  6.2608e-03,  3.2224e-04, -4.0478e-03,\n",
      "         -2.9829e-03],\n",
      "        [-1.0390e-04,  4.1702e-05,  9.4136e-04,  2.2116e-03, -1.5785e-03,\n",
      "          3.4736e-03, -1.9913e-03, -3.2110e-03,  3.3898e-03,  1.2457e-03,\n",
      "         -2.0681e-03, -2.7886e-03,  1.4454e-03,  3.1180e-03, -2.3631e-03,\n",
      "         -1.6783e-03],\n",
      "        [-2.7304e-03, -1.6578e-03,  1.2250e-03,  6.6119e-03,  3.3758e-03,\n",
      "         -3.9430e-04, -1.4244e-03, -3.0271e-03,  6.3076e-03,  1.1800e-03,\n",
      "         -3.8912e-03, -6.4100e-03, -2.8049e-03,  1.7063e-04,  1.9931e-03,\n",
      "          1.4330e-03],\n",
      "        [ 2.9996e-04, -2.2933e-03,  5.2743e-04,  4.1097e-03,  3.7290e-03,\n",
      "         -1.7836e-03, -1.4194e-03, -4.2405e-04,  3.7406e-03,  1.1474e-03,\n",
      "         -8.7536e-04, -2.9188e-03, -2.6598e-03, -3.5145e-03,  1.1045e-03,\n",
      "          9.9956e-04],\n",
      "        [-1.6422e-03,  2.1827e-03,  9.3529e-04,  1.3921e-03, -1.6362e-02,\n",
      "          1.9944e-02, -7.4538e-03, -1.2595e-02,  1.0647e-02,  1.5442e-03,\n",
      "         -7.3304e-03, -4.4653e-03,  1.4120e-02,  2.0074e-02, -1.1868e-02,\n",
      "         -9.1748e-03],\n",
      "        [ 5.6787e-03,  5.0445e-03, -4.6926e-03, -2.1974e-02,  3.5434e-03,\n",
      "         -1.7069e-02,  1.3473e-02,  2.0040e-02, -3.0198e-02, -6.5691e-03,\n",
      "          1.6618e-02,  2.2664e-02, -4.3803e-03, -1.4663e-02,  7.2902e-03,\n",
      "          5.4222e-03]]), 'exp_avg_sq': tensor([[8.3751e-03, 1.5397e-03, 2.3911e-03, 2.9236e-02, 1.4224e-01, 2.6123e-01,\n",
      "         5.0228e-02, 1.2590e-01, 1.3335e-01, 5.7066e-03, 4.9161e-02, 4.7861e-02,\n",
      "         1.1407e-01, 2.3266e-01, 1.0131e-01, 5.8386e-02],\n",
      "        [1.0245e-02, 9.7704e-04, 4.5657e-03, 5.6667e-02, 2.3010e-01, 4.8255e-01,\n",
      "         1.0037e-01, 2.6517e-01, 2.9904e-01, 1.0343e-02, 1.1196e-01, 1.0398e-01,\n",
      "         1.8427e-01, 4.5233e-01, 1.5956e-01, 9.3374e-02],\n",
      "        [1.1106e-02, 9.4639e-04, 4.7092e-03, 5.8127e-02, 2.2108e-01, 4.7234e-01,\n",
      "         9.9444e-02, 2.6195e-01, 2.9635e-01, 1.0719e-02, 1.1108e-01, 1.0574e-01,\n",
      "         1.7744e-01, 4.3899e-01, 1.5948e-01, 9.3026e-02],\n",
      "        [5.1529e-03, 4.9615e-04, 2.1453e-03, 3.0009e-02, 1.0219e-01, 2.1605e-01,\n",
      "         4.7625e-02, 1.1874e-01, 1.4216e-01, 5.1670e-03, 5.0246e-02, 4.9982e-02,\n",
      "         8.3610e-02, 1.9479e-01, 7.3475e-02, 4.2616e-02],\n",
      "        [4.8751e-03, 1.1215e-03, 2.0245e-03, 2.4481e-02, 1.0272e-01, 2.0141e-01,\n",
      "         4.0882e-02, 1.0422e-01, 1.1655e-01, 4.8107e-03, 4.2166e-02, 4.0978e-02,\n",
      "         8.2401e-02, 1.8456e-01, 7.0777e-02, 4.1276e-02],\n",
      "        [1.3488e-02, 9.9786e-04, 2.3701e-03, 4.4228e-02, 1.5990e-01, 2.9792e-01,\n",
      "         6.4836e-02, 1.5507e-01, 1.9425e-01, 5.3682e-03, 7.0807e-02, 6.8726e-02,\n",
      "         1.3057e-01, 2.7275e-01, 1.0188e-01, 5.8781e-02],\n",
      "        [9.1889e-03, 1.6472e-03, 1.9735e-03, 3.5767e-02, 4.4723e-01, 7.3774e-01,\n",
      "         1.5631e-01, 3.1146e-01, 3.5616e-01, 9.1058e-03, 1.1055e-01, 6.8142e-02,\n",
      "         3.6881e-01, 6.2714e-01, 2.7151e-01, 1.5494e-01],\n",
      "        [1.1814e-02, 1.1866e-03, 2.7479e-03, 4.6338e-02, 2.1560e-01, 3.9897e-01,\n",
      "         8.8930e-02, 1.9682e-01, 2.4353e-01, 7.5245e-03, 8.3205e-02, 7.4136e-02,\n",
      "         1.7723e-01, 3.4843e-01, 1.3955e-01, 8.0420e-02],\n",
      "        [1.6742e-02, 2.8587e-03, 1.6462e-03, 3.2992e-02, 1.1820e-01, 1.7449e-01,\n",
      "         3.6106e-02, 6.9232e-02, 8.9459e-02, 4.1615e-03, 3.0711e-02, 3.7781e-02,\n",
      "         9.6307e-02, 1.4026e-01, 8.1747e-02, 4.5796e-02],\n",
      "        [8.6635e-03, 1.6292e-03, 5.2554e-03, 5.7465e-02, 2.9860e-01, 6.1296e-01,\n",
      "         1.2452e-01, 3.1936e-01, 3.4438e-01, 1.3526e-02, 1.2376e-01, 1.1010e-01,\n",
      "         2.3993e-01, 5.5647e-01, 2.1593e-01, 1.2567e-01],\n",
      "        [2.7549e-02, 4.5055e-03, 2.2055e-03, 4.6900e-02, 1.9067e-01, 2.4597e-01,\n",
      "         4.3585e-02, 7.4036e-02, 7.9063e-02, 5.2514e-03, 2.7866e-02, 4.7097e-02,\n",
      "         1.5554e-01, 1.7677e-01, 1.4225e-01, 7.8335e-02],\n",
      "        [2.0723e-03, 4.3775e-04, 8.7670e-04, 1.0910e-02, 6.0702e-02, 1.1908e-01,\n",
      "         2.3946e-02, 5.9901e-02, 6.5408e-02, 2.4795e-03, 2.2952e-02, 1.9973e-02,\n",
      "         4.8943e-02, 1.0796e-01, 4.2208e-02, 2.4540e-02],\n",
      "        [2.8961e-02, 1.5199e-03, 5.9808e-03, 1.0362e-01, 3.3319e-01, 6.4756e-01,\n",
      "         1.4083e-01, 3.5519e-01, 4.4073e-01, 1.2083e-02, 1.6832e-01, 1.6618e-01,\n",
      "         2.6878e-01, 6.0893e-01, 2.1067e-01, 1.2284e-01],\n",
      "        [6.7390e-03, 1.8230e-03, 1.8187e-03, 2.7786e-02, 3.2599e-01, 5.5997e-01,\n",
      "         1.0898e-01, 2.4450e-01, 2.6015e-01, 7.4726e-03, 8.7053e-02, 5.6313e-02,\n",
      "         2.6348e-01, 4.9401e-01, 2.0371e-01, 1.1831e-01],\n",
      "        [1.1010e-02, 2.2013e-03, 2.1658e-03, 2.7552e-02, 1.6462e-01, 2.8648e-01,\n",
      "         5.4490e-02, 1.2593e-01, 1.2961e-01, 6.1179e-03, 4.5213e-02, 4.3173e-02,\n",
      "         1.3329e-01, 2.4412e-01, 1.2015e-01, 6.8720e-02],\n",
      "        [2.5236e-02, 4.4053e-03, 5.0665e-03, 8.5524e-02, 5.2145e-01, 8.7627e-01,\n",
      "         1.8511e-01, 3.8061e-01, 4.3933e-01, 1.6203e-02, 1.3983e-01, 1.2603e-01,\n",
      "         4.3040e-01, 7.2506e-01, 3.5306e-01, 1.9944e-01]])}, 6: {'step': tensor(11460.), 'exp_avg': tensor([-2.4099e-04,  7.0326e-05,  2.2503e-04, -2.7476e-04,  5.7040e-04,\n",
      "        -2.6637e-04, -2.7748e-04,  2.5093e-05,  1.3930e-04,  1.9076e-04,\n",
      "         1.1137e-04,  3.2547e-04,  1.1377e-04, -4.4216e-05, -6.5807e-05,\n",
      "         2.3559e-04, -2.6152e-04, -1.6586e-05, -9.2900e-05, -4.4154e-04,\n",
      "        -5.4281e-05,  1.9209e-04,  8.5420e-05, -1.4574e-04,  2.0347e-05,\n",
      "         1.2821e-04,  4.1761e-05, -2.6357e-06, -2.9134e-04, -1.3921e-04,\n",
      "        -3.1530e-04,  2.3415e-04, -4.9526e-04, -1.3969e-04, -3.9230e-04,\n",
      "        -1.2413e-04, -1.9018e-04, -5.5180e-04, -1.6233e-04, -5.8822e-04,\n",
      "         4.0316e-04,  1.7136e-04,  1.9670e-04,  4.1077e-04,  1.6156e-04,\n",
      "        -2.5579e-04, -3.1540e-04,  6.8270e-06,  2.9619e-05, -2.7663e-04,\n",
      "         2.8819e-05, -2.5674e-04, -6.0422e-05, -1.0538e-04,  2.6990e-04,\n",
      "        -6.4603e-05,  1.6304e-04,  3.8146e-04, -7.6519e-04,  1.4323e-04,\n",
      "         2.5578e-04,  1.6706e-04,  3.7297e-04,  2.4605e-04,  2.8143e-04,\n",
      "         1.3092e-04,  1.6724e-04,  5.2919e-04, -5.4179e-04,  3.3192e-05,\n",
      "         7.7941e-05, -4.0964e-04, -3.6782e-05, -9.4913e-05,  6.0551e-04,\n",
      "         4.0169e-04,  9.9878e-05,  1.2662e-04, -4.9392e-05,  1.8063e-04,\n",
      "        -9.0332e-05, -2.5168e-04, -1.2314e-04,  2.7560e-04, -1.9213e-05,\n",
      "        -9.4652e-05,  1.3548e-04,  2.2603e-05,  1.0599e-04, -2.2339e-04,\n",
      "        -8.1072e-05,  1.9175e-04,  3.1056e-04,  2.9041e-04, -1.0823e-04,\n",
      "        -4.2320e-04,  1.5509e-04,  7.1654e-05, -1.1652e-04, -1.5313e-05]), 'exp_avg_sq': tensor([7.0124e-05, 8.7370e-05, 7.0638e-05, 7.3498e-05, 1.1684e-04, 2.5946e-04,\n",
      "        6.3355e-05, 6.9696e-05, 7.4052e-05, 1.8375e-04, 1.6601e-04, 1.1133e-04,\n",
      "        2.5868e-04, 1.1324e-04, 6.8961e-05, 6.8819e-05, 6.7990e-05, 8.5977e-05,\n",
      "        7.8301e-05, 8.2425e-05, 8.3809e-05, 1.7194e-04, 1.4511e-04, 1.8708e-04,\n",
      "        9.9818e-05, 2.1287e-04, 1.1134e-04, 1.1060e-04, 1.6841e-04, 1.4827e-04,\n",
      "        9.2209e-05, 7.8899e-05, 1.3378e-04, 1.5427e-04, 1.5286e-04, 1.1262e-04,\n",
      "        5.6698e-05, 9.3578e-05, 4.3154e-04, 2.5698e-04, 4.4040e-04, 1.6307e-04,\n",
      "        7.1944e-05, 3.1585e-04, 1.1324e-04, 1.1382e-04, 8.1548e-05, 1.1786e-04,\n",
      "        5.1350e-05, 1.6187e-04, 9.8595e-05, 1.2278e-04, 1.5222e-04, 9.6735e-05,\n",
      "        8.0271e-05, 5.6573e-05, 6.3772e-05, 1.5348e-04, 3.9505e-04, 1.7121e-04,\n",
      "        8.0920e-05, 1.2586e-04, 1.3289e-04, 1.3077e-04, 1.2650e-04, 9.0884e-05,\n",
      "        1.0905e-04, 1.9562e-04, 6.4535e-05, 1.0635e-04, 1.4296e-04, 1.1043e-04,\n",
      "        1.5694e-04, 1.1996e-04, 1.2371e-04, 1.2363e-04, 1.1895e-04, 9.3965e-05,\n",
      "        1.6233e-04, 7.8665e-05, 8.6442e-05, 6.8802e-05, 1.0148e-04, 1.5548e-04,\n",
      "        1.8475e-04, 1.3677e-04, 2.9635e-04, 1.4694e-04, 1.0857e-04, 1.7466e-04,\n",
      "        1.3879e-04, 7.4855e-05, 1.8421e-04, 1.0919e-04, 1.3959e-04, 8.5609e-05,\n",
      "        7.4826e-05, 1.1071e-04, 9.8538e-05, 1.2932e-04])}, 7: {'step': tensor(11460.), 'exp_avg': tensor([ 3.5801e-04,  2.4859e-04,  2.6454e-04, -5.9100e-04,  8.8831e-04,\n",
      "        -4.0783e-04,  7.0133e-05, -2.1528e-04, -3.5854e-04, -1.1825e-04,\n",
      "        -1.5206e-04, -3.1144e-04,  1.6499e-04, -5.6716e-04,  8.2729e-05,\n",
      "        -5.1259e-05, -3.5551e-04, -2.6531e-06, -1.2327e-04, -2.1698e-04,\n",
      "         4.3275e-05, -4.2047e-04,  2.4738e-04,  3.0759e-04, -2.3404e-04,\n",
      "        -2.0651e-04, -3.1051e-04, -8.4508e-04, -8.8647e-04, -4.0006e-04,\n",
      "        -3.0762e-04,  4.4381e-04, -4.7037e-04, -1.0522e-03,  2.1245e-04,\n",
      "         1.8805e-04,  2.4452e-05,  4.1107e-04, -4.1581e-04, -1.8282e-04,\n",
      "        -6.9366e-04,  6.5209e-06, -4.1363e-04,  5.2236e-05, -4.1008e-04,\n",
      "         7.7468e-05, -6.9713e-04, -2.7514e-04, -4.8872e-04, -3.7189e-04,\n",
      "         3.0370e-05, -6.6071e-04,  2.6575e-04, -6.7168e-04,  1.3135e-04,\n",
      "        -7.5359e-04,  1.5948e-04, -3.0445e-04, -1.0066e-04, -6.8814e-04,\n",
      "         8.3351e-05, -1.0483e-03,  2.5879e-04, -1.3352e-04, -5.8050e-04,\n",
      "         6.2394e-05, -9.1949e-06,  3.9725e-06, -5.1017e-04, -3.6794e-04,\n",
      "        -4.3864e-04, -2.9057e-04, -7.1886e-04, -2.1465e-04, -9.3728e-04,\n",
      "        -3.3080e-04, -2.3471e-04, -4.9745e-04, -3.2676e-05, -9.1306e-04,\n",
      "        -1.5799e-04, -6.8026e-04, -3.9080e-04, -8.1346e-04, -5.6991e-04,\n",
      "        -5.2756e-04,  2.5284e-04,  2.7930e-04, -2.5505e-04, -6.9929e-04,\n",
      "        -2.3443e-04, -6.1415e-04, -5.6320e-04, -7.5990e-04, -4.9050e-04,\n",
      "        -8.5753e-04, -6.0670e-04, -2.0997e-04, -1.8153e-04, -3.8959e-04]), 'exp_avg_sq': tensor([0.0003, 0.0004, 0.0005, 0.0005, 0.0004, 0.0005, 0.0003, 0.0003, 0.0005,\n",
      "        0.0002, 0.0003, 0.0008, 0.0006, 0.0005, 0.0004, 0.0003, 0.0007, 0.0003,\n",
      "        0.0004, 0.0005, 0.0004, 0.0002, 0.0004, 0.0004, 0.0004, 0.0007, 0.0004,\n",
      "        0.0003, 0.0005, 0.0005, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004,\n",
      "        0.0005, 0.0004, 0.0004, 0.0007, 0.0002, 0.0006, 0.0005, 0.0008, 0.0004,\n",
      "        0.0006, 0.0006, 0.0005, 0.0005, 0.0005, 0.0004, 0.0004, 0.0006, 0.0004,\n",
      "        0.0005, 0.0004, 0.0008, 0.0005, 0.0004, 0.0004, 0.0004, 0.0003, 0.0004,\n",
      "        0.0004, 0.0006, 0.0003, 0.0004, 0.0006, 0.0005, 0.0004, 0.0003, 0.0007,\n",
      "        0.0006, 0.0003, 0.0006, 0.0005, 0.0003, 0.0003, 0.0005, 0.0005, 0.0004,\n",
      "        0.0005, 0.0008, 0.0004, 0.0007, 0.0005, 0.0008, 0.0005, 0.0004, 0.0003,\n",
      "        0.0007, 0.0006, 0.0004, 0.0005, 0.0006, 0.0005, 0.0005, 0.0005, 0.0007,\n",
      "        0.0005])}, 8: {'step': tensor(11460.), 'exp_avg': tensor([-1.8097e-03, -2.7616e-03, -4.9231e-03, -8.6199e-03,  5.6367e-03,\n",
      "        -6.4083e-04, -6.2722e-04,  7.4366e-05,  6.9197e-03,  3.2573e-04,\n",
      "         1.2207e-03,  3.7236e-03, -1.6945e-03, -5.7631e-04,  3.8938e-04,\n",
      "         1.7409e-02, -1.6856e-04, -2.8079e-02,  1.7605e-03, -1.7780e-04,\n",
      "         2.9458e-04,  1.5050e-03,  1.2104e-02, -1.1728e-03, -1.1223e-04]), 'exp_avg_sq': tensor([0.1332, 0.0171, 0.1521, 0.0675, 0.0809, 0.0101, 0.0087, 0.0090, 0.0280,\n",
      "        0.0273, 0.0442, 0.8232, 0.0387, 0.0173, 0.0136, 0.3818, 0.0179, 0.2410,\n",
      "        0.0337, 0.0076, 0.0135, 0.0206, 0.0237, 0.0239, 0.0131])}, 9: {'step': tensor(11460.), 'exp_avg': tensor([[ 5.5569e-03,  6.5746e-03,  6.1478e-03, -4.0286e-03, -1.1189e-03,\n",
      "         -1.8449e-02,  8.2940e-03,  1.8580e-02, -1.2490e-02,  1.0764e-02,\n",
      "         -8.9348e-03, -9.5829e-03, -4.2396e-03, -2.1798e-03,  6.2980e-03,\n",
      "         -1.1819e-03],\n",
      "        [ 1.7872e-03,  1.9021e-03,  3.0611e-03, -6.1871e-03, -1.6118e-03,\n",
      "         -9.2075e-03,  5.7981e-03,  1.4561e-02, -7.3071e-03,  9.5792e-03,\n",
      "         -3.9435e-03, -2.8456e-03, -1.1789e-03, -6.4609e-03,  2.1465e-03,\n",
      "          2.9667e-05],\n",
      "        [ 6.0413e-04,  1.9437e-04, -8.2309e-04,  7.5556e-04, -1.5588e-03,\n",
      "         -3.4616e-05, -1.0168e-03,  3.4778e-04,  1.4177e-04,  8.7485e-04,\n",
      "         -2.5462e-04,  1.0645e-03,  4.7407e-04, -2.3979e-05,  6.4315e-04,\n",
      "         -1.1383e-03],\n",
      "        [ 6.2882e-03,  5.5562e-03,  4.7295e-03, -3.6521e-03, -2.8337e-03,\n",
      "         -1.5885e-02,  6.6373e-03,  1.7996e-02, -1.0890e-02,  1.1058e-02,\n",
      "         -9.1179e-03, -7.6221e-03, -3.4001e-03, -1.8532e-03,  5.1669e-03,\n",
      "         -1.9607e-03],\n",
      "        [-1.6492e-03, -6.6278e-04,  8.1990e-04, -4.0371e-03,  2.0266e-04,\n",
      "         -1.6044e-03,  2.5264e-03,  5.0190e-03, -1.9865e-03,  3.5650e-03,\n",
      "          8.9443e-04,  7.1081e-04,  3.8304e-04, -5.4004e-03, -2.9934e-05,\n",
      "          1.0423e-03],\n",
      "        [ 2.1365e-03,  2.0304e-03,  1.8451e-03, -4.6680e-04, -9.4178e-05,\n",
      "         -5.0421e-03,  2.1217e-03,  4.4170e-03, -3.2777e-03,  2.2200e-03,\n",
      "         -3.0776e-03, -3.3828e-03, -1.5239e-03,  8.3099e-04,  1.5571e-03,\n",
      "         -3.3792e-04],\n",
      "        [ 1.3560e-03,  1.2714e-03,  1.1196e-03, -3.5322e-04, -1.8100e-04,\n",
      "         -3.2188e-03,  1.3277e-03,  2.9589e-03, -2.1086e-03,  1.5711e-03,\n",
      "         -1.9456e-03, -2.0305e-03, -9.1444e-04,  3.7535e-04,  1.0199e-03,\n",
      "         -2.7340e-04],\n",
      "        [-1.4863e-04, -3.8456e-05, -1.4617e-04, -1.2293e-04, -2.5272e-04,\n",
      "         -5.3124e-05, -5.7630e-05,  2.7983e-04, -6.6071e-05,  3.5628e-04,\n",
      "          1.8428e-04,  3.6357e-04,  1.6715e-04, -4.9835e-04,  1.6483e-04,\n",
      "         -1.3808e-04],\n",
      "        [-8.9889e-03, -9.3202e-03, -8.9854e-03,  8.3936e-03,  3.5425e-03,\n",
      "          2.8290e-02, -1.3169e-02, -3.2454e-02,  1.9798e-02, -1.9833e-02,\n",
      "          1.4356e-02,  1.3260e-02,  5.8454e-03,  6.0854e-03, -9.0082e-03,\n",
      "          2.1713e-03],\n",
      "        [ 7.5363e-04,  5.7514e-04, -1.8875e-04,  1.2864e-03, -3.7641e-04,\n",
      "         -3.7485e-04, -6.4212e-04, -7.8900e-04,  5.5478e-05, -5.1927e-04,\n",
      "         -5.9518e-04, -4.1115e-04, -2.1097e-04,  1.5000e-03,  5.3904e-04,\n",
      "         -6.2916e-04],\n",
      "        [ 1.9034e-03,  2.1068e-03,  1.4348e-03,  5.0663e-04, -1.0995e-04,\n",
      "         -4.5193e-03,  1.3755e-03,  2.8695e-03, -2.7027e-03,  1.3234e-03,\n",
      "         -2.5580e-03, -3.0002e-03, -1.3623e-03,  1.4344e-03,  1.8700e-03,\n",
      "         -6.2548e-04],\n",
      "        [ 2.8549e-03,  1.1256e-03,  4.9484e-04,  5.2754e-03,  2.2674e-03,\n",
      "          1.8905e-03, -1.9746e-03, -7.7927e-03,  2.4052e-03, -7.0120e-03,\n",
      "         -2.4999e-03, -4.2325e-03, -2.0398e-03,  9.9748e-03, -1.2774e-03,\n",
      "          1.9610e-04],\n",
      "        [ 9.1012e-04,  1.1649e-03,  7.9739e-04, -5.6289e-04, -6.2593e-04,\n",
      "         -3.2104e-03,  1.1646e-03,  3.3343e-03, -2.1310e-03,  2.1922e-03,\n",
      "         -1.3677e-03, -1.1603e-03, -5.0166e-04, -7.1419e-04,  1.3813e-03,\n",
      "         -5.1482e-04],\n",
      "        [ 2.1945e-03,  1.7487e-03,  1.7637e-03, -9.6664e-04, -2.9797e-04,\n",
      "         -4.7576e-03,  2.2140e-03,  4.9794e-03, -3.2437e-03,  2.6554e-03,\n",
      "         -3.1892e-03, -3.1480e-03, -1.4226e-03,  4.0522e-04,  1.1731e-03,\n",
      "         -2.6927e-04],\n",
      "        [ 1.1659e-03,  1.4802e-03,  1.1980e-03, -3.3036e-04, -1.3533e-04,\n",
      "         -3.7056e-03,  1.4524e-03,  3.1198e-03, -2.3877e-03,  1.7162e-03,\n",
      "         -1.7758e-03, -2.0675e-03, -9.2006e-04,  8.2597e-05,  1.4291e-03,\n",
      "         -3.3244e-04],\n",
      "        [ 7.0768e-03,  1.1065e-02,  1.1838e-02, -5.7900e-03,  3.0408e-03,\n",
      "         -2.9749e-02,  1.4838e-02,  2.5222e-02, -1.9814e-02,  1.2385e-02,\n",
      "         -1.2988e-02, -1.8833e-02, -8.3110e-03, -1.0379e-03,  9.6658e-03,\n",
      "          6.6514e-04],\n",
      "        [-3.1818e-04,  3.8687e-04,  1.5453e-03, -5.1720e-03, -1.1052e-03,\n",
      "         -4.9983e-03,  3.8303e-03,  9.7546e-03, -4.3947e-03,  6.8833e-03,\n",
      "         -9.5129e-04, -1.5507e-04,  2.1185e-05, -6.7007e-03,  1.2046e-03,\n",
      "          3.3178e-04],\n",
      "        [-1.3927e-02, -1.8606e-02, -1.4773e-02, -3.3268e-03, -3.8387e-03,\n",
      "          4.0197e-02, -1.4562e-02, -2.2668e-02,  2.4151e-02, -8.3852e-03,\n",
      "          2.0361e-02,  2.9034e-02,  1.3050e-02, -1.2378e-02, -1.5952e-02,\n",
      "          2.4731e-03],\n",
      "        [ 6.4332e-04,  1.2085e-03,  6.2358e-04,  1.0779e-03,  3.3940e-04,\n",
      "         -1.9830e-03,  2.8114e-04, -7.7822e-05, -9.4700e-04, -3.9969e-04,\n",
      "         -7.9074e-04, -1.5420e-03, -6.9484e-04,  1.4077e-03,  1.2063e-03,\n",
      "         -3.2398e-04],\n",
      "        [ 1.1750e-03,  1.2800e-03,  8.4962e-04, -2.3129e-04, -5.1425e-04,\n",
      "         -3.2068e-03,  1.0709e-03,  2.9452e-03, -2.0742e-03,  1.7983e-03,\n",
      "         -1.6531e-03, -1.5401e-03, -6.9091e-04, -2.1220e-05,  1.3173e-03,\n",
      "         -5.3516e-04],\n",
      "        [ 3.3960e-04,  6.2949e-04,  4.6936e-04, -3.5138e-04, -2.1306e-04,\n",
      "         -1.7740e-03,  6.9675e-04,  1.7361e-03, -1.1867e-03,  1.1206e-03,\n",
      "         -6.0774e-04, -6.4745e-04, -2.8023e-04, -4.9989e-04,  7.8661e-04,\n",
      "         -2.0914e-04],\n",
      "        [-4.4942e-03, -4.7734e-03, -4.4949e-03,  2.2111e-03,  4.5548e-04,\n",
      "          1.2739e-02, -5.6777e-03, -1.2219e-02,  8.4942e-03, -6.6867e-03,\n",
      "          6.8570e-03,  7.4881e-03,  3.3346e-03,  2.1407e-05, -4.1077e-03,\n",
      "          7.3722e-04],\n",
      "        [-1.0096e-02, -9.8160e-03, -1.1316e-02,  1.4591e-02,  4.7584e-03,\n",
      "          3.4211e-02, -1.8041e-02, -4.4607e-02,  2.5052e-02, -2.7838e-02,\n",
      "          1.7240e-02,  1.4807e-02,  6.4696e-03,  1.2239e-02, -9.4301e-03,\n",
      "          1.5582e-03],\n",
      "        [-5.9341e-04, -7.7722e-04, -1.3270e-03,  2.5408e-03,  4.4383e-04,\n",
      "          3.8118e-03, -2.4437e-03, -5.7587e-03,  3.0250e-03, -3.7004e-03,\n",
      "          1.5308e-03,  1.3159e-03,  5.6373e-04,  2.6204e-03, -8.7557e-04,\n",
      "         -1.1630e-04],\n",
      "        [ 3.4696e-03,  3.6938e-03,  3.3172e-03, -1.0590e-03, -1.8262e-04,\n",
      "         -9.3657e-03,  3.9563e-03,  8.2463e-03, -6.1152e-03,  4.3109e-03,\n",
      "         -5.1731e-03, -5.8428e-03, -2.6173e-03,  7.9165e-04,  3.1112e-03,\n",
      "         -6.1868e-04]]), 'exp_avg_sq': tensor([[3.2153e-02, 3.0890e-02, 3.5418e-02, 7.2930e-02, 7.7541e-03, 3.4029e-01,\n",
      "         7.9043e-02, 5.4364e-01, 1.8739e-01, 2.1852e-01, 6.9199e-02, 5.7301e-02,\n",
      "         9.9800e-03, 6.3039e-02, 2.9397e-02, 1.2663e-03],\n",
      "        [1.1587e-02, 1.2393e-02, 1.5202e-02, 2.7450e-02, 2.2553e-03, 1.4333e-01,\n",
      "         3.4811e-02, 2.2520e-01, 7.7926e-02, 8.8124e-02, 2.8120e-02, 2.3543e-02,\n",
      "         4.0095e-03, 2.3171e-02, 1.2511e-02, 3.4018e-04],\n",
      "        [3.8740e-02, 2.9807e-02, 2.5002e-02, 4.1768e-02, 4.7634e-03, 2.3382e-01,\n",
      "         4.6529e-02, 3.1526e-01, 1.1933e-01, 1.1968e-01, 6.8723e-02, 6.3622e-02,\n",
      "         1.1529e-02, 4.4685e-02, 2.2830e-02, 3.0140e-03],\n",
      "        [1.8997e-02, 1.2947e-02, 1.4245e-02, 2.4290e-02, 3.6140e-03, 1.3720e-01,\n",
      "         3.0216e-02, 2.1684e-01, 7.4019e-02, 8.4262e-02, 3.7389e-02, 2.6499e-02,\n",
      "         4.6744e-03, 1.7504e-02, 1.1175e-02, 1.0345e-03],\n",
      "        [8.7774e-03, 1.5537e-02, 2.0538e-02, 5.0366e-02, 8.6488e-04, 1.7666e-01,\n",
      "         4.7886e-02, 2.6584e-01, 9.8023e-02, 1.0566e-01, 2.2224e-02, 2.8817e-02,\n",
      "         5.1441e-03, 5.8493e-02, 1.5138e-02, 9.9333e-04],\n",
      "        [4.5426e-03, 4.7643e-03, 5.7173e-03, 1.0854e-02, 6.8773e-04, 5.1570e-02,\n",
      "         1.1849e-02, 7.7262e-02, 2.7657e-02, 2.9906e-02, 1.0001e-02, 9.1255e-03,\n",
      "         1.6206e-03, 1.0090e-02, 4.3686e-03, 1.7106e-04],\n",
      "        [2.1145e-02, 2.7587e-02, 2.7320e-02, 2.8095e-02, 1.5889e-03, 2.5090e-01,\n",
      "         5.0416e-02, 2.9697e-01, 1.2785e-01, 1.0729e-01, 4.6045e-02, 5.2153e-02,\n",
      "         9.2579e-03, 1.7493e-02, 2.3797e-02, 4.3783e-04],\n",
      "        [1.8374e-02, 1.7350e-02, 2.1597e-02, 3.3217e-02, 2.2808e-03, 1.9736e-01,\n",
      "         4.4445e-02, 2.8783e-01, 1.0564e-01, 1.0889e-01, 4.0788e-02, 3.4735e-02,\n",
      "         6.1709e-03, 2.3026e-02, 1.6052e-02, 4.6670e-04],\n",
      "        [2.7634e-02, 2.6330e-02, 3.3712e-02, 6.1372e-02, 4.9056e-03, 3.1623e-01,\n",
      "         7.4326e-02, 4.9724e-01, 1.7297e-01, 1.9324e-01, 6.2845e-02, 5.0184e-02,\n",
      "         8.4306e-03, 4.9085e-02, 2.6195e-02, 6.7081e-04],\n",
      "        [1.0961e-02, 1.4939e-02, 1.7705e-02, 3.2242e-02, 1.0648e-03, 1.5979e-01,\n",
      "         3.7881e-02, 2.2271e-01, 8.5742e-02, 8.5146e-02, 2.5513e-02, 2.7624e-02,\n",
      "         4.8475e-03, 3.0213e-02, 1.4227e-02, 7.6184e-04],\n",
      "        [6.5782e-03, 1.3724e-02, 1.3553e-02, 1.9235e-02, 3.1364e-04, 1.1971e-01,\n",
      "         2.6462e-02, 1.3810e-01, 6.0373e-02, 5.1348e-02, 1.6633e-02, 2.4875e-02,\n",
      "         4.6330e-03, 1.9800e-02, 1.3271e-02, 5.4481e-04],\n",
      "        [1.8007e-01, 1.2289e-01, 1.7025e-01, 4.3421e-01, 4.6206e-02, 1.5720e+00,\n",
      "         4.0522e-01, 2.8151e+00, 9.1557e-01, 1.1407e+00, 3.6075e-01, 2.5504e-01,\n",
      "         4.2744e-02, 3.6481e-01, 1.1018e-01, 1.0268e-02],\n",
      "        [1.0832e-02, 9.3982e-03, 1.1407e-02, 1.8766e-02, 1.7064e-03, 1.0245e-01,\n",
      "         2.4178e-02, 1.5429e-01, 5.5767e-02, 5.9331e-02, 2.3086e-02, 1.9716e-02,\n",
      "         3.4678e-03, 1.3713e-02, 8.3106e-03, 4.6437e-04],\n",
      "        [6.2529e-03, 1.0251e-02, 1.0862e-02, 1.3505e-02, 3.3247e-04, 9.5463e-02,\n",
      "         2.0978e-02, 1.1318e-01, 4.8683e-02, 4.1693e-02, 1.5104e-02, 1.9347e-02,\n",
      "         3.5714e-03, 1.1329e-02, 9.8039e-03, 2.8696e-04],\n",
      "        [1.9519e-02, 1.5695e-02, 2.1962e-02, 3.9067e-02, 2.0193e-03, 1.9199e-01,\n",
      "         4.4627e-02, 2.9561e-01, 1.0579e-01, 1.1153e-01, 4.0666e-02, 3.2594e-02,\n",
      "         5.5687e-03, 2.7082e-02, 1.3674e-02, 3.4123e-04],\n",
      "        [3.4673e-02, 9.8510e-02, 1.5330e-01, 3.7547e-01, 4.3806e-03, 1.2833e+00,\n",
      "         3.7250e-01, 1.9751e+00, 7.2424e-01, 7.8785e-01, 1.2347e-01, 1.7514e-01,\n",
      "         3.0456e-02, 4.2084e-01, 1.1041e-01, 5.9726e-03],\n",
      "        [2.3788e-02, 2.2212e-02, 2.5476e-02, 3.8810e-02, 2.7060e-03, 2.3538e-01,\n",
      "         5.1359e-02, 3.3320e-01, 1.2410e-01, 1.2621e-01, 4.9702e-02, 4.3456e-02,\n",
      "         7.6744e-03, 2.9402e-02, 2.0069e-02, 9.3703e-04],\n",
      "        [8.4649e-02, 1.3056e-01, 4.4147e-02, 8.5517e-02, 3.3277e-03, 4.2021e-01,\n",
      "         3.0389e-02, 1.0665e-01, 1.3679e-01, 3.3917e-02, 1.2213e-01, 2.4971e-01,\n",
      "         5.1024e-02, 2.0204e-01, 9.7573e-02, 1.5121e-02],\n",
      "        [1.3042e-02, 1.2313e-02, 1.4113e-02, 2.4939e-02, 2.6262e-03, 1.3331e-01,\n",
      "         3.0544e-02, 2.0418e-01, 7.2583e-02, 8.0276e-02, 2.8240e-02, 2.3667e-02,\n",
      "         4.1433e-03, 1.9426e-02, 1.1512e-02, 4.5054e-04],\n",
      "        [2.0634e-02, 2.2552e-02, 2.1112e-02, 1.8094e-02, 1.5129e-03, 1.8963e-01,\n",
      "         3.5861e-02, 2.0734e-01, 9.4994e-02, 7.4471e-02, 4.0525e-02, 4.6036e-02,\n",
      "         8.6193e-03, 1.1213e-02, 1.8789e-02, 7.5092e-04],\n",
      "        [2.1138e-02, 2.0401e-02, 3.1701e-02, 6.3807e-02, 3.3703e-03, 2.6595e-01,\n",
      "         7.1271e-02, 4.4349e-01, 1.5244e-01, 1.7211e-01, 5.1647e-02, 4.2839e-02,\n",
      "         7.2465e-03, 4.8199e-02, 1.8550e-02, 2.1062e-04],\n",
      "        [5.8208e-02, 6.5133e-02, 7.9271e-02, 1.2247e-01, 1.0135e-02, 7.1852e-01,\n",
      "         1.8452e-01, 1.1113e+00, 3.8169e-01, 4.2594e-01, 1.5675e-01, 1.3736e-01,\n",
      "         2.5645e-02, 9.2995e-02, 6.2127e-02, 1.7329e-03],\n",
      "        [2.6552e-02, 2.2585e-02, 2.5820e-02, 3.9776e-02, 4.3123e-03, 2.3598e-01,\n",
      "         5.0769e-02, 3.4598e-01, 1.2549e-01, 1.3180e-01, 5.4465e-02, 4.5239e-02,\n",
      "         8.0156e-03, 2.7667e-02, 1.9865e-02, 8.3236e-04],\n",
      "        [2.4234e-02, 2.0450e-02, 2.2205e-02, 4.2583e-02, 4.7663e-03, 2.1445e-01,\n",
      "         4.5253e-02, 3.2698e-01, 1.1452e-01, 1.2902e-01, 4.7940e-02, 3.8004e-02,\n",
      "         6.8180e-03, 3.7430e-02, 1.9178e-02, 1.2597e-03],\n",
      "        [1.9412e-02, 2.4280e-02, 2.8105e-02, 4.6406e-02, 1.9205e-03, 2.5752e-01,\n",
      "         5.6363e-02, 3.5191e-01, 1.3714e-01, 1.3425e-01, 4.3100e-02, 4.4153e-02,\n",
      "         7.6977e-03, 3.8664e-02, 2.2773e-02, 4.8908e-04]])}, 10: {'step': tensor(11460.), 'exp_avg': tensor([-2.6368e-04, -2.6770e-04,  5.1825e-04, -7.9478e-04,  1.0930e-04,\n",
      "        -7.4344e-04, -1.1140e-04, -1.0660e-04, -7.3103e-05, -5.2837e-04,\n",
      "         1.6778e-04,  2.9361e-05,  5.5506e-04,  7.3242e-04, -3.1391e-04,\n",
      "         1.7071e-03, -2.1396e-04, -9.0496e-04,  1.1163e-03, -4.5802e-04,\n",
      "        -6.9733e-04,  1.0702e-03,  2.7817e-04, -9.3776e-05,  1.1038e-03,\n",
      "        -5.5192e-04,  4.6878e-05, -2.3824e-04, -2.2274e-04, -6.1169e-04,\n",
      "        -1.3862e-03,  2.7714e-04, -1.3816e-03, -2.1175e-04, -1.0447e-03,\n",
      "        -1.6782e-04, -1.2727e-03, -6.9907e-04, -6.9719e-04, -8.6348e-04,\n",
      "         8.0686e-04,  1.8759e-04, -3.3678e-04,  1.0290e-03,  4.2063e-04,\n",
      "        -1.1167e-04,  8.9184e-05,  1.2349e-04,  3.1888e-04,  2.1298e-04,\n",
      "         7.3663e-04, -1.7252e-03, -3.9506e-04, -7.4709e-04, -7.9108e-04,\n",
      "         3.6786e-04, -3.1588e-04,  1.0875e-04, -9.4426e-05,  1.9130e-03,\n",
      "         1.5428e-05,  3.4317e-05,  3.9621e-04,  1.7508e-04, -2.7126e-04,\n",
      "         2.9248e-04,  7.4938e-04,  9.1303e-04, -1.0897e-03, -4.3045e-04,\n",
      "        -3.6396e-04, -1.9799e-04, -1.2145e-03,  1.5799e-03, -3.4062e-04,\n",
      "         1.0238e-03, -2.1306e-03, -4.4951e-04,  6.8636e-04,  8.9996e-04,\n",
      "         1.8168e-03, -7.9864e-04, -1.1990e-03,  3.2629e-04,  2.5779e-04,\n",
      "        -8.3771e-05, -9.5511e-04,  2.2301e-04,  6.9261e-04,  5.5924e-04,\n",
      "        -6.8072e-04,  7.7829e-04,  6.5234e-04,  9.0632e-04, -1.1229e-03,\n",
      "        -2.3315e-03, -1.1295e-03, -1.0830e-03,  4.1243e-04,  2.1244e-04]), 'exp_avg_sq': tensor([0.0004, 0.0006, 0.0006, 0.0007, 0.0006, 0.0010, 0.0005, 0.0006, 0.0006,\n",
      "        0.0007, 0.0008, 0.0008, 0.0011, 0.0005, 0.0004, 0.0006, 0.0006, 0.0006,\n",
      "        0.0005, 0.0006, 0.0007, 0.0006, 0.0009, 0.0015, 0.0009, 0.0012, 0.0005,\n",
      "        0.0004, 0.0006, 0.0013, 0.0006, 0.0005, 0.0006, 0.0009, 0.0008, 0.0010,\n",
      "        0.0007, 0.0007, 0.0013, 0.0014, 0.0014, 0.0011, 0.0005, 0.0016, 0.0007,\n",
      "        0.0006, 0.0008, 0.0009, 0.0006, 0.0008, 0.0007, 0.0007, 0.0007, 0.0005,\n",
      "        0.0007, 0.0005, 0.0008, 0.0008, 0.0006, 0.0007, 0.0006, 0.0008, 0.0006,\n",
      "        0.0008, 0.0009, 0.0008, 0.0007, 0.0011, 0.0007, 0.0009, 0.0010, 0.0008,\n",
      "        0.0007, 0.0005, 0.0013, 0.0007, 0.0010, 0.0009, 0.0011, 0.0008, 0.0006,\n",
      "        0.0005, 0.0012, 0.0008, 0.0009, 0.0009, 0.0016, 0.0012, 0.0008, 0.0008,\n",
      "        0.0007, 0.0006, 0.0007, 0.0007, 0.0009, 0.0011, 0.0007, 0.0012, 0.0007,\n",
      "        0.0008])}, 11: {'step': tensor(11460.), 'exp_avg': tensor([-1.8442e-10, -1.7773e-10, -8.4323e-11, -1.6905e-10,  6.1918e-12,\n",
      "        -3.5136e-11, -1.1422e-10,  2.4494e-10,  5.2933e-11, -5.4146e-11,\n",
      "        -4.5902e-11,  1.2053e-11,  2.8100e-11, -1.3036e-10, -1.0479e-10,\n",
      "         1.1703e-10, -1.8903e-10, -5.0604e-11, -8.8527e-11, -7.6766e-11,\n",
      "        -5.9301e-11,  2.3659e-10,  1.1655e-10,  8.9954e-12,  4.7241e-11,\n",
      "         2.2496e-10,  7.0451e-12,  1.6703e-10, -2.4053e-11, -4.8965e-11,\n",
      "        -1.0138e-10, -6.2053e-11, -2.1274e-10, -2.1678e-11, -1.5581e-10,\n",
      "         6.0294e-11, -3.5372e-10, -1.3074e-10, -7.3589e-11, -1.2481e-10,\n",
      "         9.4306e-12,  1.7834e-11,  1.3135e-10,  1.3541e-10,  1.6999e-10,\n",
      "        -8.0213e-11,  1.9397e-10, -7.1519e-11, -2.8167e-11,  1.6153e-11,\n",
      "         1.0419e-11,  1.2322e-10,  1.1013e-11,  2.5957e-10, -9.4975e-11,\n",
      "         2.6394e-10, -9.3002e-11, -1.0212e-10,  1.3848e-10,  1.6684e-10,\n",
      "         1.1047e-10,  4.7222e-11,  1.8673e-10,  1.6193e-10, -7.6328e-11,\n",
      "        -1.6621e-10,  4.2074e-10, -5.5263e-11,  2.7330e-10, -8.3607e-11,\n",
      "        -4.2204e-11,  4.0561e-12, -1.3866e-10,  1.7788e-11,  8.3618e-11,\n",
      "         2.8481e-11,  5.4773e-12, -1.2931e-10, -1.1232e-10,  1.1261e-10,\n",
      "         2.8899e-10,  2.4740e-11, -3.2521e-11, -2.2102e-10, -3.0231e-11,\n",
      "        -3.0529e-11,  1.1320e-10, -1.8145e-11, -1.7163e-10,  5.9669e-10,\n",
      "        -2.2337e-11, -2.6801e-10,  4.1066e-11,  1.4887e-10,  1.8317e-12,\n",
      "        -1.2669e-10,  1.9789e-11,  2.6218e-10, -6.4893e-11,  1.2378e-10]), 'exp_avg_sq': tensor([2.1003e-17, 3.1122e-17, 2.0970e-17, 3.4374e-17, 3.0798e-17, 2.2270e-17,\n",
      "        1.8125e-17, 2.1076e-17, 3.1273e-17, 2.7120e-17, 3.3817e-17, 3.0762e-17,\n",
      "        3.0341e-17, 5.1004e-17, 2.1069e-17, 4.4628e-17, 3.2883e-17, 2.3106e-17,\n",
      "        3.4630e-17, 3.0599e-17, 3.2517e-17, 3.0369e-17, 3.4219e-17, 4.2528e-17,\n",
      "        3.8311e-17, 2.8318e-17, 3.3761e-17, 2.5543e-17, 2.5170e-17, 4.7022e-17,\n",
      "        2.3891e-17, 3.6036e-17, 3.7537e-17, 3.8194e-17, 2.6153e-17, 5.3872e-17,\n",
      "        2.3615e-17, 2.7867e-17, 3.6653e-17, 7.0787e-17, 4.2454e-17, 4.3946e-17,\n",
      "        4.3848e-17, 4.0537e-17, 4.1621e-17, 3.8211e-17, 4.6119e-17, 2.9617e-17,\n",
      "        3.7871e-17, 3.1476e-17, 2.5995e-17, 3.4634e-17, 2.5848e-17, 3.5729e-17,\n",
      "        4.0997e-17, 3.1515e-17, 6.7656e-17, 2.9303e-17, 3.6649e-17, 4.0996e-17,\n",
      "        2.7147e-17, 2.7915e-17, 2.0795e-17, 3.3317e-17, 3.4520e-17, 3.9416e-17,\n",
      "        2.6253e-17, 5.6094e-17, 4.3604e-17, 6.1238e-17, 4.1694e-17, 4.0753e-17,\n",
      "        4.3270e-17, 2.5930e-17, 4.5926e-17, 3.4958e-17, 2.8794e-17, 3.0172e-17,\n",
      "        3.8618e-17, 4.1836e-17, 3.1523e-17, 2.0709e-17, 5.9498e-17, 3.2639e-17,\n",
      "        3.5561e-17, 3.8422e-17, 4.2918e-17, 5.4507e-17, 4.5948e-17, 2.6020e-17,\n",
      "        4.1578e-17, 5.1205e-17, 3.1184e-17, 2.9784e-17, 3.6388e-17, 3.5596e-17,\n",
      "        3.5558e-17, 4.6490e-17, 3.6942e-17, 4.2188e-17])}, 12: {'step': tensor(11460.), 'exp_avg': tensor([ 0.1244,  0.6790, -1.6159,  0.3040,  1.5888, -1.0035, -1.0258,  0.9492]), 'exp_avg_sq': tensor([ 401.1679,  508.2223, 2672.2786,  117.3333, 2118.5020, 1952.2720,\n",
      "         731.3947,  740.0448])}, 13: {'step': tensor(11460.), 'exp_avg': tensor([[-0.0052, -0.0155,  0.0141],\n",
      "        [-0.1142, -0.0068, -0.1581],\n",
      "        [ 0.2356,  0.0500,  0.2864],\n",
      "        [-0.0595, -0.0026, -0.1106],\n",
      "        [-0.2267, -0.0524, -0.2697],\n",
      "        [ 0.1431,  0.0384,  0.2176],\n",
      "        [ 0.1830,  0.0213,  0.2128],\n",
      "        [-0.1560, -0.0324, -0.1926]]), 'exp_avg_sq': tensor([[0.3299, 0.0899, 1.0134],\n",
      "        [0.3515, 0.1132, 0.9408],\n",
      "        [1.8335, 0.6128, 4.2395],\n",
      "        [0.1995, 0.0282, 0.8454],\n",
      "        [1.6956, 0.5222, 3.9746],\n",
      "        [1.1480, 0.4203, 2.6439],\n",
      "        [0.8923, 0.2389, 2.3368],\n",
      "        [0.7400, 0.2087, 1.8209]])}, 14: {'step': tensor(11460.), 'exp_avg': tensor([ 2.0186e-03,  5.3568e-04, -1.7527e-04,  3.2985e-04, -8.1158e-04,\n",
      "         8.8145e-04,  7.4164e-04,  8.7020e-04, -1.3494e-04, -7.5405e-04,\n",
      "         6.0020e-05, -5.4738e-04,  1.0711e-03, -1.3219e-04, -3.9019e-04,\n",
      "         1.9520e-03,  9.5415e-04,  5.3076e-04,  2.1921e-04, -8.6787e-05,\n",
      "         6.3205e-05,  1.7909e-04, -4.3237e-04,  1.1118e-04,  1.5495e-03,\n",
      "        -9.3507e-04,  2.8553e-04, -1.0352e-04, -7.8324e-04,  9.2547e-05,\n",
      "        -1.0149e-03,  2.4751e-04, -1.8775e-04, -2.6976e-06, -3.5675e-04,\n",
      "        -6.9896e-05,  8.1093e-05, -5.1709e-04, -1.5010e-04,  1.9167e-03,\n",
      "         2.0424e-04,  3.7143e-05, -5.6267e-04,  6.9964e-04, -8.1788e-04,\n",
      "        -1.7844e-04,  3.9473e-04, -2.7457e-04,  4.8669e-04, -5.9534e-04,\n",
      "        -5.1772e-04, -1.6152e-03, -3.0221e-04, -7.4419e-04,  4.1543e-04,\n",
      "         1.6051e-04, -2.3048e-04, -1.0555e-03,  3.9194e-04, -3.8129e-04,\n",
      "         2.3331e-04,  8.5622e-04,  7.6922e-04, -7.2411e-04, -8.6296e-04,\n",
      "         2.4983e-05, -7.3787e-04, -1.3303e-04, -1.4581e-03, -7.5003e-05,\n",
      "        -8.4677e-04,  7.9387e-05, -2.9332e-04,  9.6058e-04, -9.3520e-04,\n",
      "         3.7989e-04, -5.6405e-04, -2.4846e-05, -4.8241e-04,  2.6182e-04,\n",
      "         4.1951e-04,  4.1960e-04, -1.2164e-04,  2.3705e-04, -8.6752e-05,\n",
      "         7.1373e-04,  3.1077e-04, -2.9099e-04,  1.4447e-04,  7.1257e-04,\n",
      "        -2.5024e-04, -3.9157e-04, -2.1949e-04, -1.7314e-03, -5.6573e-04,\n",
      "         1.2804e-04, -2.2850e-04, -1.0276e-03,  5.2612e-04,  1.1608e-03]), 'exp_avg_sq': tensor([1.1195e-03, 2.1477e-04, 3.9848e-04, 5.0340e-04, 3.1108e-04, 1.3285e-03,\n",
      "        3.1885e-04, 2.2618e-04, 1.6254e-04, 3.6911e-04, 1.1325e-03, 1.7580e-03,\n",
      "        5.3616e-04, 1.8699e-04, 5.2125e-04, 1.7655e-04, 1.9913e-04, 2.6790e-04,\n",
      "        1.6288e-04, 2.4770e-04, 1.2189e-03, 5.6968e-04, 5.7728e-04, 5.3900e-04,\n",
      "        5.7510e-04, 3.1009e-04, 2.7981e-04, 3.0512e-04, 2.6144e-03, 3.6843e-04,\n",
      "        5.4730e-04, 2.4401e-04, 7.2400e-04, 5.8051e-04, 5.6685e-04, 6.7144e-04,\n",
      "        1.8876e-03, 1.3836e-04, 3.2949e-04, 4.7047e-04, 2.3984e-04, 2.7222e-04,\n",
      "        2.6522e-04, 2.8548e-04, 2.3866e-04, 1.2957e-04, 3.3846e-04, 8.4455e-04,\n",
      "        1.6123e-04, 1.6055e-04, 2.3745e-04, 4.4321e-04, 9.6949e-04, 4.7680e-04,\n",
      "        3.3088e-04, 1.9891e-04, 9.6713e-05, 7.3150e-04, 3.7063e-04, 4.7016e-04,\n",
      "        6.8757e-04, 2.7470e-04, 3.9651e-04, 1.5307e-03, 7.9579e-04, 3.5228e-03,\n",
      "        1.8140e-03, 2.9700e-04, 4.2858e-04, 3.8464e-04, 5.2151e-04, 6.4474e-04,\n",
      "        6.7835e-04, 8.2486e-04, 7.0697e-04, 1.0929e-03, 1.0026e-03, 2.1633e-04,\n",
      "        2.6947e-04, 2.0540e-04, 2.2018e-04, 3.3091e-04, 3.3408e-04, 3.2120e-04,\n",
      "        4.7056e-03, 2.3272e-03, 6.9233e-04, 1.0052e-03, 2.5660e-04, 5.6360e-04,\n",
      "        3.9892e-04, 4.1213e-04, 5.7071e-04, 3.4391e-04, 1.1295e-03, 3.5620e-04,\n",
      "        4.5248e-04, 7.7943e-04, 2.7446e-04, 6.6975e-04])}, 15: {'step': tensor(11460.), 'exp_avg': tensor([ 0.0048,  0.0005,  0.0048,  0.0032,  0.0064, -0.0006,  0.0010,  0.0062,\n",
      "         0.0038, -0.0041,  0.0037,  0.0064,  0.0011,  0.0002,  0.0007,  0.0062,\n",
      "         0.0083,  0.0047,  0.0047,  0.0033,  0.0112,  0.0036,  0.0045,  0.0089,\n",
      "        -0.0034,  0.0061,  0.0067,  0.0058,  0.0017,  0.0037,  0.0061,  0.0074,\n",
      "         0.0116,  0.0049,  0.0043,  0.0044,  0.0080,  0.0091,  0.0070,  0.0074,\n",
      "         0.0047,  0.0061,  0.0047,  0.0026,  0.0046,  0.0060,  0.0034,  0.0031,\n",
      "         0.0046,  0.0071,  0.0043,  0.0011, -0.0014,  0.0031,  0.0042,  0.0027,\n",
      "         0.0048,  0.0042,  0.0058,  0.0021,  0.0074,  0.0115,  0.0082,  0.0096,\n",
      "         0.0064,  0.0032,  0.0040,  0.0080,  0.0020,  0.0035,  0.0052,  0.0072,\n",
      "         0.0059,  0.0013,  0.0034,  0.0106,  0.0052,  0.0033,  0.0037,  0.0008,\n",
      "         0.0042, -0.0013,  0.0067,  0.0074,  0.0063, -0.0053,  0.0045,  0.0022,\n",
      "         0.0075,  0.0083,  0.0024,  0.0073,  0.0043,  0.0059,  0.0198,  0.0038,\n",
      "         0.0032,  0.0077,  0.0066,  0.0117]), 'exp_avg_sq': tensor([0.0145, 0.0171, 0.0112, 0.0060, 0.0189, 0.0221, 0.0155, 0.0094, 0.0094,\n",
      "        0.0100, 0.0229, 0.0215, 0.0204, 0.0077, 0.0109, 0.0162, 0.0095, 0.0097,\n",
      "        0.0099, 0.0077, 0.0113, 0.0128, 0.0134, 0.0194, 0.0148, 0.0121, 0.0078,\n",
      "        0.0118, 0.0319, 0.0104, 0.0122, 0.0084, 0.0248, 0.0182, 0.0094, 0.0203,\n",
      "        0.0262, 0.0053, 0.0212, 0.0389, 0.0137, 0.0167, 0.0105, 0.0160, 0.0252,\n",
      "        0.0070, 0.0071, 0.0060, 0.0056, 0.0130, 0.0093, 0.0076, 0.0175, 0.0101,\n",
      "        0.0135, 0.0049, 0.0073, 0.0112, 0.0114, 0.0202, 0.0097, 0.0103, 0.0110,\n",
      "        0.0168, 0.0255, 0.0176, 0.0199, 0.0218, 0.0088, 0.0110, 0.0253, 0.0157,\n",
      "        0.0148, 0.0164, 0.0206, 0.0099, 0.0160, 0.0185, 0.0177, 0.0086, 0.0096,\n",
      "        0.0159, 0.0095, 0.0164, 0.0225, 0.0086, 0.0175, 0.0103, 0.0143, 0.0164,\n",
      "        0.0113, 0.0126, 0.0109, 0.0127, 0.0156, 0.0142, 0.0155, 0.0274, 0.0117,\n",
      "        0.0177])}, 16: {'step': tensor(11460.), 'exp_avg': tensor([ 0.2383, -0.0118, -0.1720, -0.1028,  0.1266, -0.1062, -0.2172,  0.2452]), 'exp_avg_sq': tensor([52.0925,  0.9878,  8.7572, 11.4377, 16.8060, 25.4565, 29.7473, 21.9833])}, 17: {'step': tensor(11460.), 'exp_avg': tensor([[-0.1250,  0.0901, -0.0500, -0.1889,  0.1804, -0.0054,  0.2094, -0.1131],\n",
      "        [ 0.0094, -0.0029,  0.0074,  0.0169, -0.0244,  0.0021, -0.0281,  0.0196],\n",
      "        [ 0.0479, -0.0343,  0.0364,  0.0967, -0.1004, -0.0012, -0.1166,  0.0729],\n",
      "        [ 0.0403, -0.0423,  0.0387,  0.1065, -0.0827, -0.0175, -0.0956,  0.0537],\n",
      "        [-0.0533,  0.0405, -0.0383, -0.1079,  0.1046,  0.0047,  0.1211, -0.0728],\n",
      "        [ 0.0533, -0.0460,  0.0235,  0.0899, -0.0720, -0.0048, -0.0836,  0.0410],\n",
      "        [ 0.1304, -0.0614,  0.0324,  0.1400, -0.1911,  0.0408, -0.2219,  0.1330],\n",
      "        [-0.1031,  0.0564, -0.0502, -0.1534,  0.1856, -0.0186,  0.2153, -0.1342]]), 'exp_avg_sq': tensor([[1.3411, 0.6930, 0.1524, 1.5134, 1.3793, 0.1500, 1.8330, 0.6966],\n",
      "        [0.0703, 0.0266, 0.0090, 0.0592, 0.0586, 0.0118, 0.0730, 0.0219],\n",
      "        [0.3310, 0.1416, 0.0480, 0.3220, 0.3291, 0.0555, 0.4317, 0.1629],\n",
      "        [0.5769, 0.2393, 0.0657, 0.5132, 0.5637, 0.0825, 0.7419, 0.2571],\n",
      "        [0.5153, 0.2450, 0.0572, 0.5315, 0.5053, 0.0617, 0.6637, 0.2408],\n",
      "        [0.7320, 0.3612, 0.0681, 0.6876, 0.6135, 0.0843, 0.7974, 0.2864],\n",
      "        [0.9442, 0.3728, 0.0921, 0.8464, 0.8847, 0.1498, 1.1619, 0.3960],\n",
      "        [0.7644, 0.3324, 0.1029, 0.8510, 0.8405, 0.1103, 1.0992, 0.3956]])}, 18: {'step': tensor(11460.), 'exp_avg': tensor([ 1.6463e-03,  1.7349e-04,  4.9146e-05,  1.1526e-04, -4.4638e-04,\n",
      "         8.4119e-05, -1.3285e-04,  9.0557e-05, -2.2366e-04, -6.2558e-04,\n",
      "        -5.6143e-05, -3.5760e-04,  2.5982e-04,  3.3252e-04, -1.2129e-04,\n",
      "         4.3885e-03,  2.2327e-04,  2.0149e-04,  3.4972e-04,  4.3694e-04,\n",
      "         4.7786e-05,  1.6877e-04, -3.0158e-04, -2.3449e-04,  6.1650e-04,\n",
      "        -7.3739e-04,  3.0240e-04,  1.9873e-04, -7.2544e-04,  2.4045e-06,\n",
      "        -1.0423e-03,  8.4479e-04,  2.8347e-05, -2.1182e-05, -7.3563e-04,\n",
      "        -2.1763e-04, -9.6200e-05,  9.8266e-05, -2.1978e-06,  2.0491e-03,\n",
      "        -1.0145e-03, -1.2802e-04, -3.5623e-04,  8.9666e-04, -4.0388e-04,\n",
      "         5.5079e-04,  2.0506e-04, -2.6373e-04,  6.1054e-04, -5.8851e-04,\n",
      "        -4.1641e-04, -1.3645e-03, -7.0821e-04, -4.6513e-04,  2.6485e-04,\n",
      "         9.2897e-05, -4.0268e-04, -7.4732e-04,  3.2967e-04, -3.0990e-04,\n",
      "         2.6370e-04,  2.3786e-04,  1.0214e-03, -6.3612e-04, -5.4346e-04,\n",
      "        -5.9998e-04, -4.4466e-04, -1.0617e-04, -7.4017e-04, -2.4732e-04,\n",
      "        -1.8272e-03,  6.6122e-05,  5.6464e-04,  5.0527e-04, -7.7219e-04,\n",
      "         1.1742e-03, -2.7653e-04, -3.0955e-04,  3.6706e-04, -5.0511e-05,\n",
      "         1.7333e-04,  5.2032e-04,  5.1225e-05,  8.8006e-04,  5.3193e-04,\n",
      "         1.1126e-04,  2.8760e-04, -1.8889e-04,  2.9671e-04,  8.0916e-04,\n",
      "        -5.3756e-05, -4.1714e-04, -5.1142e-04, -1.1116e-03, -2.1594e-04,\n",
      "        -5.5877e-04, -4.0626e-04, -5.9753e-04,  5.7720e-04,  1.3721e-03]), 'exp_avg_sq': tensor([2.2203e-04, 1.4719e-04, 1.4439e-04, 2.1914e-04, 1.8368e-04, 2.2290e-04,\n",
      "        2.4548e-04, 6.2681e-04, 7.2724e-05, 1.6361e-04, 5.4081e-04, 2.4607e-04,\n",
      "        2.7767e-04, 1.1855e-04, 1.6794e-04, 9.5631e-05, 1.2159e-04, 8.2254e-04,\n",
      "        9.8121e-05, 2.0866e-04, 3.7468e-04, 1.9001e-04, 1.8071e-04, 1.9878e-04,\n",
      "        2.4199e-04, 1.3466e-04, 1.6526e-04, 2.0058e-04, 2.2451e-04, 1.3591e-04,\n",
      "        2.1382e-04, 4.0681e-04, 2.7893e-04, 2.8822e-04, 5.4641e-04, 2.2504e-04,\n",
      "        3.5474e-04, 8.6149e-05, 1.6539e-04, 2.0992e-04, 1.7449e-04, 1.3557e-04,\n",
      "        1.6260e-04, 1.7511e-04, 2.0684e-04, 1.1010e-04, 1.6664e-04, 3.7840e-04,\n",
      "        1.2169e-04, 9.6290e-05, 1.6928e-04, 9.2052e-05, 2.0122e-04, 1.4744e-04,\n",
      "        1.7724e-04, 1.1420e-04, 6.0207e-05, 4.1167e-04, 2.9923e-04, 2.5321e-04,\n",
      "        3.2645e-04, 1.8049e-04, 1.2413e-04, 1.9126e-04, 1.5203e-04, 3.5665e-04,\n",
      "        3.9675e-04, 1.2945e-04, 1.9462e-04, 1.5441e-04, 7.8767e-05, 2.7218e-04,\n",
      "        3.2250e-04, 2.4517e-04, 2.6805e-04, 9.0741e-04, 3.2891e-04, 1.1296e-04,\n",
      "        1.8758e-04, 1.1790e-04, 2.5416e-04, 1.8608e-04, 1.5754e-04, 1.4993e-04,\n",
      "        2.9228e-04, 3.0853e-04, 2.3750e-04, 4.1298e-04, 1.9846e-04, 2.8664e-04,\n",
      "        2.1209e-04, 2.3931e-04, 1.3507e-04, 1.2447e-03, 1.1157e-03, 2.0380e-04,\n",
      "        1.7671e-04, 4.6753e-04, 1.3466e-04, 3.9250e-04])}, 19: {'step': tensor(11460.), 'exp_avg': tensor([-2.9643e-03,  4.2771e-04, -3.1777e-03, -1.8531e-04, -3.0611e-03,\n",
      "         1.2810e-03,  1.6402e-03, -3.6193e-03, -1.8420e-03,  2.0447e-03,\n",
      "        -2.0060e-03, -1.5081e-03,  5.6509e-04,  1.8174e-05, -8.0181e-04,\n",
      "        -5.5453e-03, -6.5902e-03, -1.0263e-03, -3.5876e-03, -4.9547e-04,\n",
      "        -6.0270e-03, -1.5190e-03, -3.2127e-03, -5.2590e-03, -4.1855e-04,\n",
      "        -2.5723e-03, -4.3934e-03, -8.3551e-05,  1.1742e-03, -1.2622e-03,\n",
      "         7.7624e-04, -4.0791e-03, -7.1020e-03, -4.0347e-03, -1.3027e-03,\n",
      "        -1.0524e-03, -6.1466e-03, -4.9168e-03, -2.3567e-03, -1.4950e-03,\n",
      "        -1.7882e-03, -3.1188e-03, -1.9804e-03, -1.0129e-03, -1.7164e-03,\n",
      "        -4.4378e-03, -7.6851e-04, -1.7621e-04, -1.5804e-03, -5.4795e-03,\n",
      "        -7.5933e-04,  7.0959e-04,  2.5209e-03, -1.9571e-03, -1.1194e-03,\n",
      "        -8.0839e-04, -2.2039e-03, -1.5191e-03, -2.4763e-03, -1.0274e-03,\n",
      "        -4.2232e-03, -8.2020e-03, -4.1057e-03, -3.5969e-03, -2.3698e-03,\n",
      "        -4.6164e-04, -1.4491e-03, -4.5004e-03, -6.3172e-04, -2.1233e-03,\n",
      "        -4.7561e-03, -2.6612e-03, -2.1248e-03, -4.5518e-04,  9.4434e-04,\n",
      "        -5.8741e-03, -3.8753e-03, -1.8624e-03, -2.4951e-03, -2.3772e-04,\n",
      "        -2.8437e-03,  2.5349e-03, -3.4353e-03, -2.4551e-03, -2.3251e-03,\n",
      "         8.5112e-04, -3.9641e-03, -1.4469e-04, -3.3596e-03, -4.3687e-03,\n",
      "        -2.4508e-03, -9.3188e-04, -1.5567e-03, -3.5925e-03, -1.4336e-02,\n",
      "        -1.4057e-03,  2.8244e-04, -2.6498e-03, -2.9591e-03, -5.4491e-03]), 'exp_avg_sq': tensor([0.0055, 0.0062, 0.0060, 0.0047, 0.0075, 0.0067, 0.0057, 0.0057, 0.0069,\n",
      "        0.0056, 0.0074, 0.0090, 0.0078, 0.0051, 0.0049, 0.0062, 0.0073, 0.0045,\n",
      "        0.0062, 0.0052, 0.0050, 0.0060, 0.0074, 0.0083, 0.0069, 0.0078, 0.0056,\n",
      "        0.0062, 0.0094, 0.0060, 0.0054, 0.0057, 0.0073, 0.0087, 0.0057, 0.0096,\n",
      "        0.0072, 0.0048, 0.0075, 0.0111, 0.0070, 0.0065, 0.0062, 0.0092, 0.0090,\n",
      "        0.0058, 0.0054, 0.0051, 0.0056, 0.0083, 0.0053, 0.0052, 0.0074, 0.0059,\n",
      "        0.0062, 0.0048, 0.0065, 0.0062, 0.0062, 0.0074, 0.0062, 0.0055, 0.0062,\n",
      "        0.0062, 0.0108, 0.0074, 0.0069, 0.0083, 0.0069, 0.0069, 0.0071, 0.0094,\n",
      "        0.0082, 0.0075, 0.0098, 0.0071, 0.0067, 0.0073, 0.0084, 0.0067, 0.0083,\n",
      "        0.0057, 0.0067, 0.0058, 0.0094, 0.0072, 0.0090, 0.0075, 0.0063, 0.0078,\n",
      "        0.0074, 0.0079, 0.0066, 0.0079, 0.0093, 0.0072, 0.0076, 0.0091, 0.0082,\n",
      "        0.0076])}, 20: {'step': tensor(11460.), 'exp_avg': tensor([-0.3173, -0.0186,  0.1665, -0.3650,  0.0375,  0.2779,  0.0955,  0.1235]), 'exp_avg_sq': tensor([28.0200,  1.8447, 20.0785, 38.6033,  5.4843, 47.5723,  5.4639,  2.8639])}, 21: {'step': tensor(11460.), 'exp_avg': tensor([[-0.1055, -0.0486,  0.3190, -0.2547,  0.1462,  0.2549, -0.2766, -0.0502],\n",
      "        [-0.0358,  0.0015,  0.0552, -0.0675,  0.0528,  0.0596, -0.0550, -0.0119],\n",
      "        [ 0.0813,  0.0398, -0.2674,  0.2015, -0.1182, -0.2046,  0.2310,  0.0450],\n",
      "        [-0.1491, -0.0250,  0.3244, -0.3115,  0.2172,  0.2957, -0.2991, -0.0702],\n",
      "        [ 0.0257, -0.0119,  0.0059,  0.0351, -0.0342, -0.0223,  0.0044, -0.0010],\n",
      "        [ 0.1063,  0.0484, -0.3364,  0.2574, -0.1552, -0.2614,  0.2920,  0.0628],\n",
      "        [ 0.0323, -0.0097, -0.0243,  0.0495, -0.0501, -0.0410,  0.0312,  0.0166],\n",
      "        [ 0.0447,  0.0055, -0.0765,  0.0903, -0.0585, -0.0810,  0.0723,  0.0090]]), 'exp_avg_sq': tensor([[0.5543, 0.3094, 2.6223, 1.8465, 1.6644, 1.5754, 1.9265, 0.4872],\n",
      "        [0.0631, 0.0265, 0.1195, 0.1149, 0.1810, 0.0957, 0.1013, 0.0475],\n",
      "        [0.4757, 0.2384, 1.9201, 1.4282, 1.4304, 1.2131, 1.4474, 0.4027],\n",
      "        [0.4785, 0.2326, 2.4465, 1.9396, 1.4127, 1.5787, 1.8761, 0.4521],\n",
      "        [0.1489, 0.0676, 0.4427, 0.3603, 0.4039, 0.3119, 0.3422, 0.1460],\n",
      "        [0.6942, 0.3259, 3.2044, 2.5419, 2.0988, 2.0836, 2.4790, 0.6467],\n",
      "        [0.0786, 0.0535, 0.3048, 0.2229, 0.2265, 0.1858, 0.2159, 0.0959],\n",
      "        [0.0958, 0.0381, 0.4334, 0.3297, 0.2495, 0.2894, 0.3325, 0.0580]])}, 22: {'step': tensor(11460.), 'exp_avg': tensor([ 2.4676e-03, -5.3338e-04, -3.5305e-04, -4.3300e-04, -1.9532e-04,\n",
      "        -1.3141e-03, -4.5705e-04,  3.4099e-04, -8.3231e-04, -1.5554e-03,\n",
      "         3.4308e-04, -2.7448e-05, -6.3497e-05,  1.1275e-03, -1.8780e-04,\n",
      "         3.4484e-03,  1.9940e-03, -6.1906e-04,  1.3968e-03,  1.3320e-04,\n",
      "        -3.6362e-04,  8.2102e-04,  6.6297e-04, -7.9008e-04,  4.1412e-04,\n",
      "        -1.2494e-03,  8.2274e-05,  1.7425e-04, -9.3113e-04, -1.1450e-04,\n",
      "        -2.8999e-03,  2.9441e-04, -9.1220e-04, -7.3870e-05, -5.8509e-04,\n",
      "        -4.8943e-04, -2.0026e-04,  8.8232e-04, -2.7811e-04,  6.0928e-05,\n",
      "         2.1974e-03,  4.9515e-04,  4.1139e-05,  1.3059e-03, -1.6977e-04,\n",
      "         9.6044e-04,  1.2702e-03, -1.3687e-04,  1.0622e-03,  1.1940e-03,\n",
      "        -5.5106e-05, -2.7792e-03, -5.7202e-04, -2.3412e-04, -7.0232e-04,\n",
      "         7.4688e-04, -1.0042e-03, -4.6190e-04, -4.2924e-04,  1.7533e-03,\n",
      "        -5.7103e-04,  6.5191e-04,  8.6815e-05,  1.9868e-05, -5.2166e-04,\n",
      "         1.1983e-03, -2.5559e-04,  4.5441e-04, -2.2189e-03, -1.2913e-03,\n",
      "        -1.4411e-03, -2.7027e-04, -1.3017e-03,  1.0414e-03, -9.4912e-04,\n",
      "         2.9213e-03, -1.0336e-03, -1.7938e-03, -2.8452e-04,  6.6879e-04,\n",
      "         1.5395e-03, -1.1946e-04, -7.9916e-04,  1.2672e-03,  1.0433e-03,\n",
      "        -8.9573e-04,  3.2130e-04, -3.9918e-04,  3.0953e-04,  1.1711e-03,\n",
      "        -1.3498e-03, -5.5740e-04,  3.5159e-04,  6.3753e-04,  3.2025e-04,\n",
      "        -9.7217e-04, -1.8584e-03, -1.5961e-03,  4.3063e-05, -2.4566e-04]), 'exp_avg_sq': tensor([0.0009, 0.0010, 0.0007, 0.0012, 0.0007, 0.0008, 0.0007, 0.0008, 0.0008,\n",
      "        0.0009, 0.0009, 0.0011, 0.0008, 0.0011, 0.0007, 0.0005, 0.0007, 0.0006,\n",
      "        0.0005, 0.0008, 0.0009, 0.0007, 0.0007, 0.0009, 0.0011, 0.0008, 0.0007,\n",
      "        0.0006, 0.0007, 0.0006, 0.0008, 0.0008, 0.0007, 0.0008, 0.0010, 0.0007,\n",
      "        0.0007, 0.0007, 0.0007, 0.0010, 0.0010, 0.0007, 0.0007, 0.0009, 0.0008,\n",
      "        0.0006, 0.0008, 0.0009, 0.0007, 0.0008, 0.0008, 0.0006, 0.0006, 0.0006,\n",
      "        0.0007, 0.0007, 0.0007, 0.0009, 0.0006, 0.0006, 0.0007, 0.0008, 0.0006,\n",
      "        0.0008, 0.0007, 0.0007, 0.0007, 0.0004, 0.0005, 0.0007, 0.0006, 0.0008,\n",
      "        0.0007, 0.0006, 0.0010, 0.0010, 0.0008, 0.0006, 0.0006, 0.0006, 0.0008,\n",
      "        0.0006, 0.0008, 0.0007, 0.0008, 0.0006, 0.0007, 0.0012, 0.0008, 0.0008,\n",
      "        0.0006, 0.0008, 0.0007, 0.0005, 0.0009, 0.0007, 0.0006, 0.0011, 0.0007,\n",
      "        0.0007])}, 23: {'step': tensor(11460.), 'exp_avg': tensor([ 2.1025e-03,  8.8553e-03, -2.7376e-03,  9.1566e-03,  4.8487e-03,\n",
      "         1.6927e-03,  4.5932e-03, -2.4673e-03,  7.4752e-03, -7.2365e-04,\n",
      "         4.1854e-03,  5.7603e-03,  3.5148e-03,  7.7375e-03,  4.6758e-03,\n",
      "         3.7854e-03, -2.6785e-03,  6.5111e-03,  3.5606e-03,  7.8760e-03,\n",
      "         6.9144e-03,  4.1380e-03,  4.4844e-06,  1.7302e-03,  2.5960e-03,\n",
      "         5.4171e-03,  1.3443e-03,  5.3938e-03,  5.5086e-03,  3.9638e-03,\n",
      "         7.0691e-04, -5.4680e-03, -2.5907e-03, -3.4599e-03,  4.9680e-03,\n",
      "         4.5193e-03, -3.6840e-03,  3.3800e-03,  1.9647e-03,  8.5005e-03,\n",
      "         1.0464e-02,  3.3290e-03,  6.8416e-03,  8.5436e-03,  7.3511e-03,\n",
      "        -5.4529e-03,  4.3821e-03,  5.7798e-03,  5.2594e-03, -9.1022e-04,\n",
      "         5.4774e-03, -4.4422e-04,  5.8735e-03, -5.5686e-03,  4.1694e-03,\n",
      "         4.6746e-03,  9.5353e-04,  8.5223e-04,  1.3405e-04,  5.7778e-03,\n",
      "         4.5978e-03,  1.0672e-03,  7.7419e-03,  9.9268e-03, -1.5296e-03,\n",
      "         1.0522e-02,  7.6807e-03,  6.8960e-04, -2.1160e-03,  3.0636e-03,\n",
      "        -4.7989e-03, -2.3608e-03,  3.7961e-03,  6.8768e-03,  9.4092e-03,\n",
      "         3.9100e-03,  5.0236e-03,  4.1169e-03, -1.9097e-03,  8.8583e-03,\n",
      "        -1.7915e-04,  4.0005e-03,  5.2237e-03,  6.7820e-03,  6.6064e-03,\n",
      "         8.5652e-03, -1.6347e-03,  7.0731e-03, -7.4350e-04,  5.2531e-03,\n",
      "         4.4362e-03,  9.1884e-03,  1.0095e-02,  4.0415e-03,  1.8290e-03,\n",
      "        -5.9046e-03,  1.0322e-03,  2.4911e-03, -1.4769e-03,  1.2336e-02]), 'exp_avg_sq': tensor([0.0154, 0.0227, 0.0249, 0.0210, 0.0267, 0.0162, 0.0232, 0.0184, 0.0250,\n",
      "        0.0153, 0.0237, 0.0222, 0.0262, 0.0207, 0.0161, 0.0182, 0.0262, 0.0163,\n",
      "        0.0175, 0.0205, 0.0196, 0.0157, 0.0286, 0.0238, 0.0239, 0.0265, 0.0189,\n",
      "        0.0180, 0.0170, 0.0213, 0.0165, 0.0179, 0.0166, 0.0252, 0.0172, 0.0195,\n",
      "        0.0246, 0.0180, 0.0210, 0.0195, 0.0196, 0.0186, 0.0154, 0.0212, 0.0174,\n",
      "        0.0176, 0.0227, 0.0165, 0.0241, 0.0189, 0.0180, 0.0214, 0.0194, 0.0263,\n",
      "        0.0220, 0.0213, 0.0221, 0.0209, 0.0178, 0.0196, 0.0179, 0.0202, 0.0190,\n",
      "        0.0172, 0.0219, 0.0206, 0.0209, 0.0214, 0.0226, 0.0230, 0.0231, 0.0215,\n",
      "        0.0228, 0.0143, 0.0311, 0.0205, 0.0184, 0.0199, 0.0282, 0.0171, 0.0258,\n",
      "        0.0147, 0.0168, 0.0171, 0.0184, 0.0213, 0.0266, 0.0188, 0.0168, 0.0199,\n",
      "        0.0205, 0.0212, 0.0157, 0.0222, 0.0160, 0.0176, 0.0178, 0.0184, 0.0276,\n",
      "        0.0221])}, 24: {'step': tensor(11460.), 'exp_avg': tensor([-4.9885e-04,  2.4910e-05, -2.0022e-04, -4.2309e-04, -2.0019e-04,\n",
      "         9.2499e-04,  1.0472e-03, -6.7474e-04]), 'exp_avg_sq': tensor([0.0003, 0.0003, 0.0001, 0.0014, 0.0013, 0.0011, 0.0009, 0.0006])}, 25: {'step': tensor(11460.), 'exp_avg': tensor([[-1.2556e-03,  3.0477e-03, -2.6155e-03,  1.2130e-03, -3.3092e-03,\n",
      "          1.3862e-03, -2.5198e-03,  3.7180e-03],\n",
      "        [ 6.6271e-05,  6.5781e-04, -6.3934e-04,  8.1781e-05, -6.7046e-04,\n",
      "          4.9239e-04, -7.7387e-04,  8.6464e-04],\n",
      "        [-4.7896e-04,  1.3267e-04, -6.3527e-05,  2.9485e-04, -2.5052e-04,\n",
      "         -1.8262e-04,  4.3086e-04, -1.0900e-05],\n",
      "        [-2.9403e-03,  2.9664e-03, -2.4830e-03,  2.2395e-03, -3.7879e-03,\n",
      "          4.9386e-04,  1.2539e-04,  2.9653e-03],\n",
      "        [ 3.7641e-03,  1.0017e-03, -8.6261e-04, -2.2129e-03,  4.6529e-04,\n",
      "          2.5524e-03, -7.9248e-03,  3.1529e-03],\n",
      "        [-7.5338e-04, -4.9428e-03,  4.2219e-03, -2.1221e-04,  4.3078e-03,\n",
      "         -3.6320e-03,  8.8953e-03, -7.3213e-03],\n",
      "        [-6.7459e-04, -6.1716e-03,  5.2750e-03, -4.4073e-04,  5.4745e-03,\n",
      "         -4.3965e-03,  1.0639e-02, -9.0262e-03],\n",
      "        [ 2.2723e-03,  3.3080e-03, -2.8329e-03, -9.6325e-04, -2.2296e-03,\n",
      "          3.2863e-03, -8.8724e-03,  5.6575e-03]]), 'exp_avg_sq': tensor([[7.2154e-04, 1.0891e-03, 8.0212e-04, 2.9558e-04, 9.2101e-04, 6.0182e-04,\n",
      "         4.4856e-03, 2.4089e-03],\n",
      "        [1.2141e-03, 1.6404e-03, 1.2763e-03, 3.2498e-04, 9.7528e-04, 1.3706e-03,\n",
      "         1.0579e-02, 4.6469e-03],\n",
      "        [3.9133e-04, 4.3014e-04, 3.4501e-04, 8.7228e-05, 2.2134e-04, 4.1330e-04,\n",
      "         3.0190e-03, 1.2998e-03],\n",
      "        [3.5913e-03, 6.5994e-03, 4.9053e-03, 1.0455e-03, 4.3245e-03, 4.7093e-03,\n",
      "         3.4957e-02, 1.7622e-02],\n",
      "        [3.3959e-03, 2.5523e-03, 2.0395e-03, 9.1694e-04, 1.3528e-03, 3.0872e-03,\n",
      "         2.3274e-02, 8.7266e-03],\n",
      "        [2.7625e-03, 3.7546e-03, 2.9800e-03, 6.7549e-04, 2.1357e-03, 3.4245e-03,\n",
      "         2.3992e-02, 1.0518e-02],\n",
      "        [2.2969e-03, 3.0998e-03, 2.2071e-03, 7.6062e-04, 2.0498e-03, 1.7407e-03,\n",
      "         1.7190e-02, 7.8733e-03],\n",
      "        [1.6125e-03, 1.1678e-03, 9.1560e-04, 4.1358e-04, 5.0248e-04, 1.3868e-03,\n",
      "         1.1360e-02, 4.0619e-03]])}, 26: {'step': tensor(11460.), 'exp_avg': tensor([ 3.7158e-05,  1.0492e-05, -3.7494e-06,  2.0314e-05, -5.8446e-05,\n",
      "        -4.4336e-06, -5.6512e-06, -8.6327e-06,  1.7650e-05, -1.7642e-05,\n",
      "         1.9171e-06,  1.1596e-04,  3.3251e-05, -6.3263e-06, -3.9913e-06,\n",
      "        -6.0503e-05,  6.3359e-05,  2.2229e-04,  3.6593e-05, -1.4315e-05,\n",
      "        -4.8600e-06, -1.0543e-05,  3.9173e-05,  2.6330e-05,  1.7600e-06]), 'exp_avg_sq': tensor([7.8736e-07, 9.4855e-07, 1.8750e-06, 1.0197e-06, 1.1571e-06, 7.1589e-07,\n",
      "        4.2093e-07, 3.9700e-07, 1.1322e-06, 8.3888e-07, 1.0426e-06, 3.7947e-05,\n",
      "        1.2286e-06, 7.7207e-07, 5.0608e-07, 1.1996e-05, 1.3622e-06, 4.6790e-06,\n",
      "        9.2614e-07, 7.7372e-07, 5.6588e-07, 5.8092e-07, 1.0809e-06, 1.8150e-06,\n",
      "        9.1467e-07])}, 27: {'step': tensor(11460.), 'exp_avg': tensor([-1.7762e-04, -9.0647e-05, -1.9377e-04, -8.8851e-05,  2.3975e-04,\n",
      "        -2.5109e-05, -1.5053e-05,  1.8270e-06, -6.4764e-05,  2.8433e-05,\n",
      "        -4.4178e-05, -1.7810e-03, -5.8012e-05, -6.6064e-06, -1.5562e-05,\n",
      "         9.1507e-04, -1.5542e-04, -2.2291e-03, -2.9363e-05,  1.0768e-05,\n",
      "        -8.9842e-06,  1.9519e-05,  2.7188e-05, -1.7940e-04, -4.0425e-05]), 'exp_avg_sq': tensor([2.0103e-05, 1.4537e-05, 2.1131e-05, 2.4023e-05, 5.2654e-05, 8.1022e-06,\n",
      "        7.7610e-06, 7.6283e-06, 1.3745e-05, 2.7190e-05, 3.1677e-05, 3.9676e-03,\n",
      "        2.2737e-05, 2.0028e-05, 8.2485e-06, 4.2783e-03, 7.5593e-06, 2.4160e-04,\n",
      "        2.2372e-05, 1.0126e-05, 7.0082e-06, 7.6300e-06, 1.6749e-05, 1.4679e-05,\n",
      "        1.0078e-05])}, 28: {'step': tensor(11460.), 'exp_avg': tensor([ 0.0022, -0.0082, -0.0015, -0.0032,  0.0017, -0.0026,  0.0061,  0.0056]), 'exp_avg_sq': tensor([0.0040, 0.0131, 0.0136, 0.0030, 0.0019, 0.0042, 0.0074, 0.0034])}, 29: {'step': tensor(11460.), 'exp_avg': tensor([[-1.2116e-03,  1.6969e-03, -1.1342e-04,  1.2516e-03,  3.5967e-04,\n",
      "         -3.5788e-04, -8.0758e-05, -1.3156e-03],\n",
      "        [ 7.0541e-03, -8.8584e-03,  1.0905e-03, -7.5465e-03, -1.6679e-03,\n",
      "          7.5687e-04, -7.1422e-04,  9.1453e-03],\n",
      "        [-5.0120e-03,  5.7667e-03, -2.2235e-04,  5.5793e-04,  1.0713e-03,\n",
      "         -2.2442e-04, -2.0618e-03, -2.5769e-04],\n",
      "        [ 6.3189e-03, -7.6254e-03,  5.4931e-04, -3.3495e-03, -1.4516e-03,\n",
      "          4.6386e-04,  1.2255e-03,  3.6794e-03],\n",
      "        [-1.1462e-03,  1.4640e-03, -9.8078e-05,  8.5306e-04,  2.9599e-04,\n",
      "         -1.1223e-04, -1.3946e-04, -9.4820e-04],\n",
      "        [ 6.3172e-03, -7.6611e-03,  4.8186e-04, -2.9997e-03, -1.4659e-03,\n",
      "          5.3849e-04,  1.4965e-03,  3.1963e-03],\n",
      "        [-4.5570e-03,  5.7412e-03, -7.3733e-04,  5.1726e-03,  1.0853e-03,\n",
      "         -4.3054e-04,  6.5482e-04, -6.3176e-03],\n",
      "        [-7.7635e-03,  9.4762e-03, -9.5054e-04,  6.0605e-03,  1.7732e-03,\n",
      "         -6.3415e-04, -3.8060e-04, -7.1819e-03]]), 'exp_avg_sq': tensor([[1.1341e-02, 1.6513e-02, 5.4846e-05, 4.1307e-03, 5.0029e-04, 2.9492e-04,\n",
      "         7.0047e-04, 4.6651e-03],\n",
      "        [2.8067e-02, 4.0334e-02, 1.5602e-04, 1.2100e-02, 1.2290e-03, 6.3949e-04,\n",
      "         1.6221e-03, 1.4843e-02],\n",
      "        [2.8238e-02, 3.8227e-02, 2.1522e-04, 9.1452e-03, 1.1427e-03, 4.5123e-04,\n",
      "         1.1390e-03, 1.1150e-02],\n",
      "        [8.6651e-03, 1.3033e-02, 2.1434e-05, 2.3323e-03, 3.8872e-04, 2.3796e-04,\n",
      "         9.6093e-04, 2.2189e-03],\n",
      "        [5.5414e-03, 7.4982e-03, 3.0087e-05, 1.3040e-03, 2.1713e-04, 7.7168e-05,\n",
      "         3.7272e-04, 1.5249e-03],\n",
      "        [8.2832e-03, 1.1105e-02, 5.1364e-05, 1.6761e-03, 3.3177e-04, 1.3367e-04,\n",
      "         6.0305e-04, 1.7939e-03],\n",
      "        [2.1608e-02, 3.0055e-02, 1.3327e-04, 8.1365e-03, 8.7860e-04, 4.2480e-04,\n",
      "         1.1226e-03, 9.7771e-03],\n",
      "        [5.9124e-03, 8.7159e-03, 3.6282e-05, 3.0434e-03, 2.6747e-04, 1.8893e-04,\n",
      "         3.6744e-04, 3.7659e-03]])}, 30: {'step': tensor(11460.), 'exp_avg': tensor([ 3.2034e-05,  4.1966e-06, -6.7647e-06,  1.6087e-05, -5.9753e-05,\n",
      "         2.0695e-06, -3.5830e-07, -5.0733e-06,  3.1625e-06, -1.9794e-05,\n",
      "        -5.9687e-08,  4.4471e-05,  3.7312e-05, -3.6081e-06,  4.5615e-07,\n",
      "        -1.1618e-04,  6.2267e-05,  1.3864e-04,  3.7062e-05, -1.0364e-05,\n",
      "        -4.9376e-07, -8.7769e-06,  2.6796e-05,  2.8956e-05,  7.0906e-06]), 'exp_avg_sq': tensor([1.2111e-06, 6.4552e-07, 1.2440e-06, 7.7780e-07, 2.0276e-06, 5.4104e-07,\n",
      "        4.8150e-07, 5.1186e-07, 7.8856e-07, 1.3309e-06, 1.4553e-06, 6.2837e-05,\n",
      "        8.5756e-07, 1.0737e-06, 6.0705e-07, 1.3326e-05, 8.8420e-07, 6.0404e-06,\n",
      "        7.8931e-07, 7.4372e-07, 5.5242e-07, 6.1905e-07, 1.0250e-06, 1.3429e-06,\n",
      "        8.7905e-07])}, 31: {'step': tensor(11460.), 'exp_avg': tensor([-4.8204e-05, -5.4235e-05, -6.4061e-05, -4.7708e-05, -3.0306e-04,\n",
      "        -5.6960e-05, -6.2467e-05, -8.6959e-05, -2.0056e-05, -1.6708e-04,\n",
      "        -1.4087e-04, -6.0814e-05, -3.3859e-05, -1.0549e-04, -8.2354e-05,\n",
      "        -1.9101e-03,  2.4936e-06, -6.3705e-04, -3.5847e-05, -1.0376e-04,\n",
      "        -7.9591e-05, -1.1300e-04,  3.3782e-05, -1.7206e-04, -7.6335e-05]), 'exp_avg_sq': tensor([1.5062e-05, 1.5175e-05, 1.5048e-05, 1.6276e-05, 7.6182e-06, 2.4997e-06,\n",
      "        2.5285e-06, 2.5370e-06, 1.3137e-05, 4.5947e-06, 5.1374e-06, 7.7527e-04,\n",
      "        1.7797e-05, 3.5487e-06, 2.7270e-06, 1.4924e-04, 9.9769e-06, 3.7658e-05,\n",
      "        2.1145e-05, 2.5646e-06, 3.4983e-06, 3.0990e-06, 1.7044e-05, 5.5544e-06,\n",
      "        2.9245e-06])}, 32: {'step': tensor(11460.), 'exp_avg': tensor([-0.0025,  0.0029, -0.0027,  0.0009,  0.0021,  0.0005, -0.0020,  0.0004,\n",
      "         0.0002,  0.0004]), 'exp_avg_sq': tensor([0.0016, 0.0008, 0.0029, 0.0008, 0.0008, 0.0029, 0.0045, 0.0018, 0.0004,\n",
      "        0.0003])}, 33: {'step': tensor(11460.), 'exp_avg': tensor([[-3.8754e-03, -8.6349e-04,  3.6065e-03, -1.1106e-03, -1.9601e-04,\n",
      "          2.1766e-03,  2.0361e-03, -2.0116e-03],\n",
      "        [ 2.4463e-03,  1.4933e-03,  1.0497e-03,  7.5006e-04,  7.5827e-04,\n",
      "         -8.2685e-03, -3.2640e-04,  2.3802e-03],\n",
      "        [ 3.3518e-04, -4.5835e-04, -5.9184e-04,  2.1609e-04,  5.4700e-05,\n",
      "          3.9016e-05, -1.6635e-04,  4.2270e-04],\n",
      "        [ 1.2035e-03,  4.8317e-04, -5.2504e-04,  3.5274e-04,  1.3711e-04,\n",
      "         -1.9290e-03, -4.1070e-04,  7.8570e-04],\n",
      "        [ 2.8685e-03,  1.2660e-03, -4.6174e-05,  9.0307e-04,  6.6151e-04,\n",
      "         -7.1549e-03, -7.0258e-04,  2.4562e-03],\n",
      "        [-1.9298e-03, -7.7335e-04,  4.7672e-04, -6.0302e-04, -2.5214e-04,\n",
      "          4.0626e-03,  4.1806e-04, -1.4393e-03],\n",
      "        [ 3.2072e-04, -7.5097e-04, -3.6937e-03, -1.4008e-06, -7.3191e-04,\n",
      "          6.8234e-03, -1.0374e-03, -1.1045e-03],\n",
      "        [-2.7116e-03, -8.2583e-04,  1.0670e-03, -8.7199e-04, -3.7374e-04,\n",
      "          4.8438e-03,  7.9366e-04, -2.0238e-03],\n",
      "        [ 4.0365e-04,  1.9418e-04, -4.8123e-04,  9.1421e-05, -7.8530e-05,\n",
      "         -7.3198e-06, -1.6155e-04,  6.3107e-05],\n",
      "        [ 9.3900e-04,  2.3531e-04, -8.6188e-04,  2.7361e-04,  2.0737e-05,\n",
      "         -5.8568e-04, -4.4282e-04,  4.7129e-04]]), 'exp_avg_sq': tensor([[3.3441e-03, 8.7117e-04, 2.4778e-03, 2.7920e-04, 6.0900e-05, 2.8805e-03,\n",
      "         1.1836e-03, 7.0276e-04],\n",
      "        [2.0110e-03, 7.4251e-04, 9.0236e-04, 1.7203e-04, 2.4626e-05, 6.4649e-03,\n",
      "         5.1092e-04, 8.2110e-04],\n",
      "        [7.5759e-03, 9.8524e-04, 4.5572e-03, 7.9806e-04, 1.0622e-04, 8.8884e-03,\n",
      "         2.3310e-03, 3.5258e-03],\n",
      "        [1.5248e-03, 4.9877e-04, 8.4937e-04, 1.2623e-04, 2.1495e-05, 2.2292e-03,\n",
      "         4.7736e-04, 3.8347e-04],\n",
      "        [8.7070e-04, 4.4659e-04, 2.8275e-04, 7.3952e-05, 1.0627e-05, 3.4288e-03,\n",
      "         1.7763e-04, 3.8964e-04],\n",
      "        [9.5915e-03, 8.8293e-04, 4.9416e-03, 1.0457e-03, 1.1907e-04, 1.2091e-02,\n",
      "         2.6140e-03, 5.0371e-03],\n",
      "        [5.4721e-03, 2.1293e-03, 3.3238e-03, 4.8851e-04, 7.7312e-05, 1.5310e-02,\n",
      "         1.3898e-03, 2.2126e-03],\n",
      "        [4.8162e-03, 7.1283e-04, 2.2004e-03, 4.6558e-04, 3.9446e-05, 7.2133e-03,\n",
      "         1.2925e-03, 2.2017e-03],\n",
      "        [1.6553e-03, 4.0979e-04, 9.3422e-04, 1.3768e-04, 2.2744e-05, 1.9367e-03,\n",
      "         5.1087e-04, 4.6119e-04],\n",
      "        [7.4166e-04, 1.9963e-04, 4.4157e-04, 6.9062e-05, 1.0942e-05, 9.1507e-04,\n",
      "         2.3082e-04, 2.3995e-04]])}, 34: {'step': tensor(11460.), 'exp_avg': tensor([-0.0008, -0.0003, -0.0010, -0.0007, -0.0008, -0.0003, -0.0003, -0.0003,\n",
      "        -0.0003, -0.0004, -0.0004, -0.0018, -0.0006, -0.0003, -0.0003, -0.0026,\n",
      "        -0.0003, -0.0017, -0.0005, -0.0003, -0.0003, -0.0003, -0.0003, -0.0006,\n",
      "        -0.0004]), 'exp_avg_sq': tensor([2.6695e-04, 2.9296e-05, 2.0444e-04, 1.0401e-04, 1.4609e-04, 2.6316e-05,\n",
      "        2.4249e-05, 2.1205e-05, 2.8383e-05, 6.9282e-05, 8.0905e-05, 4.7228e-03,\n",
      "        5.7097e-05, 4.6029e-05, 2.6136e-05, 1.3627e-03, 2.2181e-05, 7.1536e-04,\n",
      "        6.9878e-05, 3.2658e-05, 2.1224e-05, 2.1098e-05, 3.8437e-05, 7.1783e-05,\n",
      "        3.7327e-05])}, 35: {'step': tensor(11460.), 'exp_avg': tensor([ 3.4450e-10, -1.2883e-10,  1.4911e-10, -4.4745e-11, -2.4005e-11,\n",
      "         7.9272e-11, -4.0443e-11, -3.1343e-12, -2.6648e-10, -2.5273e-10,\n",
      "         1.9097e-10, -3.8059e-11,  1.0333e-10,  1.1270e-10,  7.9608e-12,\n",
      "        -1.3852e-10, -2.1132e-10, -8.9076e-11, -1.8705e-10, -2.3400e-10,\n",
      "        -1.5198e-13, -4.6878e-11, -9.2962e-11, -1.0481e-10, -1.1187e-10]), 'exp_avg_sq': tensor([3.5884e-17, 2.5885e-17, 3.2710e-17, 2.1454e-17, 4.8889e-17, 1.0696e-17,\n",
      "        1.4298e-17, 7.0807e-18, 1.5489e-17, 2.5665e-17, 2.4779e-17, 1.0881e-16,\n",
      "        1.8550e-17, 2.0407e-17, 6.4365e-18, 6.2423e-17, 1.0340e-17, 3.3475e-17,\n",
      "        1.9198e-17, 1.3318e-17, 5.3640e-18, 6.3163e-18, 1.2522e-17, 1.4376e-17,\n",
      "        8.9696e-18])}, 36: {'step': tensor(11460.), 'exp_avg': tensor([ 0.0496, -0.0198,  0.0677, -0.0252, -0.0096,  0.0450, -0.0156,  0.0024,\n",
      "         0.0639, -0.0459, -0.0647, -0.0478]), 'exp_avg_sq': tensor([0.1945, 0.0893, 1.2348, 0.5208, 0.7184, 0.3214, 0.2772, 0.1067, 2.6102,\n",
      "        0.6774, 0.6010, 0.9723])}, 37: {'step': tensor(11460.), 'exp_avg': tensor([[-0.2652,  0.0356, -0.0336,  0.1785, -0.1340, -0.1006,  0.4107, -0.0612],\n",
      "        [-0.0029,  0.0165, -0.0189,  0.0027, -0.0220,  0.0060,  0.0018,  0.0075],\n",
      "        [-0.3556,  0.0770, -0.0715,  0.2425, -0.2093, -0.1083,  0.4934, -0.0314],\n",
      "        [ 0.2024, -0.0679,  0.0533, -0.1385,  0.1336,  0.0441, -0.2043, -0.0305],\n",
      "        [ 0.1080, -0.0708,  0.0468, -0.0755,  0.0926, -0.0070,  0.0081, -0.0939],\n",
      "        [-0.2134,  0.0292, -0.0191,  0.1424, -0.0999, -0.0758,  0.2859, -0.0277],\n",
      "        [ 0.0182,  0.0483, -0.0394, -0.0074, -0.0369,  0.0451, -0.1281,  0.0857],\n",
      "        [-0.0331,  0.0018, -0.0116,  0.0232, -0.0244, -0.0177,  0.1012, -0.0321],\n",
      "        [-0.3032,  0.0893, -0.0627,  0.2052, -0.1826, -0.0636,  0.2803,  0.0543],\n",
      "        [ 0.2577, -0.0293,  0.0363, -0.1728,  0.1345,  0.1010, -0.4377,  0.0801],\n",
      "        [ 0.2845, -0.0424,  0.0398, -0.1926,  0.1480,  0.1010, -0.4273,  0.0528],\n",
      "        [ 0.3027, -0.0872,  0.0806, -0.2076,  0.2004,  0.0759, -0.3840, -0.0036]]), 'exp_avg_sq': tensor([[ 1.1655,  0.1178,  0.0893,  0.5079,  0.3734,  0.1847,  2.4500,  0.2163],\n",
      "        [ 0.5004,  0.1244,  0.0826,  0.2139,  0.2255,  0.0924,  0.9118,  0.2009],\n",
      "        [ 4.2029,  0.6799,  0.4841,  1.7645,  1.5492,  0.6826,  6.8975,  1.0289],\n",
      "        [ 1.7223,  0.2696,  0.1918,  0.7016,  0.5682,  0.3167,  3.1000,  0.4728],\n",
      "        [ 3.9433,  0.5622,  0.3924,  1.6748,  1.3431,  0.6847,  7.7335,  0.9588],\n",
      "        [ 1.1844,  0.1596,  0.1107,  0.4799,  0.3776,  0.1914,  1.8653,  0.2676],\n",
      "        [ 2.0303,  0.4532,  0.3149,  0.8591,  0.7894,  0.4612,  4.9395,  0.9096],\n",
      "        [ 0.8230,  0.1363,  0.0917,  0.3624,  0.3375,  0.1130,  1.3273,  0.1729],\n",
      "        [ 8.2796,  1.0689,  0.7742,  3.4355,  2.6630,  1.4010, 14.5206,  1.7076],\n",
      "        [ 2.8071,  0.3807,  0.2706,  1.1964,  0.9846,  0.4342,  4.8194,  0.5858],\n",
      "        [ 1.9765,  0.2134,  0.1723,  0.8399,  0.6399,  0.2958,  3.3737,  0.2952],\n",
      "        [ 3.7681,  0.8040,  0.5617,  1.5972,  1.5668,  0.7062,  6.8771,  1.2938]])}, 38: {'step': tensor(11460.), 'exp_avg': tensor([ 4.9688e-04, -2.9714e-04, -2.9617e-04, -8.2327e-06, -2.6268e-04,\n",
      "        -3.5372e-04, -3.4075e-04, -2.7946e-04, -1.8449e-04, -7.9358e-05,\n",
      "        -2.7174e-04,  5.7724e-04,  1.8837e-04, -3.0176e-04, -3.7148e-04,\n",
      "        -1.4589e-03,  1.0225e-04, -2.4462e-03,  2.7361e-04, -6.7654e-05,\n",
      "        -3.9872e-04, -3.7607e-05,  8.6811e-05, -7.9080e-04, -3.9222e-04]), 'exp_avg_sq': tensor([2.7964e-04, 1.4671e-04, 4.2449e-04, 1.9351e-04, 5.0083e-04, 1.1635e-04,\n",
      "        9.4978e-05, 6.4315e-05, 1.1382e-04, 2.1516e-04, 2.6367e-04, 4.3309e-03,\n",
      "        1.7143e-04, 1.4337e-04, 6.7030e-05, 3.1174e-03, 1.8425e-04, 1.4806e-03,\n",
      "        1.3410e-04, 8.3891e-05, 8.6356e-05, 1.6034e-04, 1.2081e-04, 2.0990e-04,\n",
      "        1.8933e-04])}, 39: {'step': tensor(11460.), 'exp_avg': tensor([-0.0093, -0.0091, -0.0140, -0.0108, -0.0365, -0.0079, -0.0081, -0.0089,\n",
      "        -0.0093, -0.0114, -0.0082, -0.0565, -0.0091, -0.0084, -0.0086, -0.1037,\n",
      "        -0.0102,  0.0005, -0.0083, -0.0095, -0.0085, -0.0100, -0.0088, -0.0088,\n",
      "        -0.0083]), 'exp_avg_sq': tensor([0.0035, 0.0050, 0.0035, 0.0040, 0.0143, 0.0038, 0.0039, 0.0045, 0.0052,\n",
      "        0.0040, 0.0034, 0.3288, 0.0055, 0.0034, 0.0044, 0.2294, 0.0058, 0.0610,\n",
      "        0.0051, 0.0044, 0.0041, 0.0046, 0.0056, 0.0060, 0.0045])}, 40: {'step': tensor(11460.), 'exp_avg': tensor([ 0.1109, -0.0055,  0.0413,  0.0931,  0.1081, -0.0842,  0.0988, -0.1359,\n",
      "        -0.1954, -0.1053,  0.2022, -0.1281]), 'exp_avg_sq': tensor([1.6818, 3.3448, 2.1950, 7.1037, 2.7612, 1.6159, 2.5336, 7.9833, 2.5662,\n",
      "        2.5557, 1.8883, 0.8920])}, 41: {'step': tensor(11460.), 'exp_avg': tensor([[ 0.0934, -0.0207,  0.0611,  0.1918, -0.0575, -0.1627, -0.0337, -0.1193,\n",
      "          0.0593, -0.0615,  0.0308,  0.0313],\n",
      "        [ 0.0144,  0.0037,  0.1015,  0.2049, -0.0892, -0.1410, -0.0515, -0.0564,\n",
      "          0.0305,  0.0746, -0.0984,  0.0063],\n",
      "        [ 0.0045,  0.0055, -0.0307, -0.0500,  0.0362,  0.0152,  0.0011,  0.0068,\n",
      "          0.0105, -0.0293,  0.0300,  0.0072],\n",
      "        [ 0.1183, -0.0256,  0.0365,  0.1771, -0.0372, -0.1807, -0.0350, -0.1375,\n",
      "          0.0795, -0.1148,  0.0836,  0.0452],\n",
      "        [ 0.0501, -0.0199,  0.0417,  0.1054, -0.0437, -0.0612, -0.0019, -0.0631,\n",
      "          0.0105, -0.0280,  0.0145,  0.0074],\n",
      "        [-0.0593,  0.0232,  0.0696,  0.0892, -0.0556, -0.0435, -0.0397,  0.0305,\n",
      "         -0.0068,  0.1388, -0.1415, -0.0149],\n",
      "        [ 0.0505, -0.0193,  0.1935,  0.3902, -0.1819, -0.2313, -0.0658, -0.1227,\n",
      "          0.0273,  0.1056, -0.1416,  0.0048],\n",
      "        [-0.0740,  0.0012, -0.1896, -0.4245,  0.1574,  0.3183,  0.1099,  0.1513,\n",
      "         -0.0875, -0.0832,  0.1354, -0.0328],\n",
      "        [-0.1564,  0.0301, -0.1945, -0.4956,  0.1759,  0.3838,  0.1014,  0.2362,\n",
      "         -0.1165,  0.0194,  0.0480, -0.0534],\n",
      "        [-0.0338,  0.0193, -0.0752, -0.1522,  0.0756,  0.0737,  0.0097,  0.0580,\n",
      "          0.0014, -0.0205,  0.0324,  0.0008],\n",
      "        [ 0.1038, -0.0255,  0.0676,  0.2066, -0.0601, -0.1668, -0.0329, -0.1289,\n",
      "          0.0576, -0.0686,  0.0381,  0.0330],\n",
      "        [-0.1116,  0.0281, -0.0815, -0.2430,  0.0800,  0.1962,  0.0384,  0.1451,\n",
      "         -0.0658,  0.0674, -0.0315, -0.0349]]), 'exp_avg_sq': tensor([[ 0.5755,  0.1004,  0.6203,  2.8418,  0.5637,  1.3298,  0.1921,  0.7763,\n",
      "          0.1124,  1.2056,  1.1630,  0.0361],\n",
      "        [ 1.0126,  0.1769,  0.7498,  3.5325,  0.7523,  1.6491,  0.2576,  1.2405,\n",
      "          0.1735,  1.9585,  1.7762,  0.0623],\n",
      "        [ 0.8577,  0.1579,  0.8004,  3.3687,  0.7400,  1.4759,  0.2614,  1.0198,\n",
      "          0.1168,  2.0245,  1.9102,  0.0452],\n",
      "        [ 2.2204,  0.3858,  2.2748, 11.0848,  2.2594,  5.0414,  0.6151,  3.1676,\n",
      "          0.4544,  3.7723,  3.5390,  0.1388],\n",
      "        [ 0.3346,  0.0859,  0.4349,  2.0068,  0.5346,  0.9233,  0.1641,  0.5131,\n",
      "          0.1239,  0.6139,  0.5931,  0.0385],\n",
      "        [ 0.6439,  0.1115,  0.5823,  2.8415,  0.5665,  1.3238,  0.1746,  0.8758,\n",
      "          0.1141,  1.1753,  1.0896,  0.0377],\n",
      "        [ 0.9992,  0.1854,  1.1932,  4.9566,  1.1236,  2.1123,  0.3389,  1.2691,\n",
      "          0.1712,  2.4200,  2.3747,  0.0580],\n",
      "        [ 2.7833,  0.4999,  2.4783, 10.4383,  2.2554,  4.7079,  0.8857,  3.2012,\n",
      "          0.4024,  6.5367,  6.2255,  0.1541],\n",
      "        [ 0.8485,  0.1513,  0.9668,  4.3067,  0.8614,  1.9566,  0.2987,  1.1204,\n",
      "          0.1586,  1.8496,  1.8174,  0.0510],\n",
      "        [ 1.0161,  0.1788,  0.9211,  3.7132,  0.8425,  1.6109,  0.3006,  1.1332,\n",
      "          0.1397,  2.5221,  2.3985,  0.0551],\n",
      "        [ 0.8302,  0.1277,  0.8075,  4.0388,  0.7106,  1.9181,  0.2227,  1.1669,\n",
      "          0.1563,  1.3940,  1.3071,  0.0466],\n",
      "        [ 0.4100,  0.0645,  0.3046,  1.6315,  0.2824,  0.7805,  0.0854,  0.5562,\n",
      "          0.0667,  0.6372,  0.5623,  0.0218]])}, 42: {'step': tensor(11460.), 'exp_avg': tensor([ 1.0276e-03, -6.4095e-05, -2.7551e-04,  2.3300e-04,  1.0137e-03,\n",
      "        -6.2657e-06, -4.6949e-06,  1.3682e-05, -5.8860e-05,  2.9319e-04,\n",
      "        -4.8474e-05,  9.2556e-04,  4.0913e-04,  1.2111e-05, -7.1075e-05,\n",
      "         1.9634e-03,  3.4860e-04, -2.3730e-03,  5.4005e-04,  1.3914e-04,\n",
      "        -6.4373e-05,  2.0432e-04,  2.7690e-04, -3.8146e-04, -8.3658e-05]), 'exp_avg_sq': tensor([3.5294e-04, 1.8843e-04, 6.3898e-04, 2.5555e-04, 6.5352e-04, 1.2140e-04,\n",
      "        9.6048e-05, 7.5703e-05, 1.6159e-04, 2.5607e-04, 2.9730e-04, 6.1742e-03,\n",
      "        2.2953e-04, 1.5572e-04, 7.5114e-05, 3.8942e-03, 2.1484e-04, 1.9679e-03,\n",
      "        1.8281e-04, 1.0567e-04, 9.6093e-05, 1.4477e-04, 1.6089e-04, 2.3227e-04,\n",
      "        1.9560e-04])}, 43: {'step': tensor(11460.), 'exp_avg': tensor([-0.0051,  0.0069,  0.0102,  0.0054,  0.0259,  0.0048,  0.0055,  0.0071,\n",
      "         0.0073,  0.0083,  0.0057, -0.0445,  0.0042,  0.0072,  0.0065,  0.0593,\n",
      "         0.0103, -0.0151,  0.0015,  0.0083,  0.0063,  0.0090,  0.0062,  0.0066,\n",
      "         0.0053]), 'exp_avg_sq': tensor([0.0320, 0.0293, 0.0279, 0.0353, 0.0612, 0.0242, 0.0239, 0.0256, 0.0307,\n",
      "        0.0237, 0.0205, 0.9217, 0.0425, 0.0211, 0.0253, 0.5478, 0.0310, 0.1424,\n",
      "        0.0435, 0.0268, 0.0249, 0.0262, 0.0318, 0.0303, 0.0258])}, 44: {'step': tensor(11460.), 'exp_avg': tensor([-0.1154, -0.0219, -0.0286,  0.1911,  0.0902, -0.0484,  0.1369, -0.0867,\n",
      "        -0.0313,  0.0099, -0.1029, -0.1070,  0.2046, -0.3514,  0.0956,  0.1653]), 'exp_avg_sq': tensor([3.5067, 0.7533, 1.9041, 2.0007, 1.4963, 2.1438, 1.6255, 1.6922, 2.6151,\n",
      "        1.0649, 2.1971, 1.0270, 2.3153, 5.4212, 1.9214, 1.8430])}, 45: {'step': tensor(11460.), 'exp_avg': tensor([[-0.0970, -0.0148,  0.1998,  0.1424, -0.0223, -0.0975,  0.1268,  0.0334,\n",
      "         -0.1988, -0.0449, -0.2479,  0.1958],\n",
      "        [-0.0089,  0.0055, -0.0289, -0.0123,  0.0126,  0.0331, -0.0339, -0.0221,\n",
      "          0.0299, -0.0096,  0.0436, -0.0121],\n",
      "        [ 0.0015, -0.0170,  0.1314,  0.0643, -0.0549, -0.1124,  0.1245,  0.0677,\n",
      "         -0.1280,  0.0160, -0.1821,  0.0840],\n",
      "        [ 0.2387,  0.0521, -0.3035, -0.2963, -0.0943,  0.0870, -0.1131, -0.0331,\n",
      "          0.3654,  0.1178,  0.4131, -0.4026],\n",
      "        [ 0.0350, -0.0032,  0.0418,  0.0029, -0.0441, -0.0604,  0.0628,  0.0395,\n",
      "         -0.0240,  0.0239, -0.0488, -0.0091],\n",
      "        [-0.0283, -0.0088,  0.0378,  0.0369,  0.0109, -0.0106,  0.0128,  0.0074,\n",
      "         -0.0486, -0.0126, -0.0567,  0.0534],\n",
      "        [ 0.1769,  0.0396, -0.3581, -0.2724,  0.0088,  0.1759, -0.2178, -0.0738,\n",
      "          0.3739,  0.0795,  0.4594, -0.3636],\n",
      "        [-0.1135, -0.0245,  0.2071,  0.1657,  0.0106, -0.0968,  0.1203,  0.0383,\n",
      "         -0.2245, -0.0515, -0.2698,  0.2205],\n",
      "        [-0.0466,  0.0048,  0.0389,  0.0369,  0.0079,  0.0009,  0.0108, -0.0179,\n",
      "         -0.0337, -0.0297, -0.0324,  0.0511],\n",
      "        [-0.0170, -0.0136,  0.1018,  0.0623, -0.0241, -0.0743,  0.0830,  0.0429,\n",
      "         -0.1008, -0.0009, -0.1352,  0.0774],\n",
      "        [-0.0520, -0.0011, -0.1107, -0.0156,  0.1107,  0.1273, -0.1441, -0.0690,\n",
      "          0.0631, -0.0361,  0.1195, -0.0057],\n",
      "        [-0.1895, -0.0419,  0.3472,  0.2786,  0.0126, -0.1563,  0.1942,  0.0656,\n",
      "         -0.3675, -0.0890, -0.4442,  0.3693],\n",
      "        [ 0.0931,  0.0118, -0.1197, -0.1026, -0.0153,  0.0346, -0.0539, -0.0023,\n",
      "          0.1415,  0.0435,  0.1639, -0.1565],\n",
      "        [-0.2699, -0.0389,  0.2502,  0.2745,  0.1221, -0.0183,  0.0484, -0.0208,\n",
      "         -0.3222, -0.1405, -0.3428,  0.3964],\n",
      "        [ 0.1281,  0.0277, -0.2714, -0.2011,  0.0164,  0.1359, -0.1690, -0.0568,\n",
      "          0.2768,  0.0577,  0.3433, -0.2682],\n",
      "        [ 0.1494,  0.0223, -0.1637, -0.1642, -0.0575,  0.0320, -0.0518,  0.0010,\n",
      "          0.1975,  0.0766,  0.2169, -0.2302]]), 'exp_avg_sq': tensor([[2.7054, 0.1767, 2.4841, 2.7406, 3.3378, 1.8974, 2.6525, 0.4473, 3.3556,\n",
      "         0.8242, 4.2531, 4.8170],\n",
      "        [0.5549, 0.0347, 0.5605, 0.5698, 0.7161, 0.4343, 0.6011, 0.1002, 0.7124,\n",
      "         0.1726, 0.9320, 0.9913],\n",
      "        [1.6285, 0.1089, 1.9866, 1.9095, 1.8263, 1.1597, 1.6078, 0.2789, 2.5582,\n",
      "         0.4873, 3.4722, 3.3604],\n",
      "        [1.0273, 0.0686, 1.0594, 1.1768, 0.9462, 0.5129, 0.6983, 0.1630, 1.5358,\n",
      "         0.2977, 1.9231, 2.1068],\n",
      "        [1.3030, 0.0802, 1.5224, 1.4996, 1.4120, 0.8870, 1.2281, 0.2071, 1.9990,\n",
      "         0.3877, 2.6368, 2.6382],\n",
      "        [0.9332, 0.0742, 0.8747, 1.0760, 0.8490, 0.3974, 0.5514, 0.1453, 1.3654,\n",
      "         0.2658, 1.6783, 1.9192],\n",
      "        [1.0716, 0.0713, 1.0769, 1.1041, 1.2521, 0.7338, 1.0387, 0.1778, 1.4128,\n",
      "         0.3213, 1.8435, 2.0016],\n",
      "        [0.9799, 0.0639, 0.8957, 1.0497, 0.8903, 0.4556, 0.6402, 0.1352, 1.3267,\n",
      "         0.2898, 1.6090, 1.9174],\n",
      "        [2.2359, 0.1405, 2.6916, 2.5666, 2.4889, 1.6162, 2.2252, 0.3903, 3.4082,\n",
      "         0.6718, 4.6227, 4.4964],\n",
      "        [1.0734, 0.0686, 1.2566, 1.2414, 1.2152, 0.7626, 1.0619, 0.1779, 1.6156,\n",
      "         0.3252, 2.1477, 2.1492],\n",
      "        [2.0204, 0.1247, 1.7366, 2.1210, 2.1242, 1.0350, 1.4667, 0.2274, 2.6324,\n",
      "         0.5967, 3.2059, 3.8527],\n",
      "        [0.9424, 0.0600, 1.0943, 1.0610, 1.1217, 0.6902, 0.9780, 0.1531, 1.3794,\n",
      "         0.2859, 1.8635, 1.8533],\n",
      "        [2.1321, 0.1236, 2.4517, 2.4300, 2.1636, 1.3323, 1.8907, 0.2929, 3.2543,\n",
      "         0.6247, 4.2295, 4.3459],\n",
      "        [4.5011, 0.2697, 5.2347, 5.0904, 4.6368, 2.8482, 4.0335, 0.6481, 6.9327,\n",
      "         1.3111, 9.1387, 9.2374],\n",
      "        [1.2800, 0.0870, 1.1319, 1.2657, 1.6168, 0.8844, 1.2511, 0.2074, 1.5365,\n",
      "         0.3895, 1.9349, 2.2504],\n",
      "        [1.0385, 0.0648, 1.1746, 1.2026, 0.8354, 0.5019, 0.7089, 0.1458, 1.6503,\n",
      "         0.2926, 2.0981, 2.2281]])}, 46: {'step': tensor(11460.), 'exp_avg': tensor([ 0.0004, -0.0001, -0.0014, -0.0008, -0.0005, -0.0011, -0.0011, -0.0012,\n",
      "        -0.0005, -0.0006, -0.0008, -0.0027,  0.0003, -0.0010, -0.0012, -0.0007,\n",
      "         0.0008, -0.0011,  0.0008, -0.0010, -0.0012, -0.0011, -0.0005, -0.0011,\n",
      "        -0.0012]), 'exp_avg_sq': tensor([0.0039, 0.0024, 0.0042, 0.0035, 0.0041, 0.0010, 0.0009, 0.0006, 0.0022,\n",
      "        0.0032, 0.0035, 0.0049, 0.0031, 0.0024, 0.0007, 0.0044, 0.0019, 0.0037,\n",
      "        0.0029, 0.0011, 0.0007, 0.0009, 0.0022, 0.0013, 0.0014])}, 47: {'step': tensor(11460.), 'exp_avg': tensor([0.0298, 0.0285, 0.0274, 0.0279, 0.0277, 0.0281, 0.0281, 0.0280, 0.0285,\n",
      "        0.0278, 0.0277, 0.0339, 0.0286, 0.0279, 0.0280, 0.0276, 0.0281, 0.0279,\n",
      "        0.0290, 0.0279, 0.0280, 0.0280, 0.0289, 0.0278, 0.0280]), 'exp_avg_sq': tensor([0.0277, 0.0232, 0.0288, 0.0269, 0.0215, 0.0217, 0.0216, 0.0217, 0.0235,\n",
      "        0.0215, 0.0215, 0.0309, 0.0257, 0.0215, 0.0216, 0.0216, 0.0225, 0.0216,\n",
      "        0.0258, 0.0216, 0.0216, 0.0216, 0.0238, 0.0215, 0.0216])}, 48: {'step': tensor(11460.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 49: {'step': tensor(11460.), 'exp_avg': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'exp_avg_sq': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])}, 50: {'step': tensor(11460.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 51: {'step': tensor(11460.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 52: {'step': tensor(11460.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 53: {'step': tensor(11460.), 'exp_avg': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'exp_avg_sq': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])}, 54: {'step': tensor(11460.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 55: {'step': tensor(11460.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 56: {'step': tensor(11460.), 'exp_avg': tensor([0.]), 'exp_avg_sq': tensor([0.])}, 57: {'step': tensor(11460.), 'exp_avg': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'exp_avg_sq': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])}, 60: {'step': tensor(11460.), 'exp_avg': tensor([-2.7705e-02,  3.0257e-02,  5.6484e-03,  3.9731e-02,  1.0367e-01,\n",
      "         1.2931e-02,  5.5326e-02, -2.0349e-03, -9.5895e-03, -3.6585e-02,\n",
      "        -9.1544e-02, -3.8636e-02,  3.6208e-05, -2.8784e-02,  5.8464e-02,\n",
      "        -7.1185e-02]), 'exp_avg_sq': tensor([0.1103, 0.0902, 0.0438, 0.2145, 0.2132, 0.1718, 0.1882, 0.1063, 0.1950,\n",
      "        0.1348, 0.3571, 0.1815, 0.2333, 0.0664, 0.1255, 0.1691])}, 61: {'step': tensor(11460.), 'exp_avg': tensor([[-1.7941e-01,  1.2244e-03,  7.9873e-02,  1.0978e-02, -6.3664e-02,\n",
      "          6.6533e-02, -1.2215e-01, -6.2265e-02,  1.0144e-01,  5.0229e-02,\n",
      "         -4.8534e-02, -5.7475e-02,  5.6130e-02,  8.2217e-02,  7.0589e-02,\n",
      "         -1.0618e-02],\n",
      "        [ 2.9616e-01, -1.5004e-02, -1.2964e-01, -3.1362e-02,  8.0820e-02,\n",
      "         -1.1649e-01,  2.0266e-01,  1.0709e-01, -1.6680e-01, -7.5217e-02,\n",
      "          7.9336e-02,  9.0802e-02, -7.4973e-02, -1.3100e-01, -1.0486e-01,\n",
      "          1.7629e-02],\n",
      "        [ 3.2046e-01, -3.0994e-02, -1.2885e-01, -6.6768e-02,  2.1454e-02,\n",
      "         -1.3255e-01,  2.1315e-01,  1.3211e-01, -1.7717e-01, -5.9521e-02,\n",
      "          6.4012e-02,  8.7620e-02, -5.4954e-02, -1.3310e-01, -6.9505e-02,\n",
      "          1.9794e-02],\n",
      "        [-2.8280e-02,  4.7768e-02, -2.7269e-02,  8.9474e-02,  2.0148e-01,\n",
      "          4.0106e-02, -3.4425e-03, -4.3286e-02, -1.3229e-02, -6.0197e-02,\n",
      "          5.0487e-02,  2.5601e-02, -1.1344e-01, -1.6542e-02, -1.0553e-01,\n",
      "         -4.5249e-03],\n",
      "        [ 8.3823e-01, -4.7046e-02, -3.2525e-01, -1.4280e-01,  7.1150e-02,\n",
      "         -3.3297e-01,  5.5018e-01,  3.2032e-01, -4.3804e-01, -1.5978e-01,\n",
      "          1.5779e-01,  2.3504e-01, -1.3597e-01, -3.5410e-01, -2.1452e-01,\n",
      "          5.6328e-02],\n",
      "        [-5.5230e-02,  9.1294e-03,  2.7708e-02,  9.9296e-03, -1.2056e-02,\n",
      "          2.7601e-02, -3.9140e-02, -2.5782e-02,  3.5535e-02,  1.4746e-02,\n",
      "         -1.6455e-02, -1.3929e-02,  1.3408e-02,  2.4202e-02,  9.9944e-03,\n",
      "         -6.6568e-04],\n",
      "        [ 3.4104e-01, -2.7627e-02, -1.1625e-01, -7.6245e-02, -3.5498e-02,\n",
      "         -1.4362e-01,  2.1890e-01,  1.3134e-01, -1.5956e-01, -4.3939e-02,\n",
      "          4.7260e-02,  8.5919e-02, -5.7507e-03, -1.3431e-01, -6.3567e-02,\n",
      "          2.5149e-02],\n",
      "        [ 3.0493e-02, -1.2453e-02,  5.8875e-03, -3.7515e-02, -8.0429e-02,\n",
      "         -1.9263e-02,  1.0023e-02,  2.4378e-02, -2.9428e-03,  2.0701e-02,\n",
      "         -2.4717e-02, -4.5739e-03,  3.6315e-02, -4.4792e-03,  3.9379e-02,\n",
      "          3.6898e-03],\n",
      "        [-5.0070e-02,  1.4142e-02,  1.4530e-02,  1.5378e-02,  1.8725e-02,\n",
      "          2.6976e-02, -3.5481e-02, -1.5548e-02,  1.8266e-02,  1.4434e-03,\n",
      "         -1.3097e-02, -1.1177e-02, -2.1683e-02,  1.4091e-02,  1.2973e-02,\n",
      "         -4.6418e-03],\n",
      "        [-4.7472e-01,  4.6121e-02,  1.7757e-01,  1.0451e-01,  1.0701e-02,\n",
      "          2.0069e-01, -3.1176e-01, -1.9017e-01,  2.4342e-01,  7.4343e-02,\n",
      "         -8.2824e-02, -1.2369e-01,  4.1613e-02,  1.9087e-01,  9.4633e-02,\n",
      "         -3.1515e-02],\n",
      "        [-7.5781e-01,  3.9657e-02,  2.9348e-01,  1.3314e-01, -6.4441e-02,\n",
      "          2.9588e-01, -4.9522e-01, -2.9252e-01,  3.9980e-01,  1.4355e-01,\n",
      "         -1.3737e-01, -2.1383e-01,  1.3464e-01,  3.2182e-01,  1.9091e-01,\n",
      "         -5.1930e-02],\n",
      "        [-3.7064e-01,  3.4591e-02,  1.2247e-01,  1.0059e-01,  7.1258e-02,\n",
      "          1.5881e-01, -2.3178e-01, -1.5621e-01,  1.7556e-01,  3.8671e-02,\n",
      "         -3.4010e-02, -8.6532e-02,  3.6833e-03,  1.4575e-01,  3.7140e-02,\n",
      "         -2.6102e-02],\n",
      "        [ 3.0283e-01, -4.3683e-02, -9.6721e-02, -1.0537e-01, -9.7737e-02,\n",
      "         -1.3800e-01,  1.8786e-01,  1.4126e-01, -1.4591e-01, -1.9403e-02,\n",
      "          1.8557e-02,  6.2795e-02,  1.2636e-02, -1.1332e-01,  5.4223e-04,\n",
      "          2.0084e-02],\n",
      "        [ 6.7077e-03, -2.5796e-02,  8.7938e-03, -3.7691e-02, -7.5043e-02,\n",
      "         -1.6465e-02,  2.3688e-03,  1.6722e-02,  2.2516e-03,  2.3460e-02,\n",
      "         -1.3067e-02, -1.0668e-02,  4.4088e-02,  1.0056e-02,  3.9606e-02,\n",
      "          9.6237e-04],\n",
      "        [ 2.6835e-01, -6.2444e-04, -1.0471e-01, -2.9146e-02,  4.9796e-02,\n",
      "         -9.7457e-02,  1.7550e-01,  9.2277e-02, -1.3729e-01, -5.8835e-02,\n",
      "          5.3530e-02,  8.1414e-02, -5.7558e-02, -1.1767e-01, -9.0498e-02,\n",
      "          1.9802e-02],\n",
      "        [-4.8811e-01,  1.0595e-02,  1.9837e-01,  6.2892e-02, -9.6511e-02,\n",
      "          1.8022e-01, -3.2167e-01, -1.7971e-01,  2.6469e-01,  1.0975e-01,\n",
      "         -1.0089e-01, -1.4732e-01,  1.2182e-01,  2.1553e-01,  1.5271e-01,\n",
      "         -3.3440e-02]]), 'exp_avg_sq': tensor([[2.0009e+00, 9.6198e-02, 3.8209e-01, 3.7665e-01, 1.7788e+00, 3.7167e-01,\n",
      "         8.5697e-01, 3.8637e-01, 5.8153e-01, 2.2216e-01, 3.2907e-01, 1.7991e-01,\n",
      "         5.0959e-01, 3.6689e-01, 6.6377e-01, 1.7306e-02],\n",
      "        [2.0381e+00, 9.2561e-02, 3.7837e-01, 4.2639e-01, 1.9546e+00, 4.0124e-01,\n",
      "         8.6923e-01, 4.2280e-01, 5.8556e-01, 2.3187e-01, 3.2649e-01, 1.7226e-01,\n",
      "         5.3160e-01, 3.6566e-01, 6.8547e-01, 1.6148e-02],\n",
      "        [9.7653e-01, 4.3006e-02, 1.8828e-01, 2.1123e-01, 9.8271e-01, 1.9323e-01,\n",
      "         4.1968e-01, 2.0426e-01, 2.8299e-01, 1.1744e-01, 1.6037e-01, 8.4027e-02,\n",
      "         2.6652e-01, 1.7517e-01, 3.4450e-01, 7.2852e-03],\n",
      "        [4.7335e+00, 1.9459e-01, 8.3338e-01, 9.0218e-01, 4.1348e+00, 9.0347e-01,\n",
      "         1.9846e+00, 9.4395e-01, 1.3050e+00, 4.9988e-01, 6.9332e-01, 3.9814e-01,\n",
      "         1.1286e+00, 8.4752e-01, 1.4805e+00, 3.7788e-02],\n",
      "        [5.0213e+00, 1.9097e-01, 8.1674e-01, 1.0352e+00, 4.5473e+00, 9.6152e-01,\n",
      "         2.0382e+00, 1.0439e+00, 1.3111e+00, 5.1128e-01, 6.8986e-01, 3.9699e-01,\n",
      "         1.1624e+00, 8.7155e-01, 1.5410e+00, 3.4840e-02],\n",
      "        [3.6660e+00, 1.4056e-01, 7.2554e-01, 6.2978e-01, 3.2081e+00, 6.8314e-01,\n",
      "         1.6238e+00, 6.8458e-01, 1.1046e+00, 4.3646e-01, 5.8449e-01, 3.4287e-01,\n",
      "         9.2555e-01, 7.1066e-01, 1.2440e+00, 2.3644e-02],\n",
      "        [3.5393e+00, 1.9034e-01, 6.7528e-01, 6.1322e-01, 2.6304e+00, 7.1027e-01,\n",
      "         1.5606e+00, 6.9010e-01, 1.0388e+00, 3.5054e-01, 5.1439e-01, 3.0211e-01,\n",
      "         7.8810e-01, 6.4048e-01, 9.9468e-01, 2.6352e-02],\n",
      "        [1.9349e+00, 1.0729e-01, 3.5846e-01, 5.8071e-01, 2.6288e+00, 4.2790e-01,\n",
      "         8.1452e-01, 4.6957e-01, 5.5293e-01, 2.6765e-01, 3.7455e-01, 1.5814e-01,\n",
      "         6.3741e-01, 3.2545e-01, 8.5308e-01, 1.2788e-02],\n",
      "        [3.8124e+00, 1.9536e-01, 7.0320e-01, 9.7806e-01, 4.5547e+00, 7.7541e-01,\n",
      "         1.5862e+00, 8.4289e-01, 1.0647e+00, 4.9595e-01, 6.8854e-01, 3.1686e-01,\n",
      "         1.1753e+00, 6.5426e-01, 1.5036e+00, 2.8227e-02],\n",
      "        [3.8658e+00, 1.7208e-01, 6.7205e-01, 7.7315e-01, 3.2108e+00, 7.9489e-01,\n",
      "         1.6270e+00, 8.2071e-01, 1.0624e+00, 3.7493e-01, 5.1317e-01, 2.9415e-01,\n",
      "         8.6616e-01, 6.5386e-01, 1.0725e+00, 2.5958e-02],\n",
      "        [8.1213e+00, 3.1769e-01, 1.3178e+00, 1.7917e+00, 7.6237e+00, 1.6070e+00,\n",
      "         3.3114e+00, 1.7293e+00, 2.1254e+00, 8.2959e-01, 1.0864e+00, 6.3620e-01,\n",
      "         1.9067e+00, 1.3834e+00, 2.5489e+00, 5.5648e-02],\n",
      "        [3.2799e+00, 2.0200e-01, 5.9199e-01, 9.8754e-01, 4.3804e+00, 7.0575e-01,\n",
      "         1.3536e+00, 7.8452e-01, 9.1223e-01, 4.4553e-01, 6.3464e-01, 2.6493e-01,\n",
      "         1.0829e+00, 5.5844e-01, 1.4021e+00, 2.7838e-02],\n",
      "        [4.2380e+00, 2.3914e-01, 7.9870e-01, 1.0946e+00, 4.9391e+00, 8.7409e-01,\n",
      "         1.7972e+00, 9.3930e-01, 1.2189e+00, 5.4925e-01, 7.5929e-01, 3.6399e-01,\n",
      "         1.2944e+00, 7.6218e-01, 1.6712e+00, 3.4750e-02],\n",
      "        [1.4571e+00, 6.7517e-02, 2.4672e-01, 3.4518e-01, 1.5552e+00, 2.9426e-01,\n",
      "         5.9697e-01, 3.1658e-01, 3.9095e-01, 1.6823e-01, 2.3127e-01, 1.1486e-01,\n",
      "         3.9179e-01, 2.5054e-01, 5.1013e-01, 1.0120e-02],\n",
      "        [2.5173e+00, 8.0248e-02, 4.8140e-01, 4.1772e-01, 2.1621e+00, 4.4780e-01,\n",
      "         1.0908e+00, 4.5512e-01, 7.2378e-01, 2.9297e-01, 3.7869e-01, 2.3792e-01,\n",
      "         6.2107e-01, 4.8192e-01, 8.4939e-01, 1.7050e-02],\n",
      "        [4.3620e+00, 1.3744e-01, 6.9997e-01, 8.2815e-01, 3.5472e+00, 8.2630e-01,\n",
      "         1.7827e+00, 8.7383e-01, 1.1242e+00, 4.1034e-01, 5.2603e-01, 3.4078e-01,\n",
      "         8.9994e-01, 7.3959e-01, 1.2261e+00, 2.7586e-02]])}, 62: {'step': tensor(11460.), 'exp_avg': tensor([-0.0081, -0.0023, -0.0037, -0.0045, -0.0031, -0.0038,  0.0060, -0.0033,\n",
      "        -0.0057, -0.0046]), 'exp_avg_sq': tensor([0.0012, 0.0003, 0.0035, 0.0006, 0.0004, 0.0012, 0.0038, 0.0016, 0.0004,\n",
      "        0.0004])}, 63: {'step': tensor(11460.), 'exp_avg': tensor([-0.0958, -0.0311, -0.0481, -0.0573, -0.0420, -0.0470,  0.0930, -0.0459,\n",
      "        -0.0707, -0.0576]), 'exp_avg_sq': tensor([0.0902, 0.0513, 0.1418, 0.0577, 0.0537, 0.0522, 0.3615, 0.0488, 0.0624,\n",
      "        0.0554])}, 64: {'step': tensor(11460.), 'exp_avg': tensor([ 0.1438, -0.1041,  0.0987,  0.1049,  0.0872, -0.0485,  0.0274,  0.0429,\n",
      "         0.0913, -0.0557, -0.0908,  0.0425, -0.0530, -0.1273, -0.1441, -0.0150]), 'exp_avg_sq': tensor([1.3871, 0.3025, 0.3507, 0.4468, 0.2254, 0.1526, 0.2659, 0.2519, 0.2040,\n",
      "        0.1659, 0.4905, 0.5884, 0.3483, 0.7347, 0.5589, 0.4776])}, 65: {'step': tensor(11460.), 'exp_avg': tensor([[-0.6781, -0.0513, -0.3860,  0.1012,  0.3293,  0.3889, -0.3276,  0.3438,\n",
      "         -0.2156, -0.3094,  0.0244,  0.4650,  0.1972, -0.1196, -0.1994,  0.3821],\n",
      "        [ 0.2765, -0.0101,  0.1876, -0.0476, -0.1294, -0.1864,  0.1498, -0.1624,\n",
      "          0.0410,  0.2113,  0.0032, -0.2051, -0.0374,  0.0512,  0.0862, -0.1811],\n",
      "        [ 0.0307,  0.0805, -0.0491,  0.0040, -0.0354,  0.0445, -0.0226,  0.0415,\n",
      "          0.1248, -0.1841, -0.0381,  0.0190, -0.1031, -0.0127, -0.0088,  0.0475],\n",
      "        [-0.4202, -0.0483, -0.2338,  0.0649,  0.2135,  0.2310, -0.1975,  0.1989,\n",
      "         -0.1553, -0.1655,  0.0237,  0.2759,  0.1285, -0.0611, -0.1167,  0.2207],\n",
      "        [-0.1208,  0.0254, -0.1009,  0.0319,  0.0533,  0.0984, -0.0706,  0.0733,\n",
      "          0.0043, -0.1478, -0.0091,  0.1000, -0.0162, -0.0147, -0.0333,  0.0869],\n",
      "        [ 0.1844, -0.0087,  0.1238, -0.0290, -0.0848, -0.1256,  0.1014, -0.1132,\n",
      "          0.0237,  0.1411,  0.0027, -0.1397, -0.0290,  0.0397,  0.0600, -0.1257],\n",
      "        [-0.1824, -0.0147, -0.0960,  0.0233,  0.0819,  0.1059, -0.0896,  0.0936,\n",
      "         -0.0599, -0.0732,  0.0081,  0.1277,  0.0611, -0.0386, -0.0562,  0.1030],\n",
      "        [-0.1092,  0.0033, -0.0830,  0.0149,  0.0575,  0.0721, -0.0638,  0.0738,\n",
      "         -0.0065, -0.0939, -0.0038,  0.0763,  0.0097, -0.0225, -0.0381,  0.0784],\n",
      "        [-0.0917,  0.0855, -0.1302,  0.0182,  0.0219,  0.1314, -0.0951,  0.1274,\n",
      "          0.1156, -0.2758, -0.0380,  0.1136, -0.0778, -0.0461, -0.0536,  0.1393],\n",
      "        [ 0.2863,  0.0309,  0.1610, -0.0409, -0.1455, -0.1572,  0.1366, -0.1428,\n",
      "          0.0992,  0.1160, -0.0137, -0.1889, -0.0890,  0.0473,  0.0835, -0.1567],\n",
      "        [ 0.1807, -0.0432,  0.1591, -0.0242, -0.0776, -0.1553,  0.1270, -0.1543,\n",
      "         -0.0445,  0.2399,  0.0203, -0.1523,  0.0172,  0.0553,  0.0755, -0.1649],\n",
      "        [-0.2795, -0.0665, -0.1428,  0.0382,  0.1609,  0.1325, -0.1254,  0.1197,\n",
      "         -0.1375, -0.0491,  0.0313,  0.1609,  0.1103, -0.0299, -0.0722,  0.1269],\n",
      "        [ 0.0670, -0.0293,  0.0592, -0.0199, -0.0183, -0.0684,  0.0443, -0.0471,\n",
      "         -0.0182,  0.1077,  0.0098, -0.0680,  0.0192,  0.0139,  0.0209, -0.0573],\n",
      "        [ 0.2070, -0.0512,  0.1645, -0.0462, -0.0763, -0.1769,  0.1274, -0.1377,\n",
      "         -0.0183,  0.2538,  0.0177, -0.1816,  0.0188,  0.0429,  0.0667, -0.1599],\n",
      "        [ 0.4906,  0.0240,  0.3052, -0.0722, -0.2440, -0.2941,  0.2516, -0.2687,\n",
      "          0.1230,  0.2807, -0.0099, -0.3364, -0.1120,  0.0869,  0.1500, -0.2942],\n",
      "        [ 0.1586,  0.0737,  0.0614, -0.0167, -0.1069, -0.0408,  0.0542, -0.0458,\n",
      "          0.1243, -0.0516, -0.0288, -0.0663, -0.0973,  0.0081,  0.0355, -0.0448]]), 'exp_avg_sq': tensor([[ 2.7270,  2.0683,  1.6385,  0.0819,  1.0145,  1.3866,  0.7393,  1.5492,\n",
      "          6.4368, 11.3810,  0.4326,  1.1239,  3.6792,  0.1471,  0.2353,  1.7375],\n",
      "        [ 0.8277,  0.4875,  0.5383,  0.0413,  0.2987,  0.4650,  0.2623,  0.4791,\n",
      "          1.3833,  2.7423,  0.0940,  0.4319,  0.7566,  0.0477,  0.0914,  0.5831],\n",
      "        [ 1.2421,  0.7734,  0.8944,  0.0590,  0.4798,  0.8095,  0.4547,  0.8900,\n",
      "          2.2874,  4.5846,  0.1433,  0.6965,  1.2082,  0.0868,  0.1451,  0.9928],\n",
      "        [ 1.5102,  0.8365,  0.9105,  0.0662,  0.5342,  0.8288,  0.4599,  0.8337,\n",
      "          2.4213,  4.7316,  0.1642,  0.7901,  1.3500,  0.0840,  0.1517,  0.9708],\n",
      "        [ 1.8272,  1.2015,  1.0675,  0.0569,  0.6471,  0.9040,  0.4869,  1.0680,\n",
      "          3.7888,  6.4473,  0.2245,  0.7800,  1.9808,  0.1086,  0.1669,  1.2125],\n",
      "        [ 0.7039,  0.4583,  0.4119,  0.0256,  0.2485,  0.3613,  0.1915,  0.3904,\n",
      "          1.3580,  2.4320,  0.0872,  0.3306,  0.7290,  0.0428,  0.0653,  0.4620],\n",
      "        [ 1.1823,  0.6596,  0.6593,  0.0516,  0.4142,  0.6006,  0.3327,  0.5988,\n",
      "          1.9113,  3.5515,  0.1287,  0.5728,  1.0558,  0.0617,  0.1196,  0.7290],\n",
      "        [ 0.6314,  0.4313,  0.3647,  0.0244,  0.2497,  0.3071,  0.1735,  0.3431,\n",
      "          1.2676,  2.2580,  0.0904,  0.2692,  0.7260,  0.0341,  0.0624,  0.4054],\n",
      "        [ 0.7092,  0.4229,  0.4736,  0.0305,  0.2380,  0.3995,  0.2209,  0.4396,\n",
      "          1.3024,  2.5101,  0.0840,  0.3512,  0.6918,  0.0419,  0.0780,  0.5103],\n",
      "        [ 0.5907,  0.3915,  0.3426,  0.0281,  0.2132,  0.2924,  0.1642,  0.3201,\n",
      "          1.1536,  2.0436,  0.0800,  0.2571,  0.6320,  0.0320,  0.0580,  0.3839],\n",
      "        [ 0.5297,  0.4687,  0.4572,  0.0275,  0.1988,  0.3929,  0.2047,  0.3989,\n",
      "          1.3159,  2.8796,  0.1017,  0.2925,  0.7873,  0.0373,  0.0682,  0.4739],\n",
      "        [ 2.0359,  1.4128,  1.2869,  0.0672,  0.7225,  1.1101,  0.5869,  1.2446,\n",
      "          4.2929,  7.8326,  0.2754,  0.9401,  2.3036,  0.1249,  0.1910,  1.4085],\n",
      "        [ 1.3959,  0.7910,  0.8104,  0.0429,  0.4924,  0.6859,  0.3808,  0.7540,\n",
      "          2.4352,  4.4159,  0.1582,  0.6181,  1.3441,  0.0752,  0.1342,  0.8685],\n",
      "        [ 1.6208,  0.8152,  1.0334,  0.0615,  0.5188,  0.9009,  0.4976,  0.8673,\n",
      "          2.4171,  5.0987,  0.1648,  0.8277,  1.3766,  0.0793,  0.1707,  1.0398],\n",
      "        [ 1.9209,  1.2396,  1.1926,  0.0626,  0.7056,  1.0142,  0.5490,  1.1200,\n",
      "          3.7482,  6.8426,  0.2400,  0.8570,  2.0521,  0.1087,  0.1802,  1.2740],\n",
      "        [ 2.9764,  1.9006,  2.0394,  0.1100,  1.1450,  1.7617,  0.9666,  2.0247,\n",
      "          5.6873, 10.8939,  0.3432,  1.5185,  3.0160,  0.1964,  0.3309,  2.2428]])}, 66: {'step': tensor(11460.), 'exp_avg': tensor([-0.0003, -0.0004, -0.0001, -0.0003, -0.0003, -0.0003, -0.0053, -0.0002,\n",
      "        -0.0002, -0.0003]), 'exp_avg_sq': tensor([0.0004, 0.0002, 0.0021, 0.0003, 0.0002, 0.0006, 0.0013, 0.0007, 0.0002,\n",
      "        0.0002])}, 67: {'step': tensor(11460.), 'exp_avg': tensor([-0.1133, -0.0465, -0.0588, -0.0689, -0.0521, -0.0604,  0.0433, -0.0589,\n",
      "        -0.0851, -0.0700]), 'exp_avg_sq': tensor([0.1632, 0.1094, 0.1389, 0.1229, 0.1165, 0.1082, 0.2872, 0.1060, 0.1323,\n",
      "        0.1212])}, 68: {'step': tensor(11460.), 'exp_avg': tensor([-0.0394, -0.0149,  0.1233, -0.1021, -0.1972, -0.0823, -0.1219,  0.1907,\n",
      "        -0.2015,  0.0141,  0.0129,  0.0541,  0.0587,  0.2021, -0.0446,  0.0211,\n",
      "         0.1179,  0.1035,  0.0250, -0.0076,  0.0422, -0.0581, -0.0993,  0.1629,\n",
      "        -0.1030, -0.0298,  0.0301, -0.0401, -0.0307,  0.0737, -0.0433, -0.0164]), 'exp_avg_sq': tensor([0.6155, 0.4774, 0.5567, 0.3271, 0.4372, 1.0006, 0.3775, 0.3592, 0.3066,\n",
      "        0.3617, 0.4798, 0.2332, 0.4172, 0.9071, 0.5552, 0.2879, 0.2651, 0.4486,\n",
      "        0.2448, 0.1660, 0.3460, 0.2488, 0.3620, 0.3391, 0.4581, 0.2286, 0.4676,\n",
      "        0.3031, 0.9474, 0.5134, 0.2716, 0.3474])}, 69: {'step': tensor(11460.), 'exp_avg': tensor([[-6.7382e-03,  1.1224e-01,  5.5723e-02,  1.4838e-02, -1.3049e-02,\n",
      "          1.7125e-02, -4.8048e-02, -4.9956e-02,  2.1019e-02, -8.8101e-02,\n",
      "         -3.8090e-02,  2.8128e-02, -7.0266e-02,  3.1191e-02,  5.2828e-03,\n",
      "         -4.2214e-03],\n",
      "        [-9.9866e-02,  2.5365e-01, -1.0163e-01,  1.4804e-01,  7.7482e-02,\n",
      "         -3.9598e-02,  7.5235e-02,  1.3618e-01,  1.0464e-01, -2.6701e-01,\n",
      "         -3.0774e-02, -1.2866e-01, -1.4834e-01,  8.6434e-03,  1.7167e-01,\n",
      "         -1.6822e-01],\n",
      "        [ 1.1859e-01,  1.5892e-01,  2.7206e-01, -6.6794e-02, -1.0434e-01,\n",
      "          8.6251e-02, -2.1932e-01, -2.7251e-01, -9.3790e-03, -5.2710e-02,\n",
      "         -6.3226e-02,  2.0042e-01, -8.4212e-02,  1.0447e-01, -1.0214e-01,\n",
      "          1.2349e-01],\n",
      "        [ 1.0977e-01, -5.3758e-01, -6.0017e-02, -2.1805e-01, -5.7754e-02,\n",
      "         -1.1766e-02,  2.6070e-02, -1.3978e-02, -1.7975e-01,  4.7346e-01,\n",
      "          1.2732e-01,  4.7071e-02,  3.1273e-01, -8.2966e-02, -1.8370e-01,\n",
      "          1.7366e-01],\n",
      "        [-1.8850e-01, -2.7557e-01, -3.7148e-01,  9.0986e-02,  1.4679e-01,\n",
      "         -1.1292e-01,  3.1788e-01,  3.7848e-01,  4.9930e-03,  1.1693e-01,\n",
      "          7.8536e-02, -2.6737e-01,  1.4003e-01, -1.6356e-01,  1.0782e-01,\n",
      "         -1.5092e-01],\n",
      "        [ 5.2262e-04, -1.7317e-01, -1.3520e-01, -4.2075e-02,  2.3006e-02,\n",
      "         -4.5466e-02,  8.4670e-02,  1.0811e-01, -3.9601e-02,  1.1989e-01,\n",
      "          7.1808e-02, -8.1272e-02,  1.0961e-01, -5.1298e-02,  1.3918e-02,\n",
      "         -2.1445e-02],\n",
      "        [-1.0585e-01, -1.3321e-01, -2.3719e-01,  5.7269e-02,  9.0984e-02,\n",
      "         -7.5653e-02,  1.8945e-01,  2.3893e-01,  1.1008e-02,  3.8394e-02,\n",
      "          5.5782e-02, -1.7769e-01,  7.1286e-02, -9.0935e-02,  9.0214e-02,\n",
      "         -1.1236e-01],\n",
      "        [ 1.1151e-01,  1.5023e-01,  2.7794e-01, -4.4937e-02, -9.5997e-02,\n",
      "          9.1526e-02, -2.0866e-01, -2.6856e-01, -6.3932e-03, -4.4884e-02,\n",
      "         -6.8670e-02,  2.0792e-01, -8.3856e-02,  9.9496e-02, -1.0542e-01,\n",
      "          1.3009e-01],\n",
      "        [-3.2522e-01,  1.8234e-01, -4.2615e-01,  2.9781e-01,  2.3304e-01,\n",
      "         -1.4027e-01,  3.6731e-01,  4.8929e-01,  1.7340e-01, -3.1439e-01,\n",
      "         -1.1617e-02, -3.9508e-01, -1.2229e-01, -1.1753e-01,  3.2488e-01,\n",
      "         -3.6661e-01],\n",
      "        [-1.0549e-01,  3.2210e-01, -3.3363e-02,  1.4920e-01,  6.3405e-02,\n",
      "         -1.7775e-02,  4.2353e-02,  8.0304e-02,  1.2824e-01, -3.0037e-01,\n",
      "         -6.8478e-02, -9.1053e-02, -1.7952e-01,  2.7766e-02,  1.4650e-01,\n",
      "         -1.5397e-01],\n",
      "        [ 3.6782e-02,  9.0314e-02,  1.1272e-01, -2.4007e-02, -4.1777e-02,\n",
      "          3.5459e-02, -9.2054e-02, -1.1232e-01,  3.8047e-03, -4.4746e-02,\n",
      "         -3.5352e-02,  7.7993e-02, -4.9097e-02,  4.6012e-02, -3.7791e-02,\n",
      "          4.1350e-02],\n",
      "        [-1.0717e-01,  4.3744e-01,  8.0938e-03,  1.8916e-01,  6.2831e-02,\n",
      "         -4.6175e-03,  8.0349e-03,  5.1262e-02,  1.5377e-01, -3.9746e-01,\n",
      "         -9.6503e-02, -7.2754e-02, -2.5392e-01,  5.6906e-02,  1.7409e-01,\n",
      "         -1.6863e-01],\n",
      "        [ 1.8114e-01, -2.5218e-01,  1.3106e-01, -2.0125e-01, -1.1141e-01,\n",
      "          4.2130e-02, -1.3265e-01, -1.8561e-01, -1.2769e-01,  2.8327e-01,\n",
      "          6.4662e-02,  1.5609e-01,  1.6348e-01,  2.0004e-02, -1.7512e-01,\n",
      "          1.9067e-01],\n",
      "        [ 8.1275e-02,  4.0890e-01,  2.9433e-01,  3.5796e-02, -7.6659e-02,\n",
      "          9.0217e-02, -2.3291e-01, -2.6499e-01,  6.8212e-02, -2.7157e-01,\n",
      "         -1.1455e-01,  1.7886e-01, -2.2996e-01,  1.4740e-01, -7.6224e-03,\n",
      "          4.4135e-02],\n",
      "        [-2.5055e-02, -1.2320e-01, -1.2466e-01,  7.1378e-03,  3.6697e-02,\n",
      "         -4.0052e-02,  8.9080e-02,  1.1678e-01, -1.8427e-02,  6.6403e-02,\n",
      "          5.1292e-02, -8.1129e-02,  6.7015e-02, -4.9681e-02,  3.3997e-02,\n",
      "         -3.6820e-02],\n",
      "        [ 4.6546e-02, -2.3043e-02,  5.5455e-02, -4.4218e-02, -3.3122e-02,\n",
      "          1.7661e-02, -4.9959e-02, -6.8052e-02, -2.5425e-02,  4.4653e-02,\n",
      "          6.9479e-04,  5.3083e-02,  1.7095e-02,  1.7713e-02, -4.3421e-02,\n",
      "          5.0579e-02],\n",
      "        [ 2.5810e-01, -3.3179e-01,  2.7023e-01, -2.7934e-01, -1.7797e-01,\n",
      "          9.3221e-02, -2.3470e-01, -3.3882e-01, -1.8521e-01,  3.9988e-01,\n",
      "          5.0899e-02,  2.9041e-01,  2.0226e-01,  4.6089e-02, -2.9446e-01,\n",
      "          3.1999e-01],\n",
      "        [ 2.3637e-02,  2.2337e-01,  1.6376e-01,  3.6126e-02, -3.5505e-02,\n",
      "          5.3006e-02, -1.1919e-01, -1.4031e-01,  4.1544e-02, -1.5320e-01,\n",
      "         -7.5028e-02,  9.9906e-02, -1.3382e-01,  7.4553e-02, -8.5759e-03,\n",
      "          2.4860e-02],\n",
      "        [ 4.9992e-02, -1.6673e-01,  7.9079e-03, -7.1204e-02, -2.6470e-02,\n",
      "          4.7043e-03, -6.4238e-03, -2.7458e-02, -5.6436e-02,  1.5822e-01,\n",
      "          3.7136e-02,  3.5700e-02,  1.0102e-01, -1.9362e-02, -7.0475e-02,\n",
      "          7.0082e-02],\n",
      "        [-2.4981e-02, -7.7341e-02, -3.0387e-02,  1.8860e-03,  1.3605e-02,\n",
      "         -5.9901e-03,  4.1892e-02,  3.2624e-02, -9.2693e-03,  5.9687e-02,\n",
      "          4.4650e-03, -1.4151e-02,  3.9445e-02, -2.9002e-02, -1.7024e-02,\n",
      "          7.6275e-03],\n",
      "        [ 5.1083e-03,  6.5136e-02,  7.9633e-02,  8.4059e-03, -1.8476e-02,\n",
      "          2.7500e-02, -4.7476e-02, -6.8896e-02,  1.2100e-02, -3.4115e-02,\n",
      "         -3.8206e-02,  5.4013e-02, -4.1644e-02,  2.4586e-02, -2.6012e-02,\n",
      "          2.7669e-02],\n",
      "        [-2.3890e-02, -2.1481e-01, -1.2181e-01, -2.3621e-02,  2.9199e-02,\n",
      "         -3.5551e-02,  1.0062e-01,  1.0663e-01, -4.2705e-02,  1.5426e-01,\n",
      "          5.5214e-02, -6.4604e-02,  1.1836e-01, -6.8394e-02, -1.2082e-02,\n",
      "          8.3576e-04],\n",
      "        [-1.3502e-01, -1.6154e-01, -2.4964e-01,  8.2499e-02,  1.0654e-01,\n",
      "         -7.5889e-02,  2.1992e-01,  2.6306e-01,  1.5837e-02,  5.5312e-02,\n",
      "          4.7431e-02, -1.8493e-01,  7.9209e-02, -1.0935e-01,  8.5501e-02,\n",
      "         -1.1277e-01],\n",
      "        [ 2.0816e-01,  5.0482e-03,  3.1402e-01, -1.6283e-01, -1.5237e-01,\n",
      "          1.0053e-01, -2.6840e-01, -3.4369e-01, -7.9350e-02,  1.0602e-01,\n",
      "         -1.9797e-02,  2.6611e-01,  1.2285e-02,  1.0568e-01, -1.8361e-01,\n",
      "          2.1495e-01],\n",
      "        [-2.6571e-03, -1.5623e-01, -6.1600e-02, -5.0275e-02,  1.3871e-03,\n",
      "         -1.6787e-02,  4.1878e-02,  3.7323e-02, -4.5757e-02,  1.2397e-01,\n",
      "          3.3607e-02, -2.1872e-02,  8.7139e-02, -3.7603e-02, -3.4269e-02,\n",
      "          2.3687e-02],\n",
      "        [ 1.0645e-02, -2.9884e-02,  9.8141e-03, -3.0150e-02, -1.1675e-02,\n",
      "          3.5722e-03, -9.1144e-03, -1.9758e-02, -1.4019e-02,  3.5650e-02,\n",
      "          2.0049e-03,  1.2903e-02,  2.0317e-02, -4.9955e-04, -2.4051e-02,\n",
      "          2.0550e-02],\n",
      "        [ 6.5490e-02, -5.1579e-02,  8.2933e-02, -5.3144e-02, -4.6590e-02,\n",
      "          2.8820e-02, -7.7075e-02, -9.4635e-02, -4.4059e-02,  6.5213e-02,\n",
      "          6.4349e-03,  8.2810e-02,  2.1307e-02,  2.0834e-02, -6.3518e-02,\n",
      "          7.8440e-02],\n",
      "        [ 2.2564e-02, -1.0855e-01, -1.4813e-02, -3.9296e-02, -1.2368e-02,\n",
      "         -2.9760e-03, -1.4272e-03,  8.6639e-04, -4.0760e-02,  8.5106e-02,\n",
      "          2.9770e-02,  9.2021e-03,  5.6134e-02, -1.5720e-02, -3.1470e-02,\n",
      "          3.2778e-02],\n",
      "        [-6.5611e-02,  1.8608e-01, -5.6611e-02,  8.9445e-02,  4.5649e-02,\n",
      "         -2.4741e-02,  3.9667e-02,  8.0571e-02,  7.5751e-02, -1.8922e-01,\n",
      "         -2.3775e-02, -8.3506e-02, -1.0359e-01,  1.0460e-02,  1.1123e-01,\n",
      "         -1.1473e-01],\n",
      "        [-8.7136e-03,  1.9186e-01,  6.1745e-02,  5.7727e-02,  1.7910e-03,\n",
      "          1.7798e-02, -4.3224e-02, -4.0749e-02,  5.2006e-02, -1.5223e-01,\n",
      "         -4.7406e-02,  1.9441e-02, -1.0959e-01,  4.4560e-02,  4.2737e-02,\n",
      "         -3.1609e-02],\n",
      "        [-1.4543e-01, -1.3040e-02, -2.1129e-01,  1.2835e-01,  1.1145e-01,\n",
      "         -6.5644e-02,  1.9411e-01,  2.4089e-01,  5.8321e-02, -6.3384e-02,\n",
      "          1.2691e-02, -1.7801e-01, -3.5637e-03, -7.7331e-02,  1.2371e-01,\n",
      "         -1.4330e-01],\n",
      "        [ 4.0349e-02,  4.1842e-02,  3.8413e-02, -4.3475e-02, -2.8305e-02,\n",
      "          6.1821e-03, -4.7551e-02, -5.1013e-02, -4.1948e-04, -1.2953e-02,\n",
      "          1.7246e-03,  2.2016e-02, -5.0423e-03,  2.6879e-02, -1.0776e-02,\n",
      "          1.0154e-02]]), 'exp_avg_sq': tensor([[1.1022, 0.9667, 1.9086, 0.8496, 0.5350, 0.2010, 1.5743, 2.4596, 0.3209,\n",
      "         1.1556, 0.0722, 1.5008, 0.3524, 0.2449, 0.8544, 1.1932],\n",
      "        [1.8447, 1.5103, 3.0797, 1.6035, 0.9618, 0.3188, 2.8692, 4.1809, 0.5868,\n",
      "         1.7620, 0.1079, 2.4332, 0.5308, 0.4224, 1.4157, 1.9321],\n",
      "        [1.0479, 0.9172, 1.7944, 0.8370, 0.5184, 0.1888, 1.5473, 2.3191, 0.3160,\n",
      "         1.0528, 0.0731, 1.3897, 0.3303, 0.2441, 0.7817, 1.0951],\n",
      "        [2.5169, 2.5872, 4.3367, 2.2982, 1.3411, 0.4538, 4.0728, 5.8633, 0.8464,\n",
      "         2.7326, 0.1894, 3.3799, 0.9310, 0.6083, 2.0300, 2.6553],\n",
      "        [1.4935, 1.3901, 2.6182, 1.2881, 0.7863, 0.2745, 2.4366, 3.4811, 0.4706,\n",
      "         1.4482, 0.1017, 2.0167, 0.4857, 0.3893, 1.1111, 1.5370],\n",
      "        [2.0378, 1.8573, 3.4624, 1.6253, 1.0046, 0.3612, 2.9630, 4.5378, 0.6196,\n",
      "         2.1606, 0.1289, 2.7509, 0.6724, 0.4456, 1.5836, 2.1860],\n",
      "        [1.4664, 1.4893, 2.6495, 1.2469, 0.7660, 0.2751, 2.4183, 3.4737, 0.4542,\n",
      "         1.4406, 0.1263, 1.9957, 0.5299, 0.3941, 1.0618, 1.4812],\n",
      "        [1.4050, 1.2345, 2.4806, 1.2122, 0.7473, 0.2553, 2.2661, 3.2967, 0.4351,\n",
      "         1.3550, 0.0845, 1.9148, 0.4461, 0.3432, 1.0802, 1.4720],\n",
      "        [1.0509, 0.9334, 1.8983, 0.9146, 0.5669, 0.1951, 1.7535, 2.5187, 0.3275,\n",
      "         0.9953, 0.0681, 1.4461, 0.3325, 0.2656, 0.8139, 1.0911],\n",
      "        [1.1380, 0.7546, 1.9393, 0.9143, 0.5831, 0.2037, 1.7525, 2.5953, 0.3290,\n",
      "         0.9268, 0.0607, 1.5233, 0.2686, 0.2621, 0.8431, 1.1714],\n",
      "        [1.3620, 1.0504, 2.3427, 1.1225, 0.6929, 0.2463, 2.0862, 3.1084, 0.4115,\n",
      "         1.2152, 0.0903, 1.8305, 0.3688, 0.3176, 1.0175, 1.4190],\n",
      "        [1.1593, 0.9932, 1.9767, 1.0460, 0.6217, 0.2053, 1.8656, 2.6787, 0.3817,\n",
      "         1.1224, 0.0666, 1.5570, 0.3572, 0.2724, 0.9133, 1.2162],\n",
      "        [1.2394, 1.2479, 2.3236, 1.0653, 0.6594, 0.2379, 2.0396, 3.0014, 0.3931,\n",
      "         1.2616, 0.1008, 1.7311, 0.4431, 0.3163, 0.9746, 1.3008],\n",
      "        [2.0403, 1.6320, 3.7760, 1.6309, 1.0602, 0.3913, 3.2245, 4.8579, 0.5895,\n",
      "         1.8338, 0.1220, 2.8861, 0.5739, 0.4979, 1.5489, 2.1753],\n",
      "        [1.4543, 1.6491, 2.5899, 1.1863, 0.7392, 0.2663, 2.2788, 3.3333, 0.4469,\n",
      "         1.6586, 0.1246, 1.9656, 0.5480, 0.3809, 1.0850, 1.5242],\n",
      "        [1.1051, 1.0516, 1.9993, 0.9686, 0.5925, 0.2075, 1.8474, 2.6537, 0.3469,\n",
      "         1.0798, 0.0787, 1.5174, 0.3795, 0.2898, 0.8523, 1.1430],\n",
      "        [2.2500, 1.9872, 3.8841, 2.0789, 1.2240, 0.4012, 3.7100, 5.3210, 0.7379,\n",
      "         2.2313, 0.1259, 3.0554, 0.7281, 0.5358, 1.8134, 2.3792],\n",
      "        [1.4485, 1.4570, 2.6472, 1.2373, 0.7689, 0.2761, 2.3787, 3.4459, 0.4545,\n",
      "         1.4695, 0.1105, 1.9985, 0.5134, 0.3768, 1.1070, 1.5133],\n",
      "        [0.8309, 0.8925, 1.4574, 0.7348, 0.4400, 0.1551, 1.3389, 1.9237, 0.2756,\n",
      "         0.9397, 0.0613, 1.1177, 0.3133, 0.2129, 0.6763, 0.8863],\n",
      "        [0.6601, 0.7239, 1.1753, 0.5894, 0.3533, 0.1224, 1.0916, 1.5544, 0.2159,\n",
      "         0.7437, 0.0494, 0.8954, 0.2574, 0.1712, 0.5262, 0.7011],\n",
      "        [0.8073, 1.0314, 1.3821, 0.7117, 0.4051, 0.1446, 1.1965, 1.7915, 0.2842,\n",
      "         1.0495, 0.0817, 1.0687, 0.3580, 0.1899, 0.6441, 0.8676],\n",
      "        [1.0798, 1.0999, 1.8563, 0.9848, 0.5743, 0.1942, 1.7425, 2.5077, 0.3585,\n",
      "         1.1947, 0.0669, 1.4509, 0.3988, 0.2683, 0.8764, 1.1537],\n",
      "        [1.3897, 1.4263, 2.5464, 1.2031, 0.7378, 0.2693, 2.3221, 3.3287, 0.4447,\n",
      "         1.3961, 0.1308, 1.9169, 0.5044, 0.3708, 1.0655, 1.4333],\n",
      "        [0.9291, 0.7088, 1.6162, 0.7521, 0.4815, 0.1701, 1.4793, 2.1391, 0.2738,\n",
      "         0.8056, 0.0515, 1.2514, 0.2543, 0.2316, 0.6848, 0.9500],\n",
      "        [2.5434, 2.4870, 4.4180, 2.1840, 1.3407, 0.4480, 4.1549, 5.8895, 0.7993,\n",
      "         2.5655, 0.1567, 3.3978, 0.8973, 0.6459, 1.9048, 2.5852],\n",
      "        [1.2953, 1.4695, 2.2225, 1.2028, 0.6862, 0.2350, 2.0807, 3.0039, 0.4440,\n",
      "         1.5397, 0.1002, 1.7342, 0.5249, 0.3239, 1.0678, 1.3877],\n",
      "        [1.5638, 1.3607, 2.6982, 1.2681, 0.7985, 0.2827, 2.4477, 3.5363, 0.4867,\n",
      "         1.4751, 0.1180, 2.0925, 0.4870, 0.3729, 1.1739, 1.5942],\n",
      "        [1.3119, 1.2527, 2.2468, 1.1659, 0.6956, 0.2324, 2.0904, 3.0207, 0.4266,\n",
      "         1.4029, 0.0757, 1.7665, 0.4535, 0.3171, 1.0540, 1.3984],\n",
      "        [1.9316, 1.1137, 3.6489, 1.3716, 0.9914, 0.3761, 3.0952, 4.6252, 0.4772,\n",
      "         1.3029, 0.1042, 2.7272, 0.3999, 0.4826, 1.3569, 1.9501],\n",
      "        [0.7863, 0.5952, 1.4851, 0.5771, 0.3954, 0.1572, 1.1978, 1.8738, 0.2071,\n",
      "         0.7045, 0.0500, 1.1296, 0.2029, 0.1917, 0.6137, 0.8534],\n",
      "        [1.5880, 1.4357, 2.7011, 1.4188, 0.8428, 0.2774, 2.5347, 3.6680, 0.5134,\n",
      "         1.6276, 0.0885, 2.1329, 0.5273, 0.3689, 1.2544, 1.6812],\n",
      "        [3.1145, 2.6562, 5.1875, 2.8268, 1.6655, 0.5310, 4.9949, 7.1561, 1.0194,\n",
      "         3.0545, 0.1563, 4.1187, 0.9773, 0.7157, 2.4442, 3.2532]])}, 70: {'step': tensor(11460.), 'exp_avg': tensor([-0.0022, -0.0025, -0.0026, -0.0024, -0.0025, -0.0023, -0.0034, -0.0021,\n",
      "        -0.0024, -0.0023]), 'exp_avg_sq': tensor([0.1041, 0.1042, 0.1041, 0.1040, 0.1040, 0.1043, 0.1040, 0.1038, 0.1042,\n",
      "        0.1041])}, 71: {'step': tensor(11460.), 'exp_avg': tensor([-0.0025, -0.0025, -0.0025, -0.0025, -0.0025, -0.0025, -0.0025, -0.0025,\n",
      "        -0.0025, -0.0025]), 'exp_avg_sq': tensor([0.0771, 0.0771, 0.0771, 0.0771, 0.0771, 0.0771, 0.0771, 0.0771, 0.0771,\n",
      "        0.0771])}, 72: {'step': tensor(11460.), 'exp_avg': tensor([[-5.8101e-02,  6.4704e-02,  7.8915e-03,  ..., -3.1145e-02,\n",
      "         -6.5226e-02,  7.8072e-02],\n",
      "        [ 1.8996e-04, -8.0752e-05,  1.8060e-05,  ...,  2.8176e-04,\n",
      "          2.1500e-04, -3.3466e-04],\n",
      "        [-5.6052e-45,  5.6052e-45,  5.6052e-45,  ...,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45],\n",
      "        ...,\n",
      "        [-5.6052e-45,  5.6052e-45,  5.6052e-45,  ...,  5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45],\n",
      "        [ 1.7123e-05, -1.1780e-05, -1.8557e-06,  ...,  1.4745e-05,\n",
      "          1.6229e-05, -2.0139e-05],\n",
      "        [-5.0788e-01,  3.1839e-01,  1.6159e-03,  ..., -5.0830e-01,\n",
      "         -5.2600e-01,  7.3473e-01]]), 'exp_avg_sq': tensor([[2.9732e+00, 3.6714e+00, 3.2870e-01,  ..., 4.7703e+00, 3.6953e+00,\n",
      "         7.1484e+00],\n",
      "        [1.4610e-02, 2.2380e-02, 3.1983e-03,  ..., 2.1169e-02, 1.0869e-02,\n",
      "         2.0165e-02],\n",
      "        [1.4411e-03, 4.4185e-03, 8.4811e-04,  ..., 4.0447e-03, 4.9199e-04,\n",
      "         1.9270e-03],\n",
      "        ...,\n",
      "        [5.3008e-03, 1.4172e-02, 3.7294e-03,  ..., 1.3955e-02, 1.0710e-03,\n",
      "         8.6347e-03],\n",
      "        [1.7034e-01, 2.0212e-01, 2.9756e-02,  ..., 1.8783e-01, 1.3464e-01,\n",
      "         2.2760e-01],\n",
      "        [4.3091e+00, 5.6420e+00, 5.6812e-01,  ..., 7.4824e+00, 5.4364e+00,\n",
      "         1.0596e+01]])}, 73: {'step': tensor(11460.), 'exp_avg': tensor([ 3.9221e-41, -1.8291e-05,  5.6052e-45, -3.1940e-06,  1.3298e-29,\n",
      "         1.9064e-05,  9.2661e-07,  2.2353e-02,  3.4132e-15,  5.3367e-08,\n",
      "         9.3543e-05,  1.8854e-32,  7.2582e-09,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  7.0197e-08,  5.6052e-45,  2.6135e-07,\n",
      "         9.8814e-05,  5.4168e-39, -2.2803e-03,  5.6052e-45, -4.4724e-08,\n",
      "        -4.1670e-02,  1.8247e-08, -1.8231e-10,  5.6052e-45,  5.6052e-45,\n",
      "        -1.0254e-10,  8.6897e-03,  5.6052e-45, -5.8279e-07,  5.6052e-45,\n",
      "        -6.7849e-07,  3.6471e-04,  1.4549e-08,  1.0939e-02, -3.6242e-02,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -1.8665e-03,  5.6052e-45,  2.1416e-03,\n",
      "         1.5250e-08, -9.6994e-07,  5.6454e-38,  5.6052e-45,  5.6052e-45,\n",
      "         6.5066e-15,  1.4785e-24,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         4.3988e-02,  5.6052e-45, -2.1284e-06,  4.3751e-02]), 'exp_avg_sq': tensor([1.7867e-03, 2.3473e-04, 2.4561e-05, 4.6505e-04, 2.9547e-04, 1.3923e-05,\n",
      "        5.9470e-04, 1.7955e-02, 6.6971e-05, 4.3673e-03, 2.2355e-04, 2.1406e-04,\n",
      "        2.3685e-03, 8.7828e-05, 6.8478e-05, 4.8343e-05, 1.1692e-04, 3.9669e-03,\n",
      "        5.2211e-04, 1.3554e-04, 2.2496e-03, 1.3384e-05, 9.1899e-03, 3.2333e-05,\n",
      "        3.2781e-03, 9.2412e-02, 1.8880e-03, 1.1745e-03, 2.1034e-04, 2.5467e-04,\n",
      "        2.4495e-03, 3.6860e-03, 1.3928e-05, 2.1053e-03, 9.8693e-05, 9.0235e-04,\n",
      "        1.0916e-02, 1.5424e-03, 6.7182e-04, 1.0019e-01, 1.6880e-05, 7.1708e-05,\n",
      "        3.1495e-05, 1.7052e-05, 2.8054e-04, 3.2063e-04, 2.0793e-04, 1.4842e-02,\n",
      "        9.7308e-06, 1.2612e-03, 7.8282e-04, 5.9279e-03, 8.5548e-04, 3.3276e-05,\n",
      "        4.6720e-05, 8.7826e-04, 2.4352e-03, 7.8278e-04, 9.6532e-05, 1.0612e-04,\n",
      "        2.4210e-02, 9.3878e-05, 2.6657e-03, 1.2759e-02])}}\n",
      "param_groups \t [{'lr': 0.0001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]}]\n"
     ]
    }
   ],
   "source": [
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'{model_name}_state_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, model_name+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([5.039967060089111,\n",
       "  2.9724743366241455,\n",
       "  0.325209379196167,\n",
       "  3.7244646549224854,\n",
       "  1.7943934202194214,\n",
       "  0.27664899826049805,\n",
       "  4.176661014556885,\n",
       "  2.7181761264801025,\n",
       "  0.8257138133049011,\n",
       "  7.458323955535889,\n",
       "  5.480461597442627,\n",
       "  3.049443006515503,\n",
       "  12.76567554473877,\n",
       "  4.077723026275635,\n",
       "  0.2736821472644806,\n",
       "  1.7346400022506714,\n",
       "  9.646903991699219,\n",
       "  24.3457088470459,\n",
       "  5.952641487121582,\n",
       "  0.1685463786125183,\n",
       "  41.964481353759766,\n",
       "  39.0633544921875,\n",
       "  8.183717727661133,\n",
       "  0.6456655859947205,\n",
       "  2.02899432182312,\n",
       "  3.640676259994507,\n",
       "  3.502286195755005,\n",
       "  1.8068784475326538,\n",
       "  13.45116138458252,\n",
       "  0.5916929244995117,\n",
       "  1.4256943464279175,\n",
       "  3.334533214569092,\n",
       "  5.09161376953125,\n",
       "  5.105195045471191,\n",
       "  1.1639260053634644,\n",
       "  9.224519729614258,\n",
       "  5.765036582946777,\n",
       "  3.002119302749634,\n",
       "  4.072312831878662,\n",
       "  4.419891357421875,\n",
       "  1.739321231842041,\n",
       "  2.0448732376098633,\n",
       "  2.216447353363037,\n",
       "  0.7246847152709961,\n",
       "  5.340191841125488,\n",
       "  2.9733636379241943,\n",
       "  2.3104124069213867,\n",
       "  4.049636363983154,\n",
       "  1.0916879177093506,\n",
       "  1.4349595308303833,\n",
       "  10.239782333374023,\n",
       "  17.407283782958984,\n",
       "  2.1172218322753906,\n",
       "  3.3600192070007324,\n",
       "  3.6813340187072754,\n",
       "  3.0659749507904053,\n",
       "  1.0990791320800781,\n",
       "  3.2304599285125732,\n",
       "  1.3363269567489624,\n",
       "  1.849318265914917,\n",
       "  1.4694151878356934,\n",
       "  1.079952597618103,\n",
       "  1.0926121473312378,\n",
       "  8.330862998962402,\n",
       "  1.295486330986023,\n",
       "  2.294828176498413,\n",
       "  5.410950183868408,\n",
       "  6.084533214569092,\n",
       "  0.7728542685508728,\n",
       "  2.153050422668457,\n",
       "  5.901288032531738,\n",
       "  0.8332223892211914,\n",
       "  0.533145010471344,\n",
       "  0.4715433418750763,\n",
       "  1.5290038585662842,\n",
       "  0.45679551362991333,\n",
       "  1.0007413625717163,\n",
       "  4.135443687438965,\n",
       "  5.534121513366699,\n",
       "  0.6787559390068054,\n",
       "  5.03037691116333,\n",
       "  4.07681131362915,\n",
       "  5.612641334533691,\n",
       "  5.1013617515563965,\n",
       "  1.009545087814331,\n",
       "  3.741560697555542,\n",
       "  3.8979787826538086,\n",
       "  2.329594373703003,\n",
       "  1.159079670906067,\n",
       "  21.98623275756836,\n",
       "  6.507981777191162,\n",
       "  2.68440318107605,\n",
       "  0.250221312046051,\n",
       "  17.235471725463867,\n",
       "  5.019718647003174,\n",
       "  3.1230416297912598,\n",
       "  2.4575142860412598,\n",
       "  17.440263748168945,\n",
       "  6.973242282867432,\n",
       "  6.728861331939697,\n",
       "  2.513024091720581,\n",
       "  6.101136684417725,\n",
       "  0.1689053773880005,\n",
       "  4.630340099334717,\n",
       "  1.4027354717254639,\n",
       "  6.7702789306640625,\n",
       "  0.09165049344301224,\n",
       "  1.3154644966125488,\n",
       "  6.562411785125732,\n",
       "  3.084425210952759,\n",
       "  7.20587158203125,\n",
       "  4.9945783615112305,\n",
       "  5.446061134338379,\n",
       "  1.238279938697815,\n",
       "  7.924715518951416,\n",
       "  3.583991765975952,\n",
       "  5.466407299041748,\n",
       "  21.23461151123047,\n",
       "  3.957393169403076,\n",
       "  0.6040295958518982,\n",
       "  4.266897201538086,\n",
       "  3.279918670654297,\n",
       "  6.506266117095947,\n",
       "  0.533844530582428,\n",
       "  1.0326309204101562,\n",
       "  3.8035836219787598,\n",
       "  0.8274067044258118,\n",
       "  2.6525304317474365,\n",
       "  11.207351684570312,\n",
       "  1.622188687324524,\n",
       "  1.897011399269104,\n",
       "  29.255189895629883,\n",
       "  0.5457914471626282,\n",
       "  2.692683219909668,\n",
       "  6.066189765930176,\n",
       "  4.609647274017334,\n",
       "  32.6300163269043,\n",
       "  3.396498918533325,\n",
       "  0.5035101175308228,\n",
       "  2.233384132385254,\n",
       "  4.621105670928955,\n",
       "  7.594211578369141,\n",
       "  2.661932945251465,\n",
       "  15.615015983581543,\n",
       "  5.9456353187561035,\n",
       "  22.951274871826172,\n",
       "  8.556624412536621,\n",
       "  0.7296763062477112,\n",
       "  1.4049091339111328,\n",
       "  9.833560943603516,\n",
       "  15.694023132324219,\n",
       "  6.798214912414551,\n",
       "  2.880017042160034,\n",
       "  1.977057933807373,\n",
       "  1.7469950914382935,\n",
       "  2.113002300262451,\n",
       "  3.1138205528259277,\n",
       "  0.7641503214836121,\n",
       "  1.2900793552398682,\n",
       "  4.342440128326416,\n",
       "  6.552082061767578,\n",
       "  14.869295120239258,\n",
       "  2.539553642272949,\n",
       "  0.7098106741905212,\n",
       "  2.7714874744415283,\n",
       "  3.4958465099334717,\n",
       "  1.849095106124878,\n",
       "  3.4036061763763428,\n",
       "  7.281669616699219,\n",
       "  8.577940940856934,\n",
       "  1.525895357131958,\n",
       "  1.8241567611694336,\n",
       "  1.908798336982727,\n",
       "  0.8516178727149963,\n",
       "  0.6395072937011719,\n",
       "  0.9795640110969543,\n",
       "  2.0972089767456055,\n",
       "  0.8102375864982605,\n",
       "  1.3287044763565063,\n",
       "  1.4155759811401367,\n",
       "  1.7630444765090942,\n",
       "  4.17244291305542,\n",
       "  0.6768512725830078,\n",
       "  3.793093681335449,\n",
       "  0.5227379202842712,\n",
       "  2.4463305473327637,\n",
       "  2.805417537689209,\n",
       "  0.9057397246360779,\n",
       "  0.9231354594230652,\n",
       "  4.725438594818115,\n",
       "  5.997207164764404,\n",
       "  2.8279449939727783],\n",
       " [21.462493896484375,\n",
       "  1.6850557327270508,\n",
       "  0.4270240366458893,\n",
       "  1.8479760885238647,\n",
       "  0.3239920735359192,\n",
       "  0.6358694434165955,\n",
       "  0.6962898373603821,\n",
       "  2.7617056369781494,\n",
       "  5.086317539215088,\n",
       "  3.5667099952697754,\n",
       "  2.557560682296753,\n",
       "  4.844542503356934,\n",
       "  4.52178430557251,\n",
       "  1.3334335088729858,\n",
       "  1.2027573585510254,\n",
       "  0.3847198188304901,\n",
       "  2.144850015640259,\n",
       "  2.3371880054473877,\n",
       "  1.3302903175354004,\n",
       "  22.287389755249023,\n",
       "  4.277734279632568,\n",
       "  6.2921881675720215,\n",
       "  1.0920084714889526,\n",
       "  2.3792386054992676,\n",
       "  1.629514455795288,\n",
       "  4.975550651550293,\n",
       "  13.099637985229492,\n",
       "  4.535473346710205,\n",
       "  2.0740771293640137,\n",
       "  0.8958407640457153,\n",
       "  15.267965316772461,\n",
       "  6.131594657897949,\n",
       "  2.1022417545318604,\n",
       "  2.2337260246276855,\n",
       "  1.2291369438171387,\n",
       "  0.8915408253669739,\n",
       "  6.001418113708496,\n",
       "  10.738232612609863,\n",
       "  2.323061227798462,\n",
       "  0.34472063183784485,\n",
       "  5.139225959777832,\n",
       "  3.396787643432617,\n",
       "  25.98320770263672,\n",
       "  12.021385192871094,\n",
       "  3.9930410385131836,\n",
       "  4.314311981201172,\n",
       "  13.263143539428711,\n",
       "  6.669399738311768,\n",
       "  2.7870688438415527,\n",
       "  0.22045673429965973,\n",
       "  3.328066349029541,\n",
       "  1.3573557138442993,\n",
       "  1.3840192556381226,\n",
       "  0.22111602127552032,\n",
       "  7.165188789367676,\n",
       "  6.17869234085083,\n",
       "  4.635007381439209,\n",
       "  4.8942036628723145,\n",
       "  0.41645950078964233,\n",
       "  0.2625696361064911,\n",
       "  1.8094377517700195,\n",
       "  3.674003839492798,\n",
       "  16.301345825195312,\n",
       "  9.290502548217773,\n",
       "  4.764239311218262,\n",
       "  0.3930353820323944,\n",
       "  0.7326529026031494,\n",
       "  3.38395094871521,\n",
       "  12.915682792663574,\n",
       "  2.557482957839966,\n",
       "  7.968605041503906,\n",
       "  2.630415916442871,\n",
       "  1.3861448764801025,\n",
       "  12.873642921447754,\n",
       "  0.6765618920326233,\n",
       "  17.214126586914062,\n",
       "  23.834651947021484,\n",
       "  1.0063515901565552,\n",
       "  1.5022683143615723,\n",
       "  5.164508819580078,\n",
       "  14.180558204650879,\n",
       "  0.19410108029842377,\n",
       "  5.449356555938721,\n",
       "  14.183359146118164,\n",
       "  5.283179759979248,\n",
       "  11.620007514953613,\n",
       "  4.633279323577881,\n",
       "  8.781316757202148,\n",
       "  2.2212274074554443,\n",
       "  5.927606582641602,\n",
       "  0.984818696975708,\n",
       "  4.788410663604736,\n",
       "  0.8388341665267944,\n",
       "  39.519004821777344,\n",
       "  0.3196604549884796,\n",
       "  3.6738905906677246,\n",
       "  2.7163584232330322,\n",
       "  6.200467586517334,\n",
       "  6.126611232757568,\n",
       "  12.429795265197754,\n",
       "  3.864666700363159,\n",
       "  17.6527156829834,\n",
       "  5.876191139221191,\n",
       "  1.643673300743103,\n",
       "  6.709354400634766,\n",
       "  9.09605884552002,\n",
       "  0.1978270709514618,\n",
       "  10.518985748291016,\n",
       "  1.088234543800354,\n",
       "  1.5450938940048218,\n",
       "  0.6314882636070251,\n",
       "  0.4570995271205902,\n",
       "  2.093029737472534,\n",
       "  12.311003684997559,\n",
       "  7.64024019241333,\n",
       "  0.9112231135368347,\n",
       "  0.13485883176326752,\n",
       "  1.499569296836853,\n",
       "  4.067442893981934,\n",
       "  4.202629566192627,\n",
       "  0.6297771334648132,\n",
       "  6.186830997467041,\n",
       "  2.911264181137085,\n",
       "  1.040027141571045,\n",
       "  4.782416343688965,\n",
       "  2.8941092491149902,\n",
       "  1.9941655397415161,\n",
       "  8.211752891540527,\n",
       "  7.377791404724121,\n",
       "  1.1923649311065674,\n",
       "  2.0607714653015137,\n",
       "  0.8129435181617737,\n",
       "  8.14073657989502,\n",
       "  2.7218761444091797,\n",
       "  9.104578018188477,\n",
       "  3.497962474822998,\n",
       "  7.8733015060424805,\n",
       "  0.11873432248830795,\n",
       "  6.709433555603027,\n",
       "  11.409102439880371,\n",
       "  3.9188709259033203,\n",
       "  3.3753888607025146,\n",
       "  0.9397850036621094,\n",
       "  6.449773788452148,\n",
       "  7.850849151611328,\n",
       "  9.64048957824707,\n",
       "  7.77512788772583,\n",
       "  1.9247653484344482,\n",
       "  3.023911952972412,\n",
       "  5.186160564422607,\n",
       "  0.8936074376106262,\n",
       "  14.038817405700684,\n",
       "  1.267249584197998,\n",
       "  0.6945303678512573,\n",
       "  21.588869094848633,\n",
       "  12.363740921020508,\n",
       "  0.9179737567901611,\n",
       "  0.2575451731681824,\n",
       "  5.6178975105285645,\n",
       "  2.122727155685425,\n",
       "  14.555573463439941,\n",
       "  3.152617931365967,\n",
       "  15.827773094177246,\n",
       "  0.36126232147216797,\n",
       "  7.989954471588135,\n",
       "  1.5222034454345703,\n",
       "  0.17365609109401703,\n",
       "  1.0501350164413452,\n",
       "  1.0878996849060059,\n",
       "  4.520658016204834,\n",
       "  4.850472927093506,\n",
       "  14.166645050048828,\n",
       "  4.124582767486572,\n",
       "  9.705635070800781,\n",
       "  0.21105939149856567,\n",
       "  0.59087735414505,\n",
       "  1.313372254371643,\n",
       "  4.5636420249938965,\n",
       "  10.82264232635498,\n",
       "  5.474557876586914,\n",
       "  9.83341121673584,\n",
       "  1.0995279550552368,\n",
       "  5.073470592498779,\n",
       "  1.1972451210021973,\n",
       "  1.3733471632003784,\n",
       "  0.32594725489616394,\n",
       "  0.369862824678421,\n",
       "  13.878031730651855,\n",
       "  11.184929847717285,\n",
       "  13.377955436706543],\n",
       " [460.6388854980469,\n",
       "  0.0,\n",
       "  2.839402675628662,\n",
       "  0.0,\n",
       "  0.45534390211105347,\n",
       "  0.0,\n",
       "  0.18234752118587494,\n",
       "  0.0,\n",
       "  0.5232356190681458,\n",
       "  3.41499400138855,\n",
       "  0.0,\n",
       "  0.10497188568115234,\n",
       "  0.4043262302875519,\n",
       "  0.0,\n",
       "  0.484815388917923,\n",
       "  7.627011299133301,\n",
       "  25.870655059814453,\n",
       "  0.030374927446246147,\n",
       "  0.0,\n",
       "  12.721399307250977,\n",
       "  6.541103363037109,\n",
       "  0.0,\n",
       "  23.469554901123047,\n",
       "  20.446481704711914,\n",
       "  1.7780382633209229,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.5275415778160095,\n",
       "  1.4466307163238525,\n",
       "  0.14801089465618134,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  4.600371360778809,\n",
       "  5.462433338165283,\n",
       "  0.0,\n",
       "  1.7696659564971924,\n",
       "  0.0,\n",
       "  0.6913177967071533,\n",
       "  496.7279968261719,\n",
       "  18.298986434936523,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  39.591697692871094,\n",
       "  0.0,\n",
       "  1.1924835443496704,\n",
       "  5.660789966583252,\n",
       "  2.655324697494507,\n",
       "  0.12555080652236938,\n",
       "  0.0,\n",
       "  24.756052017211914,\n",
       "  0.0,\n",
       "  171.60064697265625,\n",
       "  20.570466995239258,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  4.301814556121826,\n",
       "  0.802534818649292,\n",
       "  233.1109161376953,\n",
       "  37.5964469909668,\n",
       "  4.419443607330322,\n",
       "  0.0,\n",
       "  0.1667121797800064,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  4.989551067352295,\n",
       "  1.5107799768447876,\n",
       "  0.79485023021698,\n",
       "  36.0169677734375,\n",
       "  115.30976104736328,\n",
       "  5.39658784866333,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.11883272230625153,\n",
       "  26.411691665649414,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  11.538126945495605,\n",
       "  0.0,\n",
       "  0.07580018043518066,\n",
       "  675.1267700195312,\n",
       "  144.51361083984375,\n",
       "  15.944416999816895,\n",
       "  18.613243103027344,\n",
       "  175.91082763671875,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  44.48093032836914,\n",
       "  0.0,\n",
       "  7.767723560333252,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.048601821064949036,\n",
       "  11.076043128967285,\n",
       "  1.8424174785614014,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.9155151844024658,\n",
       "  0.0,\n",
       "  0.048892948776483536,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  51.339881896972656,\n",
       "  38.17629623413086,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  21.48331642150879,\n",
       "  23.953201293945312,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.05159391090273857,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.17343704402446747,\n",
       "  0.027815725654363632,\n",
       "  0.21795207262039185,\n",
       "  0.0689426138997078,\n",
       "  3.2740538120269775,\n",
       "  13.498281478881836,\n",
       "  265.7340087890625,\n",
       "  86.31354522705078,\n",
       "  0.2792697548866272,\n",
       "  0.0,\n",
       "  0.2950732409954071,\n",
       "  22.697948455810547,\n",
       "  0.15447697043418884,\n",
       "  0.5367767214775085,\n",
       "  11.451157569885254,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  166.81500244140625,\n",
       "  6.540740013122559,\n",
       "  0.0,\n",
       "  63.49858093261719,\n",
       "  0.10319946706295013,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  6.919066429138184,\n",
       "  1.921412467956543,\n",
       "  0.0,\n",
       "  165.73056030273438,\n",
       "  0.0,\n",
       "  0.45773470401763916,\n",
       "  296.32635498046875,\n",
       "  568.0908813476562,\n",
       "  1.012737512588501,\n",
       "  2.2568061351776123,\n",
       "  26.672101974487305,\n",
       "  201.08811950683594,\n",
       "  0.0,\n",
       "  0.03767605125904083,\n",
       "  29.69545555114746,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.5621676445007324,\n",
       "  0.0,\n",
       "  201.16778564453125,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  27.911958694458008,\n",
       "  135.0245361328125,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  21.46726417541504,\n",
       "  0.690714418888092,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  77.1114730834961,\n",
       "  0.8250978589057922,\n",
       "  4.933866024017334,\n",
       "  35.13655471801758,\n",
       "  0.9698725342750549,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  22.928926467895508,\n",
       "  0.7036473751068115,\n",
       "  1561.7520751953125,\n",
       "  0.10218006372451782,\n",
       "  13.497427940368652,\n",
       "  7.378615856170654,\n",
       "  38.44573211669922,\n",
       "  0.0,\n",
       "  37.535335540771484,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  154.49974060058594,\n",
       "  14.935667037963867,\n",
       "  311.6185607910156,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  34.52968215942383,\n",
       "  2.7016592025756836,\n",
       "  45.01546096801758,\n",
       "  82.73823547363281,\n",
       "  0.0,\n",
       "  0.039134472608566284,\n",
       "  0.0,\n",
       "  110.64918518066406,\n",
       "  0.0,\n",
       "  1.184248447418213,\n",
       "  0.0,\n",
       "  0.15679176151752472,\n",
       "  0.0,\n",
       "  2.3873066902160645,\n",
       "  0.3987790048122406,\n",
       "  0.2089371383190155,\n",
       "  0.0,\n",
       "  4.380760669708252,\n",
       "  0.0,\n",
       "  0.21729803085327148,\n",
       "  0.0,\n",
       "  151.5607147216797,\n",
       "  58.37335205078125,\n",
       "  0.8303325772285461,\n",
       "  0.0,\n",
       "  0.01818724162876606,\n",
       "  0.029789000749588013,\n",
       "  2.248699188232422,\n",
       "  0.0,\n",
       "  16.54412269592285,\n",
       "  17.662067413330078,\n",
       "  0.3966253101825714,\n",
       "  38.276912689208984,\n",
       "  8.475480079650879,\n",
       "  1.081654667854309,\n",
       "  0.0,\n",
       "  22.871492385864258,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  8.375901222229004,\n",
       "  3.9766833782196045,\n",
       "  0.2063075751066208,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  67.43280792236328,\n",
       "  54.43177795410156,\n",
       "  0.0,\n",
       "  1.4217272996902466,\n",
       "  4.246767044067383,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6608749628067017,\n",
       "  66.27151489257812,\n",
       "  0.24650166928768158,\n",
       "  0.0,\n",
       "  7.40863037109375,\n",
       "  82.89334106445312,\n",
       "  0.0,\n",
       "  12.235723495483398,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.07307460904121399,\n",
       "  61.988800048828125,\n",
       "  0.014098474755883217,\n",
       "  45.01643371582031,\n",
       "  0.0,\n",
       "  130.167724609375,\n",
       "  0.0,\n",
       "  15.357573509216309,\n",
       "  11.39324951171875,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.8831902742385864,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  41.59954071044922,\n",
       "  61.635780334472656,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.055624086409807205,\n",
       "  92.93913269042969,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  60.45256042480469,\n",
       "  3.7047290802001953,\n",
       "  0.0,\n",
       "  9.144024848937988,\n",
       "  26.896286010742188,\n",
       "  0.798538327217102,\n",
       "  197.08831787109375,\n",
       "  1.6059281826019287,\n",
       "  0.48237359523773193,\n",
       "  466.07952880859375,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.08420815318822861,\n",
       "  0.0,\n",
       "  152.86221313476562,\n",
       "  0.8426816463470459,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.06633108109235764,\n",
       "  0.0,\n",
       "  31.56077766418457,\n",
       "  4.5059494972229,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  211.8645782470703,\n",
       "  9.939018249511719,\n",
       "  0.0,\n",
       "  0.022016335278749466,\n",
       "  0.12995602190494537,\n",
       "  0.0004176856891717762,\n",
       "  250.51821899414062,\n",
       "  0.13050925731658936,\n",
       "  63.839447021484375,\n",
       "  0.0,\n",
       "  2.317093849182129,\n",
       "  0.030156809836626053,\n",
       "  1.1027897596359253,\n",
       "  1.1835192441940308,\n",
       "  20.43637466430664,\n",
       "  23.527114868164062,\n",
       "  200.69375610351562,\n",
       "  17.01215934753418,\n",
       "  94.19925689697266,\n",
       "  0.036009207367897034,\n",
       "  0.0,\n",
       "  0.04454483836889267,\n",
       "  0.34913259744644165,\n",
       "  1.7249548435211182,\n",
       "  20.826828002929688,\n",
       "  0.0,\n",
       "  117.12969207763672,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10442321002483368,\n",
       "  29.970815658569336,\n",
       "  96.6960678100586,\n",
       "  1.20895516872406,\n",
       "  0.0,\n",
       "  25.74014663696289,\n",
       "  1.433390736579895,\n",
       "  1.8860745429992676,\n",
       "  0.10623975098133087,\n",
       "  0.13679631054401398,\n",
       "  0.22777658700942993,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.008884415030479431,\n",
       "  0.005908496677875519,\n",
       "  192.5998992919922,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  125.10254669189453,\n",
       "  178.96981811523438,\n",
       "  0.0],\n",
       " [1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\AppData\\Local\\Temp\\ipykernel_12996\\3520072505.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tr_results = np.asarray(train_results)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "tr_results = np.asarray(train_results)\n",
    "tr_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tr_results[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mshape\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "tr_results[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(123)\n",
    "\n",
    "w = 0.8    # bar width\n",
    "x = [1, 2] # x-coordinates of your bars\n",
    "colors = [(0, 0, 1, 1), (1, 0, 0, 1)]    # corresponding colors\n",
    "y = [np.random.random(30) * 2 + 5,       # data series\n",
    "    np.random.random(10) * 3 + 8]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(x,\n",
    "       height=[np.mean(yi) for yi in y],\n",
    "       yerr=[np.std(yi) for yi in y],    # error bars\n",
    "       capsize=12, # error bar cap width in points\n",
    "       width=w,    # bar width\n",
    "       tick_label=[\"control\", \"test\"],\n",
    "       color=(0,0,0,0),  # face color transparent\n",
    "       edgecolor=colors,\n",
    "       #ecolor=colors,    # error bar colors; setting this raises an error for whatever reason.\n",
    "       )\n",
    "\n",
    "for i in range(len(x)):\n",
    "    # distribute scatter randomly across whole width of bar\n",
    "    ax.scatter(x[i] + np.random.random(y[i].size) * w - w / 2, y[i], color=colors[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save(f'{model_name}_training_loss.npy', tr_loss, allow_pickle=True)\n",
    "np.save(f'{model_name}_training_accuracy.npy', tr_acc, allow_pickle=True)\n",
    "\n",
    "np.save(f'{model_name}_validation_loss.npy', v_loss, allow_pickle=True)\n",
    "np.save(f'{model_name}_validation_accuracy.npy', v_acc, allow_pickle=True)\n",
    "\n",
    "np.save(f'{model_name}_test_loss.npy', tst_loss, allow_pickle=True)\n",
    "np.save(f'{model_name}_test_accuracy.npy', tst_acc, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "training_loss = np.load(f'{model_name}_training_loss.npy', allow_pickle=True)\n",
    "training_accuracy = np.load(f'{model_name}_training_accuracy.npy', allow_pickle=True)\n",
    "\n",
    "validation_loss = np.load(f'{model_name}_validation_loss.npy', allow_pickle=True)\n",
    "validation_accuracy = np.load(f'{model_name}_validation_accuracy.npy', allow_pickle=True)\n",
    "\n",
    "test_loss = np.load(f'{model_name}_test_loss.npy', allow_pickle=True)\n",
    "test_accuracy = np.load(f'{model_name}_test_accuracy.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a sequence of integers to represent the epoch numbers\n",
    "epochs = range(1, num_epochs+1)\n",
    " \n",
    "# Plot and label the training and validation loss values\n",
    "plt.plot(epochs, training_loss, label='Training Loss')\n",
    "plt.plot(epochs, validation_loss, label='Validation Loss')\n",
    " \n",
    "# Add in a title and axes labels\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    " \n",
    "# Set the tick locations\n",
    "plt.xticks(np.arange(0, num_epochs+1, num_epochs/10))\n",
    " \n",
    "# Display the plot\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(f'{model_name}_Training and Validation Loss.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a sequence of integers to represent the epoch numbers\n",
    "epochs = range(1, num_epochs+1)\n",
    " \n",
    "# Plot and label the training and validation loss values\n",
    "plt.plot(epochs, training_accuracy, label='Training Accuracy')\n",
    "plt.plot(epochs, validation_accuracy, label='Validation Accuracy')\n",
    "plt.plot(epochs, test_accuracy, label='Test Accuracy')\n",
    " \n",
    "# Add in a title and axes labels\n",
    "plt.title('Accuracy vs. Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    " \n",
    "# Set the tick locations\n",
    "plt.xticks(np.arange(0, num_epochs+1, num_epochs/10))\n",
    "plt.ylim(0,1)\n",
    " \n",
    "# Display the plot\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(f'{model_name}_Accuracy vs. Epochs.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_fraction = [0,0]\n",
    "\n",
    "train_fraction = [0,0]\n",
    "val_fraction = [0,0]\n",
    "test_fraction = [0,0]\n",
    "\n",
    "for grph in train_dataset: \n",
    "    if grph.y == 1: \n",
    "        train_fraction[1] +=1\n",
    "        dataset_fraction[1] +=1 \n",
    "    else: \n",
    "        train_fraction[0] +=1\n",
    "        dataset_fraction[0] +=1 \n",
    "\n",
    "for grph in val_dataset: \n",
    "    if grph.y == 1:\n",
    "         val_fraction[1] +=1\n",
    "         dataset_fraction[1] +=1  \n",
    "    else:\n",
    "         val_fraction[0] +=1\n",
    "         dataset_fraction[0] +=1\n",
    "\n",
    "for grph in test_dataset: \n",
    "    if grph.y == 1:\n",
    "         test_fraction[1] +=1\n",
    "         dataset_fraction[1] +=1 \n",
    "    else:\n",
    "         test_fraction[0] +=1\n",
    "         dataset_fraction[0] +=1\n",
    "\n",
    "print(f'Overall dataset percentage of label 1 = {dataset_fraction[1]/len(dataset)})')\n",
    "print(f'Training dataset percentage of label 1 = {train_fraction} = {train_fraction[1]/len(train_dataset)}')\n",
    "print(f'Validation dataset percentage of label 1 = {val_fraction} = {val_fraction[1]/len(val_dataset)}')\n",
    "print(f'Test dataset percentage of label 1 = {test_fraction} = {test_fraction[1]/len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Graph: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, pos0, adj0 = torch.load(f'{model_name}_img0_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Embedding GNN\n",
    "print(x0[0].shape)\n",
    "x0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pos0[0].shape)\n",
    "pos0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adj0[0].shape)\n",
    "adj0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index, _ = dense_to_sparse(adj0[0])\n",
    "visualize_points(pos0[0].cpu(), edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph After 1st Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_emb, x1_pool, pos1, adj1, s1= torch.load(f'{model_name}_img1_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Embedding GNN (adj0 @ x_0 @ w_gnn_emb)\n",
    "print(x1_emb[0].shape)\n",
    "x1_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Pooling GNN: adj_0 @ x_0 @ w_gnn_pool\n",
    "print(s1[0].shape)\n",
    "s1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Coordinate Matrix (pos_out = softmax(s).t() @ pos_in)\n",
    "print(pos1[0].shape)\n",
    "pos1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Feature Matrix (x_out = softmax(s).t() @ x_in)\n",
    "print(x1_pool[0].shape)\n",
    "x1_pool[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Adjacency Matrix = softmax(adj_out = softmax(s.t()) @ adj_in @ softmax(s))\n",
    "print(adj1[0].shape)\n",
    "adj1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index, _ = dense_to_sparse(adj1[0])\n",
    "visualize_points(pos1[0].cpu(), edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph after 2nd reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_emb, x2_pool, pos2, adj2, s2 = torch.load(f'{model_name}_img2_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Embedding GNN (adj1 @ x1_pool @ w_gnn_emb)\n",
    "print(x2_emb[0].shape)\n",
    "x2_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Pooling GNN: adj1 @ x1_pool @ w_gnn_pool), dim=1\n",
    "print(s2[0].shape)\n",
    "s2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Coordinate Matrix (pos_out = softmax(s.t()) @ pos_in)\n",
    "print(pos2[0].shape)\n",
    "pos2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Feature Matrix (x_out = softmax(s2).t() @ x2_emb)\n",
    "print(x2_pool[0].shape)\n",
    "x2_pool[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Adjacency Matrix (adj = softmax(s).T @ adj @ softmax(s)\n",
    "print(adj2[0].shape)\n",
    "adj2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index, _ = dense_to_sparse(adj2[0])\n",
    "visualize_points(pos2[0].cpu(), edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph after 3rd reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3_emb, x3_pool, pos3, adj3, s3 = torch.load(f'{model_name}_img3_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Embedding GNN (adj_0 @ x_0 @ w_gnn_emb)\n",
    "print(x3_emb[0].shape)\n",
    "x3_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Pooling GNN: torch.softmax(adj_0 @ x_0 @ w_gnn_pool), dim=1)\n",
    "print(s3[0].shape)\n",
    "s3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Coordinate Matrix (pos_out = softmax(s.t()) @ pos_in)\n",
    "print(pos3[0].shape)\n",
    "pos3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Feature Matrix (x_out = softmax(s.t()) @ x_0)\n",
    "print(x3_pool[0].shape)\n",
    "x3_pool[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Adjacency Matrix (adj = softmax(s.t()) @ adj @ softmax(s)\n",
    "print(adj3[0].shape)\n",
    "adj3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index, _ = dense_to_sparse(adj3[0])\n",
    "visualize_points(pos3[0].cpu(), edge_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3baeb0c3f97feb3023477fbaa09b9f4da769e45e64d8febc6957bb84d33ff77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
