{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize features? \n",
    "## Invert h-bond and charge? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_siamese_071222'\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import DenseDataLoader #To make use of this data loader, all graph attributes in the dataset need to have the same shape. In particular, this data loader should only be used when working with dense adjacency matrices.\n",
    "from torch_geometric.nn import DenseGCNConv, dense_diff_pool\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dir_1 = 'C:/Users/david/pyproj/pyg/adl/patch_label_1'\n",
    "#data_dir_0 = 'C:/Users/david/pyproj/pyg/adl/patch_label_0'\n",
    "data_dir_1 = 'C:/Users/thoma/OneDrive - ZHAW/ProteinSurfaces-DESKTOP-AQ00763/patch_label_1'\n",
    "data_dir_0 = 'C:/Users/thoma/OneDrive - ZHAW/ProteinSurfaces-DESKTOP-AQ00763/patch_label_0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "572"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from c_PatchDataset import PatchDataset\n",
    "dataset = PatchDataset(data_dir_label_0 = data_dir_0,  data_dir_label_1=data_dir_1,  neg_pos_ratio=1)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: PatchDataset(572):\n",
      "====================\n",
      "Number of graphs pairs: 572\n",
      "\n",
      "PairData(adj1=[100, 100], x1=[100, 3], adj2=[100, 100], x2=[100, 3], y=0)\n",
      "=============================================================\n",
      "Number of nodes in each: None\n",
      "Number of node features: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thoma\\Desktop\\ZHAW MLS\\David prod\\ADLProtProject\\.venv\\lib\\site-packages\\torch_geometric\\data\\storage.py:271: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'adj1', 'y', 'x2', 'adj2', 'x1'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs pairs: {len(dataset)}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "print()\n",
    "print(data)\n",
    "print('=============================================================')\n",
    "\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes in each: {data.num_nodes}')\n",
    "print(f'Number of node features: {data.num_node_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1326,  0.0000, -0.9912],\n",
       "        [ 0.1678,  0.0000, -0.9858],\n",
       "        [-0.0268,  0.0000, -0.9996],\n",
       "        [-0.7292, -0.4013, -0.5542],\n",
       "        [ 0.2186,  0.0000, -0.9758],\n",
       "        [ 0.0228,  0.0000, -0.9997],\n",
       "        [-0.3309, -0.0772, -0.9405],\n",
       "        [ 0.1528,  0.0000, -0.9883],\n",
       "        [-0.3264, -0.0052, -0.9452],\n",
       "        [ 0.0373,  0.0000, -0.9993],\n",
       "        [-0.4718, -0.2317, -0.8507],\n",
       "        [-0.4182, -0.1799, -0.8904],\n",
       "        [ 0.2864,  0.0000, -0.9581],\n",
       "        [-0.3658, -0.1671, -0.9156],\n",
       "        [ 0.1610,  0.0000, -0.9870],\n",
       "        [ 0.0115,  0.0000, -0.9999],\n",
       "        [-0.1636,  0.0000, -0.9865],\n",
       "        [ 0.0921,  0.0000, -0.9958],\n",
       "        [-0.2295,  0.0000, -0.9733],\n",
       "        [ 0.1141, -0.0899, -0.9894],\n",
       "        [ 0.0916,  0.0000, -0.9958],\n",
       "        [-0.3753,  0.0000, -0.9269],\n",
       "        [ 0.1169,  0.0000, -0.9931],\n",
       "        [ 0.0214,  0.0000, -0.9998],\n",
       "        [ 0.0407,  0.0000, -0.9992],\n",
       "        [ 0.3154,  0.0000, -0.9490],\n",
       "        [-0.6600, -0.2849, -0.6951],\n",
       "        [-0.1177,  0.0000, -0.9930],\n",
       "        [-0.1756, -0.0560, -0.9829],\n",
       "        [-0.2225, -0.0126, -0.9748],\n",
       "        [-0.3515, -0.0083, -0.9361],\n",
       "        [ 0.0757,  0.0000, -0.9971],\n",
       "        [-0.4002, -0.0661, -0.9141],\n",
       "        [ 0.3359,  0.0804, -0.9385],\n",
       "        [-0.2304, -0.0182, -0.9729],\n",
       "        [ 0.0835,  0.0000, -0.9965],\n",
       "        [-0.2492,  0.0000, -0.9685],\n",
       "        [-0.0082,  0.0000, -1.0000],\n",
       "        [ 0.0925,  0.0000, -0.9957],\n",
       "        [-0.3520, -0.1926, -0.9160],\n",
       "        [-0.3653, -0.1930, -0.9107],\n",
       "        [ 0.1292,  0.0000, -0.9916],\n",
       "        [ 0.2322,  0.0000, -0.9727],\n",
       "        [ 0.0940,  0.0000, -0.9956],\n",
       "        [ 0.0441,  0.0000, -0.9990],\n",
       "        [-0.0356,  0.0000, -0.9994],\n",
       "        [ 0.1035,  0.0000, -0.9946],\n",
       "        [-0.0010,  0.0000, -1.0000],\n",
       "        [ 0.3048,  0.1208, -0.9447],\n",
       "        [ 0.5259, -0.3061,  0.7936],\n",
       "        [ 0.1509,  0.1749, -0.9730],\n",
       "        [-0.1849,  0.0000, -0.9828],\n",
       "        [ 0.1753,  0.0000, -0.9845],\n",
       "        [ 0.1481,  0.0928, -0.9846],\n",
       "        [ 0.1324,  0.0000, -0.9912],\n",
       "        [-0.8670, -0.0054, -0.4982],\n",
       "        [ 0.0348,  0.0000, -0.9994],\n",
       "        [ 0.1422,  0.0000, -0.9898],\n",
       "        [ 0.2313,  0.0000, -0.9729],\n",
       "        [ 0.1683,  0.1625, -0.9722],\n",
       "        [ 0.0752,  0.0000, -0.9972],\n",
       "        [ 0.1557,  0.0000, -0.9878],\n",
       "        [ 0.1794,  0.0000, -0.9838],\n",
       "        [ 0.0229,  0.0000, -0.9997],\n",
       "        [ 0.1514,  0.0633, -0.9864],\n",
       "        [ 0.0753,  0.0000, -0.9972],\n",
       "        [ 0.3357,  0.0000, -0.9420],\n",
       "        [ 0.0682,  0.0000, -0.9977],\n",
       "        [-0.1347,  0.0000, -0.9909],\n",
       "        [-0.3804, -0.1137, -0.9178],\n",
       "        [-0.5282, -0.3486, -0.7743],\n",
       "        [-0.0266,  0.0000, -0.9996],\n",
       "        [ 0.1234,  0.0000, -0.9924],\n",
       "        [ 0.3683,  0.0000, -0.9297],\n",
       "        [ 0.2695,  0.0000, -0.9630],\n",
       "        [ 0.1169,  0.1032, -0.9878],\n",
       "        [ 0.1085,  0.0000, -0.9941],\n",
       "        [ 0.2079,  0.0000, -0.9781],\n",
       "        [-0.3769, -0.0046, -0.9262],\n",
       "        [ 0.2479,  0.1767, -0.9525],\n",
       "        [-0.1729,  0.0000, -0.9849],\n",
       "        [ 0.1208,  0.0000, -0.9927],\n",
       "        [ 0.0195,  0.0000, -0.9998],\n",
       "        [-0.1979, -0.7435, -0.6387],\n",
       "        [ 0.3036,  0.0000, -0.9528],\n",
       "        [ 0.4825,  0.0000, -0.8759],\n",
       "        [ 0.1582,  0.0000, -0.9874],\n",
       "        [ 0.1341,  0.0000, -0.9910],\n",
       "        [-0.3203, -0.2318, -0.9185],\n",
       "        [-0.0795, -0.0014, -0.9968],\n",
       "        [-0.3173,  0.0000, -0.9483],\n",
       "        [ 0.2570,  0.0391, -0.9656],\n",
       "        [ 0.1057, -0.0304, -0.9939],\n",
       "        [ 0.3593,  0.0971, -0.9282],\n",
       "        [ 0.3753,  0.0000, -0.9269],\n",
       "        [ 0.1619,  0.0000, -0.9868],\n",
       "        [ 0.3908,  0.0000, -0.9205],\n",
       "        [ 0.0548,  0.0000, -0.9985],\n",
       "        [ 0.2898,  0.2488, -0.9242],\n",
       "        [ 0.1045,  0.0000, -0.9945]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does not work we do not have pos\n",
    "#visualize_points(data.pos, data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs pairs: 382\n",
      "Number of validation graphs: 95\n",
      "Number of test graphs: 95\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader \n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "n_train = math.ceil((4/6) * len(dataset))\n",
    "n_val = math.ceil((len(dataset) - n_train)/2)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "print(f'Number of training graphs pairs: {len(train_dataset)}')\n",
    "print(f'Number of validation graphs: {len(val_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')\n",
    "\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size= batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset = val_dataset, batch_size= batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size= batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PairDataBatch(adj1=[100, 100], x1=[100, 3], adj2=[100, 100], x2=[100, 3], y=[1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "databatch = next(iter(train_loader))\n",
    "databatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_nodes, in_channels, hidden_channels, out_channels,\n",
    "                 normalize=False, lin=True):\n",
    "        super(GNN, self).__init__()\n",
    "\n",
    "        # Each instance of this GNN will have 3 convolutional layers and three batch norm layers        \n",
    "        self.conv1 = DenseGCNConv(in_channels, hidden_channels, normalize)\n",
    "        self.bns1 = torch.nn.BatchNorm1d(in_nodes)\n",
    "        \n",
    "        self.conv2 = DenseGCNConv(hidden_channels, hidden_channels, normalize)\n",
    "        self.bns2 = torch.nn.BatchNorm1d(in_nodes)\n",
    "        \n",
    "        self.conv3 = DenseGCNConv(hidden_channels, out_channels, normalize)\n",
    "        self.bns3 = torch.nn.BatchNorm1d(in_nodes)\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        \n",
    "        #Step 1\n",
    "        x = self.conv1(x, adj, mask)\n",
    "        x = self.bns1(x)\n",
    "        \n",
    "        #Step 2\n",
    "        x = self.conv2(x, adj, mask)\n",
    "        x = self.bns2(x)\n",
    "\n",
    "        #Step 3\n",
    "        x = self.conv3(x, adj, mask)\n",
    "        if x.shape[2] != 1: \n",
    "            x = self.bns3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class DiffPool(torch.nn.Module):\n",
    "    def __init__(self, num_nodes):\n",
    "        super(DiffPool, self).__init__()\n",
    "\n",
    "        #Hierarchical Step #1\n",
    "        in_nodes = num_nodes\n",
    "        out_nodes = 25 # Number of clusters / nodes in the next layer\n",
    "        self.gnn1_pool = GNN(in_nodes, dataset.num_features, 16, out_nodes) # PoolGNN --> Cluster Assignment Matrix to reduce to num_nodes\n",
    "        self.gnn1_embed = GNN(in_nodes, dataset.num_features, 8, 8) # EmbGNN --> Convolutions to create new node embedding\n",
    "\n",
    "        # Hierarchical Step #2\n",
    "        in_nodes = out_nodes\n",
    "        out_nodes = 10\n",
    "        self.gnn2_pool = GNN(in_nodes, 8, 8, out_nodes)\n",
    "        self.gnn2_embed = GNN(in_nodes, 8, 12, 16, lin=False)\n",
    "\n",
    "        # Hierarchical Step #3\n",
    "        in_nodes = out_nodes\n",
    "        out_nodes = 1\n",
    "        self.gnn3_pool = GNN(in_nodes, 16, 16, out_nodes)\n",
    "        self.gnn3_embed = GNN(in_nodes, 16, 16, 32, lin=False)\n",
    "\n",
    "        # Final Classifier\n",
    "        self.lin1 = torch.nn.Linear(32, 64) \n",
    "        #self.lin2 = torch.nn.Linear(64, 2)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, batch, mask=None):\n",
    "        \n",
    "        #if batch == 0: print('Shape of input data batch:')\n",
    "        #if batch == 0: print(f'Feature Matrix: {tuple(x.shape)}')\n",
    "        #if batch == 0: print(f'Adjacency Matrix: {tuple(adj.shape)}')\n",
    "       \n",
    "\n",
    "\n",
    "        #Hierarchical Step #1\n",
    "        #if batch == 0: print('Hierarchical Step #1')\n",
    "        x1 = self.gnn1_embed(x, adj, mask) # node feature embedding\n",
    "        s = self.gnn1_pool(x, adj, mask) # cluster assignment matrix\n",
    "\n",
    "        #if batch == 0: print(f'X1 = {tuple(x1.shape)}    S1: {tuple(s.shape)}')\n",
    "\n",
    "        x, adj, l1, e1 = dense_diff_pool(x1, adj, s, mask) # does the necessary matrix multiplications\n",
    "        adj = torch.softmax(adj, dim=-1)\n",
    "\n",
    "        #if batch == 0: print(f'---matmul---> New feature matrix (softmax(s_0.t()) @ z_0) = {tuple(x.shape)}')\n",
    "        #if batch == 0: print(f'---matmul---> New adjacency matrix (s_0.t() @ adj_0 @ s_0) = {tuple(adj.shape)}')\n",
    "   \n",
    "\n",
    "\n",
    "        # Hierarchical Step #2\n",
    "        #if batch == 0: print('Hierarchical Step #2')\n",
    "        x2 = self.gnn2_embed(x, adj)\n",
    "        s = self.gnn2_pool(x, adj)\n",
    "\n",
    "        #if batch == 0: print(f'X2: {tuple(x2.shape)}    S2: {tuple(s.shape)}')\n",
    "        \n",
    "        x, adj, l2, e2 = dense_diff_pool(x2, adj, s)\n",
    "        adj = torch.softmax(adj, dim=-1)\n",
    "\n",
    "        #if batch == 0: print(f'---matmul---> New feature matrix (softmax(s_0.t()) @ z_0) = {tuple(x.shape)}')\n",
    "        #if batch == 0: print(f'---matmul---> New adjacency matrix (s_0.t() @ adj_0 @ s_0) = {tuple(adj.shape)}')\n",
    "      \n",
    "        \n",
    "\n",
    "        # Hierarchical Step #3\n",
    "        #if batch == 0: print('Hierarchical Step #3')\n",
    "        x3 = self.gnn3_embed(x, adj)\n",
    "        s = self.gnn3_pool(x, adj)\n",
    "        \n",
    "        #if batch == 0: print(f'X3: {tuple(x3.shape)}    S3: {tuple(s.shape)}')\n",
    "\n",
    "        x, adj, l3, e3 = dense_diff_pool(x3, adj, s)\n",
    "        adj = torch.softmax(adj, dim=-1)\n",
    "\n",
    "        #if batch == 0: print(f'---matmul---> New feature matrix (softmax(s_0.t()) @ z_0) = {tuple(x.shape)}')\n",
    "        #if batch == 0: print(f'---matmul---> New adjacency matrix (s_0.t() @ adj_0 @ s_0) = {tuple(adj.shape)}')\n",
    "     \n",
    "        \n",
    "\n",
    "        # Final Classification\n",
    "        #if batch == 0: print('Final Output')\n",
    "        x = x.mean(dim=1) # Pool the features of all nodes (global mean pool)  dim = 1 refers to columns\n",
    "        #if batch == 0: print(f'---X Output after mean= {tuple(x.shape)}')\n",
    "\n",
    "        x = F.relu(self.lin1(x)) # Fully connected layer + relu\n",
    "        #if batch == 0: print(f'------ X Output 3 after lin= {tuple(x.shape)}')\n",
    "\n",
    "        \n",
    "        return x, l1 + l2 + l3, e1 + e2 + e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An attempt of a contrastive loss function\n",
    "#   pairs with label 1 --> should get small euclid dist = small loss\n",
    "#   pairs with label 0 --> should get large euclid dist = small loss\n",
    "\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, margin=1):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, x0, x1, y,epochs):\n",
    "        # euclidian distance\n",
    "        #print(x0)\n",
    "        #print(x1)\n",
    "        #print(y)\n",
    "        diff = x0 - x1\n",
    "        #print(diff)\n",
    "        pow = torch.pow(diff, 2)\n",
    "        #print(pow)\n",
    "        dist_sq = torch.sum(pow, 1)\n",
    "        #print(dist_sq) # sum of squared distance = 0.5 = 9\n",
    "        dist = torch.sqrt(dist_sq)\n",
    "        #print(dist) # euclidean distance = 0.7 = 3\n",
    "\n",
    "        mdist = self.margin- dist #negative euclidean distance - margin = 0.3 = -2\n",
    "        #print(mdist)\n",
    "        dist_marg = torch.clamp(mdist, min=0.0) # only distances <margin will be still positive here = 0.3 = 0\n",
    "        #print(dist)\n",
    "        loss =  y * torch.pow(dist, 2) + (1-y) * torch.pow(dist_marg,2)\n",
    "\n",
    "        # What happens to a pair with squared euclid dist (dist_sq) of 0.5\n",
    "        # if label = 0 --> 0 + squared clampled euclid distance --> loss = 0.3^2\n",
    "        # if label = 1 --> squared euclidean distance + 0 --> loss = 0.5\n",
    "\n",
    "        # What happens to a pair with squared euclid dist (dist_sq) of 9\n",
    "        # if label = 0 --> 0 + squared clampled euclid distance --> loss = 0\n",
    "        # if label = 1 --> squared euclidean distance + 0 --> loss = 9\n",
    "\n",
    "        #print(loss)\n",
    "        #loss = torch.sum(loss) / 2.0 \n",
    "        #print(loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch: 001, Train Loss: 187.875\n",
      "Epoch: 002, Train Loss: 38.115\n",
      "Epoch: 003, Train Loss: 8.652\n",
      "Epoch: 004, Train Loss: 2.306\n",
      "Epoch: 005, Train Loss: 0.740\n",
      "Epoch: 006, Train Loss: 0.332\n",
      "Epoch: 007, Train Loss: 0.257\n",
      "Epoch: 008, Train Loss: 0.237\n",
      "Epoch: 009, Train Loss: 0.217\n",
      "Epoch: 010, Train Loss: 0.213\n",
      "Epoch: 011, Train Loss: 0.212\n",
      "Epoch: 012, Train Loss: 0.213\n",
      "Epoch: 013, Train Loss: 0.204\n",
      "Epoch: 014, Train Loss: 0.221\n",
      "Epoch: 015, Train Loss: 0.209\n",
      "Epoch: 016, Train Loss: 0.207\n",
      "Epoch: 017, Train Loss: 0.214\n",
      "Epoch: 018, Train Loss: 0.221\n",
      "Epoch: 019, Train Loss: 0.216\n",
      "Epoch: 020, Train Loss: 0.218\n",
      "Epoch: 021, Train Loss: 0.203\n",
      "Epoch: 022, Train Loss: 0.209\n",
      "Epoch: 023, Train Loss: 0.219\n",
      "Epoch: 024, Train Loss: 0.228\n",
      "Epoch: 025, Train Loss: 0.213\n",
      "Epoch: 026, Train Loss: 0.228\n",
      "Epoch: 027, Train Loss: 0.227\n",
      "Epoch: 028, Train Loss: 0.211\n",
      "Epoch: 029, Train Loss: 0.219\n",
      "Epoch: 030, Train Loss: 0.223\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = DiffPool(num_nodes = 100).to(device)\n",
    "criterion = ContrastiveLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "num_epochs = 30\n",
    "\n",
    "def train(epoch):\n",
    "    batch = 0\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output1, _, _ = model(data.x1, data.adj1, batch)\n",
    "        output2, _, _ = model(data.x2, data.adj2, batch = None)\n",
    "        \n",
    "        #Contrastive Loss\n",
    "        loss_contrastive = criterion(output1,output2,data.y,epoch)\n",
    "        loss_contrastive.backward()\n",
    "        loss_all += data.y.size(0) * loss_contrastive.item()\n",
    "        optimizer.step()\n",
    "        batch +=1\n",
    "\n",
    "    return loss_all / len(train_dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader,epochs):\n",
    "    model.eval()\n",
    "\n",
    "    distances_lab1 = []\n",
    "    distances_lab0 = []\n",
    "    labels = []\n",
    "    losses = []\n",
    "    \n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output1, _, _ = model(data.x1, data.adj1, batch=None)\n",
    "        output2, _, _ = model(data.x2, data.adj2, batch=None)\n",
    "\n",
    "        test_loss_contrastive = criterion(output1, output2, data.y,epochs)\n",
    "        #diff = output1 -output2\n",
    "        #print(diff)\n",
    "        #pow = torch.pow(diff, 2)\n",
    "        #print(pow)\n",
    "        #dist_sq = torch.sum(pow, 1)\n",
    "        #print(dist_sq) # sum of squared distance = 0.5 = 9\n",
    "        #euclidean_distance = torch.sqrt(dist_sq)\n",
    "        #print(dist) # euclidean distance = 0.7 = 3\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        label = data.y\n",
    "\n",
    "        if int(label) == 1: \n",
    "            distances_lab1.append(float(euclidean_distance))\n",
    "            labels.append(int(label))\n",
    "            losses.append(float(test_loss_contrastive))\n",
    "        else:\n",
    "            distances_lab0.append(float(euclidean_distance))\n",
    "            labels.append(int(label))\n",
    "            losses.append(float(test_loss_contrastive))\n",
    "\n",
    "    return  distances_lab0, distances_lab1, losses, labels\n",
    "\n",
    "\n",
    "\n",
    "train_distances_lab0 = []\n",
    "train_distances_lab1 = []\n",
    "train_losses = []\n",
    "train_labels = []\n",
    "\n",
    "validation_distances_lab0 = []\n",
    "validation_distances_lab1 = []\n",
    "validation_losses = []\n",
    "validation_labels = []\n",
    "\n",
    "test_distances_lab0 = []\n",
    "test_distances_lab1 = []\n",
    "test_losses = []\n",
    "test_labels = []\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    train_loss = train(epoch)\n",
    "\n",
    "    train_results = test(train_loader,epoch)\n",
    "    train_distances_lab0.append(train_results[0])\n",
    "    train_distances_lab1.append(train_results[1])\n",
    "    train_losses.append(train_results[2])\n",
    "    train_labels.append(train_results[3])\n",
    "\n",
    "\n",
    "    validation_results = test(val_loader,epoch)\n",
    "    validation_distances_lab0.append(validation_results[0])\n",
    "    validation_distances_lab1.append(validation_results[1])\n",
    "    validation_losses.append(validation_results[2])\n",
    "    validation_labels.append(validation_results[3])\n",
    "\n",
    "    test_results = test(test_loader,epoch)\n",
    "    test_distances_lab0.append(test_results[0])\n",
    "    test_distances_lab1.append(test_results[1])\n",
    "    test_losses.append(test_results[2])\n",
    "    test_labels.append(test_results[3])\n",
    "\n",
    "\n",
    "    print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.3f}')\n",
    "    #Train Acc: {train_acc:.3f}, f'Val Acc: {val_acc:.3f}, Test Acc: {test_acc:.3f}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compare_euclid_distances(distances_lab0, distances_lab1):\n",
    "\n",
    "    w = 0.8    # bar width\n",
    "    x = [1, 2] # x-coordinates of your bars\n",
    "    colors = [(0, 0, 1, 1), (1, 0, 0, 1)]    # corresponding colors\n",
    "\n",
    "    # Epoch 0\n",
    "    y = [distances_lab0, distances_lab1]\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(x,\n",
    "        height=[np.mean(yi) for yi in y],\n",
    "        yerr=[np.std(yi) for yi in y],    # error bars\n",
    "        capsize=12, # error bar cap width in points\n",
    "        width=w,    # bar width\n",
    "        tick_label=[\"Label 0\", \"Label 1\"],\n",
    "        color=(0,0,0,0),  # face color transparent\n",
    "        edgecolor=colors,\n",
    "        )\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        # distribute scatter randomly across whole width of bar\n",
    "        ax.scatter(x[i] + np.random.random(len(y[i])) * w - w / 2, y[i], color=colors[i])\n",
    "\n",
    "    plt.ylabel = 'Euclidean Distance'\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_euclid_distances(train_distances_lab0[2], train_distances_lab1[2])\n",
    "compare_euclid_distances(train_distances_lab0[6], train_distances_lab1[6])\n",
    "\n",
    "compare_euclid_distances(train_distances_lab0[8], train_distances_lab1[8])\n",
    "compare_euclid_distances(train_distances_lab0[24], train_distances_lab1[24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "gnn1_pool.conv1.bias \t torch.Size([16])\n",
      "gnn1_pool.conv1.lin.weight \t torch.Size([16, 3])\n",
      "gnn1_pool.bns1.weight \t torch.Size([100])\n",
      "gnn1_pool.bns1.bias \t torch.Size([100])\n",
      "gnn1_pool.bns1.running_mean \t torch.Size([100])\n",
      "gnn1_pool.bns1.running_var \t torch.Size([100])\n",
      "gnn1_pool.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn1_pool.conv2.bias \t torch.Size([16])\n",
      "gnn1_pool.conv2.lin.weight \t torch.Size([16, 16])\n",
      "gnn1_pool.bns2.weight \t torch.Size([100])\n",
      "gnn1_pool.bns2.bias \t torch.Size([100])\n",
      "gnn1_pool.bns2.running_mean \t torch.Size([100])\n",
      "gnn1_pool.bns2.running_var \t torch.Size([100])\n",
      "gnn1_pool.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn1_pool.conv3.bias \t torch.Size([25])\n",
      "gnn1_pool.conv3.lin.weight \t torch.Size([25, 16])\n",
      "gnn1_pool.bns3.weight \t torch.Size([100])\n",
      "gnn1_pool.bns3.bias \t torch.Size([100])\n",
      "gnn1_pool.bns3.running_mean \t torch.Size([100])\n",
      "gnn1_pool.bns3.running_var \t torch.Size([100])\n",
      "gnn1_pool.bns3.num_batches_tracked \t torch.Size([])\n",
      "gnn1_embed.conv1.bias \t torch.Size([8])\n",
      "gnn1_embed.conv1.lin.weight \t torch.Size([8, 3])\n",
      "gnn1_embed.bns1.weight \t torch.Size([100])\n",
      "gnn1_embed.bns1.bias \t torch.Size([100])\n",
      "gnn1_embed.bns1.running_mean \t torch.Size([100])\n",
      "gnn1_embed.bns1.running_var \t torch.Size([100])\n",
      "gnn1_embed.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn1_embed.conv2.bias \t torch.Size([8])\n",
      "gnn1_embed.conv2.lin.weight \t torch.Size([8, 8])\n",
      "gnn1_embed.bns2.weight \t torch.Size([100])\n",
      "gnn1_embed.bns2.bias \t torch.Size([100])\n",
      "gnn1_embed.bns2.running_mean \t torch.Size([100])\n",
      "gnn1_embed.bns2.running_var \t torch.Size([100])\n",
      "gnn1_embed.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn1_embed.conv3.bias \t torch.Size([8])\n",
      "gnn1_embed.conv3.lin.weight \t torch.Size([8, 8])\n",
      "gnn1_embed.bns3.weight \t torch.Size([100])\n",
      "gnn1_embed.bns3.bias \t torch.Size([100])\n",
      "gnn1_embed.bns3.running_mean \t torch.Size([100])\n",
      "gnn1_embed.bns3.running_var \t torch.Size([100])\n",
      "gnn1_embed.bns3.num_batches_tracked \t torch.Size([])\n",
      "gnn2_pool.conv1.bias \t torch.Size([8])\n",
      "gnn2_pool.conv1.lin.weight \t torch.Size([8, 8])\n",
      "gnn2_pool.bns1.weight \t torch.Size([25])\n",
      "gnn2_pool.bns1.bias \t torch.Size([25])\n",
      "gnn2_pool.bns1.running_mean \t torch.Size([25])\n",
      "gnn2_pool.bns1.running_var \t torch.Size([25])\n",
      "gnn2_pool.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn2_pool.conv2.bias \t torch.Size([8])\n",
      "gnn2_pool.conv2.lin.weight \t torch.Size([8, 8])\n",
      "gnn2_pool.bns2.weight \t torch.Size([25])\n",
      "gnn2_pool.bns2.bias \t torch.Size([25])\n",
      "gnn2_pool.bns2.running_mean \t torch.Size([25])\n",
      "gnn2_pool.bns2.running_var \t torch.Size([25])\n",
      "gnn2_pool.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn2_pool.conv3.bias \t torch.Size([10])\n",
      "gnn2_pool.conv3.lin.weight \t torch.Size([10, 8])\n",
      "gnn2_pool.bns3.weight \t torch.Size([25])\n",
      "gnn2_pool.bns3.bias \t torch.Size([25])\n",
      "gnn2_pool.bns3.running_mean \t torch.Size([25])\n",
      "gnn2_pool.bns3.running_var \t torch.Size([25])\n",
      "gnn2_pool.bns3.num_batches_tracked \t torch.Size([])\n",
      "gnn2_embed.conv1.bias \t torch.Size([12])\n",
      "gnn2_embed.conv1.lin.weight \t torch.Size([12, 8])\n",
      "gnn2_embed.bns1.weight \t torch.Size([25])\n",
      "gnn2_embed.bns1.bias \t torch.Size([25])\n",
      "gnn2_embed.bns1.running_mean \t torch.Size([25])\n",
      "gnn2_embed.bns1.running_var \t torch.Size([25])\n",
      "gnn2_embed.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn2_embed.conv2.bias \t torch.Size([12])\n",
      "gnn2_embed.conv2.lin.weight \t torch.Size([12, 12])\n",
      "gnn2_embed.bns2.weight \t torch.Size([25])\n",
      "gnn2_embed.bns2.bias \t torch.Size([25])\n",
      "gnn2_embed.bns2.running_mean \t torch.Size([25])\n",
      "gnn2_embed.bns2.running_var \t torch.Size([25])\n",
      "gnn2_embed.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn2_embed.conv3.bias \t torch.Size([16])\n",
      "gnn2_embed.conv3.lin.weight \t torch.Size([16, 12])\n",
      "gnn2_embed.bns3.weight \t torch.Size([25])\n",
      "gnn2_embed.bns3.bias \t torch.Size([25])\n",
      "gnn2_embed.bns3.running_mean \t torch.Size([25])\n",
      "gnn2_embed.bns3.running_var \t torch.Size([25])\n",
      "gnn2_embed.bns3.num_batches_tracked \t torch.Size([])\n",
      "gnn3_pool.conv1.bias \t torch.Size([16])\n",
      "gnn3_pool.conv1.lin.weight \t torch.Size([16, 16])\n",
      "gnn3_pool.bns1.weight \t torch.Size([10])\n",
      "gnn3_pool.bns1.bias \t torch.Size([10])\n",
      "gnn3_pool.bns1.running_mean \t torch.Size([10])\n",
      "gnn3_pool.bns1.running_var \t torch.Size([10])\n",
      "gnn3_pool.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn3_pool.conv2.bias \t torch.Size([16])\n",
      "gnn3_pool.conv2.lin.weight \t torch.Size([16, 16])\n",
      "gnn3_pool.bns2.weight \t torch.Size([10])\n",
      "gnn3_pool.bns2.bias \t torch.Size([10])\n",
      "gnn3_pool.bns2.running_mean \t torch.Size([10])\n",
      "gnn3_pool.bns2.running_var \t torch.Size([10])\n",
      "gnn3_pool.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn3_pool.conv3.bias \t torch.Size([1])\n",
      "gnn3_pool.conv3.lin.weight \t torch.Size([1, 16])\n",
      "gnn3_pool.bns3.weight \t torch.Size([10])\n",
      "gnn3_pool.bns3.bias \t torch.Size([10])\n",
      "gnn3_pool.bns3.running_mean \t torch.Size([10])\n",
      "gnn3_pool.bns3.running_var \t torch.Size([10])\n",
      "gnn3_pool.bns3.num_batches_tracked \t torch.Size([])\n",
      "gnn3_embed.conv1.bias \t torch.Size([16])\n",
      "gnn3_embed.conv1.lin.weight \t torch.Size([16, 16])\n",
      "gnn3_embed.bns1.weight \t torch.Size([10])\n",
      "gnn3_embed.bns1.bias \t torch.Size([10])\n",
      "gnn3_embed.bns1.running_mean \t torch.Size([10])\n",
      "gnn3_embed.bns1.running_var \t torch.Size([10])\n",
      "gnn3_embed.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn3_embed.conv2.bias \t torch.Size([16])\n",
      "gnn3_embed.conv2.lin.weight \t torch.Size([16, 16])\n",
      "gnn3_embed.bns2.weight \t torch.Size([10])\n",
      "gnn3_embed.bns2.bias \t torch.Size([10])\n",
      "gnn3_embed.bns2.running_mean \t torch.Size([10])\n",
      "gnn3_embed.bns2.running_var \t torch.Size([10])\n",
      "gnn3_embed.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn3_embed.conv3.bias \t torch.Size([32])\n",
      "gnn3_embed.conv3.lin.weight \t torch.Size([32, 16])\n",
      "gnn3_embed.bns3.weight \t torch.Size([10])\n",
      "gnn3_embed.bns3.bias \t torch.Size([10])\n",
      "gnn3_embed.bns3.running_mean \t torch.Size([10])\n",
      "gnn3_embed.bns3.running_var \t torch.Size([10])\n",
      "gnn3_embed.bns3.num_batches_tracked \t torch.Size([])\n",
      "lin1.weight \t torch.Size([64, 32])\n",
      "lin1.bias \t torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer's state_dict:\n",
      "state \t {0: {'step': tensor(11460.), 'exp_avg': tensor([ 0.0526,  0.0039,  0.0426,  0.0689,  0.0741, -0.0094, -0.1085,  0.0382,\n",
      "        -0.0392,  0.1301, -0.0260, -0.0650,  0.0367, -0.0624, -0.0166, -0.1200]), 'exp_avg_sq': tensor([3.6119, 0.4970, 0.4290, 0.8927, 2.5314, 0.5512, 3.4185, 1.1845, 1.2207,\n",
      "        1.9328, 1.0335, 2.1603, 1.8470, 0.7112, 0.8927, 2.7273])}, 1: {'step': tensor(11460.), 'exp_avg': tensor([[-0.0106, -0.0018, -0.0086],\n",
      "        [ 0.0025,  0.0002,  0.0326],\n",
      "        [-0.0149,  0.0003, -0.0337],\n",
      "        [-0.0090,  0.0043,  0.0028],\n",
      "        [-0.0013,  0.0023,  0.0073],\n",
      "        [ 0.0209,  0.0008,  0.0398],\n",
      "        [ 0.0223, -0.0042,  0.0150],\n",
      "        [-0.0126,  0.0002, -0.0233],\n",
      "        [ 0.0055, -0.0007,  0.0074],\n",
      "        [-0.0134,  0.0056, -0.0052],\n",
      "        [-0.0041, -0.0014, -0.0175],\n",
      "        [ 0.0105, -0.0017,  0.0156],\n",
      "        [-0.0019,  0.0014,  0.0148],\n",
      "        [-0.0018, -0.0017, -0.0305],\n",
      "        [ 0.0044,  0.0002,  0.0327],\n",
      "        [ 0.0034, -0.0038, -0.0492]]), 'exp_avg_sq': tensor([[3.9100e-02, 1.4952e-03, 1.9889e-01],\n",
      "        [6.6093e-03, 3.6198e-04, 2.7943e-02],\n",
      "        [1.7281e-02, 4.4114e-04, 3.9094e-02],\n",
      "        [1.4256e-02, 6.3215e-04, 3.3247e-02],\n",
      "        [1.1908e-02, 9.8124e-04, 2.6012e-01],\n",
      "        [7.5349e-03, 5.1251e-04, 6.0491e-02],\n",
      "        [3.0987e-02, 1.5612e-03, 1.8383e-01],\n",
      "        [1.6474e-02, 5.3306e-04, 3.7940e-02],\n",
      "        [2.9876e-02, 6.2766e-04, 2.0719e-02],\n",
      "        [1.2064e-02, 8.0029e-04, 1.0362e-01],\n",
      "        [6.0413e-03, 5.3481e-04, 4.6220e-02],\n",
      "        [1.7106e-02, 5.6279e-04, 3.5827e-02],\n",
      "        [3.4788e-02, 9.4326e-04, 3.6434e-02],\n",
      "        [5.8920e-03, 6.3281e-04, 1.6550e-01],\n",
      "        [5.6319e-02, 8.9705e-04, 4.7307e-02],\n",
      "        [2.0755e-02, 1.6651e-03, 4.0775e-01]])}, 2: {'step': tensor(11460.), 'exp_avg': tensor([-2.1577e-04, -1.3857e-04,  6.4679e-07,  1.0366e-04, -3.6738e-04,\n",
      "        -6.0392e-05,  5.7367e-05,  2.4601e-04,  3.5286e-05, -7.3935e-05,\n",
      "         3.8156e-04,  1.9532e-04,  1.3224e-05, -4.9836e-05, -6.3532e-05,\n",
      "        -1.2986e-04, -2.9710e-04,  2.7163e-04,  7.0734e-04, -3.2898e-05,\n",
      "         1.4842e-04,  2.1408e-04,  3.2268e-05, -1.5745e-04, -1.9877e-04,\n",
      "        -1.7751e-04, -3.0970e-04,  7.3439e-05, -2.7601e-06, -4.2482e-04,\n",
      "        -1.2766e-04,  7.8705e-05,  2.8137e-04,  8.9196e-05,  2.2848e-04,\n",
      "         3.1214e-04, -1.3890e-04,  3.3954e-04,  5.0409e-04, -1.0776e-04,\n",
      "        -5.8963e-05,  1.0389e-04,  6.9246e-05, -2.1717e-04, -1.2327e-04,\n",
      "         5.0772e-05, -1.5670e-04, -3.7870e-06, -9.3167e-05,  4.8819e-04,\n",
      "        -2.9827e-04,  9.1977e-05,  1.7327e-04,  4.1598e-04,  2.6534e-04,\n",
      "         1.9169e-04, -1.2843e-04, -3.0623e-05,  2.5972e-04,  3.1303e-04,\n",
      "         7.8195e-04, -9.9039e-05, -2.7813e-04, -1.0612e-03, -5.8883e-05,\n",
      "         2.4536e-04,  3.1634e-04, -1.9461e-04, -1.2540e-04,  2.7071e-05,\n",
      "         1.8680e-04,  2.1369e-04, -6.7276e-05,  1.3173e-04, -1.1573e-04,\n",
      "        -1.1169e-04,  1.2696e-04,  1.1391e-04, -1.0658e-04, -5.5556e-04,\n",
      "         2.1124e-04, -2.2300e-04, -2.6256e-04, -1.5050e-04, -4.2628e-04,\n",
      "        -8.7101e-04,  9.8848e-06,  4.7776e-04,  3.2883e-04,  7.3002e-05,\n",
      "         3.3156e-04, -7.6014e-06, -1.3929e-04, -3.8726e-04, -2.2401e-04,\n",
      "         1.7765e-04, -5.5697e-04, -6.4388e-04,  3.4117e-05, -2.8586e-04]), 'exp_avg_sq': tensor([1.1128e-05, 1.8476e-05, 2.2344e-05, 1.6924e-05, 1.4623e-05, 1.7275e-05,\n",
      "        1.1932e-05, 1.2322e-05, 1.0764e-05, 2.1398e-05, 2.7041e-05, 2.8864e-05,\n",
      "        2.2818e-05, 2.4854e-05, 1.6788e-05, 2.2584e-05, 2.7317e-05, 1.9899e-05,\n",
      "        1.4553e-05, 1.7499e-05, 2.8788e-05, 2.3757e-05, 2.4075e-05, 2.3882e-05,\n",
      "        5.1734e-05, 1.3841e-05, 4.2108e-05, 2.9754e-05, 2.6097e-05, 3.7636e-05,\n",
      "        1.8051e-05, 1.5263e-05, 1.3795e-05, 1.6420e-05, 3.2374e-05, 1.3656e-05,\n",
      "        3.4869e-05, 4.4260e-05, 1.1482e-05, 2.8373e-05, 2.3245e-05, 1.7793e-05,\n",
      "        3.0321e-05, 2.0377e-05, 1.5164e-05, 2.4401e-05, 2.5910e-05, 1.5660e-05,\n",
      "        1.3124e-05, 2.3988e-05, 3.0987e-05, 2.8535e-05, 1.6206e-05, 3.0857e-05,\n",
      "        2.9874e-05, 1.8548e-05, 6.6913e-05, 2.6822e-05, 2.4512e-05, 2.6426e-05,\n",
      "        1.0940e-05, 1.6798e-05, 4.5011e-05, 3.7390e-05, 2.8121e-05, 1.6158e-05,\n",
      "        1.6012e-05, 2.4457e-05, 1.7313e-05, 1.7702e-05, 3.1323e-05, 2.3903e-05,\n",
      "        2.5796e-05, 2.9149e-05, 2.3562e-05, 4.0780e-05, 1.4835e-05, 2.5725e-05,\n",
      "        1.3889e-05, 2.3048e-05, 3.6281e-05, 2.4853e-05, 2.0143e-05, 4.7796e-05,\n",
      "        2.5135e-05, 2.6760e-05, 3.9357e-05, 5.6182e-05, 1.8745e-05, 7.9679e-05,\n",
      "        3.1873e-05, 1.8742e-05, 2.9287e-05, 2.2926e-05, 3.9715e-05, 1.8051e-05,\n",
      "        4.1731e-05, 3.0816e-05, 1.5344e-05, 3.0610e-05])}, 3: {'step': tensor(11460.), 'exp_avg': tensor([ 2.3466e-04, -5.8681e-04, -7.0581e-04,  1.1118e-04, -8.0376e-04,\n",
      "        -4.0950e-04, -1.7160e-04,  1.6280e-03, -6.2654e-04, -6.5440e-04,\n",
      "         1.7487e-03, -6.0381e-04, -5.1999e-04, -4.3014e-04, -3.9908e-04,\n",
      "        -7.8076e-04,  6.0614e-04,  1.2014e-05,  1.2143e-03,  7.5858e-05,\n",
      "        -5.1990e-04, -3.5370e-04, -4.5059e-04, -4.0717e-04, -8.1084e-04,\n",
      "        -8.2601e-04, -2.9022e-04,  1.7469e-04, -6.7400e-04, -7.5617e-04,\n",
      "        -5.7496e-04, -8.5823e-04, -5.0199e-04, -1.2354e-03, -1.3678e-04,\n",
      "        -6.2111e-04, -5.5738e-04,  1.9178e-03,  3.2702e-04, -2.7387e-04,\n",
      "        -6.1080e-04, -4.0242e-04, -4.9706e-04, -1.0622e-04, -5.9342e-04,\n",
      "        -1.1784e-03, -1.6085e-04,  1.1947e-05,  1.3567e-04, -9.6900e-04,\n",
      "        -7.4150e-04,  1.9053e-04, -1.9096e-04, -3.5171e-04, -3.6381e-04,\n",
      "        -1.9037e-04, -4.9291e-04, -6.0516e-05,  2.0837e-04,  2.2287e-04,\n",
      "        -1.3464e-03, -8.0072e-04, -5.4610e-04,  7.0506e-05, -9.4318e-04,\n",
      "        -8.3328e-04, -1.1112e-04, -5.6964e-04,  5.8927e-04, -6.8673e-04,\n",
      "        -5.4000e-04, -3.7586e-04, -1.0606e-03, -5.7125e-04, -4.1159e-04,\n",
      "        -5.8094e-04, -4.7616e-04, -1.0428e-03, -4.5756e-04,  6.0456e-04,\n",
      "         3.0316e-05,  2.4372e-04, -7.1225e-04, -5.0447e-04,  7.6306e-04,\n",
      "         1.3218e-03, -8.4080e-05,  1.2133e-04,  3.9891e-04, -4.5512e-04,\n",
      "         2.6849e-04,  1.1720e-04, -6.6089e-04, -1.0456e-03, -6.6681e-04,\n",
      "        -2.8582e-04, -8.2421e-04,  8.9384e-04,  6.5570e-04, -4.3577e-04]), 'exp_avg_sq': tensor([4.8031e-05, 7.0603e-05, 7.9585e-05, 4.8471e-05, 3.8078e-05, 4.4770e-05,\n",
      "        6.8561e-05, 5.0278e-05, 6.8904e-05, 5.8828e-05, 8.4369e-05, 6.5784e-05,\n",
      "        6.3683e-05, 7.5699e-05, 5.0958e-05, 1.8869e-04, 8.8142e-05, 6.7647e-05,\n",
      "        5.5554e-05, 9.6024e-05, 1.0182e-04, 5.8777e-05, 7.7672e-05, 7.8027e-05,\n",
      "        9.7186e-05, 6.2316e-05, 1.2605e-04, 9.7844e-05, 6.0215e-05, 1.4706e-04,\n",
      "        4.4277e-05, 5.3818e-05, 4.4251e-05, 8.2371e-05, 6.7424e-05, 1.0720e-04,\n",
      "        6.8501e-05, 7.4765e-05, 5.3446e-05, 6.3213e-05, 6.2599e-05, 1.4972e-04,\n",
      "        4.5458e-05, 6.1472e-05, 7.0849e-05, 1.1255e-04, 1.0860e-04, 6.3351e-05,\n",
      "        7.1219e-05, 5.9732e-05, 7.8248e-05, 7.5216e-05, 5.1208e-05, 5.5510e-05,\n",
      "        6.2631e-05, 5.7272e-05, 1.2826e-04, 6.3309e-05, 7.2686e-05, 5.3619e-05,\n",
      "        5.5480e-05, 8.3432e-05, 8.4982e-05, 8.0945e-05, 1.3760e-04, 6.8109e-05,\n",
      "        4.0337e-05, 1.2271e-04, 4.8119e-05, 5.6103e-05, 1.1047e-04, 6.1910e-05,\n",
      "        9.6685e-05, 7.6673e-05, 7.0412e-05, 7.6650e-05, 5.6020e-05, 7.5612e-05,\n",
      "        6.1086e-05, 7.4830e-05, 1.0900e-04, 6.8762e-05, 8.3410e-05, 7.2032e-05,\n",
      "        6.8478e-05, 8.0202e-05, 7.5763e-05, 7.6790e-05, 7.4834e-05, 1.0410e-04,\n",
      "        1.0915e-04, 7.6685e-05, 9.9903e-05, 8.7917e-05, 7.9489e-05, 8.9647e-05,\n",
      "        5.3632e-05, 1.0538e-04, 6.0908e-05, 7.3920e-05])}, 4: {'step': tensor(11460.), 'exp_avg': tensor([ 0.0032, -0.0244, -0.0172,  0.0049,  0.0173, -0.0110,  0.0070,  0.0069,\n",
      "         0.0138, -0.0080, -0.0034,  0.0019,  0.0239,  0.0002, -0.0252,  0.0101]), 'exp_avg_sq': tensor([0.0189, 0.0683, 0.0470, 0.0084, 0.0387, 0.0493, 0.0125, 0.0068, 0.0289,\n",
      "        0.0096, 0.0091, 0.0183, 0.0573, 0.0132, 0.0654, 0.0163])}, 5: {'step': tensor(11460.), 'exp_avg': tensor([[-1.6827e-02, -1.8911e-02, -8.3360e-03,  1.0348e-04,  1.7556e-02,\n",
      "          1.0747e-02, -7.9809e-03,  7.0786e-03,  6.0989e-03,  2.5945e-03,\n",
      "         -6.9589e-03,  1.0917e-02,  1.3331e-02,  1.0224e-02, -1.6825e-02,\n",
      "         -3.0969e-03],\n",
      "        [-1.4265e-02, -1.0400e-02,  1.6410e-03, -2.5860e-03,  1.2339e-02,\n",
      "          3.6511e-03, -7.7996e-03,  3.1060e-04, -7.3752e-03,  9.0812e-03,\n",
      "          8.9271e-04,  9.3455e-03,  5.6323e-03,  5.5086e-04, -1.0378e-02,\n",
      "          1.0670e-02],\n",
      "        [-9.8016e-03, -8.7641e-03,  7.7792e-05, -8.0895e-04,  9.6480e-03,\n",
      "          2.7411e-03, -5.4830e-03,  1.6451e-03, -2.9625e-03,  5.9863e-03,\n",
      "         -1.2165e-03,  6.5145e-03,  4.0349e-03,  2.0665e-03, -8.5612e-03,\n",
      "          5.7268e-03],\n",
      "        [ 1.2955e-02,  1.3075e-02,  5.1771e-03,  6.1982e-04, -1.2499e-02,\n",
      "         -7.7140e-03,  6.0269e-03, -4.0971e-03, -2.6494e-03, -2.5979e-03,\n",
      "          3.7331e-03, -8.4009e-03, -9.5596e-03, -6.3346e-03,  1.1746e-02,\n",
      "          3.4574e-04],\n",
      "        [ 1.0208e-02,  8.0168e-03,  4.4289e-04,  1.5337e-03, -8.8265e-03,\n",
      "         -3.7543e-03,  5.1611e-03, -9.1189e-04,  3.0650e-03, -4.9520e-03,\n",
      "          1.8144e-04, -6.6850e-03, -5.0833e-03, -1.6999e-03,  7.7193e-03,\n",
      "         -5.3097e-03],\n",
      "        [-1.8707e-03, -1.7199e-03, -2.9058e-03,  1.2513e-04,  8.0663e-04,\n",
      "          2.7749e-03,  2.2038e-04,  7.5816e-04,  3.2548e-03, -2.1831e-03,\n",
      "         -8.4863e-04,  1.2801e-03,  2.4741e-03,  2.3692e-03, -1.2891e-03,\n",
      "         -2.7225e-03],\n",
      "        [ 2.2466e-02,  2.3830e-02,  8.6287e-03,  3.9611e-04, -2.2880e-02,\n",
      "         -1.2628e-02,  1.0962e-02, -7.9694e-03, -4.7661e-03, -5.5957e-03,\n",
      "          7.6107e-03, -1.4656e-02, -1.5881e-02, -1.1542e-02,  2.1576e-02,\n",
      "          2.2737e-04],\n",
      "        [ 1.3248e-02,  1.3439e-02,  6.1040e-03,  5.3383e-04, -1.2534e-02,\n",
      "         -8.4939e-03,  5.8208e-03, -4.3593e-03, -3.7949e-03, -1.7522e-03,\n",
      "          4.0351e-03, -8.6044e-03, -1.0241e-02, -7.0687e-03,  1.1974e-02,\n",
      "          1.4212e-03],\n",
      "        [-1.4176e-02, -1.7911e-02, -9.8388e-03,  9.1370e-04,  1.5829e-02,\n",
      "          1.0857e-02, -6.5421e-03,  7.9331e-03,  9.1164e-03,  4.6681e-05,\n",
      "         -8.1578e-03,  9.1281e-03,  1.3271e-02,  1.1202e-02, -1.5531e-02,\n",
      "         -7.0607e-03],\n",
      "        [ 1.3848e-03,  3.4784e-03,  7.2429e-03, -9.4662e-04, -1.1001e-03,\n",
      "         -5.7340e-03, -1.0708e-03, -3.0328e-03, -9.1048e-03,  6.2878e-03,\n",
      "          3.4449e-03, -7.9645e-04, -5.7000e-03, -5.7112e-03,  2.1153e-03,\n",
      "          9.7546e-03],\n",
      "        [-6.2080e-03, -5.2830e-03, -4.1777e-03, -8.2547e-04,  4.4713e-03,\n",
      "          5.4671e-03, -1.8919e-03,  1.4244e-03,  2.8536e-03, -1.3005e-03,\n",
      "         -1.0582e-03,  3.9349e-03,  6.1369e-03,  3.4179e-03, -4.3835e-03,\n",
      "         -2.3813e-03],\n",
      "        [ 5.0555e-03,  3.9323e-03,  2.6120e-03,  8.8410e-04, -3.5506e-03,\n",
      "         -3.9286e-03,  1.7126e-03, -7.5144e-04, -1.1942e-03,  3.6338e-04,\n",
      "          3.6664e-04, -3.1981e-03, -4.5196e-03, -2.0883e-03,  3.3429e-03,\n",
      "          7.9725e-04],\n",
      "        [ 4.8798e-03,  2.0386e-03, -6.0519e-03,  1.4132e-03, -4.5425e-03,\n",
      "          2.9654e-03,  4.0038e-03,  1.8683e-03,  9.4307e-03, -8.6413e-03,\n",
      "         -2.5208e-03, -3.3821e-03,  2.3302e-03,  3.6204e-03,  3.1022e-03,\n",
      "         -1.1799e-02],\n",
      "        [-6.9678e-03, -7.3794e-03, -5.2350e-03, -1.6064e-04,  6.2299e-03,\n",
      "          6.0801e-03, -2.4496e-03,  2.8226e-03,  4.4946e-03, -1.2452e-03,\n",
      "         -2.7196e-03,  4.4683e-03,  6.9233e-03,  5.0190e-03, -6.2352e-03,\n",
      "         -3.6598e-03],\n",
      "        [-5.0317e-03, -2.4751e-03,  6.6223e-03, -1.1892e-03,  5.1580e-03,\n",
      "         -3.5625e-03, -4.3815e-03, -1.6914e-03, -9.9460e-03,  9.5947e-03,\n",
      "          2.2415e-03,  3.5326e-03, -2.9272e-03, -3.6809e-03, -3.6407e-03,\n",
      "          1.2705e-02],\n",
      "        [ 4.9516e-03,  5.0318e-03, -2.0035e-03, -6.2269e-06, -6.1052e-03,\n",
      "          5.3126e-04,  3.6912e-03, -1.0274e-03,  3.4790e-03, -5.6867e-03,\n",
      "          9.7438e-04, -3.3980e-03, -2.2133e-04, -3.4390e-04,  5.2678e-03,\n",
      "         -5.6186e-03]]), 'exp_avg_sq': tensor([[8.0502e-03, 7.2965e-03, 1.1850e-02, 2.0288e-04, 6.2867e-03, 1.2386e-02,\n",
      "         1.9576e-03, 9.2616e-04, 1.2634e-02, 1.1405e-02, 9.2296e-04, 3.2648e-03,\n",
      "         1.2885e-02, 5.6769e-03, 5.4316e-03, 1.4924e-02],\n",
      "        [1.2371e-02, 1.3745e-02, 1.4704e-02, 3.0312e-04, 1.4350e-02, 1.3884e-02,\n",
      "         4.6982e-03, 1.8365e-03, 1.8094e-02, 1.9019e-02, 2.0304e-03, 5.2884e-03,\n",
      "         1.4164e-02, 7.4495e-03, 1.1953e-02, 2.3157e-02],\n",
      "        [1.9416e-02, 1.8932e-02, 1.4582e-02, 2.1924e-04, 1.4292e-02, 1.7635e-02,\n",
      "         2.9482e-03, 2.3791e-03, 1.3314e-02, 7.3326e-03, 2.3585e-03, 7.9980e-03,\n",
      "         2.0916e-02, 9.9874e-03, 1.3549e-02, 1.3258e-02],\n",
      "        [7.1150e-03, 7.9759e-03, 2.5458e-03, 4.6595e-05, 6.7756e-03, 3.7032e-03,\n",
      "         1.4151e-03, 1.0098e-03, 1.8833e-03, 1.0726e-03, 1.0218e-03, 3.0342e-03,\n",
      "         4.9266e-03, 2.7504e-03, 6.3753e-03, 1.4269e-03],\n",
      "        [1.1774e-02, 1.1518e-02, 1.3833e-02, 1.7198e-04, 8.5228e-03, 1.5011e-02,\n",
      "         1.9896e-03, 1.6222e-03, 1.4037e-02, 9.7534e-03, 1.6345e-03, 4.8205e-03,\n",
      "         1.6519e-02, 8.0042e-03, 8.1405e-03, 1.5331e-02],\n",
      "        [1.9996e-02, 2.0769e-02, 1.6726e-02, 2.0368e-04, 1.6649e-02, 1.8447e-02,\n",
      "         3.9104e-03, 2.7789e-03, 1.7754e-02, 1.1312e-02, 2.8880e-03, 8.3163e-03,\n",
      "         2.1244e-02, 1.1498e-02, 1.5339e-02, 1.7909e-02],\n",
      "        [2.0095e-02, 2.3858e-02, 6.2228e-03, 7.2847e-05, 2.0318e-02, 9.1702e-03,\n",
      "         4.1424e-03, 3.1719e-03, 4.5853e-03, 1.9274e-03, 3.3068e-03, 8.6340e-03,\n",
      "         1.2648e-02, 7.9334e-03, 1.9089e-02, 2.6494e-03],\n",
      "        [8.1386e-03, 8.2838e-03, 4.7399e-03, 6.3223e-05, 6.1820e-03, 6.2013e-03,\n",
      "         1.1278e-03, 1.0582e-03, 3.8920e-03, 1.5200e-03, 1.0494e-03, 3.4027e-03,\n",
      "         7.6421e-03, 3.9362e-03, 6.1085e-03, 3.1520e-03],\n",
      "        [3.6277e-02, 3.9902e-02, 1.6240e-02, 1.9401e-04, 3.3243e-02, 2.2127e-02,\n",
      "         6.9886e-03, 5.0315e-03, 1.3024e-02, 6.5376e-03, 5.0319e-03, 1.5155e-02,\n",
      "         2.9113e-02, 1.4890e-02, 3.0408e-02, 1.1192e-02],\n",
      "        [6.2614e-03, 6.7431e-03, 7.4629e-03, 6.8905e-05, 4.7548e-03, 7.9727e-03,\n",
      "         9.8857e-04, 1.0713e-03, 7.7263e-03, 4.7533e-03, 1.1153e-03, 2.5748e-03,\n",
      "         8.8159e-03, 4.7557e-03, 4.7338e-03, 7.7545e-03],\n",
      "        [5.3175e-03, 6.4929e-03, 4.6044e-03, 7.5534e-05, 7.3318e-03, 4.1676e-03,\n",
      "         2.3932e-03, 7.8757e-04, 6.1162e-03, 7.5124e-03, 8.6369e-04, 2.3016e-03,\n",
      "         4.2945e-03, 2.4773e-03, 5.8623e-03, 8.0620e-03],\n",
      "        [8.0620e-03, 9.1221e-03, 5.2159e-03, 6.2856e-05, 6.8314e-03, 6.1517e-03,\n",
      "         1.2620e-03, 1.3568e-03, 5.1427e-03, 1.8417e-03, 1.4681e-03, 3.4013e-03,\n",
      "         7.4786e-03, 4.6362e-03, 6.7172e-03, 4.0547e-03],\n",
      "        [6.0649e-02, 6.3909e-02, 3.9479e-02, 2.8940e-04, 4.4433e-02, 5.0634e-02,\n",
      "         6.8612e-03, 8.8083e-03, 3.1822e-02, 7.6595e-03, 8.8523e-03, 2.5153e-02,\n",
      "         6.2496e-02, 3.2622e-02, 4.4937e-02, 2.4457e-02],\n",
      "        [1.2806e-02, 1.5241e-02, 5.8800e-03, 7.7621e-05, 1.4528e-02, 7.0897e-03,\n",
      "         3.6591e-03, 1.8838e-03, 5.8504e-03, 6.3282e-03, 1.9757e-03, 5.4875e-03,\n",
      "         8.8001e-03, 4.9227e-03, 1.2601e-02, 6.6595e-03],\n",
      "        [2.2553e-02, 2.4010e-02, 1.8506e-02, 2.6459e-04, 1.9861e-02, 2.1015e-02,\n",
      "         4.6358e-03, 3.1727e-03, 1.8121e-02, 1.3561e-02, 3.2880e-03, 9.4125e-03,\n",
      "         2.4350e-02, 1.2050e-02, 1.8226e-02, 2.0169e-02],\n",
      "        [6.0303e-03, 6.0602e-03, 7.7405e-03, 1.4231e-04, 5.9313e-03, 7.9952e-03,\n",
      "         1.8798e-03, 7.3496e-04, 8.4242e-03, 8.9228e-03, 7.4384e-04, 2.5246e-03,\n",
      "         8.2337e-03, 3.7175e-03, 5.0430e-03, 1.0492e-02]])}, 6: {'step': tensor(11460.), 'exp_avg': tensor([-3.1621e-05, -3.8777e-05, -3.4051e-04,  1.1456e-04, -3.1115e-04,\n",
      "        -2.0422e-04,  7.6440e-05,  4.7017e-04, -2.6059e-05, -2.0409e-05,\n",
      "         5.3608e-04, -2.1971e-05, -8.5583e-05, -3.7326e-05, -2.7158e-05,\n",
      "        -1.1626e-04,  9.8800e-05,  2.5347e-04,  1.0059e-03, -1.1720e-05,\n",
      "         1.6171e-05,  2.5416e-04,  4.3578e-05, -8.7250e-05, -4.5710e-04,\n",
      "        -1.0274e-04, -7.7077e-06,  8.5940e-05,  3.3303e-06, -1.8703e-04,\n",
      "        -3.9923e-04, -7.3045e-05,  1.0678e-04,  7.3963e-05,  4.9123e-04,\n",
      "         2.2310e-04, -1.6866e-04,  4.4951e-04,  7.0508e-04,  7.2790e-05,\n",
      "         4.1284e-05,  4.4034e-04, -4.0520e-05, -1.5153e-04, -5.2599e-05,\n",
      "         9.5171e-05, -1.7331e-04,  6.4005e-05, -2.1763e-05,  2.1240e-04,\n",
      "        -1.0800e-04,  6.4366e-05,  6.1417e-05,  2.5795e-04,  4.0404e-04,\n",
      "         7.7701e-05, -1.0129e-04,  2.2090e-06,  1.9164e-04,  5.1124e-04,\n",
      "         5.5849e-04, -1.0006e-04, -2.9700e-04, -9.8336e-04, -4.9378e-05,\n",
      "         1.7514e-04,  2.8148e-04, -2.9123e-04, -4.9087e-05, -7.4722e-06,\n",
      "         1.2248e-04,  8.4746e-05,  8.9624e-05,  2.5080e-05, -1.6709e-04,\n",
      "        -1.1449e-04, -2.1790e-05,  3.7589e-05, -2.4630e-04, -7.2517e-04,\n",
      "        -6.1404e-05, -2.1467e-04, -2.9609e-04, -9.7949e-05, -8.7540e-05,\n",
      "        -9.3908e-04, -1.1578e-04,  3.6501e-04,  2.0836e-04,  1.3568e-04,\n",
      "         9.8512e-05, -1.5004e-04,  2.2235e-05, -3.4121e-04, -2.1496e-06,\n",
      "         2.7874e-04, -6.6498e-04, -7.4412e-04, -7.3481e-05, -1.7278e-04]), 'exp_avg_sq': tensor([8.8546e-06, 1.9509e-05, 2.5562e-05, 1.5136e-05, 1.0658e-05, 1.9329e-05,\n",
      "        1.4514e-05, 2.1742e-05, 1.1687e-05, 1.6207e-05, 2.2373e-05, 2.5174e-05,\n",
      "        1.6756e-05, 1.8353e-05, 1.3845e-05, 4.2689e-05, 1.9677e-05, 1.4434e-05,\n",
      "        1.8565e-05, 2.3270e-05, 3.6666e-05, 1.8543e-05, 2.4242e-05, 2.7749e-05,\n",
      "        1.4148e-05, 1.6980e-05, 1.6643e-05, 2.1840e-05, 2.3894e-05, 3.4114e-05,\n",
      "        1.7643e-05, 1.3893e-05, 1.0600e-05, 2.6096e-05, 2.7113e-05, 1.3712e-05,\n",
      "        1.9799e-05, 2.3328e-05, 1.4615e-05, 1.7596e-05, 2.5589e-05, 1.8017e-05,\n",
      "        1.5924e-05, 2.0085e-05, 1.8329e-05, 2.0589e-05, 3.2890e-05, 1.5138e-05,\n",
      "        8.8244e-06, 1.6905e-05, 2.3594e-05, 1.9592e-05, 1.7038e-05, 1.7112e-05,\n",
      "        2.1105e-05, 1.3209e-05, 3.6902e-05, 2.2704e-05, 1.8222e-05, 1.9088e-05,\n",
      "        9.7364e-06, 2.5863e-05, 3.5300e-05, 2.9284e-05, 3.4886e-05, 1.7972e-05,\n",
      "        1.2319e-05, 2.0807e-05, 1.5820e-05, 2.3039e-05, 1.6604e-05, 2.0174e-05,\n",
      "        2.6086e-05, 2.9549e-05, 2.1029e-05, 2.9892e-05, 1.8138e-05, 2.8355e-05,\n",
      "        2.1069e-05, 1.9270e-05, 3.5348e-05, 1.9372e-05, 2.5544e-05, 2.6075e-05,\n",
      "        1.7788e-05, 1.8742e-05, 1.7991e-05, 2.1043e-05, 1.9073e-05, 5.7383e-05,\n",
      "        2.3418e-05, 1.8052e-05, 2.6627e-05, 2.2021e-05, 2.5620e-05, 1.8081e-05,\n",
      "        4.6157e-05, 2.6030e-05, 1.3694e-05, 2.0694e-05])}, 7: {'step': tensor(11460.), 'exp_avg': tensor([ 2.6481e-04,  8.0153e-04,  7.3165e-04,  3.7465e-04,  6.4279e-04,\n",
      "         3.0591e-04,  1.1476e-04, -1.0666e-03,  6.9252e-04,  4.5083e-04,\n",
      "        -1.6283e-03,  1.3690e-03,  7.9367e-04,  9.0908e-04,  5.4091e-04,\n",
      "         5.3112e-04,  2.7691e-04,  2.6266e-04, -8.2745e-04, -2.0250e-04,\n",
      "         1.0060e-03, -3.1070e-05,  1.1450e-03,  9.6036e-04,  5.3076e-04,\n",
      "         6.5250e-04,  7.4431e-04, -7.2136e-05,  1.3182e-03,  1.2379e-03,\n",
      "         1.1131e-03,  7.3271e-04,  1.3861e-04,  6.9836e-04,  6.8816e-05,\n",
      "         9.4236e-04,  7.8502e-04, -1.3963e-03, -5.3748e-04,  1.0415e-03,\n",
      "         3.9805e-04,  8.9831e-04,  2.0277e-04,  5.0795e-04,  6.7783e-04,\n",
      "         8.7327e-04,  3.6852e-04, -1.5820e-04,  1.1700e-03,  1.2433e-03,\n",
      "         7.2049e-04,  9.9097e-05,  2.0380e-04, -4.9441e-05,  2.5750e-04,\n",
      "         5.0800e-04,  1.0004e-03, -7.4728e-05, -1.0167e-04, -1.0910e-04,\n",
      "         1.0293e-03,  6.3742e-04,  7.5793e-04, -4.1338e-06,  5.7838e-04,\n",
      "         7.2554e-04, -1.9806e-04,  1.0859e-03,  6.2437e-05,  1.0097e-03,\n",
      "         5.1574e-04,  7.8566e-04,  1.0125e-03,  1.1924e-03,  1.2756e-03,\n",
      "         8.6829e-04,  4.6377e-04,  3.6281e-04,  5.5326e-04, -4.0998e-04,\n",
      "        -8.2438e-05,  2.0005e-04,  1.0115e-03,  9.1215e-04, -1.4736e-04,\n",
      "        -6.7885e-04, -7.5926e-05, -1.4506e-05,  8.9028e-04,  1.0407e-03,\n",
      "        -4.1041e-05, -8.2171e-05,  4.6100e-04,  7.8176e-04,  1.0747e-03,\n",
      "         3.9807e-04,  2.8400e-04, -6.2884e-04, -3.3552e-04,  8.4369e-04]), 'exp_avg_sq': tensor([4.9394e-05, 5.0508e-05, 6.7911e-05, 8.2231e-05, 5.0117e-05, 4.7578e-05,\n",
      "        6.2751e-05, 6.3551e-05, 4.7928e-05, 5.4894e-05, 9.8714e-05, 6.8630e-05,\n",
      "        6.9841e-05, 4.1662e-05, 4.0498e-05, 7.6823e-05, 7.0777e-05, 5.5475e-05,\n",
      "        4.3512e-05, 7.9243e-05, 7.4689e-05, 4.6858e-05, 6.9570e-05, 5.7799e-05,\n",
      "        8.2236e-05, 4.7045e-05, 6.3373e-05, 5.4379e-05, 5.5613e-05, 8.4778e-05,\n",
      "        5.7879e-05, 5.1796e-05, 4.4041e-05, 4.7155e-05, 4.8451e-05, 5.7387e-05,\n",
      "        5.1179e-05, 7.1590e-05, 3.7962e-05, 4.5574e-05, 7.8715e-05, 8.3471e-05,\n",
      "        6.2201e-05, 4.6050e-05, 4.0427e-05, 7.5698e-05, 7.4762e-05, 6.6282e-05,\n",
      "        5.8347e-05, 8.4713e-05, 6.6123e-05, 4.7225e-05, 5.6101e-05, 5.2788e-05,\n",
      "        6.2247e-05, 4.6097e-05, 6.4744e-05, 6.3007e-05, 6.6322e-05, 5.4645e-05,\n",
      "        5.9967e-05, 5.8564e-05, 8.6294e-05, 6.9729e-05, 7.9331e-05, 4.8165e-05,\n",
      "        5.4260e-05, 4.8717e-05, 7.8703e-05, 5.3403e-05, 5.7354e-05, 5.7311e-05,\n",
      "        6.6583e-05, 5.0038e-05, 7.7661e-05, 5.3604e-05, 4.7156e-05, 5.1054e-05,\n",
      "        6.3416e-05, 8.0328e-05, 8.2286e-05, 5.0432e-05, 7.6349e-05, 5.3683e-05,\n",
      "        7.1725e-05, 4.9028e-05, 6.5144e-05, 4.5002e-05, 5.6942e-05, 7.7624e-05,\n",
      "        8.0327e-05, 8.6946e-05, 9.8909e-05, 9.2044e-05, 4.9241e-05, 5.7643e-05,\n",
      "        6.4388e-05, 6.6417e-05, 6.7875e-05, 6.1315e-05])}, 8: {'step': tensor(11460.), 'exp_avg': tensor([-0.0002, -0.0036,  0.0004, -0.0015,  0.0100, -0.0029,  0.0061, -0.0020,\n",
      "         0.0002,  0.0090, -0.0297,  0.0010,  0.0013,  0.0028,  0.0086, -0.0042,\n",
      "        -0.0040, -0.0034,  0.0018,  0.0033,  0.0293, -0.0098, -0.0031, -0.0035,\n",
      "        -0.0059]), 'exp_avg_sq': tensor([0.0007, 0.0015, 0.0004, 0.0003, 0.0037, 0.0012, 0.0439, 0.0005, 0.0778,\n",
      "        0.0086, 0.0541, 0.0003, 0.0008, 0.0011, 0.0024, 0.0086, 0.0004, 0.0039,\n",
      "        0.0013, 0.0326, 0.0950, 0.0070, 0.0004, 0.0033, 0.0022])}, 9: {'step': tensor(11460.), 'exp_avg': tensor([[-4.5418e-03,  1.6032e-03,  1.3012e-03, -1.3265e-03, -2.6383e-03,\n",
      "          7.0720e-04,  1.8339e-03, -1.8457e-03,  2.8240e-03, -2.5189e-03,\n",
      "          4.1649e-03, -2.2845e-03, -4.0918e-04, -2.6601e-04,  1.8629e-03,\n",
      "          1.4942e-03],\n",
      "        [-2.7696e-04, -1.2552e-03,  3.9700e-04,  4.4927e-03,  9.9799e-04,\n",
      "         -2.0726e-03,  1.3152e-03,  8.6752e-04, -2.2428e-03, -4.0577e-04,\n",
      "         -3.0832e-04,  3.6351e-03,  6.8931e-04, -3.9982e-03, -1.0321e-03,\n",
      "         -8.7742e-04],\n",
      "        [-3.3241e-04, -4.7303e-04,  1.0464e-04,  1.7447e-03,  4.7343e-04,\n",
      "         -9.6577e-04,  6.4196e-04,  4.3127e-04, -7.9134e-04, -1.8125e-04,\n",
      "          2.1706e-07,  1.2401e-03,  4.3353e-04, -1.5774e-03, -5.6010e-04,\n",
      "         -1.8816e-04],\n",
      "        [-9.6833e-04, -3.0153e-04,  5.0450e-04,  2.3094e-03, -9.4742e-05,\n",
      "         -9.8631e-04,  1.0745e-03, -4.6978e-06, -6.9116e-04, -8.7210e-04,\n",
      "          7.4366e-04,  1.5229e-03,  3.5311e-04, -2.3089e-03, -1.4383e-04,\n",
      "         -1.6585e-04],\n",
      "        [-1.5730e-02,  5.4265e-03,  3.3989e-03, -6.7951e-03, -7.6157e-03,\n",
      "          2.1383e-03,  5.9096e-03, -5.0562e-03,  1.0497e-02, -7.1649e-03,\n",
      "          1.3507e-02, -9.9407e-03, -7.2814e-04,  1.2788e-03,  5.0322e-03,\n",
      "          5.9911e-03],\n",
      "        [-4.6817e-03,  7.0177e-04,  1.3130e-03,  1.1048e-03, -1.5927e-03,\n",
      "         -7.0353e-04,  2.5605e-03, -9.3214e-04,  1.4780e-03, -2.3470e-03,\n",
      "          3.6617e-03, -2.7240e-04,  1.4528e-04, -2.3845e-03,  8.6338e-04,\n",
      "          1.0458e-03],\n",
      "        [-2.0419e-02,  5.4055e-03,  3.7878e-03, -7.8859e-03, -7.3449e-03,\n",
      "          1.4300e-03,  7.9099e-03, -4.3313e-03,  1.2332e-02, -7.3079e-03,\n",
      "          1.5598e-02, -1.1044e-02, -7.3681e-04,  8.9856e-04,  4.7704e-03,\n",
      "          7.0531e-03],\n",
      "        [-3.2842e-03,  2.9253e-04,  1.0107e-03,  1.6217e-03, -1.0002e-03,\n",
      "         -8.3985e-04,  2.0178e-03, -5.5936e-04,  6.2053e-04, -1.7792e-03,\n",
      "          2.5397e-03,  4.7247e-04,  2.2129e-04, -2.4122e-03,  4.6538e-04,\n",
      "          5.6574e-04],\n",
      "        [ 2.5567e-03, -2.9375e-03, -4.4153e-04,  8.0699e-03,  3.5347e-03,\n",
      "         -4.1140e-03,  9.7688e-04,  2.7739e-03, -5.3815e-03,  1.0365e-03,\n",
      "         -3.2258e-03,  6.8913e-03,  1.7920e-03, -6.1464e-03, -3.3085e-03,\n",
      "         -2.0213e-03],\n",
      "        [ 2.6296e-03,  4.2642e-03, -1.4382e-03, -1.5476e-02, -3.5886e-03,\n",
      "          7.7267e-03, -5.3841e-03, -3.2836e-03,  7.1481e-03,  1.6812e-03,\n",
      "          1.3936e-04, -1.2035e-02, -2.7694e-03,  1.4181e-02,  3.9150e-03,\n",
      "          2.4532e-03],\n",
      "        [ 4.6615e-02, -1.7339e-02, -9.6120e-03,  2.5837e-02,  2.3558e-02,\n",
      "         -8.9906e-03, -1.5991e-02,  1.5805e-02, -3.3814e-02,  2.0334e-02,\n",
      "         -4.0143e-02,  3.3550e-02,  3.4392e-03, -8.6951e-03, -1.6241e-02,\n",
      "         -1.8581e-02],\n",
      "        [-2.2863e-03,  9.5365e-04,  6.4089e-04, -9.1283e-04, -1.4715e-03,\n",
      "          4.7458e-04,  8.6590e-04, -1.0547e-03,  1.5944e-03, -1.3597e-03,\n",
      "          2.2247e-03, -1.4668e-03, -1.8149e-04,  9.4587e-05,  1.0192e-03,\n",
      "          8.6904e-04],\n",
      "        [ 1.8408e-04, -4.5290e-04, -3.6889e-05,  1.4605e-03,  5.3731e-04,\n",
      "         -7.9226e-04,  3.1833e-04,  4.3644e-04, -8.3910e-04,  1.0779e-05,\n",
      "         -3.1501e-04,  1.0791e-03,  4.1139e-04, -1.1688e-03, -5.7725e-04,\n",
      "         -2.4027e-04],\n",
      "        [-2.5987e-03,  1.3452e-03,  6.0680e-04, -2.0226e-03, -1.8219e-03,\n",
      "          9.2406e-04,  7.3490e-04, -1.3237e-03,  2.3138e-03, -1.4295e-03,\n",
      "          2.6001e-03, -2.5121e-03, -2.9518e-04,  9.8461e-04,  1.3015e-03,\n",
      "          1.2259e-03],\n",
      "        [-1.5000e-02,  8.2414e-03,  4.0202e-03, -1.2456e-02, -1.1699e-02,\n",
      "          6.4785e-03,  3.9272e-03, -8.6552e-03,  1.3919e-02, -8.7533e-03,\n",
      "          1.5528e-02, -1.4656e-02, -2.6248e-03,  6.1528e-03,  8.8325e-03,\n",
      "          6.8302e-03],\n",
      "        [-3.2516e-03, -1.5776e-04,  7.9324e-04,  1.7715e-03, -2.4414e-04,\n",
      "         -1.2130e-03,  2.0480e-03,  1.0264e-04,  2.8695e-04, -1.1285e-03,\n",
      "          1.9247e-03,  9.1389e-04,  2.7277e-04, -2.5226e-03, -7.4020e-05,\n",
      "          3.9882e-04],\n",
      "        [-1.2532e-03, -1.5738e-05,  1.3209e-03,  4.0381e-03, -1.3516e-03,\n",
      "         -9.2917e-04,  1.5997e-03, -1.0901e-03, -1.0380e-03, -2.3759e-03,\n",
      "          1.8522e-03,  2.6559e-03,  1.6315e-04, -4.0291e-03,  8.2002e-04,\n",
      "         -4.7705e-04],\n",
      "        [ 2.4924e-03, -1.4860e-03, -6.3211e-04,  2.1571e-03,  2.0156e-03,\n",
      "         -1.0631e-03, -6.4235e-04,  1.5037e-03, -2.4255e-03,  1.5737e-03,\n",
      "         -2.7165e-03,  2.7050e-03,  2.9219e-04, -1.1308e-03, -1.4367e-03,\n",
      "         -1.2772e-03],\n",
      "        [-1.4835e-03,  4.6070e-04,  5.7509e-04,  6.1181e-04, -9.5731e-04,\n",
      "         -1.4004e-04,  8.8219e-04, -7.0016e-04,  5.1988e-04, -1.2614e-03,\n",
      "          1.5774e-03, -1.5938e-04,  1.1210e-04, -9.7705e-04,  5.4525e-04,\n",
      "          4.0421e-04],\n",
      "        [ 1.6536e-03,  2.2140e-04, -9.1693e-04, -3.2537e-03,  5.4996e-04,\n",
      "          1.2384e-03, -1.6369e-03,  3.3945e-04,  7.6241e-04,  1.5975e-03,\n",
      "         -1.4782e-03, -2.0534e-03, -3.9621e-04,  3.3767e-03, -1.2754e-04,\n",
      "          1.6893e-04],\n",
      "        [ 3.5822e-02, -4.1143e-03, -1.2587e-02, -2.0147e-02,  1.3763e-02,\n",
      "          8.3928e-03, -2.2513e-02,  8.6037e-03, -6.4599e-03,  2.2307e-02,\n",
      "         -2.9792e-02, -6.7155e-03, -1.7952e-03,  2.8750e-02, -7.3814e-03,\n",
      "         -5.6264e-03],\n",
      "        [-1.5032e-02,  2.0961e-03,  4.6709e-03,  5.5069e-03, -5.4723e-03,\n",
      "         -2.7344e-03,  8.7068e-03, -3.3237e-03,  3.9807e-03, -8.3669e-03,\n",
      "          1.2153e-02,  5.3920e-04,  6.0641e-04, -9.4118e-03,  2.9573e-03,\n",
      "          2.9885e-03],\n",
      "        [-2.5505e-03,  3.2399e-04,  1.2304e-03,  2.4367e-03, -1.4191e-03,\n",
      "         -6.9020e-04,  1.8386e-03, -1.0059e-03,  1.2705e-04, -2.2097e-03,\n",
      "          2.4852e-03,  1.1834e-03,  1.0402e-04, -2.9707e-03,  8.4422e-04,\n",
      "          1.9228e-04],\n",
      "        [ 4.8156e-04, -1.1462e-03, -1.0156e-04,  2.5234e-03,  1.3327e-03,\n",
      "         -1.3530e-03,  4.3579e-04,  1.1032e-03, -1.7259e-03,  5.6994e-04,\n",
      "         -1.1226e-03,  2.4464e-03,  3.9420e-04, -2.0450e-03, -1.0877e-03,\n",
      "         -7.6929e-04],\n",
      "        [ 1.2556e-03, -1.6569e-03,  9.0031e-05,  4.5893e-03,  1.5490e-03,\n",
      "         -1.9227e-03,  5.6994e-04,  1.1998e-03, -2.9951e-03,  3.5154e-04,\n",
      "         -1.5976e-03,  4.3054e-03,  5.0650e-04, -3.6722e-03, -1.2591e-03,\n",
      "         -1.4567e-03]]), 'exp_avg_sq': tensor([[5.2627e-03, 5.0626e-04, 3.2465e-04, 8.5923e-04, 1.4245e-03, 3.0090e-04,\n",
      "         1.1060e-03, 6.6243e-04, 1.8652e-03, 1.5131e-03, 4.2179e-03, 1.5201e-03,\n",
      "         3.5976e-05, 7.4414e-04, 6.5240e-04, 6.0716e-04],\n",
      "        [6.4677e-03, 5.2164e-04, 3.2765e-04, 1.7250e-03, 1.2853e-03, 7.7681e-04,\n",
      "         1.6148e-03, 6.2016e-04, 1.9375e-03, 1.3892e-03, 4.2444e-03, 1.6824e-03,\n",
      "         1.5052e-04, 1.7677e-03, 7.0870e-04, 6.5279e-04],\n",
      "        [6.4111e-03, 2.2733e-04, 3.1326e-04, 5.6245e-04, 7.3955e-04, 3.4394e-04,\n",
      "         1.6678e-03, 2.5340e-04, 1.2517e-03, 1.3476e-03, 4.0068e-03, 6.2311e-04,\n",
      "         6.8399e-05, 1.2503e-03, 2.3444e-04, 5.6848e-04],\n",
      "        [4.0207e-03, 1.6913e-04, 1.9276e-04, 4.0500e-04, 5.1312e-04, 2.3119e-04,\n",
      "         1.0214e-03, 1.9046e-04, 8.6737e-04, 8.4217e-04, 2.5495e-03, 4.9414e-04,\n",
      "         4.4837e-05, 7.5551e-04, 1.9162e-04, 3.7128e-04],\n",
      "        [7.9281e-03, 4.9223e-04, 3.3467e-04, 2.5105e-03, 1.0975e-03, 1.1115e-03,\n",
      "         2.2240e-03, 5.3212e-04, 2.0130e-03, 1.4723e-03, 4.7026e-03, 2.0134e-03,\n",
      "         1.9785e-04, 2.8257e-03, 5.8643e-04, 7.5364e-04],\n",
      "        [6.5758e-03, 3.2401e-04, 3.5498e-04, 6.1149e-04, 1.0500e-03, 2.6855e-04,\n",
      "         1.6068e-03, 4.0050e-04, 1.5868e-03, 1.6384e-03, 4.6072e-03, 9.4569e-04,\n",
      "         4.5355e-05, 1.1216e-03, 3.6902e-04, 6.4282e-04],\n",
      "        [1.3357e-01, 4.0171e-03, 4.7797e-03, 6.9003e-02, 5.8504e-03, 4.1538e-02,\n",
      "         5.8412e-02, 5.7437e-03, 7.4893e-03, 1.6745e-02, 5.0421e-02, 1.9627e-02,\n",
      "         7.6739e-03, 1.0035e-01, 8.6567e-03, 5.5966e-03],\n",
      "        [4.1025e-03, 1.6976e-04, 2.2217e-04, 4.1336e-04, 5.6381e-04, 2.1262e-04,\n",
      "         1.0793e-03, 2.0982e-04, 8.3158e-04, 9.5105e-04, 2.6799e-03, 4.5809e-04,\n",
      "         3.8858e-05, 8.5467e-04, 1.9720e-04, 3.5923e-04],\n",
      "        [1.6012e-02, 2.3412e-02, 4.8950e-04, 1.7086e-01, 3.4764e-02, 7.0789e-02,\n",
      "         2.3069e-02, 2.7125e-02, 4.5156e-02, 2.5831e-03, 1.0178e-02, 1.0164e-01,\n",
      "         1.3125e-02, 1.3407e-01, 3.8099e-02, 3.7437e-03],\n",
      "        [1.2884e-02, 1.1248e-03, 7.0553e-04, 5.1522e-03, 2.6581e-03, 2.2658e-03,\n",
      "         3.9375e-03, 1.4128e-03, 3.4309e-03, 3.1796e-03, 8.5882e-03, 3.9484e-03,\n",
      "         3.8789e-04, 5.7829e-03, 1.4533e-03, 1.2194e-03],\n",
      "        [5.8946e-02, 9.7672e-03, 3.3267e-03, 3.0190e-02, 2.1240e-02, 1.0200e-02,\n",
      "         1.2369e-02, 1.1378e-02, 3.0070e-02, 1.6002e-02, 4.8381e-02, 3.5202e-02,\n",
      "         1.4280e-03, 1.9278e-02, 1.2197e-02, 8.3391e-03],\n",
      "        [4.5635e-03, 2.6809e-04, 2.3960e-04, 3.3479e-04, 7.9782e-04, 1.4480e-04,\n",
      "         1.0195e-03, 3.1001e-04, 1.2382e-03, 1.1008e-03, 3.2546e-03, 7.6178e-04,\n",
      "         2.6166e-05, 5.2929e-04, 2.9083e-04, 4.7748e-04],\n",
      "        [7.0160e-03, 3.3678e-04, 3.5266e-04, 9.0290e-04, 9.8663e-04, 4.3369e-04,\n",
      "         1.7910e-03, 3.7993e-04, 1.5890e-03, 1.5446e-03, 4.5573e-03, 1.0028e-03,\n",
      "         8.5833e-05, 1.4420e-03, 3.7046e-04, 6.5338e-04],\n",
      "        [1.0007e-02, 4.2415e-04, 4.7125e-04, 7.0290e-04, 1.3203e-03, 3.9771e-04,\n",
      "         2.3771e-03, 4.7815e-04, 2.3664e-03, 2.1255e-03, 6.6295e-03, 1.3582e-03,\n",
      "         7.7269e-05, 1.3893e-03, 4.3514e-04, 1.0043e-03],\n",
      "        [7.7961e-03, 8.7594e-04, 4.1143e-04, 2.4443e-03, 2.0481e-03, 8.3634e-04,\n",
      "         1.6450e-03, 9.9295e-04, 3.1522e-03, 1.9174e-03, 5.9399e-03, 3.0931e-03,\n",
      "         1.3449e-04, 1.7554e-03, 1.0584e-03, 9.7664e-04],\n",
      "        [2.9671e-02, 7.2571e-04, 9.5180e-04, 2.4576e-03, 2.0625e-03, 2.4262e-03,\n",
      "         7.8703e-03, 9.0455e-04, 5.0142e-03, 4.0361e-03, 1.4738e-02, 2.5930e-03,\n",
      "         3.8615e-04, 5.6797e-03, 9.1480e-04, 2.4805e-03],\n",
      "        [3.7845e-03, 1.8963e-04, 2.0586e-04, 3.7916e-04, 5.9242e-04, 2.3832e-04,\n",
      "         9.6834e-04, 2.5422e-04, 8.0910e-04, 8.4485e-04, 2.4143e-03, 4.6177e-04,\n",
      "         4.6619e-05, 7.2919e-04, 2.5427e-04, 3.3443e-04],\n",
      "        [1.1971e-02, 4.5333e-04, 6.1098e-04, 1.3583e-03, 1.4814e-03, 6.9944e-04,\n",
      "         3.2003e-03, 5.1842e-04, 2.3859e-03, 2.6919e-03, 7.6606e-03, 1.3043e-03,\n",
      "         1.2972e-04, 2.6948e-03, 5.0203e-04, 1.0571e-03],\n",
      "        [5.6811e-03, 2.2083e-04, 2.6668e-04, 1.1447e-03, 6.3254e-04, 6.1557e-04,\n",
      "         1.6740e-03, 2.6091e-04, 1.0424e-03, 1.1545e-03, 3.3871e-03, 7.6601e-04,\n",
      "         1.1599e-04, 1.8175e-03, 2.7035e-04, 4.6878e-04],\n",
      "        [6.1463e-02, 9.5506e-04, 3.4777e-03, 4.5237e-02, 1.9634e-03, 1.9766e-02,\n",
      "         3.0101e-02, 9.9141e-04, 1.9752e-03, 1.5074e-02, 3.1593e-02, 9.1247e-03,\n",
      "         4.2615e-03, 6.2000e-02, 1.9938e-03, 2.4510e-03],\n",
      "        [4.0730e-01, 5.9818e-03, 1.9598e-02, 4.4047e-02, 2.6730e-02, 3.1087e-02,\n",
      "         1.2540e-01, 6.9617e-03, 4.6205e-02, 7.7946e-02, 2.2301e-01, 1.4060e-02,\n",
      "         5.5741e-03, 1.2067e-01, 6.5017e-03, 2.8046e-02],\n",
      "        [2.1943e-02, 6.7292e-04, 1.1495e-03, 3.3305e-03, 2.1777e-03, 1.8033e-03,\n",
      "         6.5770e-03, 7.6704e-04, 3.2879e-03, 4.4090e-03, 1.2498e-02, 1.8301e-03,\n",
      "         3.0262e-04, 6.6486e-03, 8.0930e-04, 1.5944e-03],\n",
      "        [5.9865e-03, 1.8350e-04, 2.9376e-04, 4.2748e-04, 6.3717e-04, 2.9072e-04,\n",
      "         1.5886e-03, 2.0999e-04, 1.0824e-03, 1.2308e-03, 3.6713e-03, 4.9488e-04,\n",
      "         5.2940e-05, 1.1595e-03, 1.9628e-04, 5.0965e-04],\n",
      "        [1.0881e-02, 5.0996e-04, 5.6157e-04, 1.7164e-03, 1.5176e-03, 8.1023e-04,\n",
      "         2.9060e-03, 5.8494e-04, 2.3941e-03, 2.4624e-03, 7.0501e-03, 1.5642e-03,\n",
      "         1.5340e-04, 2.7178e-03, 6.0879e-04, 9.8454e-04],\n",
      "        [1.0013e-02, 4.0618e-04, 5.0671e-04, 1.0130e-03, 1.3009e-03, 4.6516e-04,\n",
      "         2.5318e-03, 4.5772e-04, 2.2083e-03, 2.2305e-03, 6.5401e-03, 1.2788e-03,\n",
      "         8.4544e-05, 1.9092e-03, 4.3489e-04, 9.3157e-04]])}, 10: {'step': tensor(11460.), 'exp_avg': tensor([-4.6392e-05, -1.3804e-04, -3.9424e-04,  8.0133e-04, -9.0499e-04,\n",
      "        -6.3659e-04,  1.1844e-03,  1.0423e-03, -4.6857e-04,  2.5932e-04,\n",
      "         7.1311e-04, -7.4718e-04, -8.6599e-04,  9.4459e-05, -2.1528e-04,\n",
      "        -8.0248e-04,  4.3798e-05,  2.0922e-04,  1.2358e-03,  8.1859e-04,\n",
      "        -1.0045e-03,  1.0022e-03,  1.0040e-04, -3.4931e-05,  9.6280e-04,\n",
      "         6.8019e-04,  4.2386e-04,  4.9760e-04, -3.8531e-04, -4.8296e-04,\n",
      "        -3.5306e-04, -7.1902e-04,  1.2949e-03, -7.9306e-04,  1.0893e-03,\n",
      "        -1.0012e-03, -5.9375e-04,  2.6581e-03,  1.5386e-03, -4.4681e-04,\n",
      "         3.1110e-04,  3.3743e-04,  1.3471e-04,  8.6424e-04, -2.8295e-04,\n",
      "        -2.6476e-04, -2.4415e-04,  1.2910e-03, -1.1401e-03, -5.0621e-04,\n",
      "         8.4760e-04, -4.9594e-04, -6.3969e-04, -1.8551e-04,  2.1083e-03,\n",
      "         8.8141e-04,  1.7125e-04, -2.6826e-04,  4.5888e-04,  1.4036e-03,\n",
      "        -5.0086e-04,  3.2470e-04, -1.0532e-03,  3.0892e-04,  2.4833e-05,\n",
      "        -1.2436e-03,  1.0287e-03,  4.5880e-04,  2.5309e-04, -1.2899e-03,\n",
      "        -1.4438e-04,  8.2689e-05, -8.3617e-05, -1.9062e-04,  1.3569e-04,\n",
      "        -1.9754e-04, -3.7838e-04,  1.6041e-04,  5.2602e-05, -5.8393e-04,\n",
      "         4.5770e-04,  1.5325e-04, -1.7329e-03, -8.9706e-05, -3.8853e-04,\n",
      "        -3.7823e-04,  2.9141e-04,  5.0432e-04,  1.2939e-04,  6.2187e-04,\n",
      "        -1.0292e-03, -1.3317e-03, -2.7999e-04,  4.4125e-04, -6.6013e-04,\n",
      "         6.7223e-04, -1.1088e-03,  2.5108e-04,  5.4158e-04, -4.8614e-04]), 'exp_avg_sq': tensor([0.0003, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0003, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0001, 0.0004, 0.0003, 0.0003,\n",
      "        0.0002, 0.0003, 0.0002, 0.0002, 0.0002, 0.0003, 0.0001, 0.0002, 0.0002,\n",
      "        0.0002, 0.0002, 0.0004, 0.0002, 0.0002, 0.0002, 0.0002, 0.0003, 0.0002,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002, 0.0003, 0.0002, 0.0002, 0.0002, 0.0003,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0003, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002, 0.0003, 0.0004, 0.0002, 0.0002, 0.0002, 0.0002, 0.0003, 0.0003,\n",
      "        0.0003, 0.0002, 0.0003, 0.0003, 0.0003, 0.0003, 0.0002, 0.0002, 0.0002,\n",
      "        0.0003, 0.0003, 0.0002, 0.0004, 0.0002, 0.0003, 0.0003, 0.0002, 0.0002,\n",
      "        0.0002, 0.0003, 0.0003, 0.0002, 0.0004, 0.0002, 0.0004, 0.0002, 0.0005,\n",
      "        0.0002, 0.0002, 0.0003, 0.0004, 0.0002, 0.0002, 0.0003, 0.0003, 0.0003,\n",
      "        0.0002])}, 11: {'step': tensor(11460.), 'exp_avg': tensor([-5.6212e-11, -5.4544e-12,  2.7000e-11, -7.7108e-11,  7.6011e-11,\n",
      "        -9.1072e-11, -3.2106e-11,  1.7557e-10, -2.4333e-11, -4.6503e-10,\n",
      "         3.2840e-10, -1.6465e-10,  1.1609e-10, -9.7763e-11,  1.9633e-11,\n",
      "         1.6756e-10,  6.5365e-11, -6.9832e-11,  1.0559e-10, -1.1514e-10,\n",
      "        -3.2139e-11,  1.7691e-10,  4.4717e-11, -7.7955e-11,  6.7914e-11,\n",
      "         3.4667e-10, -1.2139e-10,  3.2522e-11, -1.4339e-10, -1.0572e-10,\n",
      "        -1.7095e-10, -5.3157e-10, -9.2584e-11, -2.9897e-13, -2.2027e-10,\n",
      "        -3.7632e-10, -9.0402e-11,  2.9798e-10, -1.3028e-11, -8.1818e-11,\n",
      "        -2.7384e-10,  1.4572e-10, -1.5837e-10,  7.0887e-12, -2.2074e-12,\n",
      "         1.1365e-10,  1.0592e-10, -2.7380e-10, -4.7817e-11, -1.1983e-10,\n",
      "         4.9690e-10,  2.8023e-11, -1.3469e-10,  7.2752e-11,  1.2301e-10,\n",
      "        -1.1437e-11, -2.9543e-11, -5.9374e-11, -2.0902e-10,  1.6122e-11,\n",
      "        -3.5272e-11, -1.3553e-10, -2.5911e-10,  1.2833e-10, -2.2139e-10,\n",
      "         6.4263e-11, -4.3896e-11,  4.7496e-11, -9.8324e-11,  1.9689e-10,\n",
      "         5.2815e-11,  4.3852e-11,  9.2916e-11,  1.1453e-10, -1.6459e-10,\n",
      "        -1.5611e-10, -1.0300e-10,  2.3488e-10, -2.9707e-11, -3.8520e-11,\n",
      "        -6.9855e-11, -1.2022e-11, -6.1377e-12, -1.6887e-10, -3.0552e-11,\n",
      "        -2.0206e-11, -1.1246e-12,  1.1129e-10, -8.0958e-11,  1.1534e-10,\n",
      "         4.5475e-11,  5.5909e-11, -4.0897e-11,  3.4214e-10,  1.1905e-10,\n",
      "         8.3545e-12, -6.4572e-11, -9.7012e-11,  1.7049e-10, -1.0583e-10]), 'exp_avg_sq': tensor([1.0664e-17, 7.6905e-18, 7.6885e-18, 5.7904e-18, 5.8574e-18, 4.7865e-18,\n",
      "        4.4758e-18, 1.0949e-17, 4.2419e-18, 9.7006e-18, 1.0914e-17, 4.1962e-18,\n",
      "        4.6110e-18, 5.5145e-18, 4.1854e-18, 8.0039e-18, 7.2534e-18, 1.2080e-17,\n",
      "        7.2615e-18, 1.0753e-17, 7.8928e-18, 8.2835e-18, 7.5695e-18, 9.0773e-18,\n",
      "        6.6478e-18, 1.0117e-17, 5.8795e-18, 5.7523e-18, 7.8173e-18, 9.3961e-18,\n",
      "        8.8090e-18, 8.1361e-18, 8.4354e-18, 5.8867e-18, 1.0566e-17, 8.5412e-18,\n",
      "        4.8170e-18, 6.2250e-18, 7.4061e-18, 7.5903e-18, 5.8995e-18, 7.2342e-18,\n",
      "        5.1858e-18, 6.3754e-18, 7.6696e-18, 9.1793e-18, 6.7555e-18, 6.0269e-18,\n",
      "        8.1219e-18, 8.5829e-18, 7.7808e-18, 6.3537e-18, 6.0982e-18, 6.2313e-18,\n",
      "        8.3197e-18, 8.4369e-18, 6.6125e-18, 7.4910e-18, 6.4531e-18, 1.0103e-17,\n",
      "        7.5229e-18, 6.5475e-18, 7.1856e-18, 6.4644e-18, 3.8816e-18, 8.2564e-18,\n",
      "        1.4298e-17, 9.0862e-18, 9.0567e-18, 8.7045e-18, 6.6529e-18, 6.8876e-18,\n",
      "        1.0078e-17, 1.0887e-17, 7.3444e-18, 1.1942e-17, 5.6785e-18, 7.6108e-18,\n",
      "        5.4638e-18, 7.2033e-18, 1.0330e-17, 5.8147e-18, 9.2356e-18, 8.0104e-18,\n",
      "        5.7468e-18, 6.2677e-18, 9.9588e-18, 7.1465e-18, 8.1188e-18, 1.1941e-17,\n",
      "        5.3216e-18, 7.3140e-18, 7.9804e-18, 1.0413e-17, 7.7596e-18, 5.7998e-18,\n",
      "        6.5416e-18, 6.2460e-18, 1.1347e-17, 6.1397e-18])}, 12: {'step': tensor(11460.), 'exp_avg': tensor([-1.6127,  0.6305,  0.7573, -0.1841,  0.3177, -0.9726,  0.1546,  0.9093]), 'exp_avg_sq': tensor([320.1577, 175.3894,  83.4134,  11.0242,  25.7347, 178.1560,  52.6043,\n",
      "         81.9620])}, 13: {'step': tensor(11460.), 'exp_avg': tensor([[ 0.7556, -0.0684,  0.3384],\n",
      "        [-0.3888,  0.0118, -0.1612],\n",
      "        [-0.1148,  0.0604, -0.1671],\n",
      "        [-0.0231, -0.0246, -0.0022],\n",
      "        [-0.1786,  0.0086, -0.0821],\n",
      "        [ 0.1810, -0.0524,  0.3009],\n",
      "        [ 0.1119,  0.0233, -0.0369],\n",
      "        [-0.3431,  0.0412, -0.1897]]), 'exp_avg_sq': tensor([[ 4.8966,  0.5358, 11.5220],\n",
      "        [ 2.2507,  0.2387,  5.6142],\n",
      "        [ 0.8435,  0.0576,  1.4382],\n",
      "        [ 0.2515,  0.0153,  0.5114],\n",
      "        [ 0.3539,  0.0405,  0.9877],\n",
      "        [ 1.7372,  0.1663,  3.3613],\n",
      "        [ 0.5480,  0.0407,  1.1998],\n",
      "        [ 1.2608,  0.1760,  2.7699]])}, 14: {'step': tensor(11460.), 'exp_avg': tensor([-1.1362e-04, -3.7570e-04, -1.6758e-03,  4.8765e-04, -2.3946e-04,\n",
      "        -4.5200e-04, -1.3318e-04, -9.6350e-04,  2.1930e-04, -5.9294e-04,\n",
      "        -1.6640e-03,  4.8430e-04, -1.3649e-03,  1.6636e-04, -1.9335e-04,\n",
      "        -4.7403e-04,  1.2062e-03, -1.0092e-03, -8.0482e-04,  1.1451e-04,\n",
      "        -7.6978e-04, -3.8704e-04, -2.3059e-04,  2.5973e-04,  1.9438e-03,\n",
      "        -9.1612e-04, -1.5366e-03, -1.9076e-04, -5.7494e-05, -2.1801e-04,\n",
      "         2.6044e-04, -7.4871e-04,  2.0243e-03, -2.2451e-04, -5.8518e-04,\n",
      "        -3.2389e-04, -1.5809e-04,  5.6049e-04, -4.2264e-04, -1.6809e-03,\n",
      "        -3.7338e-04, -9.6784e-04,  1.7272e-04,  1.5124e-04,  1.2806e-04,\n",
      "        -6.8004e-04, -6.8784e-04,  3.3343e-04, -2.6750e-04, -4.3043e-04,\n",
      "        -9.2920e-04, -5.2053e-04,  2.3426e-04, -7.4140e-04, -1.2450e-04,\n",
      "        -5.4082e-05, -1.9106e-04, -9.4685e-04, -3.2821e-06, -5.5625e-04,\n",
      "         1.2970e-03, -1.6671e-05, -8.0126e-04, -1.1532e-04, -8.1295e-04,\n",
      "        -6.3991e-04, -4.4905e-04,  4.7425e-05, -5.6836e-04, -7.9230e-04,\n",
      "        -6.5317e-04,  4.2910e-04, -1.0144e-03, -4.6338e-04, -5.9160e-05,\n",
      "        -6.2738e-05, -5.4272e-04, -4.1077e-04, -1.9069e-04,  9.4061e-04,\n",
      "        -4.9213e-04, -8.3714e-05,  5.1250e-05, -1.4170e-04, -4.8238e-04,\n",
      "         2.0874e-03, -1.6694e-04, -1.6754e-03, -7.7972e-04, -3.5913e-05,\n",
      "        -3.0180e-04, -8.7239e-04, -5.5381e-04, -2.5984e-03, -1.4481e-03,\n",
      "        -1.4843e-04,  1.3006e-03,  1.1051e-03, -4.0055e-04, -8.1454e-04]), 'exp_avg_sq': tensor([2.5632e-04, 1.0250e-04, 1.5276e-04, 1.9882e-04, 6.9160e-05, 1.1459e-04,\n",
      "        1.1484e-04, 7.4679e-05, 7.3498e-05, 5.5367e-05, 2.0156e-04, 2.5046e-04,\n",
      "        9.5695e-05, 7.9827e-05, 8.1339e-05, 1.6489e-04, 2.9265e-04, 1.2048e-04,\n",
      "        1.3444e-04, 8.5682e-05, 1.3437e-04, 1.0591e-04, 2.8406e-04, 3.4893e-04,\n",
      "        1.3299e-04, 8.4363e-05, 1.0226e-04, 3.1395e-04, 1.8784e-04, 1.6155e-04,\n",
      "        1.2785e-04, 1.5172e-04, 1.9449e-04, 1.8773e-04, 1.1460e-04, 8.2272e-05,\n",
      "        1.3211e-04, 4.0979e-04, 7.2162e-05, 1.3139e-04, 8.5561e-05, 2.4204e-04,\n",
      "        1.7140e-04, 2.2481e-04, 8.0040e-05, 2.9759e-04, 1.3800e-04, 1.3291e-04,\n",
      "        4.2576e-04, 1.1698e-04, 1.4432e-04, 2.0544e-04, 1.0348e-04, 1.2316e-04,\n",
      "        8.6687e-05, 9.7583e-05, 1.2915e-04, 1.2286e-04, 1.6761e-04, 1.3742e-04,\n",
      "        6.7042e-05, 7.2284e-05, 1.9183e-04, 4.6901e-04, 1.1045e-04, 1.8825e-04,\n",
      "        1.9048e-04, 1.5281e-04, 9.1862e-05, 1.5354e-04, 1.4975e-04, 1.6886e-04,\n",
      "        1.3878e-04, 2.0861e-04, 2.1902e-04, 5.3418e-04, 1.1527e-04, 2.5848e-04,\n",
      "        1.2380e-04, 1.1395e-04, 1.5868e-04, 1.0606e-04, 2.2914e-04, 4.2625e-04,\n",
      "        1.6695e-04, 2.0286e-04, 1.1154e-04, 2.3372e-04, 1.3648e-04, 4.2063e-04,\n",
      "        1.6437e-04, 3.6233e-04, 3.4494e-04, 1.1933e-04, 1.6835e-04, 1.7119e-04,\n",
      "        1.2796e-04, 1.2443e-04, 6.2672e-05, 1.0508e-04])}, 15: {'step': tensor(11460.), 'exp_avg': tensor([ 5.4685e-03,  9.2152e-03,  9.0914e-03,  2.5483e-03,  7.0632e-03,\n",
      "         6.9713e-03,  4.9747e-03,  5.7585e-03,  6.2384e-03,  5.2001e-03,\n",
      "         4.7615e-03,  4.0869e-03,  9.4355e-03,  2.5955e-03,  2.7407e-03,\n",
      "         3.9962e-03,  7.2686e-03,  3.5613e-03,  7.0040e-03,  5.4364e-03,\n",
      "         3.6240e-03,  5.6698e-03,  3.8269e-03,  3.1876e-03,  1.2080e-02,\n",
      "         6.6253e-03,  8.9526e-03,  2.8069e-03,  2.8556e-03,  7.2024e-03,\n",
      "         5.5517e-03,  7.3203e-03,  8.5349e-03,  8.4964e-03,  7.0074e-03,\n",
      "         7.6633e-03,  5.2071e-03,  7.3192e-03,  5.5730e-03,  6.8477e-03,\n",
      "         6.5140e-03,  6.1456e-03,  7.2017e-03,  7.4035e-03,  4.1977e-03,\n",
      "         5.2906e-03,  2.4528e-03,  4.0951e-03,  5.2290e-03,  6.4263e-03,\n",
      "         8.7281e-03,  8.1307e-03,  5.3173e-03,  8.7383e-03,  6.6336e-03,\n",
      "         5.8216e-03,  3.3003e-03,  3.7432e-03,  6.4706e-03,  7.0016e-03,\n",
      "         9.5044e-03,  3.2508e-03,  2.9874e-03,  5.6977e-03,  8.9003e-03,\n",
      "         7.3149e-03,  9.0098e-03,  5.8774e-03,  7.5480e-03,  5.8291e-03,\n",
      "         8.6594e-03,  7.5161e-03,  9.0075e-03,  5.2539e-03,  7.1456e-03,\n",
      "         4.5802e-03,  5.4579e-03,  7.8037e-03,  6.4249e-03,  4.3237e-03,\n",
      "         6.9493e-03,  4.8567e-03,  3.4760e-03,  4.4984e-03,  5.6808e-03,\n",
      "         6.6236e-03,  5.8677e-03,  7.2036e-03,  3.9162e-03,  1.9262e-03,\n",
      "        -2.4738e-05,  4.5654e-03,  7.9499e-03,  1.0254e-02,  6.8985e-03,\n",
      "         4.9207e-03,  1.0417e-02,  3.4123e-03,  5.1886e-03,  5.6961e-03]), 'exp_avg_sq': tensor([0.0044, 0.0030, 0.0035, 0.0044, 0.0028, 0.0028, 0.0028, 0.0036, 0.0035,\n",
      "        0.0026, 0.0044, 0.0060, 0.0039, 0.0040, 0.0029, 0.0046, 0.0040, 0.0056,\n",
      "        0.0033, 0.0040, 0.0051, 0.0036, 0.0065, 0.0046, 0.0033, 0.0045, 0.0047,\n",
      "        0.0076, 0.0041, 0.0080, 0.0036, 0.0040, 0.0039, 0.0058, 0.0034, 0.0057,\n",
      "        0.0042, 0.0060, 0.0042, 0.0046, 0.0041, 0.0049, 0.0052, 0.0051, 0.0052,\n",
      "        0.0045, 0.0049, 0.0042, 0.0030, 0.0037, 0.0046, 0.0035, 0.0041, 0.0031,\n",
      "        0.0054, 0.0030, 0.0077, 0.0040, 0.0052, 0.0045, 0.0033, 0.0037, 0.0061,\n",
      "        0.0074, 0.0041, 0.0045, 0.0067, 0.0065, 0.0036, 0.0059, 0.0045, 0.0059,\n",
      "        0.0050, 0.0063, 0.0092, 0.0047, 0.0049, 0.0041, 0.0038, 0.0046, 0.0037,\n",
      "        0.0039, 0.0062, 0.0061, 0.0049, 0.0048, 0.0045, 0.0053, 0.0073, 0.0066,\n",
      "        0.0043, 0.0064, 0.0085, 0.0053, 0.0059, 0.0058, 0.0034, 0.0071, 0.0033,\n",
      "        0.0045])}, 16: {'step': tensor(11460.), 'exp_avg': tensor([-0.0056, -0.1434, -0.3375,  0.0081, -0.0130, -0.0668,  0.4122,  0.1460]), 'exp_avg_sq': tensor([ 6.2550,  1.4758,  8.8623, 10.8759,  2.3893,  3.0166, 21.7042,  7.9786])}, 17: {'step': tensor(11460.), 'exp_avg': tensor([[-1.0188e-01, -2.4295e-01, -1.7194e-01,  1.1438e-01, -8.1138e-02,\n",
      "         -2.5202e-04,  2.2777e-01,  2.5504e-01],\n",
      "        [-3.5239e-02, -6.6992e-02, -9.4191e-03,  1.1532e-01, -2.1906e-01,\n",
      "          3.1557e-03,  7.8006e-02,  1.1756e-01],\n",
      "        [-6.2803e-02, -1.1670e-01, -2.2307e-02,  2.0681e-01, -4.1960e-01,\n",
      "          1.0301e-02,  1.4910e-01,  2.1621e-01],\n",
      "        [ 1.1588e-01,  2.6967e-01,  1.2503e-01, -2.2785e-01,  2.7019e-01,\n",
      "          3.8458e-03, -2.4001e-01, -3.1593e-01],\n",
      "        [ 4.4091e-03,  1.7864e-02,  2.5075e-02,  1.6058e-02, -4.7312e-02,\n",
      "         -6.9350e-04, -1.2706e-02, -4.0204e-03],\n",
      "        [-8.7213e-02, -1.9593e-01, -8.8358e-02,  1.8233e-01, -2.4971e-01,\n",
      "         -3.0903e-04,  1.8578e-01,  2.4562e-01],\n",
      "        [ 2.0738e-01,  4.4295e-01,  1.7000e-01, -4.9978e-01,  7.9963e-01,\n",
      "         -6.4326e-03, -4.5039e-01, -6.1556e-01],\n",
      "        [-4.0531e-02, -1.0792e-01, -2.8081e-02,  9.2750e-02, -5.3003e-02,\n",
      "         -9.6154e-03,  6.2458e-02,  1.0108e-01]]), 'exp_avg_sq': tensor([[4.1289e-01, 3.2931e+00, 2.3595e+00, 4.9354e-01, 1.4082e+00, 1.3182e-02,\n",
      "         2.4611e+00, 2.4182e+00],\n",
      "        [8.4387e-02, 6.4771e-01, 4.5885e-01, 1.2924e-01, 4.1276e-01, 1.7665e-03,\n",
      "         4.9050e-01, 4.8945e-01],\n",
      "        [3.4245e-01, 2.6302e+00, 1.7335e+00, 5.9758e-01, 1.7121e+00, 8.0673e-03,\n",
      "         1.9942e+00, 2.0852e+00],\n",
      "        [8.0097e-01, 5.6514e+00, 4.0686e+00, 5.9622e-01, 2.0134e+00, 1.4076e-02,\n",
      "         4.5888e+00, 4.4997e+00],\n",
      "        [1.0104e-01, 7.7603e-01, 5.6784e-01, 1.1004e-01, 3.6747e-01, 2.9292e-03,\n",
      "         6.0869e-01, 5.9059e-01],\n",
      "        [2.9731e-01, 2.1139e+00, 1.5690e+00, 2.5340e-01, 8.9620e-01, 6.0842e-03,\n",
      "         1.6850e+00, 1.6436e+00],\n",
      "        [1.5009e+00, 1.0804e+01, 7.9893e+00, 1.5925e+00, 5.7466e+00, 2.8619e-02,\n",
      "         8.6141e+00, 8.4325e+00],\n",
      "        [5.9185e-01, 4.1054e+00, 2.9978e+00, 3.6166e-01, 1.2726e+00, 9.2410e-03,\n",
      "         3.3907e+00, 3.2832e+00]])}, 18: {'step': tensor(11460.), 'exp_avg': tensor([ 1.0097e-04, -2.1768e-04, -5.1482e-04,  1.8733e-04, -1.4090e-04,\n",
      "        -3.5264e-04, -3.0632e-04, -8.1351e-04, -1.2195e-04, -4.3724e-04,\n",
      "        -1.5034e-03,  2.1321e-04, -9.7506e-04,  9.3317e-05, -2.0147e-04,\n",
      "        -3.8238e-04,  3.7666e-04, -4.7424e-04, -3.6385e-04,  9.3606e-04,\n",
      "        -4.4711e-04, -3.8274e-04,  1.4516e-04, -1.0420e-04,  6.8383e-04,\n",
      "        -1.8520e-04,  7.4682e-04,  1.0929e-04, -9.7974e-05, -2.8778e-04,\n",
      "         2.3874e-04, -3.8844e-04,  6.1626e-04, -1.5950e-04, -2.9378e-04,\n",
      "        -3.1820e-04, -2.2929e-04,  2.0245e-03, -1.9980e-04, -4.4749e-04,\n",
      "         1.5143e-05, -2.5204e-04,  1.9230e-04,  9.4324e-05, -3.8770e-04,\n",
      "        -6.2195e-04, -3.0327e-04,  2.5742e-04, -4.5487e-04, -2.7069e-04,\n",
      "        -5.8535e-05, -3.0428e-04,  1.8237e-04, -4.2335e-04, -4.8225e-04,\n",
      "         1.7634e-04, -3.5455e-04, -4.5459e-04,  6.6185e-04, -3.7208e-05,\n",
      "         1.5595e-04,  1.1419e-04, -4.5789e-04,  6.9229e-04, -3.2579e-04,\n",
      "        -2.5887e-04, -1.3352e-04, -5.3946e-05, -4.1849e-04, -6.6790e-04,\n",
      "         1.5596e-04,  3.8458e-06, -2.6895e-04, -1.3083e-04,  6.0131e-05,\n",
      "         5.3549e-04, -6.0564e-04, -1.6141e-04, -4.0876e-04,  1.2562e-03,\n",
      "        -8.8114e-04,  1.1898e-04, -5.4124e-05, -2.2446e-04, -7.1352e-04,\n",
      "         2.3995e-03, -1.4267e-04, -8.3393e-04, -1.1292e-04,  9.6420e-05,\n",
      "        -7.8017e-05, -5.2018e-04,  4.5869e-04, -7.0048e-04, -5.2239e-04,\n",
      "         3.7036e-05,  1.1203e-03,  3.2073e-04,  2.9142e-05, -2.4702e-04]), 'exp_avg_sq': tensor([3.5086e-05, 9.9388e-05, 5.5324e-05, 3.5721e-05, 4.4177e-05, 3.3967e-05,\n",
      "        6.7267e-05, 3.5161e-05, 5.2699e-05, 2.9404e-05, 1.2204e-04, 9.5395e-05,\n",
      "        5.3853e-05, 4.0457e-05, 4.3930e-05, 6.8073e-05, 7.3380e-05, 4.2311e-05,\n",
      "        5.1129e-05, 4.6487e-05, 6.9922e-05, 5.6707e-05, 7.8541e-05, 6.6302e-05,\n",
      "        6.4679e-05, 6.1595e-05, 6.1635e-05, 5.4210e-05, 6.4445e-05, 1.5518e-04,\n",
      "        5.4336e-05, 6.5490e-05, 5.1173e-04, 1.2799e-04, 4.7540e-05, 4.7602e-05,\n",
      "        3.2077e-05, 7.6912e-05, 6.1051e-05, 5.3326e-05, 5.3045e-05, 1.0352e-04,\n",
      "        8.5396e-05, 8.8823e-05, 6.0934e-05, 6.2664e-05, 6.1977e-05, 4.2917e-05,\n",
      "        1.0894e-04, 7.5856e-05, 1.2224e-04, 7.1067e-05, 5.1142e-05, 4.7931e-05,\n",
      "        5.2545e-05, 4.1397e-05, 5.5302e-05, 7.2190e-05, 1.1335e-04, 7.2421e-05,\n",
      "        4.9311e-05, 5.5700e-05, 8.6803e-05, 1.1726e-04, 5.4621e-05, 6.7040e-05,\n",
      "        5.4726e-05, 6.2437e-05, 4.1072e-05, 6.3667e-05, 5.9322e-05, 8.7883e-05,\n",
      "        7.5970e-05, 1.3378e-04, 8.6022e-05, 9.5216e-05, 6.8005e-05, 1.1025e-04,\n",
      "        6.7719e-05, 6.8021e-05, 9.1436e-05, 4.9255e-05, 9.1906e-05, 1.6160e-04,\n",
      "        1.0985e-04, 6.4075e-05, 4.6954e-05, 7.5364e-05, 5.9945e-05, 9.0263e-05,\n",
      "        8.3662e-05, 5.6880e-05, 1.6183e-04, 5.9481e-05, 6.8799e-05, 7.6727e-05,\n",
      "        7.1908e-05, 7.9744e-05, 4.1575e-05, 5.9138e-05])}, 19: {'step': tensor(11460.), 'exp_avg': tensor([0.0010, 0.0040, 0.0114, 0.0011, 0.0051, 0.0128, 0.0089, 0.0100, 0.0126,\n",
      "        0.0110, 0.0107, 0.0050, 0.0086, 0.0079, 0.0036, 0.0107, 0.0092, 0.0098,\n",
      "        0.0094, 0.0077, 0.0100, 0.0069, 0.0032, 0.0016, 0.0086, 0.0092, 0.0091,\n",
      "        0.0119, 0.0050, 0.0056, 0.0046, 0.0071, 0.0067, 0.0142, 0.0139, 0.0092,\n",
      "        0.0032, 0.0110, 0.0093, 0.0088, 0.0136, 0.0050, 0.0090, 0.0070, 0.0015,\n",
      "        0.0094, 0.0032, 0.0078, 0.0027, 0.0041, 0.0149, 0.0050, 0.0076, 0.0097,\n",
      "        0.0140, 0.0031, 0.0047, 0.0062, 0.0102, 0.0088, 0.0103, 0.0158, 0.0185,\n",
      "        0.0135, 0.0089, 0.0136, 0.0160, 0.0030, 0.0050, 0.0131, 0.0178, 0.0041,\n",
      "        0.0106, 0.0049, 0.0015, 0.0092, 0.0093, 0.0142, 0.0128, 0.0062, 0.0128,\n",
      "        0.0009, 0.0016, 0.0002, 0.0155, 0.0066, 0.0083, 0.0085, 0.0034, 0.0056,\n",
      "        0.0060, 0.0023, 0.0132, 0.0108, 0.0114, 0.0080, 0.0101, 0.0086, 0.0048,\n",
      "        0.0159]), 'exp_avg_sq': tensor([0.0018, 0.0019, 0.0019, 0.0021, 0.0022, 0.0021, 0.0023, 0.0021, 0.0024,\n",
      "        0.0018, 0.0024, 0.0020, 0.0019, 0.0021, 0.0022, 0.0022, 0.0024, 0.0023,\n",
      "        0.0020, 0.0024, 0.0024, 0.0024, 0.0023, 0.0022, 0.0024, 0.0022, 0.0025,\n",
      "        0.0029, 0.0023, 0.0027, 0.0021, 0.0021, 0.0024, 0.0026, 0.0025, 0.0027,\n",
      "        0.0024, 0.0027, 0.0026, 0.0024, 0.0028, 0.0023, 0.0023, 0.0024, 0.0027,\n",
      "        0.0025, 0.0026, 0.0023, 0.0023, 0.0023, 0.0026, 0.0025, 0.0022, 0.0025,\n",
      "        0.0028, 0.0023, 0.0025, 0.0024, 0.0025, 0.0022, 0.0023, 0.0028, 0.0028,\n",
      "        0.0027, 0.0026, 0.0028, 0.0027, 0.0025, 0.0025, 0.0028, 0.0027, 0.0033,\n",
      "        0.0036, 0.0030, 0.0032, 0.0031, 0.0029, 0.0030, 0.0026, 0.0028, 0.0030,\n",
      "        0.0030, 0.0031, 0.0025, 0.0030, 0.0026, 0.0027, 0.0029, 0.0028, 0.0030,\n",
      "        0.0025, 0.0031, 0.0037, 0.0030, 0.0031, 0.0034, 0.0024, 0.0034, 0.0027,\n",
      "        0.0028])}, 20: {'step': tensor(11460.), 'exp_avg': tensor([-0.3277, -0.0027,  0.3659,  0.0915, -0.3021,  0.1346, -0.0239,  0.0643]), 'exp_avg_sq': tensor([2.6218, 2.1068, 6.1788, 2.5790, 2.9474, 2.6393, 1.0481, 0.4036])}, 21: {'step': tensor(11460.), 'exp_avg': tensor([[ 0.2407, -0.3037,  0.0336,  0.2054,  0.2753, -0.5735, -0.2394,  0.3784],\n",
      "        [-0.1066,  0.0400,  0.1551, -0.1862, -0.1530,  0.3052,  0.1703, -0.2249],\n",
      "        [-0.1311,  0.2754, -0.2283,  0.0048, -0.1063,  0.2510,  0.0497, -0.1336],\n",
      "        [ 0.0237, -0.0865,  0.0623, -0.0334,  0.0036, -0.0112,  0.0300,  0.0071],\n",
      "        [ 0.2361, -0.2442, -0.0352,  0.2486,  0.2850, -0.5963, -0.2755,  0.3970],\n",
      "        [-0.1562,  0.2265, -0.0544, -0.1054, -0.1693,  0.3499,  0.1320, -0.2302],\n",
      "        [-0.0372,  0.0608, -0.0080, -0.0212, -0.0386,  0.0757,  0.0235, -0.0539],\n",
      "        [-0.0694,  0.0317,  0.0750, -0.1126, -0.0967,  0.1991,  0.1094, -0.1398]]), 'exp_avg_sq': tensor([[0.3042, 2.0286, 3.0360, 1.4919, 0.5917, 1.9991, 1.3409, 1.1327],\n",
      "        [0.2697, 1.6664, 2.3623, 1.2286, 0.5206, 1.7504, 1.1633, 0.9905],\n",
      "        [0.3869, 1.9285, 2.8826, 1.5040, 0.7673, 2.6248, 1.4492, 1.4381],\n",
      "        [0.1183, 0.9684, 1.9657, 0.9235, 0.2921, 0.9906, 0.7647, 0.6257],\n",
      "        [0.2793, 1.5282, 2.0998, 1.0425, 0.4961, 1.7576, 0.9705, 0.9409],\n",
      "        [0.1924, 1.3898, 2.7807, 1.3020, 0.4375, 1.5264, 1.0468, 0.9376],\n",
      "        [0.0458, 0.3487, 0.8654, 0.4297, 0.1346, 0.4570, 0.3629, 0.3064],\n",
      "        [0.0703, 0.4067, 0.5187, 0.2560, 0.1150, 0.4047, 0.2361, 0.2200]])}, 22: {'step': tensor(11460.), 'exp_avg': tensor([ 7.4555e-04, -2.7726e-04,  5.2680e-04,  9.9781e-04, -5.2692e-04,\n",
      "        -1.0250e-03,  4.0812e-04,  1.0195e-03, -1.1654e-03, -1.0235e-03,\n",
      "         4.4420e-04, -2.5928e-04, -1.7634e-03, -1.1480e-04,  1.1788e-04,\n",
      "        -1.2703e-03,  7.4800e-04,  3.3345e-04,  6.4364e-04,  5.9416e-04,\n",
      "        -1.4865e-03, -5.0458e-04,  1.3955e-04,  2.0518e-04,  1.1904e-03,\n",
      "         3.7006e-04,  2.0052e-03,  7.7873e-04, -1.1160e-04, -3.7571e-04,\n",
      "         1.0369e-05, -1.5825e-03,  1.3291e-03, -1.2006e-03,  3.3108e-04,\n",
      "        -7.6961e-04, -6.3790e-04,  1.9805e-03,  8.5530e-04, -6.9121e-05,\n",
      "        -7.8943e-04, -7.2065e-05, -7.1384e-05,  8.3513e-04, -4.1802e-04,\n",
      "        -1.3547e-03,  9.0192e-05,  1.3695e-03, -6.8910e-04, -6.6259e-04,\n",
      "        -3.0388e-04, -8.0698e-04, -2.7586e-04, -1.8380e-04,  1.3247e-03,\n",
      "         3.5061e-04,  1.6234e-05, -5.4512e-04,  6.0972e-04,  6.0583e-04,\n",
      "        -5.3914e-04, -1.7830e-04, -1.3210e-03,  7.1901e-04, -8.4041e-04,\n",
      "        -4.7460e-04,  6.7638e-04,  1.1624e-03, -3.7370e-05, -1.1708e-03,\n",
      "        -9.6624e-04, -2.9136e-04, -4.0166e-04, -2.1460e-04,  3.5820e-04,\n",
      "         7.8178e-04, -5.5915e-04, -1.2787e-03, -3.4085e-04,  4.9578e-04,\n",
      "         1.5460e-05, -9.9996e-05, -1.1594e-03,  2.1457e-04,  5.2967e-04,\n",
      "         1.2435e-03, -2.0753e-04, -7.9538e-04,  4.6985e-04,  4.9327e-04,\n",
      "         2.6999e-05, -1.1366e-05, -8.5127e-04,  1.4017e-04, -3.8953e-04,\n",
      "         1.9720e-04, -2.8250e-04,  1.3503e-03,  6.6564e-04, -1.2987e-03]), 'exp_avg_sq': tensor([0.0002, 0.0003, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002, 0.0003, 0.0002, 0.0003, 0.0002, 0.0002, 0.0003, 0.0002, 0.0002,\n",
      "        0.0002, 0.0003, 0.0002, 0.0002, 0.0002, 0.0003, 0.0002, 0.0003, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0002, 0.0002, 0.0004, 0.0002, 0.0002, 0.0002,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0004, 0.0004, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "        0.0003, 0.0003, 0.0002, 0.0002, 0.0003, 0.0001, 0.0002, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0003,\n",
      "        0.0002, 0.0003, 0.0003, 0.0002, 0.0002, 0.0003, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002, 0.0003, 0.0004, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0003,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0003, 0.0003, 0.0002,\n",
      "        0.0002])}, 23: {'step': tensor(11460.), 'exp_avg': tensor([-0.0043, -0.0060, -0.0072, -0.0049, -0.0072, -0.0089, -0.0057, -0.0062,\n",
      "        -0.0109, -0.0090, -0.0071, -0.0061, -0.0109, -0.0079, -0.0040, -0.0099,\n",
      "        -0.0096, -0.0091, -0.0064, -0.0055, -0.0113, -0.0052, -0.0065, -0.0049,\n",
      "        -0.0073, -0.0088, -0.0061, -0.0070, -0.0056, -0.0064, -0.0055, -0.0099,\n",
      "        -0.0056, -0.0092, -0.0067, -0.0075, -0.0060, -0.0080, -0.0060, -0.0066,\n",
      "        -0.0103, -0.0066, -0.0108, -0.0049, -0.0029, -0.0100, -0.0043, -0.0055,\n",
      "        -0.0078, -0.0050, -0.0095, -0.0085, -0.0056, -0.0059, -0.0068, -0.0048,\n",
      "        -0.0058, -0.0063, -0.0054, -0.0052, -0.0065, -0.0098, -0.0106, -0.0074,\n",
      "        -0.0079, -0.0086, -0.0074, -0.0029, -0.0064, -0.0113, -0.0120, -0.0051,\n",
      "        -0.0086, -0.0093, -0.0073, -0.0066, -0.0108, -0.0104, -0.0090, -0.0033,\n",
      "        -0.0081, -0.0060, -0.0057, -0.0055, -0.0088, -0.0047, -0.0061, -0.0076,\n",
      "        -0.0058, -0.0061, -0.0053, -0.0036, -0.0107, -0.0082, -0.0099, -0.0053,\n",
      "        -0.0066, -0.0074, -0.0045, -0.0095]), 'exp_avg_sq': tensor([0.0008, 0.0008, 0.0009, 0.0009, 0.0008, 0.0008, 0.0009, 0.0008, 0.0009,\n",
      "        0.0008, 0.0011, 0.0009, 0.0008, 0.0008, 0.0008, 0.0009, 0.0009, 0.0009,\n",
      "        0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0009, 0.0010, 0.0009, 0.0009,\n",
      "        0.0009, 0.0008, 0.0009, 0.0008, 0.0009, 0.0008, 0.0008, 0.0008, 0.0009,\n",
      "        0.0009, 0.0009, 0.0009, 0.0009, 0.0010, 0.0008, 0.0009, 0.0009, 0.0008,\n",
      "        0.0009, 0.0008, 0.0009, 0.0009, 0.0010, 0.0009, 0.0009, 0.0009, 0.0008,\n",
      "        0.0010, 0.0009, 0.0009, 0.0009, 0.0008, 0.0008, 0.0008, 0.0009, 0.0009,\n",
      "        0.0009, 0.0008, 0.0008, 0.0009, 0.0009, 0.0009, 0.0009, 0.0010, 0.0008,\n",
      "        0.0009, 0.0009, 0.0008, 0.0009, 0.0010, 0.0008, 0.0009, 0.0009, 0.0008,\n",
      "        0.0009, 0.0009, 0.0009, 0.0008, 0.0009, 0.0011, 0.0009, 0.0009, 0.0009,\n",
      "        0.0008, 0.0010, 0.0009, 0.0009, 0.0011, 0.0008, 0.0008, 0.0009, 0.0009,\n",
      "        0.0009])}, 24: {'step': tensor(11460.), 'exp_avg': tensor([ 2.0276e-04,  1.4941e-05, -2.1899e-05, -1.6242e-04,  3.4796e-05,\n",
      "        -1.3962e-04,  9.5391e-05, -2.3950e-05]), 'exp_avg_sq': tensor([2.1032e-04, 6.1388e-05, 2.8034e-05, 7.5890e-05, 4.2490e-05, 9.1213e-05,\n",
      "        2.6338e-04, 1.2195e-04])}, 25: {'step': tensor(11460.), 'exp_avg': tensor([[ 3.2985e-04,  6.0496e-04,  7.1978e-04, -4.4329e-04, -3.3385e-04,\n",
      "          6.9505e-04, -1.3895e-03, -2.2280e-04],\n",
      "        [-2.5198e-04, -1.2249e-03, -9.0874e-04,  1.1475e-03, -1.5129e-03,\n",
      "         -2.3609e-03,  6.0650e-03, -9.8996e-04],\n",
      "        [ 1.4135e-04,  1.0290e-04, -9.0617e-07,  1.9530e-04, -1.2956e-04,\n",
      "          8.1537e-05, -1.3135e-04, -2.5581e-04],\n",
      "        [-5.2924e-04, -8.6034e-04, -7.6969e-04,  2.8729e-04,  2.7569e-04,\n",
      "         -1.0691e-03,  2.2690e-03,  4.2163e-04],\n",
      "        [ 4.1654e-04,  1.1393e-03,  8.3738e-04, -7.2978e-04,  8.1341e-04,\n",
      "          1.9349e-03, -4.7488e-03,  3.5681e-04],\n",
      "        [-3.0859e-04, -5.9789e-04, -5.9495e-04,  3.7972e-04,  1.0596e-04,\n",
      "         -7.8331e-04,  1.6952e-03,  1.2620e-04],\n",
      "        [-6.1353e-05,  4.1154e-04,  5.3887e-04, -8.8666e-04,  5.9872e-04,\n",
      "          8.4162e-04, -2.1619e-03,  7.0937e-04],\n",
      "        [ 2.6343e-04,  4.2442e-04,  1.7825e-04,  4.9911e-05,  1.8258e-04,\n",
      "          6.6018e-04, -1.5976e-03, -1.4544e-04]]), 'exp_avg_sq': tensor([[1.4427e-04, 2.3661e-04, 2.6516e-04, 6.2245e-04, 2.2519e-04, 4.7725e-04,\n",
      "         2.8215e-03, 5.8781e-04],\n",
      "        [5.8341e-05, 7.5467e-05, 7.7355e-05, 2.9968e-04, 2.0420e-04, 2.1575e-04,\n",
      "         1.3550e-03, 3.4046e-04],\n",
      "        [2.2609e-05, 8.0362e-06, 1.8829e-05, 1.7352e-04, 5.9510e-05, 3.7826e-05,\n",
      "         2.1244e-04, 1.7157e-04],\n",
      "        [9.4977e-05, 1.7836e-04, 1.7471e-04, 9.3503e-05, 5.5985e-05, 2.5388e-04,\n",
      "         1.5285e-03, 1.3034e-04],\n",
      "        [5.4398e-05, 7.3580e-05, 7.6685e-05, 1.3619e-04, 1.0571e-04, 1.2854e-04,\n",
      "         7.8944e-04, 1.7723e-04],\n",
      "        [6.3115e-05, 1.4226e-04, 1.5848e-04, 1.0986e-04, 4.2930e-05, 2.2387e-04,\n",
      "         1.3876e-03, 9.5315e-05],\n",
      "        [1.4012e-04, 1.3935e-04, 2.2211e-04, 1.0281e-03, 3.7626e-04, 4.1254e-04,\n",
      "         2.5699e-03, 9.8449e-04],\n",
      "        [7.7036e-05, 2.5096e-05, 6.7477e-05, 5.3052e-04, 2.3671e-04, 1.1872e-04,\n",
      "         8.2184e-04, 5.8095e-04]])}, 26: {'step': tensor(11460.), 'exp_avg': tensor([ 4.5226e-06,  1.1349e-05, -1.7818e-07,  3.5904e-06, -5.9001e-06,\n",
      "         8.4536e-06, -5.4526e-05,  7.0931e-06,  4.5531e-05, -1.0428e-05,\n",
      "         5.0190e-05,  6.8373e-07, -4.2539e-06, -3.6483e-06, -1.8672e-06,\n",
      "         2.2126e-05,  3.9028e-06,  1.1672e-05, -6.1875e-06, -3.5470e-05,\n",
      "        -2.1323e-05,  1.8247e-06,  5.0036e-06,  1.6608e-06,  1.5895e-05]), 'exp_avg_sq': tensor([5.9881e-08, 9.1772e-08, 6.9788e-08, 3.8594e-08, 1.6207e-07, 9.2033e-08,\n",
      "        1.5661e-06, 5.2970e-08, 9.6791e-07, 2.7328e-07, 4.1906e-07, 5.4539e-08,\n",
      "        2.3383e-07, 8.4022e-08, 4.8057e-08, 1.6847e-07, 4.6836e-08, 9.6778e-08,\n",
      "        1.9408e-07, 1.4251e-06, 1.1666e-06, 1.9613e-07, 4.6638e-08, 1.0766e-07,\n",
      "        1.0697e-07])}, 27: {'step': tensor(11460.), 'exp_avg': tensor([-1.0538e-05, -2.0646e-05, -8.0203e-06, -7.9361e-07, -1.4355e-05,\n",
      "        -8.4976e-06,  8.6609e-05, -4.9794e-06, -1.0758e-04,  3.8374e-05,\n",
      "        -4.5362e-04, -9.4201e-06, -1.1036e-05, -9.7116e-06, -1.4451e-05,\n",
      "        -2.2999e-06, -1.1345e-05, -6.2371e-05, -1.1846e-05,  1.7019e-05,\n",
      "         1.1034e-05, -9.9910e-06, -6.4571e-06, -7.1891e-05, -2.1125e-05]), 'exp_avg_sq': tensor([5.5213e-07, 5.7213e-07, 2.8385e-07, 4.6785e-07, 5.0921e-07, 4.6664e-07,\n",
      "        1.1913e-05, 4.4213e-07, 4.4185e-06, 8.2585e-07, 8.2358e-06, 4.2472e-07,\n",
      "        2.3455e-07, 2.3426e-07, 2.6424e-07, 3.7976e-06, 4.0552e-07, 8.8237e-07,\n",
      "        2.8557e-07, 4.7205e-06, 1.1586e-04, 3.0652e-06, 4.5362e-07, 6.8081e-07,\n",
      "        5.6788e-07])}, 28: {'step': tensor(11460.), 'exp_avg': tensor([-0.0007,  0.0027,  0.0017,  0.0004, -0.0021,  0.0005, -0.0033,  0.0007]), 'exp_avg_sq': tensor([5.7402e-04, 2.9605e-04, 8.3133e-04, 4.3483e-05, 1.6918e-04, 2.2443e-05,\n",
      "        7.9876e-04, 2.7080e-03])}, 29: {'step': tensor(11460.), 'exp_avg': tensor([[-1.4875e-04, -1.2728e-04, -3.4816e-05,  3.0037e-04, -2.1599e-04,\n",
      "         -1.1967e-04, -1.2563e-05,  3.4818e-04],\n",
      "        [ 2.6425e-03, -2.6438e-03, -4.7517e-04,  3.9879e-03, -3.6060e-03,\n",
      "         -1.2764e-03, -5.6276e-04,  1.8078e-03],\n",
      "        [ 2.8985e-03, -3.1407e-03, -1.4836e-04,  4.7046e-03, -4.6600e-03,\n",
      "         -2.3099e-03, -7.2616e-04,  3.2546e-03],\n",
      "        [ 6.0325e-04, -6.3879e-04,  5.7016e-07,  9.4509e-04, -9.7249e-04,\n",
      "         -5.2299e-04, -1.5417e-04,  7.1247e-04],\n",
      "        [-1.8628e-03,  1.7917e-03,  3.1721e-04, -2.6827e-03,  2.4369e-03,\n",
      "          8.5187e-04,  3.9144e-04, -1.1583e-03],\n",
      "        [ 5.8799e-04, -5.2577e-04,  6.6094e-05,  7.3956e-04, -8.4151e-04,\n",
      "         -5.1878e-04, -1.5309e-04,  6.2283e-04],\n",
      "        [-4.5878e-03,  4.7069e-03,  1.5756e-04, -6.9601e-03,  6.9963e-03,\n",
      "          3.5016e-03,  1.1266e-03, -4.7512e-03],\n",
      "        [-1.3301e-04,  5.7786e-04,  1.1691e-04, -1.0348e-03,  8.6291e-04,\n",
      "          3.9424e-04,  9.0664e-05, -8.3633e-04]]), 'exp_avg_sq': tensor([[1.6686e-04, 3.9625e-04, 5.4455e-05, 1.0315e-03, 7.7207e-04, 1.6900e-04,\n",
      "         1.9036e-05, 4.6844e-04],\n",
      "        [2.1469e-04, 3.1946e-04, 3.7746e-05, 8.5355e-04, 6.5517e-04, 1.4400e-04,\n",
      "         2.0510e-05, 3.4778e-04],\n",
      "        [4.0411e-04, 5.4486e-04, 6.9210e-05, 1.3886e-03, 1.2717e-03, 4.0993e-04,\n",
      "         5.9069e-05, 8.6080e-04],\n",
      "        [1.8240e-05, 3.1859e-05, 8.6187e-06, 7.7657e-05, 5.2536e-05, 1.1447e-05,\n",
      "         2.1381e-06, 3.4580e-05],\n",
      "        [1.1877e-04, 1.4563e-04, 1.8810e-05, 3.6982e-04, 3.5075e-04, 1.1783e-04,\n",
      "         1.7363e-05, 2.3235e-04],\n",
      "        [1.1860e-05, 2.2326e-05, 5.8094e-06, 5.8156e-05, 3.7789e-05, 7.8315e-06,\n",
      "         1.3941e-06, 2.0499e-05],\n",
      "        [6.8431e-04, 6.5772e-04, 8.9491e-05, 1.5253e-03, 1.4170e-03, 4.1821e-04,\n",
      "         6.4358e-05, 7.4837e-04],\n",
      "        [6.1560e-04, 1.8359e-03, 3.0419e-04, 4.9462e-03, 3.1639e-03, 4.4550e-04,\n",
      "         4.8765e-05, 1.6551e-03]])}, 30: {'step': tensor(11460.), 'exp_avg': tensor([ 2.7694e-06,  1.0891e-05, -3.2511e-06,  2.1146e-06, -3.2654e-06,\n",
      "         8.0687e-06, -4.3202e-05,  6.6801e-06,  4.0215e-05, -6.1615e-06,\n",
      "         3.3731e-05, -7.9786e-07, -6.9587e-06, -4.1732e-06, -1.2295e-06,\n",
      "         2.1222e-05,  1.6932e-06,  3.1927e-06, -6.7872e-06, -2.7353e-05,\n",
      "         1.0091e-06,  9.1306e-06,  3.9432e-06, -4.7184e-06,  1.3474e-05]), 'exp_avg_sq': tensor([6.1017e-08, 9.5108e-08, 7.0897e-08, 4.3370e-08, 1.7046e-07, 1.0738e-07,\n",
      "        1.1013e-06, 5.8659e-08, 6.2667e-07, 2.1614e-07, 4.1487e-07, 6.7593e-08,\n",
      "        2.4871e-07, 1.3859e-07, 4.6775e-08, 1.6852e-07, 5.8033e-08, 1.2581e-07,\n",
      "        2.4461e-07, 1.0081e-06, 1.6313e-06, 2.1722e-07, 5.0845e-08, 1.3030e-07,\n",
      "        1.2616e-07])}, 31: {'step': tensor(11460.), 'exp_avg': tensor([-5.8946e-05,  1.9793e-05, -3.2503e-05, -3.3631e-05, -8.9891e-05,\n",
      "        -3.9336e-05, -1.4223e-04, -3.8507e-05, -4.9686e-05, -1.0344e-04,\n",
      "        -1.1843e-03, -5.1922e-05, -3.8591e-05, -5.8865e-05, -7.5473e-05,\n",
      "        -4.4476e-05, -4.8382e-05,  5.1878e-05, -5.4929e-05, -8.1636e-05,\n",
      "        -1.2308e-05,  2.1622e-05, -5.0270e-05,  5.8650e-05, -3.9218e-06]), 'exp_avg_sq': tensor([5.4830e-07, 7.3124e-07, 4.4953e-07, 5.7353e-07, 5.0914e-07, 9.6900e-07,\n",
      "        4.1258e-06, 6.3828e-07, 4.2209e-06, 8.3792e-07, 3.0002e-05, 3.9980e-07,\n",
      "        2.3826e-07, 3.3138e-07, 2.3259e-07, 5.5754e-06, 4.9111e-07, 1.6468e-06,\n",
      "        2.8690e-07, 2.3957e-06, 1.0543e-04, 6.4667e-06, 6.0844e-07, 1.2456e-06,\n",
      "        1.0800e-06])}, 32: {'step': tensor(11460.), 'exp_avg': tensor([ 0.0025, -0.0009,  0.0005, -0.0002, -0.0035,  0.0020, -0.0004, -0.0005,\n",
      "         0.0009, -0.0002]), 'exp_avg_sq': tensor([1.8075e-04, 1.1221e-03, 1.1351e-04, 2.3223e-04, 7.6512e-04, 9.5720e-05,\n",
      "        2.2248e-04, 1.9781e-04, 1.4230e-04, 1.2504e-04])}, 33: {'step': tensor(11460.), 'exp_avg': tensor([[-5.4857e-03, -1.5813e-03,  2.3692e-03,  4.6607e-03,  1.3722e-03,\n",
      "         -3.6608e-04,  6.5180e-04, -1.5343e-03],\n",
      "        [ 4.7435e-03,  1.2004e-03, -2.0980e-03, -4.0616e-03, -1.1889e-03,\n",
      "          2.0138e-04, -7.4522e-04,  1.8798e-03],\n",
      "        [-1.9734e-03, -4.5542e-04,  8.4382e-04,  1.6634e-03,  4.8635e-04,\n",
      "         -9.9106e-05,  3.2335e-04, -7.6667e-04],\n",
      "        [-2.3375e-05, -1.4852e-04,  1.0082e-04,  7.4524e-05,  6.3536e-05,\n",
      "          3.0484e-05, -3.9484e-05, -5.2613e-05],\n",
      "        [ 8.9331e-03,  2.6305e-03, -3.9437e-03, -7.6479e-03, -2.2782e-03,\n",
      "          5.4254e-04, -1.0817e-03,  2.7061e-03],\n",
      "        [-3.9320e-03, -1.0957e-03,  1.6481e-03,  3.3075e-03,  9.5941e-04,\n",
      "         -2.9640e-04,  4.5720e-04, -9.8747e-04],\n",
      "        [-1.8017e-04, -1.3557e-04,  1.7131e-04,  2.1275e-04,  9.4835e-05,\n",
      "          4.4326e-05,  2.8298e-05, -2.3103e-04],\n",
      "        [ 4.0216e-04,  7.1649e-06, -8.8213e-05, -2.8978e-04, -4.9209e-05,\n",
      "          6.6739e-05, -6.6613e-05,  1.4888e-05],\n",
      "        [-2.3510e-03, -3.1255e-04,  8.7376e-04,  1.9267e-03,  4.6932e-04,\n",
      "         -1.4971e-04,  4.6118e-04, -8.9074e-04],\n",
      "        [-1.3324e-04, -1.0895e-04,  1.2285e-04,  1.5366e-04,  7.0681e-05,\n",
      "          2.5833e-05,  1.1158e-05, -1.3802e-04]]), 'exp_avg_sq': tensor([[8.1920e-04, 1.0295e-04, 1.7144e-04, 6.0396e-04, 5.9041e-05, 4.2480e-06,\n",
      "         7.8051e-06, 7.2537e-05],\n",
      "        [2.9192e-03, 6.3955e-04, 8.5079e-04, 2.3062e-03, 3.3116e-04, 6.5137e-06,\n",
      "         5.7784e-05, 6.2464e-04],\n",
      "        [3.1373e-04, 4.7710e-05, 6.5651e-05, 2.4849e-04, 2.2431e-05, 1.4139e-06,\n",
      "         1.5454e-05, 1.0946e-04],\n",
      "        [5.8656e-04, 1.9266e-04, 2.0007e-04, 4.4314e-04, 9.1488e-05, 7.1765e-07,\n",
      "         3.4122e-06, 6.6365e-05],\n",
      "        [3.0135e-03, 5.0201e-04, 7.1783e-04, 2.2676e-03, 2.6463e-04, 1.0784e-05,\n",
      "         3.0659e-05, 3.2235e-04],\n",
      "        [4.3812e-04, 4.8912e-05, 8.7226e-05, 3.1521e-04, 3.0812e-05, 1.9041e-06,\n",
      "         4.6600e-06, 3.6746e-05],\n",
      "        [4.8564e-04, 1.2653e-04, 1.6989e-04, 4.2312e-04, 6.0649e-05, 1.1835e-06,\n",
      "         6.4822e-06, 1.2085e-04],\n",
      "        [4.7236e-04, 1.2660e-04, 1.5031e-04, 3.6740e-04, 6.2559e-05, 5.1338e-07,\n",
      "         4.4187e-06, 6.7003e-05],\n",
      "        [3.4451e-04, 8.4548e-05, 8.9276e-05, 2.6624e-04, 3.4815e-05, 1.8637e-06,\n",
      "         8.4239e-06, 5.9905e-05],\n",
      "        [2.9570e-04, 7.3374e-05, 9.5943e-05, 2.4275e-04, 3.6562e-05, 3.8735e-07,\n",
      "         3.6862e-06, 5.7838e-05]])}, 34: {'step': tensor(11460.), 'exp_avg': tensor([-2.5016e-04,  1.2225e-04, -1.2821e-04, -6.6586e-05, -5.1686e-04,\n",
      "        -3.1951e-05, -3.6634e-04, -5.0898e-05,  3.0701e-04, -5.8253e-04,\n",
      "        -3.0986e-03, -2.2664e-04, -1.7173e-04, -2.8905e-04, -4.6944e-04,\n",
      "         1.8295e-06, -1.4351e-04,  4.5236e-05, -2.6772e-04, -3.4560e-04,\n",
      "         1.5220e-03,  4.3256e-04, -1.1687e-04,  6.4076e-05,  5.4123e-05]), 'exp_avg_sq': tensor([6.6927e-06, 1.4237e-05, 3.9658e-06, 8.2582e-06, 7.6178e-06, 1.6542e-05,\n",
      "        2.6188e-05, 9.9896e-06, 3.6810e-05, 1.2902e-05, 2.4426e-04, 4.3278e-06,\n",
      "        2.2914e-06, 2.5054e-06, 3.8584e-06, 4.7870e-05, 5.9893e-06, 2.8449e-05,\n",
      "        3.1975e-06, 1.7336e-05, 8.1545e-04, 7.5854e-05, 9.1678e-06, 2.6391e-05,\n",
      "        2.1461e-05])}, 35: {'step': tensor(11460.), 'exp_avg': tensor([-4.8007e-11, -2.6607e-11,  1.9768e-12, -3.5870e-12, -1.5451e-10,\n",
      "         5.4189e-11,  9.7917e-12,  2.6983e-11,  2.7531e-11, -3.7943e-11,\n",
      "         1.6830e-10,  6.5373e-11,  6.3911e-11, -3.8476e-11, -2.2835e-12,\n",
      "         5.2535e-11, -5.2624e-11, -3.3052e-11, -1.2615e-10, -1.1994e-11,\n",
      "        -1.2360e-11, -1.5321e-10,  2.1682e-12,  1.1088e-10,  2.6812e-11]), 'exp_avg_sq': tensor([1.7612e-18, 1.9278e-18, 1.9477e-18, 1.4966e-18, 4.7080e-18, 4.3864e-18,\n",
      "        8.2812e-18, 1.8618e-18, 1.8639e-18, 8.7004e-18, 1.4121e-17, 1.2227e-18,\n",
      "        2.2418e-18, 2.0407e-18, 4.0519e-18, 1.1476e-17, 6.0144e-19, 7.2432e-18,\n",
      "        2.8779e-18, 7.4022e-18, 3.3679e-17, 2.1500e-17, 1.3925e-18, 8.6420e-18,\n",
      "        7.6765e-18])}, 36: {'step': tensor(11460.), 'exp_avg': tensor([-0.0328, -0.0256, -0.0064,  0.0185,  0.0262, -0.0049,  0.0150, -0.0297,\n",
      "         0.0412,  0.0313, -0.0048, -0.0279]), 'exp_avg_sq': tensor([0.0307, 0.0184, 0.0111, 0.0379, 0.0850, 0.0532, 0.0247, 0.0129, 0.0597,\n",
      "        0.0156, 0.0919, 0.0357])}, 37: {'step': tensor(11460.), 'exp_avg': tensor([[ 0.0926,  0.1773,  0.0839, -0.0135,  0.1159,  0.2935, -0.7258, -0.0151],\n",
      "        [-0.0727, -0.0349, -0.0268, -0.0948,  0.1733,  0.0274, -0.1475,  0.1801],\n",
      "        [ 0.0203,  0.0432,  0.0279, -0.0110,  0.0288,  0.0708, -0.1803,  0.0017],\n",
      "        [-0.1356, -0.1963, -0.0979, -0.0465, -0.0042, -0.2713,  0.6171,  0.1279],\n",
      "        [ 0.1489,  0.1027,  0.0463,  0.1784, -0.2649,  0.0272,  0.0804, -0.3205],\n",
      "        [ 0.0931,  0.1191,  0.0625,  0.0468, -0.0335,  0.1493, -0.3233, -0.1114],\n",
      "        [-0.0231, -0.0652, -0.0385,  0.0284, -0.0686, -0.1183,  0.3071, -0.0253],\n",
      "        [-0.0112,  0.0298, -0.0067, -0.0414,  0.1347,  0.1008, -0.2893,  0.0895],\n",
      "        [-0.1512, -0.2646, -0.1337, -0.0032, -0.1119, -0.4110,  0.9918,  0.0721],\n",
      "        [-0.0916, -0.1577, -0.0641, -0.0128, -0.0851, -0.2540,  0.6169,  0.0401],\n",
      "        [ 0.0994,  0.1514,  0.1020,  0.0131, -0.0109,  0.2003, -0.4613, -0.0913],\n",
      "        [ 0.0311,  0.0950,  0.0451, -0.0434,  0.1264,  0.1853, -0.4857,  0.0522]]), 'exp_avg_sq': tensor([[0.2142, 0.1821, 0.1065, 0.5345, 0.6024, 0.3816, 2.6109, 0.9534],\n",
      "        [0.0849, 0.0606, 0.0386, 0.1813, 0.2294, 0.0989, 0.6807, 0.3645],\n",
      "        [0.0532, 0.0381, 0.0249, 0.0944, 0.1398, 0.0440, 0.2581, 0.2195],\n",
      "        [0.3149, 0.2456, 0.1463, 0.9475, 0.8311, 0.5249, 3.4792, 1.5148],\n",
      "        [0.7216, 0.4861, 0.2857, 1.6042, 1.9801, 0.7482, 4.9161, 3.2543],\n",
      "        [0.2210, 0.1532, 0.0973, 0.4449, 0.4299, 0.2105, 1.3746, 0.8536],\n",
      "        [0.1158, 0.0791, 0.0505, 0.2488, 0.2686, 0.1068, 0.6729, 0.4871],\n",
      "        [0.0802, 0.0635, 0.0285, 0.1452, 0.2783, 0.1242, 0.8891, 0.3567],\n",
      "        [0.5856, 0.4475, 0.2807, 1.6559, 1.5296, 0.8903, 5.9468, 2.7490],\n",
      "        [0.1533, 0.1303, 0.0689, 0.3976, 0.5137, 0.3016, 2.1193, 0.7345],\n",
      "        [0.4810, 0.3529, 0.2328, 1.1330, 1.0655, 0.5631, 3.6020, 2.0283],\n",
      "        [0.1089, 0.0827, 0.0467, 0.2064, 0.3451, 0.1591, 1.1426, 0.4765]])}, 38: {'step': tensor(11460.), 'exp_avg': tensor([-2.5289e-04,  7.3844e-04, -8.9844e-06,  1.3570e-04, -2.3559e-04,\n",
      "        -4.9348e-05, -9.5969e-04,  2.5931e-05,  7.3024e-04, -8.4686e-04,\n",
      "        -1.2102e-03, -2.3758e-04, -9.3102e-05, -2.9150e-04, -2.6796e-04,\n",
      "        -2.4090e-04,  1.0220e-04,  6.7389e-04, -2.0337e-04, -9.1142e-04,\n",
      "         5.2739e-03,  1.0506e-03, -5.6278e-06,  8.6270e-04,  8.5961e-05]), 'exp_avg_sq': tensor([2.9919e-05, 5.4796e-05, 1.8782e-05, 2.6141e-05, 1.3661e-04, 4.7010e-05,\n",
      "        6.7674e-04, 3.1664e-05, 2.6314e-04, 2.0040e-04, 8.3461e-04, 2.1026e-05,\n",
      "        4.7627e-05, 4.0435e-05, 5.1159e-05, 1.0145e-04, 1.6746e-05, 8.4184e-05,\n",
      "        7.8859e-05, 4.6565e-04, 1.2599e-03, 2.0271e-04, 2.9169e-05, 8.5686e-05,\n",
      "        6.1606e-05])}, 39: {'step': tensor(11460.), 'exp_avg': tensor([-1.6982e-03, -3.2574e-03, -1.3521e-03, -2.2670e-03,  2.0117e-05,\n",
      "        -2.9306e-03,  2.9994e-02, -2.2899e-03, -2.7628e-03,  2.9239e-02,\n",
      "        -1.6588e-01, -1.6030e-03, -7.0561e-04, -7.7458e-04, -1.6960e-03,\n",
      "        -2.8069e-03, -2.7657e-03, -3.3802e-03,  1.2195e-04,  2.9170e-02,\n",
      "        -3.2562e-02, -1.4605e-03, -2.5194e-03, -2.8079e-03, -4.5339e-03]), 'exp_avg_sq': tensor([0.0026, 0.0033, 0.0031, 0.0027, 0.0084, 0.0026, 0.3291, 0.0026, 0.0335,\n",
      "        0.0204, 0.5746, 0.0027, 0.0036, 0.0030, 0.0032, 0.0046, 0.0029, 0.0029,\n",
      "        0.0043, 0.0439, 0.1561, 0.0055, 0.0026, 0.0030, 0.0028])}, 40: {'step': tensor(11460.), 'exp_avg': tensor([ 0.2273, -0.0984,  0.1255,  0.1875, -0.1582,  0.1931, -0.0855,  0.1158,\n",
      "         0.0132, -0.2554, -0.1626, -0.1023]), 'exp_avg_sq': tensor([0.4212, 0.1728, 0.8184, 1.3617, 0.2134, 0.2722, 0.1533, 0.2641, 0.1774,\n",
      "        0.8668, 0.2763, 0.3366])}, 41: {'step': tensor(11460.), 'exp_avg': tensor([[-0.3682, -0.1086, -0.0791, -0.3241,  0.0330, -0.2241, -0.0675,  0.3682,\n",
      "          0.3908, -0.2888,  0.2966,  0.4060],\n",
      "        [ 0.1723,  0.0333, -0.0152,  0.0262, -0.0439,  0.0858,  0.0280, -0.1024,\n",
      "         -0.0755,  0.1024, -0.0978, -0.1296],\n",
      "        [-0.1525, -0.0048,  0.0683,  0.1072,  0.0807, -0.0467, -0.0487,  0.0249,\n",
      "         -0.0214, -0.0685,  0.0531,  0.0335],\n",
      "        [-0.2679, -0.0295,  0.0672,  0.0607,  0.1075, -0.1066, -0.0757,  0.1115,\n",
      "          0.0601, -0.1472,  0.1284,  0.1275],\n",
      "        [ 0.3612,  0.0449, -0.1307, -0.1865, -0.1254,  0.1548,  0.0156, -0.0692,\n",
      "          0.0784,  0.1395, -0.1200, -0.1859],\n",
      "        [-0.3470, -0.0704,  0.0251, -0.0694,  0.0863, -0.1810, -0.0560,  0.2191,\n",
      "          0.1642, -0.2094,  0.1988,  0.2693],\n",
      "        [ 0.1615,  0.0311, -0.0124,  0.0341, -0.0456,  0.0836,  0.0356, -0.1068,\n",
      "         -0.0854,  0.1009, -0.0927, -0.1176],\n",
      "        [-0.2717, -0.0583,  0.0311, -0.0196,  0.0535, -0.1432, -0.0059,  0.1381,\n",
      "          0.0693, -0.1421,  0.1397,  0.2238],\n",
      "        [-0.0744, -0.0177,  0.0115,  0.0019,  0.0108, -0.0424,  0.0093,  0.0311,\n",
      "          0.0036, -0.0330,  0.0327,  0.0658],\n",
      "        [ 0.3729,  0.0761,  0.0010,  0.1430, -0.0936,  0.1893,  0.0986, -0.2804,\n",
      "         -0.2666,  0.2579, -0.2474, -0.2953],\n",
      "        [ 0.2951,  0.0677, -0.0072,  0.0854, -0.0523,  0.1576,  0.0273, -0.1899,\n",
      "         -0.1464,  0.1791, -0.1794, -0.2607],\n",
      "        [ 0.1188,  0.0363,  0.0402,  0.1412, -0.0109,  0.0729,  0.0393, -0.1442,\n",
      "         -0.1712,  0.1092, -0.1121, -0.1367]]), 'exp_avg_sq': tensor([[3.9901, 0.2421, 0.1937, 1.0245, 0.1964, 0.9753, 0.2953, 1.0469, 0.9370,\n",
      "         1.0655, 1.2560, 3.8949],\n",
      "        [0.4149, 0.0187, 0.0403, 0.2118, 0.0463, 0.1066, 0.0302, 0.1567, 0.1522,\n",
      "         0.1149, 0.1125, 0.2870],\n",
      "        [3.5139, 0.1360, 0.5573, 1.9895, 0.4690, 0.7394, 0.1931, 0.7536, 1.0928,\n",
      "         0.7990, 0.8102, 2.2038],\n",
      "        [5.3420, 0.2292, 0.7519, 2.8949, 0.7002, 1.2213, 0.3338, 1.4119, 1.7378,\n",
      "         1.3320, 1.3541, 3.6231],\n",
      "        [1.3659, 0.0669, 0.0939, 0.3759, 0.0974, 0.3289, 0.0749, 0.3274, 0.2856,\n",
      "         0.3438, 0.3738, 1.0806],\n",
      "        [1.0846, 0.0432, 0.1048, 0.3552, 0.1281, 0.2498, 0.0711, 0.2506, 0.2184,\n",
      "         0.2711, 0.2650, 0.7044],\n",
      "        [0.4510, 0.0156, 0.0315, 0.1082, 0.0441, 0.1102, 0.0182, 0.1183, 0.0766,\n",
      "         0.1181, 0.1068, 0.2475],\n",
      "        [1.0191, 0.0443, 0.1632, 0.6157, 0.1414, 0.2156, 0.0686, 0.2192, 0.3215,\n",
      "         0.2227, 0.2422, 0.7176],\n",
      "        [0.6372, 0.0270, 0.1077, 0.4304, 0.0814, 0.1338, 0.0309, 0.1435, 0.2301,\n",
      "         0.1369, 0.1508, 0.4349],\n",
      "        [4.9165, 0.2194, 0.4856, 1.7796, 0.4579, 1.1294, 0.2720, 1.1789, 1.2305,\n",
      "         1.2455, 1.2935, 3.5398],\n",
      "        [1.1562, 0.0665, 0.0853, 0.4637, 0.0786, 0.2743, 0.0863, 0.3241, 0.3384,\n",
      "         0.2963, 0.3489, 1.0676],\n",
      "        [1.8381, 0.1010, 0.1298, 0.6651, 0.1036, 0.4266, 0.1202, 0.4705, 0.4956,\n",
      "         0.4561, 0.5337, 1.6340]])}, 42: {'step': tensor(11460.), 'exp_avg': tensor([ 3.6700e-04,  1.4650e-03,  6.7338e-04,  8.3899e-04,  2.6562e-04,\n",
      "         7.7619e-04,  1.0902e-04,  7.8923e-04,  1.4772e-03, -4.0210e-04,\n",
      "         1.6112e-03,  4.0989e-04,  5.9354e-04,  3.1980e-04,  1.1239e-04,\n",
      "         6.7274e-04,  7.9634e-04,  1.5117e-03,  4.2892e-04, -6.8140e-05,\n",
      "         5.8747e-03,  1.6975e-03,  7.3040e-04,  1.6151e-03,  1.1647e-03]), 'exp_avg_sq': tensor([2.9976e-05, 5.3940e-05, 2.5552e-05, 3.0943e-05, 1.4216e-04, 5.3615e-05,\n",
      "        6.5357e-04, 3.5777e-05, 1.8896e-04, 2.1486e-04, 1.4857e-03, 2.4645e-05,\n",
      "        5.4912e-05, 4.1838e-05, 5.5862e-05, 1.2006e-04, 2.3334e-05, 1.0128e-04,\n",
      "        8.4011e-05, 4.7965e-04, 1.7640e-03, 2.3976e-04, 3.2573e-05, 9.5584e-05,\n",
      "        7.1410e-05])}, 43: {'step': tensor(11460.), 'exp_avg': tensor([-0.0182, -0.0216, -0.0180, -0.0199, -0.0238, -0.0222,  0.0546, -0.0206,\n",
      "        -0.0123, -0.0052, -0.3415, -0.0186, -0.0174, -0.0178, -0.0205, -0.0205,\n",
      "        -0.0207, -0.0213, -0.0170,  0.0153, -0.1174, -0.0235, -0.0206, -0.0205,\n",
      "        -0.0241]), 'exp_avg_sq': tensor([0.0150, 0.0177, 0.0170, 0.0158, 0.0329, 0.0147, 0.5158, 0.0152, 0.0917,\n",
      "        0.0569, 1.1801, 0.0155, 0.0190, 0.0167, 0.0174, 0.0165, 0.0166, 0.0155,\n",
      "        0.0213, 0.1039, 0.5460, 0.0190, 0.0154, 0.0161, 0.0154])}, 44: {'step': tensor(11460.), 'exp_avg': tensor([ 0.1744, -0.0408, -0.1847, -0.0711, -0.0762,  0.1442, -0.1648,  0.3904,\n",
      "         0.2910, -0.1248,  0.1147, -0.2232,  0.0734, -0.2309,  0.0644, -0.1359]), 'exp_avg_sq': tensor([0.2988, 0.5010, 1.1416, 0.4343, 0.1715, 0.7299, 0.5960, 1.2553, 0.9006,\n",
      "        0.2715, 0.1140, 1.1904, 0.1698, 0.3724, 0.4338, 0.3942])}, 45: {'step': tensor(11460.), 'exp_avg': tensor([[ 0.1983,  0.0775,  0.0963, -0.0733, -0.1754, -0.3444, -0.1533,  0.2325,\n",
      "         -0.0417,  0.0429,  0.3708, -0.1815],\n",
      "        [-0.0755, -0.0244, -0.0214,  0.0042,  0.0561,  0.1008,  0.0554, -0.0652,\n",
      "          0.0517, -0.0412, -0.1114,  0.0637],\n",
      "        [-0.1758, -0.0008, -0.0445,  0.0150,  0.1417,  0.3106,  0.1583, -0.2188,\n",
      "         -0.0098, -0.0288, -0.3054,  0.1007],\n",
      "        [-0.0676, -0.0208, -0.0362,  0.0276,  0.0621,  0.1266,  0.0567, -0.0872,\n",
      "          0.0029, -0.0054, -0.1361,  0.0542],\n",
      "        [-0.1097,  0.1469,  0.1159, -0.1925,  0.0118,  0.0651,  0.1255, -0.0481,\n",
      "          0.0741, -0.1156, -0.0116, -0.0735],\n",
      "        [ 0.1262,  0.0480,  0.0752, -0.0709, -0.1241, -0.2579, -0.1041,  0.1802,\n",
      "          0.0248, -0.0047,  0.2707, -0.1158],\n",
      "        [-0.1564, -0.1267, -0.1444,  0.1627,  0.1797,  0.3533,  0.1107, -0.2431,\n",
      "         -0.0400,  0.0288, -0.3885,  0.2096],\n",
      "        [ 0.4552, -0.1720, -0.0726,  0.2292, -0.2615, -0.6071, -0.4338,  0.4248,\n",
      "         -0.1273,  0.2270,  0.5369, -0.0990],\n",
      "        [ 0.3095,  0.0739,  0.1227, -0.0816, -0.2653, -0.5435, -0.2551,  0.3741,\n",
      "         -0.0292,  0.0583,  0.5644, -0.2420],\n",
      "        [-0.1477, -0.0609, -0.0722,  0.0572,  0.1314,  0.2569,  0.1125, -0.1736,\n",
      "          0.0302, -0.0321, -0.2760,  0.1398],\n",
      "        [ 0.1318, -0.0604, -0.0307,  0.0788, -0.0711, -0.1705, -0.1277,  0.1195,\n",
      "         -0.0367,  0.0699,  0.1452, -0.0198],\n",
      "        [-0.2279,  0.0764,  0.0187, -0.0944,  0.1394,  0.3230,  0.2188, -0.2260,\n",
      "          0.0496, -0.0983, -0.2953,  0.0545],\n",
      "        [ 0.0982, -0.0906, -0.0651,  0.1167, -0.0317, -0.0932, -0.1044,  0.0674,\n",
      "         -0.0440,  0.0770,  0.0582,  0.0268],\n",
      "        [-0.2642,  0.0205, -0.0261, -0.0389,  0.1856,  0.4002,  0.2337, -0.2763,\n",
      "          0.0577, -0.0974, -0.3875,  0.1307],\n",
      "        [ 0.0583, -0.0143,  0.0024,  0.0154, -0.0391, -0.0894, -0.0559,  0.0624,\n",
      "         -0.0085,  0.0197,  0.0854, -0.0175],\n",
      "        [-0.1527,  0.1278,  0.0821, -0.1552,  0.0601,  0.1695,  0.1625, -0.1226,\n",
      "          0.0460, -0.1002, -0.1200, -0.0308]]), 'exp_avg_sq': tensor([[0.6714, 0.4916, 0.3479, 0.5509, 0.3254, 1.0961, 0.4871, 0.4233, 0.6901,\n",
      "         0.2861, 1.4403, 0.5320],\n",
      "        [0.8324, 0.8703, 0.5413, 1.1432, 0.2729, 1.0921, 0.7604, 0.4489, 0.6178,\n",
      "         0.4442, 1.2426, 0.5216],\n",
      "        [2.1734, 1.6258, 1.0356, 2.1975, 0.7921, 3.2223, 1.8349, 1.3396, 1.5066,\n",
      "         1.0266, 3.5776, 1.1951],\n",
      "        [0.8680, 0.7387, 0.4833, 0.9503, 0.3410, 1.2817, 0.7179, 0.5190, 0.6965,\n",
      "         0.4149, 1.5347, 0.5679],\n",
      "        [0.5427, 0.2918, 0.2117, 0.3309, 0.2473, 0.8678, 0.3832, 0.3308, 0.5279,\n",
      "         0.2212, 1.1024, 0.3480],\n",
      "        [1.6896, 1.1057, 0.7341, 1.4489, 0.6691, 2.5270, 1.3347, 1.0057, 1.3915,\n",
      "         0.7796, 3.0051, 0.9820],\n",
      "        [1.6247, 0.8165, 0.5895, 0.9181, 0.7494, 2.7270, 1.1731, 1.0783, 1.4426,\n",
      "         0.6332, 3.3463, 1.0032],\n",
      "        [2.2495, 1.0073, 0.6221, 1.4557, 0.7972, 3.7575, 1.8584, 1.6519, 1.0495,\n",
      "         0.8596, 3.6051, 0.8115],\n",
      "        [2.2562, 1.1368, 0.7998, 1.3688, 0.9903, 3.7493, 1.6717, 1.5082, 1.8287,\n",
      "         0.8933, 4.4444, 1.2932],\n",
      "        [0.4299, 0.4110, 0.2663, 0.5041, 0.1728, 0.6380, 0.3628, 0.2608, 0.3734,\n",
      "         0.2078, 0.7659, 0.3121],\n",
      "        [0.1935, 0.0952, 0.0553, 0.1378, 0.0630, 0.3057, 0.1656, 0.1359, 0.0916,\n",
      "         0.0786, 0.2822, 0.0639],\n",
      "        [2.2687, 1.7178, 1.0898, 2.3280, 0.8095, 3.2535, 1.9146, 1.3336, 1.6423,\n",
      "         1.0946, 3.6534, 1.2428],\n",
      "        [0.2812, 0.1470, 0.0976, 0.1947, 0.1165, 0.4551, 0.2071, 0.1859, 0.2507,\n",
      "         0.1156, 0.5225, 0.1604],\n",
      "        [0.7012, 0.2986, 0.1915, 0.3905, 0.2678, 1.1807, 0.5584, 0.5038, 0.3981,\n",
      "         0.2584, 1.2126, 0.2848],\n",
      "        [0.5334, 0.4642, 0.2920, 0.6648, 0.1840, 0.6820, 0.4488, 0.2832, 0.5160,\n",
      "         0.2935, 0.8186, 0.3257],\n",
      "        [0.6001, 0.3949, 0.2444, 0.5564, 0.2107, 0.9101, 0.5138, 0.3981, 0.3747,\n",
      "         0.2735, 0.9355, 0.2806]])}, 46: {'step': tensor(11460.), 'exp_avg': tensor([-1.4583e-03,  9.6806e-04, -4.4397e-04, -8.7713e-05, -2.5045e-03,\n",
      "        -1.3474e-04, -1.5385e-03, -1.4274e-04,  8.6741e-04, -2.7387e-03,\n",
      "        -2.4832e-03, -1.2840e-03, -7.6677e-04, -1.6618e-03, -2.6124e-03,\n",
      "        -1.1659e-04, -5.8922e-04,  1.3223e-03, -1.4472e-03, -1.6094e-03,\n",
      "         2.5114e-03,  2.2211e-03, -4.9440e-04,  1.4654e-03,  4.8960e-04]), 'exp_avg_sq': tensor([8.2617e-05, 1.1779e-04, 7.4501e-05, 6.3286e-05, 5.5719e-04, 2.5886e-04,\n",
      "        6.5228e-04, 9.6540e-05, 1.2072e-04, 7.3012e-04, 8.1292e-04, 7.0071e-05,\n",
      "        2.1665e-04, 1.6547e-04, 3.0379e-04, 5.7708e-04, 4.5447e-05, 5.5499e-04,\n",
      "        3.4264e-04, 6.5799e-04, 1.3669e-03, 9.5021e-04, 7.6686e-05, 4.6249e-04,\n",
      "        3.7302e-04])}, 47: {'step': tensor(11460.), 'exp_avg': tensor([-0.0135, -0.0123, -0.0135, -0.0134, -0.0128, -0.0121, -0.0128, -0.0126,\n",
      "        -0.0123, -0.0128, -0.0126, -0.0133, -0.0133, -0.0131, -0.0129, -0.0118,\n",
      "        -0.0136, -0.0125, -0.0130, -0.0129, -0.0127, -0.0117, -0.0133, -0.0125,\n",
      "        -0.0121]), 'exp_avg_sq': tensor([0.0064, 0.0064, 0.0064, 0.0064, 0.0066, 0.0064, 0.0065, 0.0064, 0.0063,\n",
      "        0.0066, 0.0065, 0.0064, 0.0065, 0.0065, 0.0065, 0.0064, 0.0064, 0.0064,\n",
      "        0.0065, 0.0065, 0.0063, 0.0064, 0.0064, 0.0064, 0.0064])}, 48: {'step': tensor(11460.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 49: {'step': tensor(11460.), 'exp_avg': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'exp_avg_sq': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])}, 50: {'step': tensor(11460.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 51: {'step': tensor(11460.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 52: {'step': tensor(11460.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 53: {'step': tensor(11460.), 'exp_avg': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'exp_avg_sq': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])}, 54: {'step': tensor(11460.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 55: {'step': tensor(11460.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 56: {'step': tensor(11460.), 'exp_avg': tensor([0.]), 'exp_avg_sq': tensor([0.])}, 57: {'step': tensor(11460.), 'exp_avg': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'exp_avg_sq': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])}, 60: {'step': tensor(11460.), 'exp_avg': tensor([-0.0716, -0.0728,  0.0136, -0.0979,  0.0953,  0.0010,  0.0558, -0.0232,\n",
      "        -0.0370, -0.0283,  0.0565,  0.0780,  0.0273,  0.0077, -0.0253,  0.0208]), 'exp_avg_sq': tensor([0.0841, 0.0366, 0.0231, 0.1163, 0.0935, 0.0080, 0.0589, 0.0972, 0.0130,\n",
      "        0.0216, 0.0728, 0.0662, 0.0213, 0.0140, 0.0365, 0.0217])}, 61: {'step': tensor(11460.), 'exp_avg': tensor([[ 3.1995e-01,  1.1643e-01, -7.0010e-02,  2.0228e-01, -2.7234e-01,\n",
      "          7.6379e-02, -4.6928e-02, -2.2187e-01,  1.4332e-01,  4.4204e-02,\n",
      "         -4.7211e-02, -1.7351e-01,  8.4513e-02,  3.8112e-01, -2.3166e-01,\n",
      "         -2.2562e-01],\n",
      "        [ 2.7517e-01,  1.3179e-01,  2.4497e-02,  3.2237e-01, -3.1251e-01,\n",
      "          8.7197e-02, -7.2088e-02, -2.1584e-01,  1.2129e-01,  1.4379e-01,\n",
      "         -4.8536e-02, -2.4236e-01, -7.6695e-02,  2.6294e-01, -1.7567e-01,\n",
      "         -1.4594e-01],\n",
      "        [-8.2613e-02, -1.8347e-02,  5.0593e-02,  9.8391e-03,  4.3011e-02,\n",
      "         -8.3544e-03, -2.6324e-04,  4.5994e-02, -4.0068e-02,  2.7290e-02,\n",
      "          1.1069e-02,  5.4645e-03, -8.2283e-02, -1.1936e-01,  6.9536e-02,\n",
      "          7.2736e-02],\n",
      "        [ 4.1960e-01,  1.6156e-01, -6.9376e-02,  3.1845e-01, -3.7584e-01,\n",
      "          1.1219e-01, -7.1009e-02, -3.0194e-01,  1.8567e-01,  8.6597e-02,\n",
      "         -5.9412e-02, -2.6230e-01,  6.5062e-02,  4.9357e-01, -3.0237e-01,\n",
      "         -2.9311e-01],\n",
      "        [-3.9576e-01, -1.6857e-01,  2.5503e-02, -3.6466e-01,  3.9404e-01,\n",
      "         -1.1255e-01,  8.2398e-02,  2.9507e-01, -1.7569e-01, -1.3310e-01,\n",
      "          6.2265e-02,  2.8749e-01,  5.6103e-03, -4.3110e-01,  2.7489e-01,\n",
      "          2.5005e-01],\n",
      "        [ 2.3903e-02,  9.1044e-03, -1.2610e-02, -1.9160e-02, -2.3735e-02,\n",
      "         -8.7985e-03, -1.2124e-03, -7.9148e-03,  1.8580e-02,  1.1237e-03,\n",
      "         -1.1634e-02,  9.6305e-03,  3.1991e-02,  1.7863e-02, -2.1291e-02,\n",
      "         -5.0521e-03],\n",
      "        [-2.8906e-01, -9.8150e-02,  8.8212e-02, -1.0742e-01,  2.3608e-01,\n",
      "         -4.4825e-02,  3.2130e-02,  1.8315e-01, -1.4050e-01, -1.6319e-02,\n",
      "          5.2210e-02,  1.0706e-01, -1.3817e-01, -3.3924e-01,  2.1610e-01,\n",
      "          1.9441e-01],\n",
      "        [ 1.2524e-01,  2.8788e-02, -6.5261e-02,  1.5279e-03, -7.0073e-02,\n",
      "          1.6335e-02, -2.0619e-03, -7.2117e-02,  5.5841e-02, -3.4913e-02,\n",
      "         -1.7684e-02, -1.7208e-02,  1.0357e-01,  1.6953e-01, -9.3259e-02,\n",
      "         -1.0251e-01],\n",
      "        [ 1.2266e-01,  6.2814e-02,  2.5384e-02,  1.7960e-01, -1.4743e-01,\n",
      "          4.8893e-02, -3.7525e-02, -1.0369e-01,  4.9851e-02,  7.8865e-02,\n",
      "         -1.8789e-02, -1.3128e-01, -6.6080e-02,  1.1389e-01, -7.3012e-02,\n",
      "         -6.4538e-02],\n",
      "        [ 2.1739e-01,  6.4367e-02, -1.1370e-01, -1.4902e-02, -1.5081e-01,\n",
      "          9.8549e-03, -1.0101e-02, -1.1993e-01,  1.1982e-01, -2.9102e-02,\n",
      "         -4.2886e-02, -2.1871e-02,  1.9965e-01,  2.8159e-01, -1.9081e-01,\n",
      "         -1.6156e-01],\n",
      "        [-2.0720e-01, -8.8491e-02, -1.3239e-03, -2.2481e-01,  2.0794e-01,\n",
      "         -7.0675e-02,  4.6483e-02,  1.6134e-01, -8.2525e-02, -7.6007e-02,\n",
      "          2.8911e-02,  1.7106e-01,  3.7125e-02, -2.2041e-01,  1.2887e-01,\n",
      "          1.2990e-01],\n",
      "        [-3.0212e-01, -1.2803e-01,  1.6010e-02, -3.0463e-01,  2.9648e-01,\n",
      "         -9.7932e-02,  6.4247e-02,  2.3233e-01, -1.2858e-01, -1.0196e-01,\n",
      "          3.9990e-02,  2.3733e-01,  2.1487e-02, -3.4169e-01,  2.0964e-01,\n",
      "          2.0350e-01],\n",
      "        [-1.7200e-01, -4.6402e-02,  9.2167e-02,  9.7398e-04,  1.0785e-01,\n",
      "         -1.6933e-02,  5.9855e-03,  9.8552e-02, -8.8009e-02,  3.3302e-02,\n",
      "          2.7025e-02,  2.4441e-02, -1.5204e-01, -2.3532e-01,  1.4694e-01,\n",
      "          1.4014e-01],\n",
      "        [-6.7442e-02, -2.7080e-02,  2.0833e-02, -6.7139e-03,  6.6716e-02,\n",
      "          1.4690e-03,  8.5712e-03,  3.7154e-02, -4.1957e-02, -1.3398e-02,\n",
      "          2.0232e-02,  1.3074e-02, -4.4695e-02, -6.5653e-02,  5.6205e-02,\n",
      "          3.1408e-02],\n",
      "        [ 1.9942e-01,  5.3865e-02, -1.1744e-01, -3.1483e-02, -1.2545e-01,\n",
      "          8.0819e-03, -4.3637e-03, -1.0766e-01,  1.0971e-01, -4.3105e-02,\n",
      "         -3.6128e-02, -9.2031e-03,  2.0399e-01,  2.7255e-01, -1.8043e-01,\n",
      "         -1.5942e-01],\n",
      "        [-1.8714e-01, -5.3643e-02,  1.0652e-01,  3.8735e-02,  1.2607e-01,\n",
      "         -3.3478e-04,  5.7384e-03,  9.7381e-02, -1.0675e-01,  3.2741e-02,\n",
      "          4.0578e-02,  2.1700e-03, -1.9304e-01, -2.4030e-01,  1.6631e-01,\n",
      "          1.3561e-01]]), 'exp_avg_sq': tensor([[2.5124, 0.4805, 0.1856, 1.9767, 3.5286, 0.1869, 0.1114, 0.9822, 0.7706,\n",
      "         0.5687, 0.3350, 1.0072, 0.9810, 1.6203, 1.1300, 0.4834],\n",
      "        [1.0520, 0.2102, 0.0686, 0.8355, 1.4786, 0.0793, 0.0492, 0.4291, 0.3164,\n",
      "         0.2430, 0.1374, 0.4395, 0.3516, 0.7236, 0.4981, 0.2242],\n",
      "        [0.9620, 0.1827, 0.0736, 0.5804, 1.4049, 0.0627, 0.0393, 0.3329, 0.3161,\n",
      "         0.2025, 0.1538, 0.2850, 0.3915, 0.5327, 0.4305, 0.1490],\n",
      "        [2.9399, 0.5669, 0.1882, 2.5323, 3.9987, 0.2299, 0.1363, 1.2485, 0.8496,\n",
      "         0.6688, 0.3364, 1.3415, 0.9471, 2.1484, 1.3409, 0.6831],\n",
      "        [1.8897, 0.3653, 0.1323, 1.7235, 2.4629, 0.1572, 0.0883, 0.8535, 0.5282,\n",
      "         0.4292, 0.1864, 0.9357, 0.5506, 1.6396, 0.9417, 0.5570],\n",
      "        [0.1249, 0.0271, 0.0189, 0.1418, 0.1874, 0.0142, 0.0067, 0.0514, 0.0383,\n",
      "         0.0375, 0.0217, 0.0647, 0.0789, 0.0833, 0.0562, 0.0300],\n",
      "        [2.5702, 0.4845, 0.1851, 1.5197, 3.7521, 0.1599, 0.1036, 0.8896, 0.8426,\n",
      "         0.5328, 0.4076, 0.7439, 1.0015, 1.4084, 1.1430, 0.3889],\n",
      "        [2.9800, 0.5824, 0.3009, 2.6317, 4.4168, 0.2358, 0.1397, 1.1149, 0.9470,\n",
      "         0.7734, 0.4527, 1.2316, 1.5668, 1.6237, 1.2715, 0.4456],\n",
      "        [0.2997, 0.0597, 0.0232, 0.2795, 0.4145, 0.0266, 0.0143, 0.1281, 0.0873,\n",
      "         0.0720, 0.0380, 0.1442, 0.1094, 0.2261, 0.1400, 0.0755],\n",
      "        [1.0141, 0.1903, 0.0685, 0.5761, 1.4805, 0.0743, 0.0406, 0.3422, 0.3462,\n",
      "         0.1955, 0.1750, 0.2887, 0.4201, 0.5630, 0.4802, 0.1609],\n",
      "        [2.0193, 0.4029, 0.1981, 1.8048, 2.8262, 0.1629, 0.0979, 0.8097, 0.6139,\n",
      "         0.5069, 0.2712, 0.8966, 0.9530, 1.3837, 0.9534, 0.4243],\n",
      "        [1.1219, 0.2208, 0.0618, 1.2238, 1.4652, 0.1059, 0.0568, 0.5505, 0.2903,\n",
      "         0.2749, 0.0902, 0.6682, 0.2844, 0.9832, 0.5225, 0.3379],\n",
      "        [1.2878, 0.2394, 0.0758, 0.5482, 1.8728, 0.0737, 0.0471, 0.4199, 0.4380,\n",
      "         0.2277, 0.2168, 0.2823, 0.4435, 0.7105, 0.6065, 0.1959],\n",
      "        [0.2368, 0.0497, 0.0439, 0.3535, 0.3553, 0.0317, 0.0145, 0.1023, 0.0738,\n",
      "         0.0855, 0.0360, 0.1629, 0.2047, 0.1631, 0.1107, 0.0543],\n",
      "        [1.6124, 0.3034, 0.1043, 0.8576, 2.2977, 0.1070, 0.0643, 0.5468, 0.5381,\n",
      "         0.3010, 0.2643, 0.4409, 0.6225, 0.9098, 0.7486, 0.2530],\n",
      "        [1.1318, 0.2116, 0.0720, 0.5233, 1.6428, 0.0765, 0.0431, 0.3639, 0.3907,\n",
      "         0.2001, 0.2041, 0.2646, 0.4367, 0.6164, 0.5282, 0.1760]])}, 62: {'step': tensor(11460.), 'exp_avg': tensor([-0.0016,  0.0009, -0.0014, -0.0011, -0.0050, -0.0015, -0.0010, -0.0010,\n",
      "        -0.0015, -0.0011]), 'exp_avg_sq': tensor([5.6264e-05, 7.5476e-04, 4.6044e-05, 5.5513e-05, 5.8363e-04, 3.8159e-05,\n",
      "        2.7692e-05, 3.7750e-05, 8.1003e-05, 2.3396e-05])}, 63: {'step': tensor(11460.), 'exp_avg': tensor([-0.0301, -0.0481,  0.0023, -0.0238, -0.0859, -0.0286, -0.0213, -0.0223,\n",
      "        -0.0030, -0.0217]), 'exp_avg_sq': tensor([0.0519, 0.2802, 0.0481, 0.0361, 0.2848, 0.0432, 0.0363, 0.0357, 0.0516,\n",
      "        0.0362])}, 64: {'step': tensor(11460.), 'exp_avg': tensor([ 0.0552,  0.2175, -0.2411,  0.0928,  0.0076, -0.3228,  0.2561,  0.0650,\n",
      "         0.0084,  0.0147, -0.0881, -0.0039, -0.2160,  0.1218, -0.0667,  0.0994]), 'exp_avg_sq': tensor([0.5770, 0.4779, 0.5383, 0.1191, 0.3415, 1.4617, 0.6463, 0.1186, 0.3888,\n",
      "        0.1444, 0.2574, 0.3398, 0.3552, 0.2797, 0.3577, 0.6770])}, 65: {'step': tensor(11460.), 'exp_avg': tensor([[-2.1641e-01,  1.8605e-01, -1.7500e-02, -1.6024e-03,  2.7836e-01,\n",
      "         -1.9394e-01, -1.0802e-01,  1.1259e-01,  1.5890e-02, -8.8285e-02,\n",
      "          6.1718e-02, -1.3875e-01,  5.8235e-03,  1.3075e-02,  1.0051e-01,\n",
      "         -7.7014e-03],\n",
      "        [ 1.9743e-01,  2.1653e-01, -2.1452e-01, -3.3452e-01,  1.4271e-01,\n",
      "         -4.2240e-01,  1.8600e-01,  6.3579e-02,  3.6216e-01,  1.4947e-01,\n",
      "         -7.2480e-02,  9.7584e-02, -3.4462e-01, -6.4451e-02, -5.3456e-02,\n",
      "          9.3922e-02],\n",
      "        [-2.2416e-01, -2.3740e-01,  2.3581e-01,  3.6952e-01, -1.5335e-01,\n",
      "          4.5593e-01, -2.0213e-01, -6.2082e-02, -3.9616e-01, -1.6493e-01,\n",
      "          8.0302e-02, -1.1083e-01,  3.7870e-01,  7.5930e-02,  5.6888e-02,\n",
      "         -1.0529e-01],\n",
      "        [ 1.0591e-01,  8.0244e-02, -9.1550e-02, -1.4575e-01,  3.9700e-02,\n",
      "         -1.6235e-01,  8.6633e-02,  1.3859e-02,  1.5354e-01,  7.0843e-02,\n",
      "         -3.4864e-02,  5.3087e-02, -1.4844e-01, -3.3039e-02, -2.9562e-02,\n",
      "          4.2920e-02],\n",
      "        [ 5.7062e-02, -1.2463e-02, -1.8404e-02, -2.3541e-02, -2.9169e-02,\n",
      "          8.1788e-04,  3.1945e-02, -1.4668e-02,  1.7864e-02,  2.2663e-02,\n",
      "         -1.0952e-02,  2.2155e-02, -2.1773e-02, -1.2321e-02, -2.0992e-02,\n",
      "          1.2098e-02],\n",
      "        [-2.4747e-01, -3.3163e-01,  3.0713e-01,  4.8466e-01, -2.3242e-01,\n",
      "          6.4428e-01, -2.5982e-01, -1.1502e-01, -5.3880e-01, -2.1128e-01,\n",
      "          1.0628e-01, -1.3623e-01,  5.0778e-01,  7.8464e-02,  6.7382e-02,\n",
      "         -1.2748e-01],\n",
      "        [ 2.6732e-01,  2.3414e-01, -2.5575e-01, -3.9890e-01,  1.3449e-01,\n",
      "         -4.7821e-01,  2.3627e-01,  6.0752e-02,  4.2890e-01,  1.8962e-01,\n",
      "         -9.4216e-02,  1.3406e-01, -4.1166e-01, -8.0163e-02, -7.7197e-02,\n",
      "          1.1408e-01],\n",
      "        [-1.6880e-02,  1.1451e-01, -5.7597e-02, -7.8534e-02,  1.2890e-01,\n",
      "         -1.5154e-01,  2.6878e-03,  4.1633e-02,  7.9880e-02,  1.8455e-03,\n",
      "          8.7795e-03, -2.8997e-02, -7.1315e-02, -2.1166e-02,  2.4409e-02,\n",
      "          2.4673e-02],\n",
      "        [ 1.4197e-01, -5.7309e-02, -2.4367e-02, -6.1562e-02, -1.2253e-01,\n",
      "          2.5826e-02,  8.4765e-02, -4.9620e-02,  6.2869e-02,  7.5382e-02,\n",
      "         -5.1884e-02,  1.0060e-01, -7.1248e-02, -1.5142e-02, -5.6371e-02,\n",
      "          1.7813e-02],\n",
      "        [ 8.1483e-02, -3.1920e-02, -1.8933e-02, -4.5033e-02, -7.3311e-02,\n",
      "         -7.8851e-03,  6.3802e-02, -1.5555e-02,  5.6312e-02,  5.2480e-02,\n",
      "         -3.5372e-02,  6.4436e-02, -5.6805e-02,  5.1017e-05, -4.2308e-02,\n",
      "          8.0996e-03],\n",
      "        [-4.8523e-02, -1.2014e-01,  8.9767e-02,  1.2392e-01, -1.1454e-01,\n",
      "          1.8090e-01, -4.2685e-02, -3.2080e-02, -1.2155e-01, -3.2463e-02,\n",
      "          6.9066e-03,  1.3122e-03,  1.1601e-01,  3.7687e-02, -3.8180e-03,\n",
      "         -4.2563e-02],\n",
      "        [-9.4389e-02,  5.2828e-02,  1.2010e-02,  4.4172e-02,  1.0533e-01,\n",
      "         -9.1546e-03, -7.3447e-02,  2.4048e-02, -6.0067e-02, -6.3717e-02,\n",
      "          4.7303e-02, -8.6046e-02,  6.1743e-02, -5.7884e-03,  5.0565e-02,\n",
      "         -4.3726e-03],\n",
      "        [-1.7885e-01, -2.3543e-01,  2.1065e-01,  3.2339e-01, -1.7493e-01,\n",
      "          4.0919e-01, -1.5430e-01, -5.4969e-02, -3.3645e-01, -1.2797e-01,\n",
      "          5.7212e-02, -7.4019e-02,  3.2262e-01,  7.8022e-02,  3.0065e-02,\n",
      "         -9.7470e-02],\n",
      "        [ 2.0893e-01,  6.8468e-02, -1.3312e-01, -2.1787e-01, -1.5446e-02,\n",
      "         -2.0707e-01,  1.6515e-01,  3.1334e-03,  2.3518e-01,  1.3378e-01,\n",
      "         -7.4893e-02,  1.2124e-01, -2.3149e-01, -4.1964e-02, -7.4542e-02,\n",
      "          6.1798e-02],\n",
      "        [-2.6988e-01,  4.8614e-02,  9.0683e-02,  1.6947e-01,  1.6587e-01,\n",
      "          6.4675e-02, -1.8992e-01,  5.0854e-02, -1.8367e-01, -1.5508e-01,\n",
      "          9.5983e-02, -1.7496e-01,  1.8961e-01,  3.0868e-02,  1.1448e-01,\n",
      "         -4.7356e-02],\n",
      "        [ 2.3646e-01,  2.4911e-02, -1.1431e-01, -2.0783e-01, -7.9673e-02,\n",
      "         -1.4906e-01,  1.7306e-01, -2.6455e-02,  2.2411e-01,  1.4764e-01,\n",
      "         -8.9822e-02,  1.5536e-01, -2.2494e-01, -4.0062e-02, -8.6055e-02,\n",
      "          5.6834e-02]]), 'exp_avg_sq': tensor([[3.9486, 1.1178, 1.1060, 2.8095, 1.0916, 2.7001, 0.9450, 0.7760, 2.1040,\n",
      "         0.7166, 0.1198, 0.4985, 2.0876, 0.7592, 0.1833, 0.5176],\n",
      "        [0.7828, 0.5715, 0.4933, 1.1540, 0.3552, 1.6496, 0.3250, 0.1347, 1.1836,\n",
      "         0.2278, 0.0453, 0.1171, 1.0649, 0.1506, 0.0436, 0.1420],\n",
      "        [1.8491, 0.7651, 0.7576, 1.8318, 0.5263, 2.0549, 0.5559, 0.2997, 1.5995,\n",
      "         0.4136, 0.0784, 0.2468, 1.5254, 0.3656, 0.0889, 0.2878],\n",
      "        [0.5879, 0.1984, 0.1822, 0.4476, 0.1958, 0.4888, 0.1444, 0.1148, 0.3600,\n",
      "         0.1100, 0.0249, 0.0835, 0.3516, 0.1088, 0.0286, 0.0770],\n",
      "        [1.7377, 0.6436, 0.5247, 1.3207, 0.6391, 1.5036, 0.3947, 0.3626, 1.0174,\n",
      "         0.3088, 0.0538, 0.2215, 1.0003, 0.3425, 0.0771, 0.2397],\n",
      "        [2.8435, 1.9094, 1.6060, 3.7966, 1.2958, 5.3365, 1.0733, 0.5006, 3.7873,\n",
      "         0.7643, 0.1457, 0.4220, 3.4403, 0.5450, 0.1537, 0.4911],\n",
      "        [1.0482, 0.7785, 0.6174, 1.4627, 0.5459, 2.2144, 0.4012, 0.2240, 1.5112,\n",
      "         0.2870, 0.0605, 0.1595, 1.3529, 0.2050, 0.0600, 0.1829],\n",
      "        [1.0037, 0.2062, 0.2694, 0.6808, 0.1825, 0.5146, 0.2410, 0.1787, 0.4710,\n",
      "         0.1804, 0.0351, 0.1224, 0.4868, 0.1983, 0.0476, 0.1347],\n",
      "        [2.8786, 0.8138, 0.8201, 2.1591, 0.6981, 1.7604, 0.6565, 0.5226, 1.4899,\n",
      "         0.5139, 0.0808, 0.3408, 1.5227, 0.6061, 0.1148, 0.4087],\n",
      "        [0.9464, 0.2801, 0.2616, 0.6682, 0.2807, 0.6614, 0.2127, 0.1898, 0.5010,\n",
      "         0.1654, 0.0296, 0.1228, 0.4988, 0.1809, 0.0413, 0.1229],\n",
      "        [1.3123, 0.4126, 0.3628, 0.9467, 0.4113, 0.9602, 0.2901, 0.2737, 0.7216,\n",
      "         0.2316, 0.0437, 0.1767, 0.7149, 0.2587, 0.0604, 0.1728],\n",
      "        [2.1434, 0.6906, 0.6471, 1.6834, 0.5937, 1.5451, 0.4924, 0.4048, 1.2278,\n",
      "         0.3884, 0.0627, 0.2615, 1.2314, 0.4519, 0.0854, 0.3075],\n",
      "        [1.3201, 0.5954, 0.5029, 1.2186, 0.5234, 1.4536, 0.3674, 0.2495, 1.0219,\n",
      "         0.2706, 0.0521, 0.1810, 0.9778, 0.2619, 0.0689, 0.1983],\n",
      "        [1.1600, 0.4051, 0.3888, 0.9651, 0.3421, 1.0764, 0.3056, 0.2359, 0.8034,\n",
      "         0.2286, 0.0424, 0.1463, 0.7697, 0.2289, 0.0554, 0.1634],\n",
      "        [3.1279, 0.6853, 0.8154, 2.1157, 0.5975, 1.6453, 0.6933, 0.6015, 1.4580,\n",
      "         0.5422, 0.0864, 0.3615, 1.4999, 0.6390, 0.1222, 0.4192],\n",
      "        [4.5936, 1.3847, 1.3617, 3.5600, 1.1759, 3.1057, 1.0696, 0.8300, 2.5732,\n",
      "         0.8416, 0.1442, 0.5707, 2.5945, 0.9548, 0.1836, 0.6532]])}, 66: {'step': tensor(11460.), 'exp_avg': tensor([ 6.4095e-05,  1.5917e-03, -3.0958e-04,  2.2016e-04,  1.7492e-04,\n",
      "         5.6784e-05,  2.2841e-04,  2.2069e-04, -4.0986e-04,  1.9460e-04]), 'exp_avg_sq': tensor([6.4687e-05, 3.3522e-04, 6.9972e-05, 5.6145e-05, 2.4893e-04, 5.5642e-05,\n",
      "        5.0681e-05, 5.1947e-05, 7.9103e-05, 4.9136e-05])}, 67: {'step': tensor(11460.), 'exp_avg': tensor([-0.0949, -0.0927, -0.0891, -0.0866, -0.1689, -0.0915, -0.0873, -0.0865,\n",
      "        -0.0883, -0.0872]), 'exp_avg_sq': tensor([0.0559, 0.0656, 0.0581, 0.0460, 0.1401, 0.0510, 0.0468, 0.0460, 0.0602,\n",
      "        0.0467])}, 68: {'step': tensor(11460.), 'exp_avg': tensor([ 0.1376,  0.0464, -0.1769, -0.0973,  0.0239,  0.0089, -0.2022,  0.2387,\n",
      "         0.2574, -0.1858,  0.0616,  0.0417, -0.1801, -0.0667, -0.0587,  0.0890,\n",
      "        -0.0886, -0.0089,  0.0480,  0.2550,  0.2374, -0.0207, -0.2563,  0.1569,\n",
      "         0.0622,  0.0415, -0.0301, -0.0997, -0.2410, -0.1062,  0.0574,  0.0556]), 'exp_avg_sq': tensor([0.1076, 0.4766, 0.1696, 0.5602, 0.2009, 0.2671, 0.8126, 0.4223, 0.2708,\n",
      "        0.4150, 0.1846, 0.2305, 0.5289, 0.2878, 0.1368, 0.4251, 0.5959, 0.1867,\n",
      "        0.3644, 0.5918, 0.5063, 0.3149, 0.3893, 0.4052, 0.2906, 0.5156, 0.7960,\n",
      "        0.2703, 0.7061, 0.5794, 0.2902, 0.1643])}, 69: {'step': tensor(11460.), 'exp_avg': tensor([[-0.0023,  0.1912, -0.0755,  0.0094, -0.0388,  0.0841, -0.2143,  0.3530,\n",
      "          0.0150, -0.1352, -0.1513, -0.1262,  0.1980,  0.1491, -0.1367, -0.0702],\n",
      "        [-0.0428,  0.2263,  0.2745, -0.1183,  0.0470, -0.1189,  0.0581, -0.0414,\n",
      "          0.0141, -0.0341, -0.1238,  0.0055, -0.0629, -0.1592, -0.0209,  0.1121],\n",
      "        [ 0.0309, -0.3494, -0.0916,  0.0706,  0.0077, -0.0146,  0.1958, -0.3505,\n",
      "         -0.0273,  0.1609,  0.2429,  0.1305, -0.1692, -0.0606,  0.1574,  0.0038],\n",
      "        [ 0.0214, -0.2141, -0.0879,  0.0247,  0.0073,  0.0035,  0.0849, -0.1785,\n",
      "         -0.0123,  0.1122,  0.1376,  0.0681, -0.0877, -0.0025,  0.0952, -0.0065],\n",
      "        [ 0.0214, -0.0471, -0.1714,  0.0907, -0.0467,  0.0991, -0.1028,  0.1533,\n",
      "         -0.0044, -0.0521,  0.0135, -0.0495,  0.1127,  0.1334, -0.0483, -0.0923],\n",
      "        [ 0.0339, -0.1045, -0.2015,  0.0392, -0.0402,  0.0907, -0.1064,  0.1323,\n",
      "         -0.0079,  0.0150,  0.0353, -0.0434,  0.0938,  0.1575, -0.0108, -0.0794],\n",
      "        [ 0.0634, -0.5015, -0.2712,  0.1174, -0.0217,  0.0528,  0.1494, -0.3146,\n",
      "         -0.0367,  0.2031,  0.3233,  0.1196, -0.1284,  0.0513,  0.1784, -0.0552],\n",
      "        [-0.0303,  0.4240,  0.0213, -0.0187, -0.0372,  0.0805, -0.3030,  0.5301,\n",
      "          0.0326, -0.2497, -0.3019, -0.1914,  0.2810,  0.1469, -0.2344, -0.0647],\n",
      "        [-0.0567,  0.5515,  0.2096, -0.1342,  0.0058, -0.0155, -0.2527,  0.4686,\n",
      "          0.0429, -0.2308, -0.3740, -0.1768,  0.2123,  0.0350, -0.2225,  0.0280],\n",
      "        [ 0.0135, -0.2853,  0.0587, -0.0065,  0.0386, -0.0963,  0.2675, -0.4441,\n",
      "         -0.0247,  0.1862,  0.2148,  0.1583, -0.2438, -0.1660,  0.1825,  0.0800],\n",
      "        [-0.0303,  0.1881,  0.1472, -0.0554,  0.0216, -0.0470, -0.0149,  0.0558,\n",
      "          0.0150, -0.0626, -0.1114, -0.0242,  0.0086, -0.0644, -0.0499,  0.0453],\n",
      "        [-0.0394,  0.1937,  0.2037, -0.0683,  0.0375, -0.0772,  0.0328, -0.0159,\n",
      "          0.0163, -0.0487, -0.1067,  0.0021, -0.0375, -0.1175, -0.0309,  0.0701],\n",
      "        [ 0.0308, -0.3395, -0.0515,  0.0464,  0.0097, -0.0397,  0.2168, -0.3712,\n",
      "         -0.0306,  0.1695,  0.2402,  0.1342, -0.1854, -0.0870,  0.1652,  0.0283],\n",
      "        [-0.0210, -0.0223,  0.1592, -0.0532,  0.0519, -0.0994,  0.1572, -0.2467,\n",
      "          0.0013,  0.0730,  0.0412,  0.0864, -0.1569, -0.1611,  0.0784,  0.0873],\n",
      "        [-0.0157, -0.0197,  0.1423, -0.0409,  0.0379, -0.0882,  0.1401, -0.2091,\n",
      "         -0.0022,  0.0554,  0.0386,  0.0714, -0.1307, -0.1424,  0.0642,  0.0776],\n",
      "        [-0.0141,  0.1556, -0.0044,  0.0156, -0.0130,  0.0407, -0.1138,  0.1954,\n",
      "          0.0149, -0.1042, -0.1074, -0.0689,  0.1070,  0.0566, -0.0927, -0.0354],\n",
      "        [ 0.0354, -0.2310, -0.1262,  0.0323, -0.0160,  0.0213,  0.0578, -0.1237,\n",
      "         -0.0217,  0.1030,  0.1412,  0.0461, -0.0491,  0.0364,  0.0838, -0.0207],\n",
      "        [ 0.0261, -0.1022, -0.1520,  0.0629, -0.0352,  0.0705, -0.0525,  0.0658,\n",
      "         -0.0100,  0.0016,  0.0509, -0.0200,  0.0598,  0.1015, -0.0046, -0.0650],\n",
      "        [ 0.0033,  0.0458, -0.0804,  0.0722, -0.0333,  0.0674, -0.0895,  0.1544,\n",
      "          0.0030, -0.0875, -0.0339, -0.0528,  0.1031,  0.0797, -0.0704, -0.0632],\n",
      "        [-0.0400,  0.4762,  0.0617, -0.0510, -0.0237,  0.0650, -0.3114,  0.5410,\n",
      "          0.0394, -0.2518, -0.3379, -0.1951,  0.2762,  0.1322, -0.2409, -0.0494],\n",
      "        [ 0.0111,  0.2697, -0.2376,  0.0460, -0.0833,  0.1951, -0.4183,  0.6618,\n",
      "          0.0236, -0.2245, -0.2373, -0.2328,  0.3821,  0.3343, -0.2382, -0.1663],\n",
      "        [-0.0348,  0.0965,  0.2195, -0.0539,  0.0464, -0.1036,  0.1251, -0.1638,\n",
      "          0.0065,  0.0024, -0.0312,  0.0555, -0.1147, -0.1739,  0.0253,  0.0903],\n",
      "        [ 0.0636, -0.5718, -0.2360,  0.1304, -0.0112,  0.0227,  0.2400, -0.4535,\n",
      "         -0.0450,  0.2409,  0.3829,  0.1699, -0.2023, -0.0138,  0.2255, -0.0322],\n",
      "        [-0.0087,  0.2310, -0.0746,  0.0371, -0.0434,  0.0988, -0.2331,  0.3920,\n",
      "          0.0190, -0.1766, -0.1727, -0.1389,  0.2234,  0.1538, -0.1652, -0.0853],\n",
      "        [-0.0023,  0.0878, -0.0426,  0.0454, -0.0267,  0.0513, -0.0932,  0.1658,\n",
      "          0.0057, -0.0920, -0.0612, -0.0586,  0.1018,  0.0652, -0.0769, -0.0467],\n",
      "        [ 0.0161,  0.0089, -0.1068,  0.0453, -0.0403,  0.0671, -0.0993,  0.1634,\n",
      "         -0.0038, -0.0549, -0.0211, -0.0580,  0.1073,  0.1053, -0.0541, -0.0596],\n",
      "        [-0.0112, -0.0104,  0.0732, -0.0514,  0.0351, -0.0508,  0.0658, -0.1197,\n",
      "          0.0046,  0.0570,  0.0124,  0.0431, -0.0829, -0.0697,  0.0471,  0.0464],\n",
      "        [-0.0146, -0.0827,  0.1559, -0.0613,  0.0561, -0.1128,  0.1958, -0.3153,\n",
      "         -0.0046,  0.1143,  0.0808,  0.1108, -0.1944, -0.1771,  0.1135,  0.0991],\n",
      "        [ 0.0221, -0.4079,  0.0120,  0.0072,  0.0512, -0.0964,  0.3217, -0.5629,\n",
      "         -0.0283,  0.2556,  0.2959,  0.2037, -0.3052, -0.1749,  0.2414,  0.0788],\n",
      "        [-0.0099, -0.0913,  0.1813, -0.1086,  0.0606, -0.1390,  0.2088, -0.3356,\n",
      "         -0.0086,  0.1488,  0.0820,  0.1141, -0.2139, -0.1888,  0.1341,  0.1268],\n",
      "        [ 0.0072,  0.0566, -0.0733,  0.0366, -0.0335,  0.0586, -0.1041,  0.1766,\n",
      "          0.0012, -0.0729, -0.0491, -0.0628,  0.1095,  0.0900, -0.0678, -0.0518],\n",
      "        [-0.0263,  0.1778,  0.1645, -0.1074,  0.0299, -0.0699, -0.0085,  0.0373,\n",
      "          0.0131, -0.0214, -0.1125, -0.0201, -0.0116, -0.0692, -0.0269,  0.0699]]), 'exp_avg_sq': tensor([[0.0181, 0.4588, 0.3485, 0.0786, 0.0232, 0.0522, 0.4698, 0.9941, 0.0095,\n",
      "         0.1298, 0.2090, 0.1439, 0.2887, 0.3723, 0.1146, 0.0405],\n",
      "        [0.0758, 2.3011, 1.4066, 0.2765, 0.0730, 0.1569, 1.2623, 2.8274, 0.0319,\n",
      "         0.5514, 0.9096, 0.4189, 0.7816, 1.0657, 0.4121, 0.1252],\n",
      "        [0.0253, 0.7470, 0.4431, 0.0907, 0.0242, 0.0617, 0.5345, 1.1713, 0.0137,\n",
      "         0.1848, 0.3241, 0.1679, 0.3385, 0.4092, 0.1583, 0.0496],\n",
      "        [0.0579, 2.4632, 0.9601, 0.2175, 0.0403, 0.1142, 0.9567, 2.4974, 0.0295,\n",
      "         0.5290, 1.0270, 0.3726, 0.6612, 0.6038, 0.4430, 0.0891],\n",
      "        [0.0389, 0.8988, 0.7709, 0.1784, 0.0545, 0.0993, 0.9614, 1.9986, 0.0187,\n",
      "         0.2529, 0.3958, 0.2951, 0.5788, 0.8023, 0.2132, 0.0717],\n",
      "        [0.0462, 1.3083, 0.8843, 0.1892, 0.0520, 0.1035, 0.9679, 2.0875, 0.0205,\n",
      "         0.3393, 0.5435, 0.3104, 0.5906, 0.7958, 0.2660, 0.0771],\n",
      "        [0.1024, 3.4928, 1.9684, 0.3635, 0.1100, 0.2627, 2.2921, 5.1971, 0.0520,\n",
      "         0.8666, 1.5113, 0.7588, 1.5009, 1.6928, 0.7457, 0.1862],\n",
      "        [0.0280, 1.4711, 0.3948, 0.1021, 0.0241, 0.0781, 0.9058, 2.2200, 0.0213,\n",
      "         0.4146, 0.7002, 0.3122, 0.6402, 0.4510, 0.3736, 0.0543],\n",
      "        [0.0430, 1.1979, 0.7420, 0.1578, 0.0473, 0.0999, 0.9538, 2.0802, 0.0214,\n",
      "         0.3222, 0.5147, 0.3056, 0.6057, 0.7319, 0.2676, 0.0693],\n",
      "        [0.0378, 1.7185, 0.6305, 0.1224, 0.0251, 0.0743, 0.6667, 1.7179, 0.0186,\n",
      "         0.3945, 0.7331, 0.2485, 0.4713, 0.4072, 0.3209, 0.0568],\n",
      "        [0.0343, 0.8466, 0.6064, 0.1245, 0.0356, 0.0850, 0.6739, 1.4133, 0.0177,\n",
      "         0.2207, 0.3474, 0.2058, 0.4146, 0.5576, 0.1776, 0.0660],\n",
      "        [0.0439, 0.9515, 0.9119, 0.2093, 0.0703, 0.1295, 1.3278, 2.7419, 0.0249,\n",
      "         0.2902, 0.4461, 0.4060, 0.7985, 1.0657, 0.2741, 0.0921],\n",
      "        [0.0513, 2.2910, 0.9259, 0.1967, 0.0420, 0.1012, 1.0206, 2.5811, 0.0274,\n",
      "         0.4967, 0.9797, 0.3866, 0.6856, 0.6408, 0.4312, 0.0760],\n",
      "        [0.0567, 1.3952, 1.1818, 0.2920, 0.0817, 0.1517, 1.4467, 3.0672, 0.0318,\n",
      "         0.3349, 0.6132, 0.4632, 0.8556, 1.1941, 0.3128, 0.1149],\n",
      "        [0.0313, 0.6843, 0.6210, 0.1221, 0.0370, 0.0753, 0.6277, 1.2761, 0.0137,\n",
      "         0.1830, 0.2775, 0.1857, 0.3678, 0.5749, 0.1405, 0.0609],\n",
      "        [0.0374, 1.8670, 0.6437, 0.1282, 0.0217, 0.0678, 0.6450, 1.7065, 0.0199,\n",
      "         0.3958, 0.7986, 0.2446, 0.4478, 0.3657, 0.3295, 0.0538],\n",
      "        [0.0653, 2.6686, 1.2325, 0.2522, 0.0582, 0.1434, 1.3481, 3.1845, 0.0347,\n",
      "         0.6045, 1.1448, 0.4676, 0.8741, 0.9167, 0.5116, 0.1091],\n",
      "        [0.0449, 0.9620, 0.9656, 0.1977, 0.0618, 0.1214, 1.0903, 2.1968, 0.0219,\n",
      "         0.2519, 0.4189, 0.3217, 0.6331, 0.9559, 0.2201, 0.0962],\n",
      "        [0.0462, 1.5447, 0.7624, 0.1830, 0.0463, 0.1110, 1.0361, 2.4128, 0.0214,\n",
      "         0.4085, 0.6801, 0.3551, 0.6920, 0.7350, 0.3432, 0.0780],\n",
      "        [0.0497, 2.2245, 0.7230, 0.1660, 0.0418, 0.1136, 1.2666, 3.1618, 0.0298,\n",
      "         0.5966, 0.9962, 0.4650, 0.9001, 0.7045, 0.5233, 0.0716],\n",
      "        [0.0787, 2.2837, 1.5464, 0.2988, 0.0903, 0.1700, 1.5645, 3.4272, 0.0320,\n",
      "         0.5643, 0.9449, 0.5063, 0.9666, 1.3140, 0.4425, 0.1275],\n",
      "        [0.0585, 1.4583, 1.1809, 0.2419, 0.0788, 0.1606, 1.4842, 3.1416, 0.0292,\n",
      "         0.3905, 0.6467, 0.4616, 0.9120, 1.2107, 0.3492, 0.1145],\n",
      "        [0.0485, 1.5267, 0.8982, 0.2151, 0.0667, 0.1377, 1.4766, 3.2604, 0.0283,\n",
      "         0.4526, 0.7160, 0.4798, 0.9503, 1.0345, 0.4114, 0.0901],\n",
      "        [0.0435, 1.6746, 0.6781, 0.1554, 0.0362, 0.1008, 0.9482, 2.2388, 0.0248,\n",
      "         0.4380, 0.7359, 0.3225, 0.6477, 0.6023, 0.3623, 0.0722],\n",
      "        [0.0373, 1.2565, 0.6021, 0.1452, 0.0354, 0.0863, 0.8246, 1.9304, 0.0181,\n",
      "         0.3239, 0.5512, 0.2852, 0.5506, 0.5771, 0.2756, 0.0592],\n",
      "        [0.0751, 2.4359, 1.4810, 0.3479, 0.0881, 0.1729, 1.6611, 3.7885, 0.0392,\n",
      "         0.5251, 1.0463, 0.5722, 1.0257, 1.2775, 0.4778, 0.1313],\n",
      "        [0.1063, 3.6476, 1.9708, 0.4639, 0.1102, 0.2388, 2.2084, 5.2039, 0.0539,\n",
      "         0.7914, 1.5583, 0.7845, 1.4103, 1.6400, 0.7085, 0.1827],\n",
      "        [0.0557, 1.2179, 1.0743, 0.2929, 0.0822, 0.1608, 1.5484, 3.2643, 0.0327,\n",
      "         0.3299, 0.5714, 0.4838, 0.9376, 1.2498, 0.3176, 0.1197],\n",
      "        [0.0644, 2.8176, 1.1098, 0.2551, 0.0577, 0.1644, 1.4761, 3.6301, 0.0370,\n",
      "         0.6850, 1.2469, 0.5290, 1.0273, 0.9034, 0.5978, 0.1179],\n",
      "        [0.0675, 2.4135, 1.1880, 0.2482, 0.0702, 0.1546, 1.5555, 3.5643, 0.0338,\n",
      "         0.6538, 1.0580, 0.5161, 1.0250, 1.0980, 0.5301, 0.1100],\n",
      "        [0.0416, 1.3165, 0.8025, 0.1992, 0.0504, 0.1020, 0.9783, 2.2219, 0.0221,\n",
      "         0.2989, 0.5773, 0.3340, 0.6115, 0.7409, 0.2748, 0.0765],\n",
      "        [0.0326, 0.8021, 0.6164, 0.1319, 0.0390, 0.0706, 0.6772, 1.4246, 0.0146,\n",
      "         0.2139, 0.3331, 0.2101, 0.4054, 0.5784, 0.1665, 0.0529]])}, 70: {'step': tensor(11460.), 'exp_avg': tensor([-0.0063, -0.0056, -0.0060, -0.0060, -0.0063, -0.0062, -0.0060, -0.0060,\n",
      "        -0.0060, -0.0060]), 'exp_avg_sq': tensor([0.0414, 0.0407, 0.0413, 0.0412, 0.0415, 0.0414, 0.0412, 0.0412, 0.0414,\n",
      "        0.0412])}, 71: {'step': tensor(11460.), 'exp_avg': tensor([-0.0099, -0.0099, -0.0099, -0.0099, -0.0099, -0.0099, -0.0099, -0.0099,\n",
      "        -0.0099, -0.0099]), 'exp_avg_sq': tensor([0.0303, 0.0303, 0.0303, 0.0303, 0.0303, 0.0303, 0.0303, 0.0303, 0.0303,\n",
      "        0.0303])}, 72: {'step': tensor(11460.), 'exp_avg': tensor([[ 5.6052e-45,  5.6052e-45,  5.6052e-45,  ..., -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45,  ...,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45,  ...,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45],\n",
      "        ...,\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45,  ...,  5.6052e-45,\n",
      "          5.6052e-45,  5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  ..., -5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45],\n",
      "        [ 1.4060e-11,  4.6298e-11,  1.7081e-11,  ..., -2.1771e-11,\n",
      "         -2.5434e-12,  2.3034e-12]]), 'exp_avg_sq': tensor([[1.2248e-03, 4.4401e-03, 1.1466e-03,  ..., 1.8139e-04, 1.1818e-03,\n",
      "         4.3948e-05],\n",
      "        [4.8570e-03, 1.4502e-02, 1.1968e-03,  ..., 8.4716e-04, 3.8432e-03,\n",
      "         6.5620e-05],\n",
      "        [5.9212e-03, 4.1412e-02, 8.1982e-03,  ..., 1.8887e-03, 4.8216e-03,\n",
      "         3.3609e-04],\n",
      "        ...,\n",
      "        [7.8983e-02, 8.4210e-01, 1.3508e-01,  ..., 5.4948e-02, 3.0956e-02,\n",
      "         2.2902e-02],\n",
      "        [1.5299e-03, 9.5282e-03, 2.4945e-03,  ..., 2.5288e-04, 1.3394e-03,\n",
      "         4.6824e-05],\n",
      "        [2.0115e-02, 1.6291e-01, 1.8617e-02,  ..., 5.1638e-02, 5.1866e-03,\n",
      "         3.8568e-03]])}, 73: {'step': tensor(11460.), 'exp_avg': tensor([ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  2.7687e-24,  5.6052e-45,  5.6052e-45, -1.2848e-01,\n",
      "         5.6052e-45,  5.6052e-45,  3.6320e-34,  5.6052e-45,  1.0438e-05,\n",
      "         9.4498e-06,  5.6052e-45, -7.9953e-02,  1.2780e-04,  2.3877e-03,\n",
      "         5.6052e-45,  4.4771e-25,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  1.1019e-07,  5.6052e-45,  9.6430e-28,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,  5.6052e-45,\n",
      "        -9.9356e-03,  5.6052e-45,  5.6052e-45,  1.3100e-15,  5.6052e-45,\n",
      "         5.6052e-45, -4.0486e-27,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  2.4345e-12]), 'exp_avg_sq': tensor([8.6180e-06, 2.2371e-05, 6.4924e-05, 7.7934e-05, 1.1841e-04, 4.7712e-06,\n",
      "        1.0964e-04, 4.1839e-05, 1.1022e-04, 1.3676e-01, 7.1345e-06, 3.6414e-03,\n",
      "        1.1658e-04, 5.9099e-05, 6.1591e-04, 2.8804e-04, 2.7646e-05, 1.4266e-02,\n",
      "        8.7895e-03, 4.5824e-02, 2.2841e-05, 1.1680e-03, 2.8003e-05, 1.1505e-05,\n",
      "        5.8608e-06, 2.9365e-05, 3.2794e-05, 3.6645e-05, 4.6151e-05, 5.8461e-05,\n",
      "        8.9314e-05, 2.1110e-03, 2.5547e-04, 1.2635e-04, 6.2055e-05, 2.8387e-07,\n",
      "        1.0300e-06, 7.4075e-06, 7.0733e-05, 6.7919e-06, 8.9160e-05, 2.3411e-03,\n",
      "        5.2641e-05, 5.7506e-04, 1.1617e-06, 1.9699e-05, 7.3497e-06, 9.4984e-05,\n",
      "        4.4303e-05, 3.8676e-05, 1.1949e-01, 1.8067e-03, 1.4180e-05, 1.3734e-04,\n",
      "        5.7784e-05, 8.7047e-05, 2.4494e-02, 1.0318e-05, 1.5794e-05, 2.4802e-04,\n",
      "        1.4266e-05, 1.0100e-03, 1.3256e-05, 6.5029e-04])}}\n",
      "param_groups \t [{'lr': 0.0001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]}]\n"
     ]
    }
   ],
   "source": [
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'{model_name}_state_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, model_name+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([32.046321868896484,\n",
       "  18.297260284423828,\n",
       "  18.39927864074707,\n",
       "  3.9532501697540283,\n",
       "  9.280409812927246,\n",
       "  2.250455856323242,\n",
       "  27.389413833618164,\n",
       "  31.146808624267578,\n",
       "  17.970500946044922,\n",
       "  6.8052754402160645,\n",
       "  2.843642234802246,\n",
       "  4.991097927093506,\n",
       "  22.497175216674805,\n",
       "  3.956347942352295,\n",
       "  2.506882667541504,\n",
       "  4.192269802093506,\n",
       "  1.906828761100769,\n",
       "  6.458434581756592,\n",
       "  0.5273571610450745,\n",
       "  0.4762130677700043,\n",
       "  8.709927558898926,\n",
       "  1.4885063171386719,\n",
       "  2.1832077503204346,\n",
       "  2.0631299018859863,\n",
       "  19.341751098632812,\n",
       "  2.7864909172058105,\n",
       "  11.30163288116455,\n",
       "  12.798023223876953,\n",
       "  0.5920411944389343,\n",
       "  17.881189346313477,\n",
       "  12.508885383605957,\n",
       "  3.1607446670532227,\n",
       "  2.5793845653533936,\n",
       "  1.3689061403274536,\n",
       "  3.2293190956115723,\n",
       "  3.122875928878784,\n",
       "  1.4737228155136108,\n",
       "  15.328455924987793,\n",
       "  3.024419069290161,\n",
       "  4.066792011260986,\n",
       "  1.9119950532913208,\n",
       "  15.254334449768066,\n",
       "  3.714618682861328,\n",
       "  3.987797260284424,\n",
       "  43.0009880065918,\n",
       "  8.198562622070312,\n",
       "  1.7031996250152588,\n",
       "  6.816945552825928,\n",
       "  11.599443435668945,\n",
       "  18.941221237182617,\n",
       "  2.8506383895874023,\n",
       "  4.895416736602783,\n",
       "  23.574560165405273,\n",
       "  7.647287368774414,\n",
       "  12.616533279418945,\n",
       "  2.6149563789367676,\n",
       "  1.476181983947754,\n",
       "  12.769879341125488,\n",
       "  0.9580188393592834,\n",
       "  13.705432891845703,\n",
       "  0.47739237546920776,\n",
       "  2.9160289764404297,\n",
       "  0.8922470211982727,\n",
       "  16.145811080932617,\n",
       "  6.458739757537842,\n",
       "  6.454627513885498,\n",
       "  13.366264343261719,\n",
       "  2.3382511138916016,\n",
       "  18.060998916625977,\n",
       "  22.041919708251953,\n",
       "  3.5936803817749023,\n",
       "  4.494021415710449,\n",
       "  23.341041564941406,\n",
       "  5.7738518714904785,\n",
       "  3.550997257232666,\n",
       "  4.505638122558594,\n",
       "  1.8623214960098267,\n",
       "  3.135565996170044,\n",
       "  2.767226219177246,\n",
       "  3.263906955718994,\n",
       "  1.2403080463409424,\n",
       "  0.4799267053604126,\n",
       "  1.5702582597732544,\n",
       "  1.577867865562439,\n",
       "  3.2975456714630127,\n",
       "  1.4543644189834595,\n",
       "  5.333065032958984,\n",
       "  9.561969757080078,\n",
       "  10.288326263427734,\n",
       "  4.5566792488098145,\n",
       "  3.8220629692077637,\n",
       "  4.992160797119141,\n",
       "  17.961536407470703,\n",
       "  3.036879301071167,\n",
       "  1.8097516298294067,\n",
       "  2.1303505897521973,\n",
       "  5.478142261505127,\n",
       "  0.7569451332092285,\n",
       "  4.959185600280762,\n",
       "  1.5353657007217407,\n",
       "  17.781105041503906,\n",
       "  4.9810967445373535,\n",
       "  2.813822031021118,\n",
       "  2.5407207012176514,\n",
       "  5.383248805999756,\n",
       "  1.8267180919647217,\n",
       "  3.116365671157837,\n",
       "  3.09786057472229,\n",
       "  3.635399580001831,\n",
       "  4.548612594604492,\n",
       "  0.7497901916503906,\n",
       "  2.761338710784912,\n",
       "  3.719578266143799,\n",
       "  2.350635290145874,\n",
       "  1.621761679649353,\n",
       "  2.29423189163208,\n",
       "  30.250106811523438,\n",
       "  4.533095359802246,\n",
       "  19.74181365966797,\n",
       "  1.394256591796875,\n",
       "  0.9849762916564941,\n",
       "  1.5498342514038086,\n",
       "  0.27630090713500977,\n",
       "  10.965460777282715,\n",
       "  6.178011417388916,\n",
       "  13.169875144958496,\n",
       "  2.932018280029297,\n",
       "  2.1205334663391113,\n",
       "  4.173831462860107,\n",
       "  8.247139930725098,\n",
       "  3.5906944274902344,\n",
       "  2.8045084476470947,\n",
       "  9.838956832885742,\n",
       "  4.906108379364014,\n",
       "  36.76697540283203,\n",
       "  10.639045715332031,\n",
       "  29.872602462768555,\n",
       "  1.067513108253479,\n",
       "  1.979527235031128,\n",
       "  5.108795642852783,\n",
       "  24.667137145996094,\n",
       "  3.978789806365967,\n",
       "  1.0278059244155884,\n",
       "  5.3645806312561035,\n",
       "  2.931062698364258,\n",
       "  4.3878045082092285,\n",
       "  5.412469387054443,\n",
       "  10.211678504943848,\n",
       "  1.216954231262207,\n",
       "  6.602946758270264,\n",
       "  2.428710460662842,\n",
       "  3.117645263671875,\n",
       "  3.340846061706543,\n",
       "  2.462641477584839,\n",
       "  4.062372207641602,\n",
       "  14.843852043151855,\n",
       "  7.529028415679932,\n",
       "  1.3020514249801636,\n",
       "  4.436988830566406,\n",
       "  10.179019927978516,\n",
       "  2.4944865703582764,\n",
       "  2.131026268005371,\n",
       "  31.151643753051758,\n",
       "  19.3475399017334,\n",
       "  3.0503251552581787,\n",
       "  2.519491672515869,\n",
       "  5.702650547027588,\n",
       "  1.354240894317627,\n",
       "  40.66301727294922,\n",
       "  2.9148306846618652,\n",
       "  2.6988167762756348,\n",
       "  1.1749920845031738,\n",
       "  24.702922821044922,\n",
       "  5.807286262512207,\n",
       "  2.1359751224517822,\n",
       "  8.549593925476074,\n",
       "  4.340007305145264,\n",
       "  10.329756736755371,\n",
       "  13.014507293701172,\n",
       "  1.2840737104415894,\n",
       "  83.58417510986328,\n",
       "  10.370373725891113,\n",
       "  14.858465194702148,\n",
       "  1.3292454481124878,\n",
       "  3.604213237762451,\n",
       "  3.1817383766174316,\n",
       "  36.389705657958984,\n",
       "  16.53635025024414,\n",
       "  3.318995475769043,\n",
       "  2.7488596439361572,\n",
       "  1.2972617149353027,\n",
       "  5.08043909072876,\n",
       "  27.51146697998047,\n",
       "  2.772381067276001,\n",
       "  3.526963233947754,\n",
       "  2.6565301418304443],\n",
       " [2.2814807891845703,\n",
       "  2.5545098781585693,\n",
       "  7.528890132904053,\n",
       "  4.485908508300781,\n",
       "  13.509096145629883,\n",
       "  10.750596046447754,\n",
       "  4.271125793457031,\n",
       "  0.40160366892814636,\n",
       "  1.1018704175949097,\n",
       "  13.407434463500977,\n",
       "  26.39272689819336,\n",
       "  15.810093879699707,\n",
       "  0.8221311569213867,\n",
       "  3.4948525428771973,\n",
       "  0.5049158930778503,\n",
       "  6.320066928863525,\n",
       "  6.615358352661133,\n",
       "  0.857691764831543,\n",
       "  5.485033988952637,\n",
       "  14.902531623840332,\n",
       "  6.2456488609313965,\n",
       "  2.942681074142456,\n",
       "  3.1293153762817383,\n",
       "  1.0522505044937134,\n",
       "  4.422384262084961,\n",
       "  0.8941328525543213,\n",
       "  9.511713981628418,\n",
       "  80.62744140625,\n",
       "  3.701019048690796,\n",
       "  13.600502967834473,\n",
       "  35.866455078125,\n",
       "  17.055383682250977,\n",
       "  5.8951802253723145,\n",
       "  6.900148391723633,\n",
       "  6.574687957763672,\n",
       "  3.916247606277466,\n",
       "  16.425281524658203,\n",
       "  0.6472588777542114,\n",
       "  1.8482896089553833,\n",
       "  3.538717746734619,\n",
       "  26.901891708374023,\n",
       "  2.2422356605529785,\n",
       "  8.798269271850586,\n",
       "  1.5838478803634644,\n",
       "  1.6243417263031006,\n",
       "  3.8969030380249023,\n",
       "  14.66286563873291,\n",
       "  2.1048145294189453,\n",
       "  3.824007034301758,\n",
       "  5.244457244873047,\n",
       "  3.2555575370788574,\n",
       "  10.009940147399902,\n",
       "  5.034704685211182,\n",
       "  0.6232653260231018,\n",
       "  1.9537676572799683,\n",
       "  2.1379334926605225,\n",
       "  16.245088577270508,\n",
       "  20.01744842529297,\n",
       "  1.6378846168518066,\n",
       "  2.7885897159576416,\n",
       "  0.6279887557029724,\n",
       "  0.15481428802013397,\n",
       "  3.361271381378174,\n",
       "  0.21239592134952545,\n",
       "  5.947115898132324,\n",
       "  1.7840685844421387,\n",
       "  2.3809802532196045,\n",
       "  21.73438262939453,\n",
       "  2.499753713607788,\n",
       "  1.4750794172286987,\n",
       "  2.641859769821167,\n",
       "  1.1627328395843506,\n",
       "  0.8229544162750244,\n",
       "  27.550182342529297,\n",
       "  2.5195605754852295,\n",
       "  0.4426348805427551,\n",
       "  8.720398902893066,\n",
       "  6.844168663024902,\n",
       "  1.2659670114517212,\n",
       "  1.8671596050262451,\n",
       "  1.3898353576660156,\n",
       "  4.504495143890381,\n",
       "  8.047096252441406,\n",
       "  0.36606308817863464,\n",
       "  7.279324531555176,\n",
       "  1.9382963180541992,\n",
       "  8.284513473510742,\n",
       "  1.3981451988220215,\n",
       "  1.803467035293579,\n",
       "  0.5361953973770142,\n",
       "  2.1066505908966064,\n",
       "  16.287460327148438,\n",
       "  10.021798133850098,\n",
       "  0.46351078152656555,\n",
       "  15.064207077026367,\n",
       "  0.5122920870780945,\n",
       "  1.530428171157837,\n",
       "  2.2544143199920654,\n",
       "  19.91429901123047,\n",
       "  2.041322708129883,\n",
       "  14.026533126831055,\n",
       "  1.8972169160842896,\n",
       "  13.948647499084473,\n",
       "  2.0863678455352783,\n",
       "  2.144136428833008,\n",
       "  1.9952976703643799,\n",
       "  2.302344799041748,\n",
       "  10.315887451171875,\n",
       "  18.473066329956055,\n",
       "  0.38232001662254333,\n",
       "  1.8152410984039307,\n",
       "  1.5204881429672241,\n",
       "  1.6989010572433472,\n",
       "  3.029451370239258,\n",
       "  3.351789712905884,\n",
       "  2.569627285003662,\n",
       "  7.574113845825195,\n",
       "  4.5101728439331055,\n",
       "  16.355192184448242,\n",
       "  1.5852766036987305,\n",
       "  22.07358169555664,\n",
       "  13.381595611572266,\n",
       "  3.0397355556488037,\n",
       "  1.9043362140655518,\n",
       "  4.347304821014404,\n",
       "  1.0277988910675049,\n",
       "  3.2516486644744873,\n",
       "  1.980151891708374,\n",
       "  2.649240255355835,\n",
       "  12.85539722442627,\n",
       "  0.4272335171699524,\n",
       "  15.187665939331055,\n",
       "  1.4694108963012695,\n",
       "  18.808042526245117,\n",
       "  0.7932987213134766,\n",
       "  4.887267589569092,\n",
       "  0.824217677116394,\n",
       "  16.10577392578125,\n",
       "  0.7072330713272095,\n",
       "  1.3806816339492798,\n",
       "  1.1497645378112793,\n",
       "  6.308766841888428,\n",
       "  13.293374061584473,\n",
       "  1.7030630111694336,\n",
       "  9.531559944152832,\n",
       "  7.931658744812012,\n",
       "  2.148841619491577,\n",
       "  1.5342057943344116,\n",
       "  2.7105441093444824,\n",
       "  2.205824375152588,\n",
       "  4.383027076721191,\n",
       "  19.907543182373047,\n",
       "  1.2364407777786255,\n",
       "  15.395852088928223,\n",
       "  3.429232597351074,\n",
       "  16.603713989257812,\n",
       "  10.686044692993164,\n",
       "  8.348073959350586,\n",
       "  12.555545806884766,\n",
       "  0.7854964137077332,\n",
       "  3.188260078430176,\n",
       "  10.510478973388672,\n",
       "  2.026899814605713,\n",
       "  1.6069319248199463,\n",
       "  11.541509628295898,\n",
       "  0.8983244895935059,\n",
       "  2.6975903511047363,\n",
       "  7.81821870803833,\n",
       "  16.16411018371582,\n",
       "  4.85800313949585,\n",
       "  2.169067859649658,\n",
       "  2.9383864402770996,\n",
       "  3.13470721244812,\n",
       "  1.0493946075439453,\n",
       "  3.1832115650177,\n",
       "  6.119629859924316,\n",
       "  1.7303473949432373,\n",
       "  16.120214462280273,\n",
       "  0.9696166515350342,\n",
       "  2.287513256072998,\n",
       "  2.8665695190429688,\n",
       "  1.7420175075531006,\n",
       "  9.746023178100586,\n",
       "  2.7491953372955322,\n",
       "  8.917433738708496,\n",
       "  4.6066789627075195],\n",
       " [5.205163478851318,\n",
       "  6.525521755218506,\n",
       "  0.0,\n",
       "  56.684173583984375,\n",
       "  20.123395919799805,\n",
       "  0.0,\n",
       "  182.49575805664062,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  115.5753173828125,\n",
       "  18.24247932434082,\n",
       "  0.16128553450107574,\n",
       "  1.2141226530075073,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  179.75936889648438,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  696.5762329101562,\n",
       "  249.9591522216797,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6759026646614075,\n",
       "  0.0,\n",
       "  12.214011192321777,\n",
       "  0.25494053959846497,\n",
       "  0.0,\n",
       "  39.943214416503906,\n",
       "  43.76297378540039,\n",
       "  0.7356317639350891,\n",
       "  0.0,\n",
       "  30.0855712890625,\n",
       "  222.08554077148438,\n",
       "  39.00811004638672,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.22338956594467163,\n",
       "  0.27435582876205444,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  8.659363746643066,\n",
       "  9.792623519897461,\n",
       "  0.0,\n",
       "  1.1072279214859009,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.16642864048480988,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  19.55750846862793,\n",
       "  0.0,\n",
       "  0.7994697093963623,\n",
       "  0.0,\n",
       "  90.47266387939453,\n",
       "  0.0,\n",
       "  6500.78564453125,\n",
       "  13.697538375854492,\n",
       "  184.9737548828125,\n",
       "  0.0,\n",
       "  1286.402587890625,\n",
       "  290.88623046875,\n",
       "  0.0,\n",
       "  34.7531852722168,\n",
       "  47.612003326416016,\n",
       "  43.226497650146484,\n",
       "  15.337018013000488,\n",
       "  269.7898254394531,\n",
       "  0.0,\n",
       "  0.4189409017562866,\n",
       "  3.416170597076416,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  12.52249813079834,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  723.7118530273438,\n",
       "  0.0,\n",
       "  5.027615547180176,\n",
       "  0.0,\n",
       "  77.40949249267578,\n",
       "  0.0,\n",
       "  2.5085816383361816,\n",
       "  0.0,\n",
       "  2.6384778022766113,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  15.185836791992188,\n",
       "  214.99954223632812,\n",
       "  4.430248260498047,\n",
       "  14.623029708862305,\n",
       "  27.504301071166992,\n",
       "  0.0,\n",
       "  10.598653793334961,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  100.19886016845703,\n",
       "  25.34822654724121,\n",
       "  0.38845542073249817,\n",
       "  0.0,\n",
       "  3.8172011375427246,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  4.570751667022705,\n",
       "  263.90301513671875,\n",
       "  0.0,\n",
       "  0.0017624128377065063,\n",
       "  400.6983947753906,\n",
       "  2.682659387588501,\n",
       "  7.776244640350342,\n",
       "  0.0,\n",
       "  0.2731161117553711,\n",
       "  0.0,\n",
       "  0.011610344983637333,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.3943704068660736,\n",
       "  0.02396799437701702,\n",
       "  11.298133850097656,\n",
       "  0.045111361891031265,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  35.36818313598633,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  3.1829001903533936,\n",
       "  5.669058799743652,\n",
       "  0.0,\n",
       "  472.38348388671875,\n",
       "  6.248781681060791,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.175859212875366,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.27047649025917053,\n",
       "  6.979438304901123,\n",
       "  1.351952075958252,\n",
       "  0.6772565245628357,\n",
       "  759.0126342773438,\n",
       "  6.3481950759887695,\n",
       "  0.19592386484146118,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  76.0452880859375,\n",
       "  0.0,\n",
       "  46.842613220214844,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.6026742458343506,\n",
       "  3.486292600631714,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.9316400289535522,\n",
       "  20.290475845336914,\n",
       "  64.75580596923828,\n",
       "  0.134001687169075,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.05907474085688591,\n",
       "  52.98856735229492,\n",
       "  0.0,\n",
       "  3.756983757019043,\n",
       "  68.63319396972656,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.9548020362854004,\n",
       "  3.2524876594543457,\n",
       "  0.0,\n",
       "  0.2875085771083832,\n",
       "  0.0,\n",
       "  4.437973499298096,\n",
       "  0.0,\n",
       "  265.28143310546875,\n",
       "  0.0,\n",
       "  100.43636322021484,\n",
       "  0.21484363079071045,\n",
       "  0.0,\n",
       "  226.930419921875,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.2624441087245941,\n",
       "  0.06260450184345245,\n",
       "  2.3422060012817383,\n",
       "  0.0,\n",
       "  5.0823774337768555,\n",
       "  396.57916259765625,\n",
       "  0.0,\n",
       "  4.167011260986328,\n",
       "  0.0,\n",
       "  196.74354553222656,\n",
       "  0.0,\n",
       "  3.599416732788086,\n",
       "  194.56484985351562,\n",
       "  0.0,\n",
       "  4.352921962738037,\n",
       "  4.5973219871521,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  3.9812142848968506,\n",
       "  5.3007893562316895,\n",
       "  0.00022564375831279904,\n",
       "  0.0,\n",
       "  0.5237388014793396,\n",
       "  106.41747283935547,\n",
       "  0.0,\n",
       "  341.25433349609375,\n",
       "  0.14616699516773224,\n",
       "  3.2951087951660156,\n",
       "  2.311887741088867,\n",
       "  0.0,\n",
       "  2.886255979537964,\n",
       "  0.0,\n",
       "  9.177571296691895,\n",
       "  0.0,\n",
       "  11.234481811523438,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  6.6029953956604,\n",
       "  57.367252349853516,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  20.341659545898438,\n",
       "  267.49224853515625,\n",
       "  0.0,\n",
       "  2.513092041015625,\n",
       "  487.24310302734375,\n",
       "  0.0,\n",
       "  179.06703186035156,\n",
       "  9.24000358581543,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  3.626500129699707,\n",
       "  18.899038314819336,\n",
       "  1.0563695430755615,\n",
       "  0.0,\n",
       "  10.57320785522461,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  3.9210000038146973,\n",
       "  0.0,\n",
       "  7.018474102020264,\n",
       "  0.0,\n",
       "  165.2611846923828,\n",
       "  0.0,\n",
       "  0.1825259029865265,\n",
       "  230.66514587402344,\n",
       "  2.159177780151367,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  353.7424011230469,\n",
       "  0.6293196678161621,\n",
       "  23.88540267944336,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6793375015258789,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  259.3960876464844,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.5001747608184814,\n",
       "  1.9062824249267578,\n",
       "  0.0,\n",
       "  1.321953296661377,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  39.80058288574219,\n",
       "  176.71371459960938,\n",
       "  2.9004194736480713,\n",
       "  90.85057830810547,\n",
       "  62.91124725341797,\n",
       "  4.617532730102539,\n",
       "  2.353792190551758,\n",
       "  7.347040176391602,\n",
       "  0.0,\n",
       "  4.865675926208496,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  19.210922241210938,\n",
       "  396.3104248046875,\n",
       "  0.0,\n",
       "  1.5287814140319824,\n",
       "  237.0321502685547,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  11.759651184082031,\n",
       "  275.6834411621094,\n",
       "  114.19161224365234,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  69.69029235839844,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  157.6417999267578,\n",
       "  0.6170058250427246,\n",
       "  0.0,\n",
       "  10.165023803710938,\n",
       "  110.47010803222656,\n",
       "  4.108322620391846,\n",
       "  2.5822291374206543,\n",
       "  133.20640563964844,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.8069846630096436,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  7.276988506317139,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  61.124507904052734,\n",
       "  0.0,\n",
       "  261.2783203125,\n",
       "  0.0,\n",
       "  23.600217819213867,\n",
       "  4.7048659324646,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  8.634115219116211,\n",
       "  0.0,\n",
       "  9.826383590698242,\n",
       "  1.101231336593628,\n",
       "  10.132816314697266,\n",
       "  0.0,\n",
       "  37.44990921020508,\n",
       "  2.994112491607666,\n",
       "  259.8614501953125,\n",
       "  0.9401555061340332,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  5.232728958129883,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  8.21721076965332,\n",
       "  3.0346133708953857,\n",
       "  94.9849853515625,\n",
       "  7.558067321777344,\n",
       "  79.52066040039062,\n",
       "  0.0,\n",
       "  21.22149085998535,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\AppData\\Local\\Temp\\ipykernel_12996\\3520072505.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tr_results = np.asarray(train_results)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "tr_results = np.asarray(train_results)\n",
    "tr_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tr_results[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mshape\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "tr_results[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(123)\n",
    "\n",
    "w = 0.8    # bar width\n",
    "x = [1, 2] # x-coordinates of your bars\n",
    "colors = [(0, 0, 1, 1), (1, 0, 0, 1)]    # corresponding colors\n",
    "y = [np.random.random(30) * 2 + 5,       # data series\n",
    "    np.random.random(10) * 3 + 8]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(x,\n",
    "       height=[np.mean(yi) for yi in y],\n",
    "       yerr=[np.std(yi) for yi in y],    # error bars\n",
    "       capsize=12, # error bar cap width in points\n",
    "       width=w,    # bar width\n",
    "       tick_label=[\"control\", \"test\"],\n",
    "       color=(0,0,0,0),  # face color transparent\n",
    "       edgecolor=colors,\n",
    "       #ecolor=colors,    # error bar colors; setting this raises an error for whatever reason.\n",
    "       )\n",
    "\n",
    "for i in range(len(x)):\n",
    "    # distribute scatter randomly across whole width of bar\n",
    "    ax.scatter(x[i] + np.random.random(y[i].size) * w - w / 2, y[i], color=colors[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save(f'{model_name}_training_loss.npy', tr_loss, allow_pickle=True)\n",
    "np.save(f'{model_name}_training_accuracy.npy', tr_acc, allow_pickle=True)\n",
    "\n",
    "np.save(f'{model_name}_validation_loss.npy', v_loss, allow_pickle=True)\n",
    "np.save(f'{model_name}_validation_accuracy.npy', v_acc, allow_pickle=True)\n",
    "\n",
    "np.save(f'{model_name}_test_loss.npy', tst_loss, allow_pickle=True)\n",
    "np.save(f'{model_name}_test_accuracy.npy', tst_acc, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "training_loss = np.load(f'{model_name}_training_loss.npy', allow_pickle=True)\n",
    "training_accuracy = np.load(f'{model_name}_training_accuracy.npy', allow_pickle=True)\n",
    "\n",
    "validation_loss = np.load(f'{model_name}_validation_loss.npy', allow_pickle=True)\n",
    "validation_accuracy = np.load(f'{model_name}_validation_accuracy.npy', allow_pickle=True)\n",
    "\n",
    "test_loss = np.load(f'{model_name}_test_loss.npy', allow_pickle=True)\n",
    "test_accuracy = np.load(f'{model_name}_test_accuracy.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a sequence of integers to represent the epoch numbers\n",
    "epochs = range(1, num_epochs+1)\n",
    " \n",
    "# Plot and label the training and validation loss values\n",
    "plt.plot(epochs, training_loss, label='Training Loss')\n",
    "plt.plot(epochs, validation_loss, label='Validation Loss')\n",
    " \n",
    "# Add in a title and axes labels\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    " \n",
    "# Set the tick locations\n",
    "plt.xticks(np.arange(0, num_epochs+1, num_epochs/10))\n",
    " \n",
    "# Display the plot\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(f'{model_name}_Training and Validation Loss.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a sequence of integers to represent the epoch numbers\n",
    "epochs = range(1, num_epochs+1)\n",
    " \n",
    "# Plot and label the training and validation loss values\n",
    "plt.plot(epochs, training_accuracy, label='Training Accuracy')\n",
    "plt.plot(epochs, validation_accuracy, label='Validation Accuracy')\n",
    "plt.plot(epochs, test_accuracy, label='Test Accuracy')\n",
    " \n",
    "# Add in a title and axes labels\n",
    "plt.title('Accuracy vs. Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    " \n",
    "# Set the tick locations\n",
    "plt.xticks(np.arange(0, num_epochs+1, num_epochs/10))\n",
    "plt.ylim(0,1)\n",
    " \n",
    "# Display the plot\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(f'{model_name}_Accuracy vs. Epochs.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_fraction = [0,0]\n",
    "\n",
    "train_fraction = [0,0]\n",
    "val_fraction = [0,0]\n",
    "test_fraction = [0,0]\n",
    "\n",
    "for grph in train_dataset: \n",
    "    if grph.y == 1: \n",
    "        train_fraction[1] +=1\n",
    "        dataset_fraction[1] +=1 \n",
    "    else: \n",
    "        train_fraction[0] +=1\n",
    "        dataset_fraction[0] +=1 \n",
    "\n",
    "for grph in val_dataset: \n",
    "    if grph.y == 1:\n",
    "         val_fraction[1] +=1\n",
    "         dataset_fraction[1] +=1  \n",
    "    else:\n",
    "         val_fraction[0] +=1\n",
    "         dataset_fraction[0] +=1\n",
    "\n",
    "for grph in test_dataset: \n",
    "    if grph.y == 1:\n",
    "         test_fraction[1] +=1\n",
    "         dataset_fraction[1] +=1 \n",
    "    else:\n",
    "         test_fraction[0] +=1\n",
    "         dataset_fraction[0] +=1\n",
    "\n",
    "print(f'Overall dataset percentage of label 1 = {dataset_fraction[1]/len(dataset)})')\n",
    "print(f'Training dataset percentage of label 1 = {train_fraction} = {train_fraction[1]/len(train_dataset)}')\n",
    "print(f'Validation dataset percentage of label 1 = {val_fraction} = {val_fraction[1]/len(val_dataset)}')\n",
    "print(f'Test dataset percentage of label 1 = {test_fraction} = {test_fraction[1]/len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Graph: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, pos0, adj0 = torch.load(f'{model_name}_img0_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Embedding GNN\n",
    "print(x0[0].shape)\n",
    "x0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pos0[0].shape)\n",
    "pos0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adj0[0].shape)\n",
    "adj0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index, _ = dense_to_sparse(adj0[0])\n",
    "visualize_points(pos0[0].cpu(), edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph After 1st Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_emb, x1_pool, pos1, adj1, s1= torch.load(f'{model_name}_img1_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Embedding GNN (adj0 @ x_0 @ w_gnn_emb)\n",
    "print(x1_emb[0].shape)\n",
    "x1_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Pooling GNN: adj_0 @ x_0 @ w_gnn_pool\n",
    "print(s1[0].shape)\n",
    "s1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Coordinate Matrix (pos_out = softmax(s).t() @ pos_in)\n",
    "print(pos1[0].shape)\n",
    "pos1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Feature Matrix (x_out = softmax(s).t() @ x_in)\n",
    "print(x1_pool[0].shape)\n",
    "x1_pool[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Adjacency Matrix = softmax(adj_out = softmax(s.t()) @ adj_in @ softmax(s))\n",
    "print(adj1[0].shape)\n",
    "adj1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index, _ = dense_to_sparse(adj1[0])\n",
    "visualize_points(pos1[0].cpu(), edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph after 2nd reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_emb, x2_pool, pos2, adj2, s2 = torch.load(f'{model_name}_img2_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Embedding GNN (adj1 @ x1_pool @ w_gnn_emb)\n",
    "print(x2_emb[0].shape)\n",
    "x2_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Pooling GNN: adj1 @ x1_pool @ w_gnn_pool), dim=1\n",
    "print(s2[0].shape)\n",
    "s2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Coordinate Matrix (pos_out = softmax(s.t()) @ pos_in)\n",
    "print(pos2[0].shape)\n",
    "pos2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Feature Matrix (x_out = softmax(s2).t() @ x2_emb)\n",
    "print(x2_pool[0].shape)\n",
    "x2_pool[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Adjacency Matrix (adj = softmax(s).T @ adj @ softmax(s)\n",
    "print(adj2[0].shape)\n",
    "adj2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index, _ = dense_to_sparse(adj2[0])\n",
    "visualize_points(pos2[0].cpu(), edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph after 3rd reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3_emb, x3_pool, pos3, adj3, s3 = torch.load(f'{model_name}_img3_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Embedding GNN (adj_0 @ x_0 @ w_gnn_emb)\n",
    "print(x3_emb[0].shape)\n",
    "x3_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Pooling GNN: torch.softmax(adj_0 @ x_0 @ w_gnn_pool), dim=1)\n",
    "print(s3[0].shape)\n",
    "s3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Coordinate Matrix (pos_out = softmax(s.t()) @ pos_in)\n",
    "print(pos3[0].shape)\n",
    "pos3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Feature Matrix (x_out = softmax(s.t()) @ x_0)\n",
    "print(x3_pool[0].shape)\n",
    "x3_pool[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Adjacency Matrix (adj = softmax(s.t()) @ adj @ softmax(s)\n",
    "print(adj3[0].shape)\n",
    "adj3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index, _ = dense_to_sparse(adj3[0])\n",
    "visualize_points(pos3[0].cpu(), edge_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3baeb0c3f97feb3023477fbaa09b9f4da769e45e64d8febc6957bb84d33ff77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
