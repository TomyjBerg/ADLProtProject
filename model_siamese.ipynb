{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize features? \n",
    "## Invert h-bond and charge? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_siamese_071222'\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import DenseDataLoader #To make use of this data loader, all graph attributes in the dataset need to have the same shape. In particular, this data loader should only be used when working with dense adjacency matrices.\n",
    "from torch_geometric.nn import DenseGCNConv, dense_diff_pool\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dir_1 = 'C:/Users/david/pyproj/pyg/adl/patch_label_1'\n",
    "#data_dir_0 = 'C:/Users/david/pyproj/pyg/adl/patch_label_0'\n",
    "data_dir_1 = 'C:/Users/thoma/OneDrive - ZHAW/ProteinSurfaces/patch_label_1'\n",
    "data_dir_0 = 'C:/Users/thoma/OneDrive - ZHAW/ProteinSurfaces/patch_label_0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "572"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from c_PatchDataset import PatchDataset\n",
    "dataset = PatchDataset(data_dir_label_0 = data_dir_0,  data_dir_label_1=data_dir_1,  neg_pos_ratio=1)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: PatchDataset(572):\n",
      "====================\n",
      "Number of graphs pairs: 572\n",
      "\n",
      "PairData(adj1=[100, 100], x1=[100, 3], adj2=[100, 100], x2=[100, 3], y=0)\n",
      "=============================================================\n",
      "Number of nodes in each: None\n",
      "Number of node features: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thoma\\Desktop\\ZHAW MLS\\David prod\\ADLProtProject\\.venv\\lib\\site-packages\\torch_geometric\\data\\storage.py:271: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'adj1', 'y', 'x1', 'adj2', 'x2'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs pairs: {len(dataset)}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "print()\n",
    "print(data)\n",
    "print('=============================================================')\n",
    "\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes in each: {data.num_nodes}')\n",
    "print(f'Number of node features: {data.num_node_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.9789e-02,  0.0000e+00,  9.9821e-01],\n",
       "        [ 5.4459e-02,  0.0000e+00,  9.9852e-01],\n",
       "        [-2.8077e-01,  0.0000e+00,  9.5978e-01],\n",
       "        [ 5.5093e-02,  0.0000e+00,  9.9848e-01],\n",
       "        [ 1.7034e-01,  0.0000e+00,  9.8539e-01],\n",
       "        [ 1.3607e-01,  0.0000e+00,  9.9070e-01],\n",
       "        [ 1.5805e-02,  0.0000e+00,  9.9988e-01],\n",
       "        [ 4.3838e-01,  1.2059e-01,  8.9066e-01],\n",
       "        [ 1.4645e-02,  0.0000e+00,  9.9989e-01],\n",
       "        [ 7.2428e-01,  0.0000e+00,  6.8950e-01],\n",
       "        [ 4.4789e-02,  0.0000e+00,  9.9900e-01],\n",
       "        [ 8.9164e-01,  0.0000e+00,  4.5274e-01],\n",
       "        [ 2.3613e-01,  0.0000e+00,  9.7172e-01],\n",
       "        [ 3.1965e-02,  0.0000e+00,  9.9949e-01],\n",
       "        [ 6.9726e-01,  0.0000e+00,  7.1682e-01],\n",
       "        [-2.0573e-01, -1.0507e-01,  9.7295e-01],\n",
       "        [ 1.7653e-01,  0.0000e+00,  9.8429e-01],\n",
       "        [ 6.8696e-01,  0.0000e+00,  7.2670e-01],\n",
       "        [ 2.2831e-02,  0.0000e+00,  9.9974e-01],\n",
       "        [ 2.3929e-02,  0.0000e+00,  9.9971e-01],\n",
       "        [ 5.6769e-02,  0.0000e+00,  9.9839e-01],\n",
       "        [ 6.7284e-02,  0.0000e+00, -9.9773e-01],\n",
       "        [ 1.1077e-01,  0.0000e+00,  9.9385e-01],\n",
       "        [ 3.7513e-01,  7.6775e-02,  9.2379e-01],\n",
       "        [ 1.9286e-02,  0.0000e+00,  9.9981e-01],\n",
       "        [ 5.6171e-02,  0.0000e+00,  9.9842e-01],\n",
       "        [-2.1327e-01,  0.0000e+00,  9.7699e-01],\n",
       "        [ 2.6680e-02,  0.0000e+00,  9.9964e-01],\n",
       "        [-3.7461e-01,  0.0000e+00,  9.2718e-01],\n",
       "        [-1.6521e-01,  0.0000e+00,  9.8626e-01],\n",
       "        [-1.2193e-01,  0.0000e+00,  9.9254e-01],\n",
       "        [ 1.4774e-02,  0.0000e+00,  9.9989e-01],\n",
       "        [ 2.2620e-02,  0.0000e+00,  9.9974e-01],\n",
       "        [ 1.5648e-02,  0.0000e+00,  9.9988e-01],\n",
       "        [ 1.3791e-01,  0.0000e+00,  9.9045e-01],\n",
       "        [ 2.1846e-02,  0.0000e+00,  9.9976e-01],\n",
       "        [ 2.0758e-01,  9.3503e-01,  2.8745e-01],\n",
       "        [ 1.6466e-01,  0.0000e+00,  9.8635e-01],\n",
       "        [ 6.1870e-02,  0.0000e+00,  9.9808e-01],\n",
       "        [ 8.3365e-02, -1.4915e-01,  9.8529e-01],\n",
       "        [-6.9113e-01,  0.0000e+00, -7.2273e-01],\n",
       "        [ 5.3754e-02,  0.0000e+00,  9.9855e-01],\n",
       "        [-2.8354e-02, -4.6042e-02,  9.9854e-01],\n",
       "        [ 1.5333e-01,  0.0000e+00,  9.8818e-01],\n",
       "        [ 4.4493e-02,  0.0000e+00,  9.9901e-01],\n",
       "        [ 7.5414e-02, -1.0461e-01,  9.9165e-01],\n",
       "        [ 2.7642e-02,  0.0000e+00,  9.9962e-01],\n",
       "        [ 1.6026e-01,  0.0000e+00,  9.8708e-01],\n",
       "        [ 3.9749e-01,  4.0621e-01,  8.2280e-01],\n",
       "        [ 8.9162e-02,  0.0000e+00,  9.9602e-01],\n",
       "        [ 1.3471e-02,  0.0000e+00,  9.9991e-01],\n",
       "        [ 8.2894e-01,  0.0000e+00,  5.5933e-01],\n",
       "        [ 2.5312e-02,  0.0000e+00,  9.9968e-01],\n",
       "        [ 3.0255e-02,  0.0000e+00,  9.9954e-01],\n",
       "        [ 2.4069e-01,  0.0000e+00,  9.7060e-01],\n",
       "        [ 4.3010e-01,  2.2144e-01,  8.7520e-01],\n",
       "        [-1.9967e-01,  0.0000e+00,  9.7986e-01],\n",
       "        [-2.1786e-01, -1.9730e-01,  9.5583e-01],\n",
       "        [ 4.2895e-01,  0.0000e+00,  9.0333e-01],\n",
       "        [ 1.7608e-02,  0.0000e+00,  9.9985e-01],\n",
       "        [ 5.7703e-02,  0.0000e+00,  9.9833e-01],\n",
       "        [-1.9183e-02, -1.0296e-01,  9.9450e-01],\n",
       "        [-4.6719e-01,  0.0000e+00,  8.8416e-01],\n",
       "        [-1.5610e-01,  0.0000e+00,  9.8774e-01],\n",
       "        [ 8.4131e-01,  0.0000e+00,  5.4055e-01],\n",
       "        [-1.9085e-01, -1.9023e-01,  9.6301e-01],\n",
       "        [-1.5596e-01,  0.0000e+00,  9.8776e-01],\n",
       "        [ 1.3212e-02,  0.0000e+00,  9.9991e-01],\n",
       "        [ 1.3151e-02,  0.0000e+00,  9.9991e-01],\n",
       "        [ 3.0268e-01,  7.7710e-01, -5.5181e-01],\n",
       "        [ 1.5091e-01,  0.0000e+00, -9.8855e-01],\n",
       "        [ 3.3519e-01,  2.1097e-02,  9.4191e-01],\n",
       "        [ 6.3665e-01,  4.9193e-03,  7.7114e-01],\n",
       "        [ 3.0530e-01,  0.0000e+00,  9.5225e-01],\n",
       "        [-7.1857e-02, -1.6738e-01, -9.8327e-01],\n",
       "        [ 1.6646e-01,  0.0000e+00,  9.8605e-01],\n",
       "        [ 7.7291e-02,  0.0000e+00,  9.9701e-01],\n",
       "        [ 4.8382e-02,  0.0000e+00,  9.9883e-01],\n",
       "        [ 4.6028e-02,  0.0000e+00,  9.9894e-01],\n",
       "        [ 8.1711e-02,  0.0000e+00,  9.9666e-01],\n",
       "        [-4.1153e-02,  0.0000e+00,  9.9915e-01],\n",
       "        [ 2.7202e-01,  0.0000e+00,  9.6229e-01],\n",
       "        [ 5.6071e-02,  0.0000e+00,  9.9843e-01],\n",
       "        [-1.5721e-01,  0.0000e+00,  9.8756e-01],\n",
       "        [-5.3815e-01, -1.8466e-01,  8.2237e-01],\n",
       "        [ 1.6685e-02,  0.0000e+00,  9.9986e-01],\n",
       "        [ 5.6378e-02,  0.0000e+00,  9.9841e-01],\n",
       "        [ 6.1206e-04, -9.0419e-03,  9.9996e-01],\n",
       "        [ 4.8779e-01,  0.0000e+00,  8.7296e-01],\n",
       "        [ 1.2627e-01,  0.0000e+00,  9.9200e-01],\n",
       "        [ 1.7526e-01,  2.0816e-02,  9.8430e-01],\n",
       "        [ 3.7948e-02,  0.0000e+00,  9.9928e-01],\n",
       "        [ 4.3893e-01,  0.0000e+00,  8.9852e-01],\n",
       "        [-5.5653e-03,  0.0000e+00,  9.9998e-01],\n",
       "        [-3.7036e-01,  0.0000e+00, -9.2889e-01],\n",
       "        [ 5.4637e-01,  2.4313e-02, -8.3719e-01],\n",
       "        [ 3.7956e-02,  0.0000e+00,  9.9928e-01],\n",
       "        [ 1.5608e-01,  0.0000e+00,  9.8774e-01],\n",
       "        [ 2.7421e-02,  0.0000e+00,  9.9962e-01],\n",
       "        [ 6.2927e-02,  0.0000e+00,  9.9802e-01]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does not work we do not have pos\n",
    "#visualize_points(data.pos, data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs pairs: 382\n",
      "Number of validation graphs: 95\n",
      "Number of test graphs: 95\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader \n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "n_train = math.ceil((4/6) * len(dataset))\n",
    "n_val = math.ceil((len(dataset) - n_train)/2)\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [n_train, n_val, n_test])\n",
    "print(f'Number of training graphs pairs: {len(train_dataset)}')\n",
    "print(f'Number of validation graphs: {len(val_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')\n",
    "\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size= batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset = val_dataset, batch_size= batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size= batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PairDataBatch(adj1=[100, 100], x1=[100, 3], adj2=[100, 100], x2=[100, 3], y=[1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "databatch = next(iter(train_loader))\n",
    "databatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_nodes, in_channels, hidden_channels, out_channels,\n",
    "                 normalize=False, lin=True):\n",
    "        super(GNN, self).__init__()\n",
    "\n",
    "        # Each instance of this GNN will have 3 convolutional layers and three batch norm layers        \n",
    "        self.conv1 = DenseGCNConv(in_channels, hidden_channels, normalize)\n",
    "        self.bns1 = torch.nn.BatchNorm1d(in_nodes)\n",
    "        \n",
    "        self.conv2 = DenseGCNConv(hidden_channels, hidden_channels, normalize)\n",
    "        self.bns2 = torch.nn.BatchNorm1d(in_nodes)\n",
    "        \n",
    "        self.conv3 = DenseGCNConv(hidden_channels, out_channels, normalize)\n",
    "        self.bns3 = torch.nn.BatchNorm1d(in_nodes)\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        \n",
    "        #Step 1\n",
    "        x = self.conv1(x, adj, mask)\n",
    "        x = self.bns1(x)\n",
    "        \n",
    "        #Step 2\n",
    "        x = self.conv2(x, adj, mask)\n",
    "        x = self.bns2(x)\n",
    "\n",
    "        #Step 3\n",
    "        x = self.conv3(x, adj, mask)\n",
    "        if x.shape[2] != 1: \n",
    "            x = self.bns3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class DiffPool(torch.nn.Module):\n",
    "    def __init__(self, num_nodes):\n",
    "        super(DiffPool, self).__init__()\n",
    "\n",
    "        #Hierarchical Step #1\n",
    "        in_nodes = num_nodes\n",
    "        out_nodes = 25 # Number of clusters / nodes in the next layer\n",
    "        self.gnn1_pool = GNN(in_nodes, dataset.num_features, 16, out_nodes) # PoolGNN --> Cluster Assignment Matrix to reduce to num_nodes\n",
    "        self.gnn1_embed = GNN(in_nodes, dataset.num_features, 8, 8) # EmbGNN --> Convolutions to create new node embedding\n",
    "\n",
    "        # Hierarchical Step #2\n",
    "        in_nodes = out_nodes\n",
    "        out_nodes = 10\n",
    "        self.gnn2_pool = GNN(in_nodes, 8, 8, out_nodes)\n",
    "        self.gnn2_embed = GNN(in_nodes, 8, 12, 16, lin=False)\n",
    "\n",
    "        # Hierarchical Step #3\n",
    "        in_nodes = out_nodes\n",
    "        out_nodes = 1\n",
    "        self.gnn3_pool = GNN(in_nodes, 16, 16, out_nodes)\n",
    "        self.gnn3_embed = GNN(in_nodes, 16, 16, 32, lin=False)\n",
    "\n",
    "        # Final Classifier\n",
    "        self.lin1 = torch.nn.Linear(32, 64) \n",
    "        #self.lin2 = torch.nn.Linear(64, 2)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x, adj, batch, mask=None):\n",
    "        \n",
    "        #if batch == 0: print('Shape of input data batch:')\n",
    "        #if batch == 0: print(f'Feature Matrix: {tuple(x.shape)}')\n",
    "        #if batch == 0: print(f'Adjacency Matrix: {tuple(adj.shape)}')\n",
    "       \n",
    "\n",
    "\n",
    "        #Hierarchical Step #1\n",
    "        #if batch == 0: print('Hierarchical Step #1')\n",
    "        x1 = self.gnn1_embed(x, adj, mask) # node feature embedding\n",
    "        s = self.gnn1_pool(x, adj, mask) # cluster assignment matrix\n",
    "\n",
    "        #if batch == 0: print(f'X1 = {tuple(x1.shape)}    S1: {tuple(s.shape)}')\n",
    "\n",
    "        x, adj, l1, e1 = dense_diff_pool(x1, adj, s, mask) # does the necessary matrix multiplications\n",
    "        adj = torch.softmax(adj, dim=-1)\n",
    "\n",
    "        #if batch == 0: print(f'---matmul---> New feature matrix (softmax(s_0.t()) @ z_0) = {tuple(x.shape)}')\n",
    "        #if batch == 0: print(f'---matmul---> New adjacency matrix (s_0.t() @ adj_0 @ s_0) = {tuple(adj.shape)}')\n",
    "   \n",
    "\n",
    "\n",
    "        # Hierarchical Step #2\n",
    "        #if batch == 0: print('Hierarchical Step #2')\n",
    "        x2 = self.gnn2_embed(x, adj)\n",
    "        s = self.gnn2_pool(x, adj)\n",
    "\n",
    "        #if batch == 0: print(f'X2: {tuple(x2.shape)}    S2: {tuple(s.shape)}')\n",
    "        \n",
    "        x, adj, l2, e2 = dense_diff_pool(x2, adj, s)\n",
    "        adj = torch.softmax(adj, dim=-1)\n",
    "\n",
    "        #if batch == 0: print(f'---matmul---> New feature matrix (softmax(s_0.t()) @ z_0) = {tuple(x.shape)}')\n",
    "        #if batch == 0: print(f'---matmul---> New adjacency matrix (s_0.t() @ adj_0 @ s_0) = {tuple(adj.shape)}')\n",
    "      \n",
    "        \n",
    "\n",
    "        # Hierarchical Step #3\n",
    "        #if batch == 0: print('Hierarchical Step #3')\n",
    "        x3 = self.gnn3_embed(x, adj)\n",
    "        s = self.gnn3_pool(x, adj)\n",
    "        \n",
    "        #if batch == 0: print(f'X3: {tuple(x3.shape)}    S3: {tuple(s.shape)}')\n",
    "\n",
    "        x, adj, l3, e3 = dense_diff_pool(x3, adj, s)\n",
    "        adj = torch.softmax(adj, dim=-1)\n",
    "\n",
    "        #if batch == 0: print(f'---matmul---> New feature matrix (softmax(s_0.t()) @ z_0) = {tuple(x.shape)}')\n",
    "        #if batch == 0: print(f'---matmul---> New adjacency matrix (s_0.t() @ adj_0 @ s_0) = {tuple(adj.shape)}')\n",
    "     \n",
    "        \n",
    "\n",
    "        # Final Classification\n",
    "        #if batch == 0: print('Final Output')\n",
    "        x = x.mean(dim=1) # Pool the features of all nodes (global mean pool)  dim = 1 refers to columns\n",
    "        #if batch == 0: print(f'---X Output after mean= {tuple(x.shape)}')\n",
    "\n",
    "        x = F.relu(self.lin1(x)) # Fully connected layer + relu\n",
    "        #if batch == 0: print(f'------ X Output 3 after lin= {tuple(x.shape)}')\n",
    "\n",
    "        \n",
    "        return x, l1 + l2 + l3, e1 + e2 + e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An attempt of a contrastive loss function\n",
    "#   pairs with label 1 --> should get small euclid dist = small loss\n",
    "#   pairs with label 0 --> should get large euclid dist = large loss\n",
    "\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, x0, x1, y):\n",
    "        # euclidian distance\n",
    "        #print(x0)\n",
    "        #print(x1)\n",
    "        #print(y)\n",
    "        diff = x0 - x1\n",
    "        #print(diff)\n",
    "        pow = torch.pow(diff, 2)\n",
    "        #print(pow)\n",
    "        dist_sq = torch.sum(pow, 1)\n",
    "        #print(dist_sq) # sum of squared distance = 0.5 = 9\n",
    "        dist = torch.sqrt(dist_sq)\n",
    "        #print(dist) # euclidean distance = 0.7 = 3\n",
    "\n",
    "        mdist = self.margin - dist #negative euclidean distance - margin = 0.3 = -2\n",
    "        #print(mdist)\n",
    "        dist_marg = torch.clamp(mdist, min=0.0) # only distances <margin will be still positive here = 0.3 = 0\n",
    "        #print(dist)\n",
    "        loss =  y * torch.pow(dist, 2) + (1-y) * torch.pow(dist_marg,2)\n",
    "\n",
    "        # What happens to a pair with squared euclid dist (dist_sq) of 0.5\n",
    "        # if label = 0 --> 0 + squared clampled euclid distance --> loss = 0.3^2\n",
    "        # if label = 1 --> squared euclidean distance + 0 --> loss = 0.5\n",
    "\n",
    "        # What happens to a pair with squared euclid dist (dist_sq) of 9\n",
    "        # if label = 0 --> 0 + squared clampled euclid distance --> loss = 0\n",
    "        # if label = 1 --> squared euclidean distance + 0 --> loss = 9\n",
    "\n",
    "        #print(loss)\n",
    "        #loss = torch.sum(loss) / 2.0 \n",
    "        loss = torch.sum(loss) / 2.0 / x0.size()[0]\n",
    "        #print(loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch: 001, Train Loss: 16.836\n",
      "Epoch: 002, Train Loss: 0.127\n",
      "Epoch: 003, Train Loss: 0.128\n",
      "Epoch: 004, Train Loss: 0.163\n",
      "Epoch: 005, Train Loss: 0.207\n",
      "Epoch: 006, Train Loss: 0.167\n",
      "Epoch: 007, Train Loss: 0.244\n",
      "Epoch: 008, Train Loss: 0.226\n",
      "Epoch: 009, Train Loss: 0.260\n",
      "Epoch: 010, Train Loss: 0.231\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = DiffPool(num_nodes = 100).to(device)\n",
    "criterion = ContrastiveLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 10\n",
    "\n",
    "def train(epoch):\n",
    "    batch = 0\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output1, _, _ = model(data.x1, data.adj1, batch)\n",
    "        output2, _, _ = model(data.x2, data.adj2, batch = None)\n",
    "        \n",
    "        #Contrastive Loss\n",
    "        loss_contrastive = criterion(output1,output2,data.y)\n",
    "        loss_contrastive.backward()\n",
    "        loss_all += data.y.size(0) * loss_contrastive.item()\n",
    "        optimizer.step()\n",
    "        batch +=1\n",
    "\n",
    "    return loss_all / len(train_dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    distances_lab1 = []\n",
    "    distances_lab0 = []\n",
    "    labels = []\n",
    "    losses = []\n",
    "    \n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output1, _, _ = model(data.x1, data.adj2, batch=None)\n",
    "        output2, _, _ = model(data.x2, data.adj2, batch=None)\n",
    "\n",
    "        test_loss_contrastive = criterion(output1, output2, data.y)\n",
    "        \n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        label = data.y\n",
    "\n",
    "        if int(label) == 1: \n",
    "            distances_lab1.append(float(euclidean_distance))\n",
    "            labels.append(int(label))\n",
    "            losses.append(float(test_loss_contrastive))\n",
    "        else:\n",
    "            distances_lab0.append(float(euclidean_distance))\n",
    "            labels.append(int(label))\n",
    "            losses.append(float(test_loss_contrastive))\n",
    "\n",
    "    return  distances_lab0, distances_lab1, losses, labels\n",
    "\n",
    "\n",
    "\n",
    "train_distances_lab0 = []\n",
    "train_distances_lab1 = []\n",
    "train_losses = []\n",
    "train_labels = []\n",
    "\n",
    "validation_distances_lab0 = []\n",
    "validation_distances_lab1 = []\n",
    "validation_losses = []\n",
    "validation_labels = []\n",
    "\n",
    "test_distances_lab0 = []\n",
    "test_distances_lab1 = []\n",
    "test_losses = []\n",
    "test_labels = []\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    train_loss = train(epoch)\n",
    "\n",
    "    train_results = test(train_loader)\n",
    "    train_distances_lab0.append(train_results[0])\n",
    "    train_distances_lab1.append(train_results[1])\n",
    "    train_losses.append(train_results[2])\n",
    "    train_labels.append(train_results[3])\n",
    "\n",
    "\n",
    "    validation_results = test(val_loader)\n",
    "    validation_distances_lab0.append(validation_results[0])\n",
    "    validation_distances_lab1.append(validation_results[1])\n",
    "    validation_losses.append(validation_results[2])\n",
    "    validation_labels.append(validation_results[3])\n",
    "\n",
    "    test_results = test(test_loader)\n",
    "    test_distances_lab0.append(test_results[0])\n",
    "    test_distances_lab1.append(test_results[1])\n",
    "    test_losses.append(test_results[2])\n",
    "    test_labels.append(test_results[3])\n",
    "\n",
    "\n",
    "    print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.3f}')\n",
    "    #Train Acc: {train_acc:.3f}, f'Val Acc: {val_acc:.3f}, Test Acc: {test_acc:.3f}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compare_euclid_distances(distances_lab0, distances_lab1):\n",
    "\n",
    "    w = 0.8    # bar width\n",
    "    x = [1, 2] # x-coordinates of your bars\n",
    "    colors = [(0, 0, 1, 1), (1, 0, 0, 1)]    # corresponding colors\n",
    "\n",
    "    # Epoch 0\n",
    "    y = [distances_lab0, distances_lab1]\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(x,\n",
    "        height=[np.mean(yi) for yi in y],\n",
    "        yerr=[np.std(yi) for yi in y],    # error bars\n",
    "        capsize=12, # error bar cap width in points\n",
    "        width=w,    # bar width\n",
    "        tick_label=[\"Label 0\", \"Label 1\"],\n",
    "        color=(0,0,0,0),  # face color transparent\n",
    "        edgecolor=colors,\n",
    "        )\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        # distribute scatter randomly across whole width of bar\n",
    "        ax.scatter(x[i] + np.random.random(len(y[i])) * w - w / 2, y[i], color=colors[i])\n",
    "\n",
    "    plt.ylabel = 'Euclidean Distance'\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_euclid_distances(train_distances_lab0[9], train_distances_lab1[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "gnn1_pool.conv1.bias \t torch.Size([16])\n",
      "gnn1_pool.conv1.lin.weight \t torch.Size([16, 3])\n",
      "gnn1_pool.bns1.weight \t torch.Size([100])\n",
      "gnn1_pool.bns1.bias \t torch.Size([100])\n",
      "gnn1_pool.bns1.running_mean \t torch.Size([100])\n",
      "gnn1_pool.bns1.running_var \t torch.Size([100])\n",
      "gnn1_pool.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn1_pool.conv2.bias \t torch.Size([16])\n",
      "gnn1_pool.conv2.lin.weight \t torch.Size([16, 16])\n",
      "gnn1_pool.bns2.weight \t torch.Size([100])\n",
      "gnn1_pool.bns2.bias \t torch.Size([100])\n",
      "gnn1_pool.bns2.running_mean \t torch.Size([100])\n",
      "gnn1_pool.bns2.running_var \t torch.Size([100])\n",
      "gnn1_pool.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn1_pool.conv3.bias \t torch.Size([25])\n",
      "gnn1_pool.conv3.lin.weight \t torch.Size([25, 16])\n",
      "gnn1_pool.bns3.weight \t torch.Size([100])\n",
      "gnn1_pool.bns3.bias \t torch.Size([100])\n",
      "gnn1_pool.bns3.running_mean \t torch.Size([100])\n",
      "gnn1_pool.bns3.running_var \t torch.Size([100])\n",
      "gnn1_pool.bns3.num_batches_tracked \t torch.Size([])\n",
      "gnn1_embed.conv1.bias \t torch.Size([8])\n",
      "gnn1_embed.conv1.lin.weight \t torch.Size([8, 3])\n",
      "gnn1_embed.bns1.weight \t torch.Size([100])\n",
      "gnn1_embed.bns1.bias \t torch.Size([100])\n",
      "gnn1_embed.bns1.running_mean \t torch.Size([100])\n",
      "gnn1_embed.bns1.running_var \t torch.Size([100])\n",
      "gnn1_embed.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn1_embed.conv2.bias \t torch.Size([8])\n",
      "gnn1_embed.conv2.lin.weight \t torch.Size([8, 8])\n",
      "gnn1_embed.bns2.weight \t torch.Size([100])\n",
      "gnn1_embed.bns2.bias \t torch.Size([100])\n",
      "gnn1_embed.bns2.running_mean \t torch.Size([100])\n",
      "gnn1_embed.bns2.running_var \t torch.Size([100])\n",
      "gnn1_embed.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn1_embed.conv3.bias \t torch.Size([8])\n",
      "gnn1_embed.conv3.lin.weight \t torch.Size([8, 8])\n",
      "gnn1_embed.bns3.weight \t torch.Size([100])\n",
      "gnn1_embed.bns3.bias \t torch.Size([100])\n",
      "gnn1_embed.bns3.running_mean \t torch.Size([100])\n",
      "gnn1_embed.bns3.running_var \t torch.Size([100])\n",
      "gnn1_embed.bns3.num_batches_tracked \t torch.Size([])\n",
      "gnn2_pool.conv1.bias \t torch.Size([8])\n",
      "gnn2_pool.conv1.lin.weight \t torch.Size([8, 8])\n",
      "gnn2_pool.bns1.weight \t torch.Size([25])\n",
      "gnn2_pool.bns1.bias \t torch.Size([25])\n",
      "gnn2_pool.bns1.running_mean \t torch.Size([25])\n",
      "gnn2_pool.bns1.running_var \t torch.Size([25])\n",
      "gnn2_pool.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn2_pool.conv2.bias \t torch.Size([8])\n",
      "gnn2_pool.conv2.lin.weight \t torch.Size([8, 8])\n",
      "gnn2_pool.bns2.weight \t torch.Size([25])\n",
      "gnn2_pool.bns2.bias \t torch.Size([25])\n",
      "gnn2_pool.bns2.running_mean \t torch.Size([25])\n",
      "gnn2_pool.bns2.running_var \t torch.Size([25])\n",
      "gnn2_pool.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn2_pool.conv3.bias \t torch.Size([10])\n",
      "gnn2_pool.conv3.lin.weight \t torch.Size([10, 8])\n",
      "gnn2_pool.bns3.weight \t torch.Size([25])\n",
      "gnn2_pool.bns3.bias \t torch.Size([25])\n",
      "gnn2_pool.bns3.running_mean \t torch.Size([25])\n",
      "gnn2_pool.bns3.running_var \t torch.Size([25])\n",
      "gnn2_pool.bns3.num_batches_tracked \t torch.Size([])\n",
      "gnn2_embed.conv1.bias \t torch.Size([12])\n",
      "gnn2_embed.conv1.lin.weight \t torch.Size([12, 8])\n",
      "gnn2_embed.bns1.weight \t torch.Size([25])\n",
      "gnn2_embed.bns1.bias \t torch.Size([25])\n",
      "gnn2_embed.bns1.running_mean \t torch.Size([25])\n",
      "gnn2_embed.bns1.running_var \t torch.Size([25])\n",
      "gnn2_embed.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn2_embed.conv2.bias \t torch.Size([12])\n",
      "gnn2_embed.conv2.lin.weight \t torch.Size([12, 12])\n",
      "gnn2_embed.bns2.weight \t torch.Size([25])\n",
      "gnn2_embed.bns2.bias \t torch.Size([25])\n",
      "gnn2_embed.bns2.running_mean \t torch.Size([25])\n",
      "gnn2_embed.bns2.running_var \t torch.Size([25])\n",
      "gnn2_embed.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn2_embed.conv3.bias \t torch.Size([16])\n",
      "gnn2_embed.conv3.lin.weight \t torch.Size([16, 12])\n",
      "gnn2_embed.bns3.weight \t torch.Size([25])\n",
      "gnn2_embed.bns3.bias \t torch.Size([25])\n",
      "gnn2_embed.bns3.running_mean \t torch.Size([25])\n",
      "gnn2_embed.bns3.running_var \t torch.Size([25])\n",
      "gnn2_embed.bns3.num_batches_tracked \t torch.Size([])\n",
      "gnn3_pool.conv1.bias \t torch.Size([16])\n",
      "gnn3_pool.conv1.lin.weight \t torch.Size([16, 16])\n",
      "gnn3_pool.bns1.weight \t torch.Size([10])\n",
      "gnn3_pool.bns1.bias \t torch.Size([10])\n",
      "gnn3_pool.bns1.running_mean \t torch.Size([10])\n",
      "gnn3_pool.bns1.running_var \t torch.Size([10])\n",
      "gnn3_pool.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn3_pool.conv2.bias \t torch.Size([16])\n",
      "gnn3_pool.conv2.lin.weight \t torch.Size([16, 16])\n",
      "gnn3_pool.bns2.weight \t torch.Size([10])\n",
      "gnn3_pool.bns2.bias \t torch.Size([10])\n",
      "gnn3_pool.bns2.running_mean \t torch.Size([10])\n",
      "gnn3_pool.bns2.running_var \t torch.Size([10])\n",
      "gnn3_pool.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn3_pool.conv3.bias \t torch.Size([1])\n",
      "gnn3_pool.conv3.lin.weight \t torch.Size([1, 16])\n",
      "gnn3_pool.bns3.weight \t torch.Size([10])\n",
      "gnn3_pool.bns3.bias \t torch.Size([10])\n",
      "gnn3_pool.bns3.running_mean \t torch.Size([10])\n",
      "gnn3_pool.bns3.running_var \t torch.Size([10])\n",
      "gnn3_pool.bns3.num_batches_tracked \t torch.Size([])\n",
      "gnn3_embed.conv1.bias \t torch.Size([16])\n",
      "gnn3_embed.conv1.lin.weight \t torch.Size([16, 16])\n",
      "gnn3_embed.bns1.weight \t torch.Size([10])\n",
      "gnn3_embed.bns1.bias \t torch.Size([10])\n",
      "gnn3_embed.bns1.running_mean \t torch.Size([10])\n",
      "gnn3_embed.bns1.running_var \t torch.Size([10])\n",
      "gnn3_embed.bns1.num_batches_tracked \t torch.Size([])\n",
      "gnn3_embed.conv2.bias \t torch.Size([16])\n",
      "gnn3_embed.conv2.lin.weight \t torch.Size([16, 16])\n",
      "gnn3_embed.bns2.weight \t torch.Size([10])\n",
      "gnn3_embed.bns2.bias \t torch.Size([10])\n",
      "gnn3_embed.bns2.running_mean \t torch.Size([10])\n",
      "gnn3_embed.bns2.running_var \t torch.Size([10])\n",
      "gnn3_embed.bns2.num_batches_tracked \t torch.Size([])\n",
      "gnn3_embed.conv3.bias \t torch.Size([32])\n",
      "gnn3_embed.conv3.lin.weight \t torch.Size([32, 16])\n",
      "gnn3_embed.bns3.weight \t torch.Size([10])\n",
      "gnn3_embed.bns3.bias \t torch.Size([10])\n",
      "gnn3_embed.bns3.running_mean \t torch.Size([10])\n",
      "gnn3_embed.bns3.running_var \t torch.Size([10])\n",
      "gnn3_embed.bns3.num_batches_tracked \t torch.Size([])\n",
      "lin1.weight \t torch.Size([64, 32])\n",
      "lin1.bias \t torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer's state_dict:\n",
      "state \t {0: {'step': tensor(3820.), 'exp_avg': tensor([ 2.8445e-20, -6.9422e-20, -3.1782e-20,  5.2043e-20,  4.7987e-22,\n",
      "         1.2048e-20, -3.6965e-20,  3.2110e-20,  1.2917e-20, -1.1714e-20,\n",
      "         1.0632e-20,  3.9492e-20, -5.6435e-20,  2.1133e-21,  5.2675e-20,\n",
      "        -3.6637e-20]), 'exp_avg_sq': tensor([ 4.2446, 64.4574,  1.5525,  7.4734, 27.9939, 37.3418, 85.5606, 95.1106,\n",
      "        13.2425, 25.7589,  9.2820,  9.6957, 10.5717, 32.5673,  9.9329, 20.5714])}, 1: {'step': tensor(3820.), 'exp_avg': tensor([[ 2.3940e-20, -7.6265e-22, -5.5771e-20],\n",
      "        [-1.1371e-19, -1.5135e-20,  1.8058e-19],\n",
      "        [-4.7432e-20, -5.7289e-21,  9.6904e-20],\n",
      "        [ 7.8894e-20,  1.0673e-20, -1.6599e-19],\n",
      "        [ 9.7582e-21,  1.8193e-21,  2.7258e-20],\n",
      "        [ 3.0610e-20,  6.5959e-21, -2.6931e-20],\n",
      "        [-6.9400e-20, -1.0735e-20,  8.5243e-20],\n",
      "        [ 7.2120e-20,  1.3122e-20, -7.4682e-20],\n",
      "        [ 2.3193e-20,  2.2115e-21, -6.3141e-20],\n",
      "        [-3.5133e-20, -7.8863e-21,  2.6737e-20],\n",
      "        [ 1.0128e-20,  4.7213e-22, -1.3880e-21],\n",
      "        [ 7.1243e-20,  1.2274e-20, -1.6357e-19],\n",
      "        [-7.6299e-20, -9.6846e-21,  1.6129e-19],\n",
      "        [ 8.2907e-21,  1.6693e-22,  1.3315e-20],\n",
      "        [ 8.1818e-20,  1.2777e-20, -1.3957e-19],\n",
      "        [-6.8025e-20, -1.0180e-20,  9.9719e-20]]), 'exp_avg_sq': tensor([[7.2498e-01, 1.7505e-02, 2.8943e+00],\n",
      "        [2.5401e+00, 3.9681e-02, 2.1026e+01],\n",
      "        [5.9742e-01, 4.5880e-02, 1.8469e+00],\n",
      "        [9.7877e-02, 1.0490e-02, 2.7538e+00],\n",
      "        [1.7719e+00, 1.3275e-01, 7.8935e+00],\n",
      "        [7.5712e+00, 2.2491e-01, 5.3427e+00],\n",
      "        [2.5459e+00, 4.3272e-02, 2.6864e+01],\n",
      "        [2.2622e+00, 7.3817e-02, 3.8084e+01],\n",
      "        [3.5185e+00, 1.1245e-01, 1.3974e+00],\n",
      "        [9.8742e-01, 2.5151e-02, 9.7905e+00],\n",
      "        [1.9560e-01, 2.0613e-02, 3.3188e+00],\n",
      "        [1.9713e-01, 1.9056e-02, 3.3092e+00],\n",
      "        [1.3321e+00, 3.1392e-02, 1.8560e+00],\n",
      "        [3.3392e+00, 7.0811e-02, 6.0902e+00],\n",
      "        [3.4968e+00, 1.3287e-01, 1.6523e+00],\n",
      "        [1.0153e+00, 2.3514e-02, 5.1510e+00]])}, 2: {'step': tensor(3820.), 'exp_avg': tensor([ 5.9874e-23, -2.4423e-22,  3.3561e-22, -1.9214e-21, -7.7384e-23,\n",
      "         2.5921e-22, -3.0910e-23, -1.4572e-22, -9.4350e-23, -4.9252e-21,\n",
      "         1.5653e-22, -9.0766e-23, -2.3045e-22,  1.0941e-21, -1.3472e-22,\n",
      "         3.5810e-22, -1.3146e-22, -1.2275e-22, -1.9709e-22, -1.4744e-22,\n",
      "         1.4520e-22, -1.4873e-23,  2.4371e-22, -1.9033e-22, -1.7772e-22,\n",
      "        -1.2896e-22, -4.0118e-22, -1.4654e-22,  1.0423e-22, -4.4168e-22,\n",
      "        -1.2437e-22,  8.0043e-22,  3.4955e-22, -2.0946e-21, -1.1401e-23,\n",
      "         1.9329e-23, -4.1568e-21,  1.9024e-22,  9.8901e-23, -3.8664e-22,\n",
      "        -1.4711e-22,  1.7858e-22, -1.3909e-22,  7.8003e-23,  5.9563e-22,\n",
      "         6.8532e-22, -5.5730e-23,  3.6210e-22, -9.4456e-23, -2.5438e-22,\n",
      "        -6.9448e-22,  1.0874e-22, -1.1812e-21, -1.3190e-22, -4.1631e-23,\n",
      "         2.2817e-22,  1.0112e-22,  1.2646e-22, -3.3078e-22, -6.1787e-24,\n",
      "        -2.4818e-22, -2.9513e-22, -2.7223e-22, -3.4191e-22,  6.3324e-22,\n",
      "        -3.5244e-21, -2.2438e-22, -1.4714e-22,  2.5308e-22, -2.4295e-22,\n",
      "         3.2030e-22, -2.2886e-24,  3.6886e-23, -1.5836e-22, -1.8336e-21,\n",
      "        -1.8286e-22,  1.4398e-21,  4.2336e-22, -7.4274e-23,  1.1739e-22,\n",
      "         4.5226e-22,  1.2424e-21,  1.1111e-21,  7.7912e-22, -3.2238e-22,\n",
      "        -5.0509e-22, -7.5663e-22, -1.0012e-22, -1.3550e-22,  2.2223e-23,\n",
      "         6.8775e-22, -1.5166e-22,  3.8417e-22, -2.6292e-22,  1.1376e-21,\n",
      "         1.2716e-22,  5.5575e-22, -7.6631e-22, -1.2722e-22,  6.1013e-23]), 'exp_avg_sq': tensor([0.0016, 0.0006, 0.0012, 0.0013, 0.0005, 0.0010, 0.0032, 0.0014, 0.0015,\n",
      "        0.0017, 0.0044, 0.0013, 0.0002, 0.0004, 0.0008, 0.0007, 0.0008, 0.0007,\n",
      "        0.0027, 0.0002, 0.0007, 0.0023, 0.0025, 0.0010, 0.0025, 0.0012, 0.0004,\n",
      "        0.0011, 0.0027, 0.0005, 0.0004, 0.0030, 0.0004, 0.0010, 0.0033, 0.0003,\n",
      "        0.0004, 0.0009, 0.0001, 0.0009, 0.0005, 0.0039, 0.0008, 0.0004, 0.0009,\n",
      "        0.0003, 0.0023, 0.0010, 0.0013, 0.0014, 0.0003, 0.0045, 0.0004, 0.0004,\n",
      "        0.0019, 0.0019, 0.0003, 0.0025, 0.0023, 0.0012, 0.0004, 0.0009, 0.0016,\n",
      "        0.0004, 0.0003, 0.0018, 0.0016, 0.0003, 0.0017, 0.0004, 0.0008, 0.0010,\n",
      "        0.0025, 0.0010, 0.0003, 0.0003, 0.0008, 0.0037, 0.0011, 0.0006, 0.0015,\n",
      "        0.0018, 0.0011, 0.0010, 0.0039, 0.0006, 0.0008, 0.0023, 0.0004, 0.0023,\n",
      "        0.0021, 0.0004, 0.0015, 0.0010, 0.0027, 0.0005, 0.0003, 0.0006, 0.0008,\n",
      "        0.0043])}, 3: {'step': tensor(3820.), 'exp_avg': tensor([-2.7850e-22,  4.2932e-21, -5.4398e-21,  6.8783e-22,  6.6034e-22,\n",
      "        -5.9018e-21,  6.3367e-22,  3.5780e-21,  1.1077e-21,  4.7723e-21,\n",
      "        -5.2830e-22,  5.2215e-22,  2.9610e-21,  6.6525e-22,  1.5906e-21,\n",
      "        -5.4592e-21, -1.3159e-21,  3.8699e-21,  1.2501e-21,  1.2814e-21,\n",
      "         1.7730e-21,  1.5436e-21,  6.0674e-21,  1.8273e-21,  1.7471e-21,\n",
      "         1.8116e-21,  1.2066e-21,  8.1730e-23, -1.5290e-21,  4.5468e-21,\n",
      "         3.3962e-21, -5.1389e-21,  8.8180e-22,  4.7352e-21,  3.4314e-21,\n",
      "        -1.4705e-22,  1.8707e-21, -1.3318e-21, -7.2448e-22,  4.7030e-21,\n",
      "         1.6657e-21,  1.1957e-23,  1.0301e-21, -6.3320e-22,  7.8994e-22,\n",
      "        -4.7125e-21,  1.1944e-22,  5.1751e-21,  2.7999e-21,  2.5825e-21,\n",
      "        -2.1794e-22, -1.2871e-21,  7.1237e-21,  2.6062e-21,  3.3384e-22,\n",
      "        -6.5972e-22,  4.3150e-22, -1.3483e-21,  2.3625e-21,  5.6472e-21,\n",
      "         2.6544e-21,  2.2572e-21, -6.1209e-22,  4.6459e-21, -3.9232e-21,\n",
      "         2.1371e-21,  5.8360e-22,  8.7610e-23, -6.8720e-21,  2.4463e-21,\n",
      "         4.5825e-21, -7.0081e-24,  2.5264e-21,  3.5301e-21,  6.8563e-21,\n",
      "         1.7764e-21, -2.0918e-22, -2.1110e-21,  2.4170e-22,  8.2850e-23,\n",
      "         2.7063e-21,  4.0292e-21,  4.7523e-21, -1.8598e-21,  2.3262e-21,\n",
      "         4.6414e-21, -6.6112e-22,  9.1279e-22,  1.4201e-21,  6.6253e-22,\n",
      "        -4.2472e-21,  2.2532e-21,  4.3243e-21,  2.8908e-21,  3.1351e-21,\n",
      "        -2.9810e-22, -6.3575e-22,  8.1276e-21,  1.3467e-22, -1.6101e-21]), 'exp_avg_sq': tensor([0.0067, 0.0022, 0.0027, 0.0020, 0.0010, 0.0096, 0.0029, 0.0034, 0.0044,\n",
      "        0.0045, 0.0017, 0.0024, 0.0036, 0.0057, 0.0042, 0.0030, 0.0050, 0.0018,\n",
      "        0.0053, 0.0024, 0.0021, 0.0042, 0.0047, 0.0014, 0.0055, 0.0037, 0.0028,\n",
      "        0.0054, 0.0044, 0.0030, 0.0026, 0.0045, 0.0044, 0.0043, 0.0066, 0.0026,\n",
      "        0.0037, 0.0055, 0.0031, 0.0034, 0.0026, 0.0078, 0.0089, 0.0023, 0.0049,\n",
      "        0.0030, 0.0068, 0.0060, 0.0046, 0.0028, 0.0065, 0.0054, 0.0038, 0.0022,\n",
      "        0.0090, 0.0044, 0.0038, 0.0059, 0.0042, 0.0056, 0.0037, 0.0019, 0.0073,\n",
      "        0.0058, 0.0013, 0.0023, 0.0067, 0.0043, 0.0021, 0.0018, 0.0044, 0.0024,\n",
      "        0.0072, 0.0072, 0.0018, 0.0044, 0.0043, 0.0023, 0.0036, 0.0047, 0.0024,\n",
      "        0.0039, 0.0035, 0.0032, 0.0069, 0.0035, 0.0041, 0.0092, 0.0026, 0.0085,\n",
      "        0.0034, 0.0035, 0.0045, 0.0035, 0.0091, 0.0042, 0.0062, 0.0066, 0.0048,\n",
      "        0.0041])}, 4: {'step': tensor(3820.), 'exp_avg': tensor([-3.9813e-20,  3.1921e-20, -3.0261e-20,  4.3858e-20, -2.8193e-20,\n",
      "         4.7086e-20,  3.9406e-21, -1.0977e-20,  1.3828e-21, -4.6878e-20,\n",
      "        -4.6368e-20,  5.3476e-20,  1.9060e-20, -8.3100e-20,  8.8825e-20,\n",
      "        -3.9588e-21]), 'exp_avg_sq': tensor([ 0.7551, 11.5135,  3.3184,  3.3862,  7.3220, 16.0925,  5.0444,  2.0648,\n",
      "         0.4438,  3.6218,  5.2000,  2.4567,  1.0006,  2.3212,  1.7146,  0.7132])}, 5: {'step': tensor(3820.), 'exp_avg': tensor([[-6.7437e-20,  2.1696e-20,  2.0406e-20,  3.3545e-20, -4.0759e-20,\n",
      "          1.4288e-20, -9.0004e-21,  2.9996e-20, -4.8014e-20,  3.3489e-20,\n",
      "          2.8420e-20,  5.8006e-20, -3.3329e-20, -5.0923e-20, -4.2322e-20,\n",
      "          3.9812e-20],\n",
      "        [ 3.3751e-20,  3.6488e-21, -6.2848e-21, -3.0084e-20,  2.9784e-20,\n",
      "         -1.3041e-20,  1.6851e-20, -1.0215e-20, -1.7082e-21, -2.7507e-20,\n",
      "         -4.4941e-21, -4.4724e-20,  3.0911e-20,  2.3348e-20,  3.2361e-20,\n",
      "         -2.2087e-20],\n",
      "        [-3.9603e-20,  6.2124e-21,  9.5728e-21,  2.5478e-20, -2.7785e-20,\n",
      "          1.0934e-20, -1.0672e-20,  1.5134e-20, -1.6616e-20,  2.4414e-20,\n",
      "          1.2359e-20,  4.0870e-20, -2.6044e-20, -2.8321e-20, -2.9626e-20,\n",
      "          2.4268e-20],\n",
      "        [ 8.2967e-20, -2.1452e-20, -2.4859e-20, -4.6558e-20,  5.3713e-20,\n",
      "         -2.0050e-20,  1.5762e-20, -3.6091e-20,  4.9958e-20, -4.5024e-20,\n",
      "         -3.1739e-20, -7.7251e-20,  4.5801e-20,  6.2666e-20,  5.6250e-20,\n",
      "         -4.9801e-20],\n",
      "        [-4.9309e-20,  7.4421e-21,  1.5105e-20,  3.3089e-20, -3.6534e-20,\n",
      "          1.4336e-20, -1.4376e-20,  2.0490e-20, -2.0191e-20,  3.1021e-20,\n",
      "          1.5067e-20,  5.2459e-20, -3.2316e-20, -3.8263e-20, -3.8333e-20,\n",
      "          3.0672e-20],\n",
      "        [ 8.3453e-20, -2.0044e-20, -2.3897e-20, -4.7995e-20,  5.4648e-20,\n",
      "         -2.0658e-20,  1.6981e-20, -3.5425e-20,  4.7535e-20, -4.6329e-20,\n",
      "         -3.0922e-20, -7.9085e-20,  4.7655e-20,  6.2165e-20,  5.7501e-20,\n",
      "         -5.0228e-20],\n",
      "        [ 2.2761e-20, -1.3200e-20, -1.0511e-20, -6.6046e-21,  1.1160e-20,\n",
      "         -2.7839e-21, -1.4234e-21, -1.3079e-20,  2.6593e-20, -7.2635e-21,\n",
      "         -1.3372e-20, -1.4072e-20,  5.2911e-21,  2.0023e-20,  1.0592e-20,\n",
      "         -1.2853e-20],\n",
      "        [-2.3388e-20,  5.1183e-21,  6.3162e-21,  1.3875e-20, -1.5247e-20,\n",
      "          6.0187e-21, -5.0787e-21,  9.7999e-21, -1.2537e-20,  1.3202e-20,\n",
      "          8.5317e-21,  2.2472e-20, -1.3758e-20, -1.6944e-20, -1.6237e-20,\n",
      "          1.4055e-20],\n",
      "        [ 1.1488e-20, -1.9888e-21, -3.1456e-21, -7.4114e-21,  7.6774e-21,\n",
      "         -3.2767e-21,  2.9488e-21, -4.9029e-21,  5.3219e-21, -6.7856e-21,\n",
      "         -4.0174e-21, -1.1551e-20,  7.1400e-21,  8.2462e-21,  8.2859e-21,\n",
      "         -6.9470e-21],\n",
      "        [-7.7083e-20,  2.2467e-20,  2.2788e-20,  4.0551e-20, -4.8194e-20,\n",
      "          1.7314e-20, -1.2305e-20,  3.3546e-20, -5.0674e-20,  4.0086e-20,\n",
      "          3.0894e-20,  6.8944e-20, -4.0411e-20, -5.7957e-20, -5.0244e-20,\n",
      "          4.5910e-20],\n",
      "        [-8.0602e-20,  2.1320e-20,  2.3283e-20,  4.4443e-20, -5.1483e-20,\n",
      "          1.9070e-20, -1.4672e-20,  3.4596e-20, -4.9301e-20,  4.3345e-20,\n",
      "          3.1090e-20,  7.4243e-20, -4.4218e-20, -6.0110e-20, -5.4002e-20,\n",
      "          4.8231e-20],\n",
      "        [ 8.2730e-20, -2.5597e-20, -2.2861e-20, -4.1517e-20,  4.9553e-20,\n",
      "         -1.7651e-20,  1.1407e-20, -3.5519e-20,  5.7062e-20, -4.1610e-20,\n",
      "         -3.4334e-20, -7.1547e-20,  4.2096e-20,  6.0463e-20,  5.1942e-20,\n",
      "         -4.8764e-20],\n",
      "        [ 2.7567e-20, -8.1220e-21, -8.7139e-21, -1.4531e-20,  1.7713e-20,\n",
      "         -6.1710e-21,  4.5045e-21, -1.2150e-20,  1.8213e-20, -1.4425e-20,\n",
      "         -1.0900e-20, -2.4866e-20,  1.4400e-20,  2.1423e-20,  1.8260e-20,\n",
      "         -1.6516e-20],\n",
      "        [-1.4509e-19,  4.2220e-20,  4.3925e-20,  7.6742e-20, -9.1080e-20,\n",
      "          3.2847e-20, -2.3451e-20,  6.3828e-20, -9.5420e-20,  7.5473e-20,\n",
      "          5.8233e-20,  1.3006e-19, -7.5877e-20, -1.0992e-19, -9.4854e-20,\n",
      "          8.6463e-20],\n",
      "        [ 1.4689e-19, -4.2855e-20, -4.3421e-20, -7.7213e-20,  9.1700e-20,\n",
      "         -3.2978e-20,  2.3392e-20, -6.3992e-20,  9.6728e-20, -7.6268e-20,\n",
      "         -5.8971e-20, -1.3123e-19,  7.6907e-20,  1.1039e-19,  9.5635e-20,\n",
      "         -8.7425e-20],\n",
      "        [-9.0973e-21,  3.1360e-21,  2.2978e-21,  4.1902e-21, -4.8649e-21,\n",
      "          1.8014e-21, -8.6833e-22,  3.9853e-21, -6.9495e-21,  4.1812e-21,\n",
      "          4.1559e-21,  7.2664e-21, -4.2473e-21, -6.2798e-21, -5.2080e-21,\n",
      "          5.2094e-21]]), 'exp_avg_sq': tensor([[2.9770e-01, 1.3869e-01, 9.7673e-02, 9.4301e-02, 9.7330e-02, 1.8066e-02,\n",
      "         3.6603e-02, 1.1706e-01, 5.7172e-01, 7.6601e-02, 1.1409e-01, 2.0736e-01,\n",
      "         9.6627e-02, 2.3432e-01, 9.7952e-02, 9.1377e-02],\n",
      "        [1.3456e+01, 6.5106e+00, 3.9311e+00, 4.6543e-01, 2.0645e+00, 1.1796e-01,\n",
      "         3.6409e-01, 4.9655e+00, 2.6891e+01, 5.2462e-01, 5.5752e+00, 2.5593e+00,\n",
      "         2.2230e-01, 1.0060e+01, 1.2696e+00, 3.6143e+00],\n",
      "        [2.0518e+00, 1.4638e+00, 7.5927e-01, 7.5318e-02, 2.2014e-01, 1.4870e-02,\n",
      "         1.6939e-01, 9.1298e-01, 5.9016e+00, 6.2785e-02, 1.1232e+00, 2.4615e-01,\n",
      "         1.0959e-01, 1.6676e+00, 1.2048e-01, 4.9505e-01],\n",
      "        [2.2195e+00, 1.2891e+00, 7.1113e-01, 1.3789e-01, 2.9689e-01, 3.2928e-02,\n",
      "         1.3629e-01, 9.1613e-01, 5.3290e+00, 1.1310e-01, 1.0711e+00, 4.4189e-01,\n",
      "         1.4124e-01, 1.6658e+00, 1.9885e-01, 5.5424e-01],\n",
      "        [2.5648e+00, 3.1958e+00, 1.2075e+00, 3.4357e-01, 1.1770e-01, 5.4385e-02,\n",
      "         6.5649e-01, 1.4663e+00, 1.2520e+01, 1.8471e-01, 2.1699e+00, 2.5393e-01,\n",
      "         5.3663e-01, 2.2467e+00, 1.1608e-01, 4.8937e-01],\n",
      "        [4.7499e+00, 7.1631e+00, 2.7336e+00, 1.0164e+00, 1.8177e-01, 1.6572e-01,\n",
      "         1.6282e+00, 3.0716e+00, 2.7670e+01, 5.5613e-01, 4.6006e+00, 7.2447e-01,\n",
      "         1.5727e+00, 4.6042e+00, 3.0598e-01, 8.4177e-01],\n",
      "        [3.0624e+00, 2.3129e+00, 1.2340e+00, 7.0836e-02, 2.8565e-01, 1.6573e-02,\n",
      "         2.6506e-01, 1.4251e+00, 9.3268e+00, 4.6099e-02, 1.7449e+00, 2.3986e-01,\n",
      "         1.3035e-01, 2.5784e+00, 1.1760e-01, 7.1059e-01],\n",
      "        [3.7458e+00, 1.6445e+00, 1.2000e+00, 2.4333e-01, 7.5733e-01, 5.3601e-02,\n",
      "         8.7910e-02, 1.3933e+00, 6.7911e+00, 2.3997e-01, 1.4157e+00, 1.0027e+00,\n",
      "         1.3187e-01, 3.0162e+00, 5.0732e-01, 1.0622e+00],\n",
      "        [8.2933e-01, 3.3045e-01, 2.8875e-01, 8.6159e-02, 2.1218e-01, 1.6852e-02,\n",
      "         1.8834e-02, 3.0053e-01, 1.3387e+00, 8.2181e-02, 2.7887e-01, 2.9993e-01,\n",
      "         5.5230e-02, 7.1323e-01, 1.5451e-01, 2.5339e-01],\n",
      "        [1.0480e+00, 1.5750e+00, 4.3011e-01, 7.6957e-01, 3.0117e-01, 1.3720e-01,\n",
      "         5.7715e-01, 5.7747e-01, 6.0232e+00, 5.1295e-01, 9.9107e-01, 1.0672e+00,\n",
      "         8.8371e-01, 7.5692e-01, 4.7672e-01, 2.4264e-01],\n",
      "        [3.7070e+00, 2.9207e+00, 1.3571e+00, 1.4856e-01, 2.9779e-01, 2.6290e-02,\n",
      "         3.8945e-01, 1.6884e+00, 1.1792e+01, 1.0672e-01, 2.2157e+00, 3.4078e-01,\n",
      "         2.5782e-01, 2.8897e+00, 1.5825e-01, 8.4163e-01],\n",
      "        [1.3005e+00, 1.0809e+00, 5.2438e-01, 1.2934e-01, 1.5912e-01, 2.2062e-02,\n",
      "         1.6886e-01, 5.9995e-01, 4.2549e+00, 1.0236e-01, 7.6908e-01, 2.6209e-01,\n",
      "         1.8903e-01, 1.1000e+00, 1.2533e-01, 3.2120e-01],\n",
      "        [8.4778e-01, 5.6664e-01, 2.6941e-01, 1.1857e-01, 1.3930e-01, 2.2767e-02,\n",
      "         9.2189e-02, 3.4368e-01, 2.2566e+00, 9.2818e-02, 4.3256e-01, 2.7024e-01,\n",
      "         1.3400e-01, 6.4164e-01, 1.2400e-01, 2.2168e-01],\n",
      "        [4.9620e+00, 1.4546e+00, 1.0514e+00, 7.3713e-01, 1.2849e+00, 1.5207e-01,\n",
      "         1.0914e-01, 1.4253e+00, 6.0888e+00, 6.6240e-01, 1.4240e+00, 2.2573e+00,\n",
      "         5.1418e-01, 3.3633e+00, 1.0916e+00, 1.5455e+00],\n",
      "        [2.7962e+00, 5.2710e-01, 4.7583e-01, 5.9498e-01, 8.2709e-01, 1.2320e-01,\n",
      "         5.4240e-02, 6.9927e-01, 2.3856e+00, 5.1162e-01, 6.3764e-01, 1.6460e+00,\n",
      "         4.6131e-01, 1.6919e+00, 7.6912e-01, 9.0039e-01],\n",
      "        [2.1016e-01, 2.9128e-01, 9.1421e-02, 1.6531e-01, 7.2796e-02, 2.8885e-02,\n",
      "         1.1399e-01, 1.1502e-01, 1.1104e+00, 1.1422e-01, 1.8414e-01, 2.4188e-01,\n",
      "         1.9018e-01, 1.5858e-01, 1.0895e-01, 5.3593e-02]])}, 6: {'step': tensor(3820.), 'exp_avg': tensor([ 1.7156e-23, -3.9519e-23,  4.6198e-22, -2.2133e-22, -5.0871e-23,\n",
      "         4.2318e-22, -4.9205e-23,  2.2184e-22, -9.4835e-23, -2.8602e-21,\n",
      "         1.1791e-22, -5.2917e-23, -2.1785e-22, -5.4339e-22, -1.1492e-22,\n",
      "         4.9076e-22, -7.6241e-22, -5.1840e-24, -1.7722e-22,  3.4243e-22,\n",
      "         3.6069e-22, -6.2995e-23,  1.0837e-21, -1.3036e-22, -1.2316e-22,\n",
      "        -2.0532e-22, -1.7458e-22, -3.2519e-22,  1.6905e-22, -4.2740e-22,\n",
      "        -1.1926e-23,  7.9622e-22,  8.5731e-22, -1.8999e-21, -4.9311e-23,\n",
      "         8.3904e-23, -5.6026e-21,  2.4538e-22,  1.0595e-22, -3.8997e-22,\n",
      "        -1.5737e-22,  1.4404e-22, -6.5199e-23,  1.1415e-22,  7.6341e-23,\n",
      "         6.5835e-22, -1.1662e-21,  1.5552e-21, -1.4790e-22, -2.7202e-22,\n",
      "        -8.1856e-22,  2.5034e-22, -9.5969e-22,  1.6875e-22, -4.0522e-23,\n",
      "         2.4580e-22,  1.1157e-22,  1.6575e-22, -1.6687e-22,  3.3446e-22,\n",
      "        -2.2998e-22,  2.4644e-22, -1.2213e-22, -1.6496e-22,  7.1756e-22,\n",
      "        -3.2336e-21,  1.5498e-21, -3.2442e-22,  5.7012e-22, -1.8688e-22,\n",
      "         1.4664e-21,  6.0909e-23,  3.1107e-23, -2.7317e-22, -1.2099e-21,\n",
      "        -1.3462e-22,  4.2119e-21,  4.5849e-22, -6.3152e-24,  2.0715e-22,\n",
      "        -2.6099e-22,  6.7321e-22, -1.4400e-21,  7.3673e-22, -2.9072e-22,\n",
      "        -4.6504e-22, -1.3430e-21, -6.3480e-23, -1.1571e-22, -6.2082e-22,\n",
      "         5.7658e-22, -1.5807e-22,  2.1371e-22, -2.7338e-22,  9.6991e-22,\n",
      "         2.3979e-22,  5.5746e-22, -2.2544e-21, -4.0613e-22, -9.6768e-22]), 'exp_avg_sq': tensor([8.4730e-04, 6.9309e-04, 8.2127e-04, 6.8134e-04, 5.8233e-04, 7.8183e-04,\n",
      "        2.1507e-03, 1.0291e-03, 3.1588e-04, 1.6502e-03, 3.1922e-03, 5.3380e-04,\n",
      "        3.0675e-04, 7.9636e-04, 1.1744e-03, 4.4576e-04, 2.7142e-04, 1.1717e-03,\n",
      "        2.4218e-03, 6.2667e-04, 1.4172e-03, 1.2743e-03, 3.0194e-03, 9.1803e-04,\n",
      "        2.1719e-03, 3.1198e-04, 4.5262e-04, 1.0836e-03, 1.0016e-03, 6.9310e-04,\n",
      "        7.4721e-04, 1.2860e-03, 1.1585e-03, 2.9465e-04, 3.5383e-03, 7.5646e-04,\n",
      "        7.7867e-04, 1.3791e-03, 1.8530e-04, 4.6767e-04, 4.0429e-04, 1.7588e-03,\n",
      "        1.0643e-03, 1.1032e-03, 1.8206e-03, 3.9650e-04, 2.1662e-03, 1.3537e-03,\n",
      "        2.3140e-03, 1.3739e-03, 1.2188e-03, 3.3442e-03, 2.9522e-04, 1.0979e-03,\n",
      "        2.2817e-03, 1.9335e-03, 6.3284e-04, 3.8299e-03, 3.3237e-03, 8.6955e-04,\n",
      "        1.6870e-04, 2.6575e-04, 1.9911e-03, 6.0693e-04, 9.1563e-05, 1.9099e-03,\n",
      "        1.2184e-03, 8.2669e-04, 1.2866e-03, 7.3831e-04, 1.1819e-03, 2.7763e-03,\n",
      "        2.5686e-03, 1.5450e-03, 3.1567e-04, 2.9499e-04, 1.6462e-03, 5.8674e-03,\n",
      "        1.0895e-03, 4.7284e-04, 1.2028e-03, 8.3101e-04, 1.3681e-03, 8.0079e-04,\n",
      "        1.4916e-03, 6.5527e-04, 4.8156e-04, 2.2497e-03, 4.0541e-04, 2.2784e-03,\n",
      "        1.3987e-03, 6.0478e-04, 1.6492e-04, 4.9270e-04, 1.9354e-03, 7.1818e-04,\n",
      "        6.1812e-04, 9.5623e-04, 1.9426e-03, 4.0205e-03])}, 7: {'step': tensor(3820.), 'exp_avg': tensor([-1.7415e-22,  4.9776e-21, -7.1238e-21, -5.4440e-22,  6.0720e-22,\n",
      "        -8.5988e-21,  4.3906e-22,  3.5591e-21,  8.0596e-22,  2.9445e-21,\n",
      "        -7.5467e-22,  1.1206e-22,  2.2884e-21,  4.1878e-22,  1.1431e-21,\n",
      "        -7.7129e-21, -6.8926e-22,  3.4525e-21,  1.0676e-21,  1.1082e-21,\n",
      "         1.4038e-21,  8.8092e-22,  6.5078e-21,  1.3192e-21,  1.3553e-21,\n",
      "         1.6197e-21,  4.7195e-22, -2.4704e-22, -2.5696e-21,  4.9492e-21,\n",
      "         3.1521e-21, -6.8907e-21,  1.0175e-21,  3.2551e-21,  2.9499e-21,\n",
      "        -7.0285e-22,  5.8805e-22, -2.4684e-21, -1.1900e-21,  4.6001e-21,\n",
      "         1.4110e-21, -4.5186e-22,  6.6553e-22, -1.1555e-21,  1.5785e-23,\n",
      "        -6.3196e-21, -3.0516e-22,  5.0458e-21,  2.2090e-21,  2.6174e-21,\n",
      "        -6.7022e-22, -2.0741e-21,  6.5646e-21,  2.4534e-21, -3.7213e-23,\n",
      "        -1.5799e-21, -7.1032e-23, -2.4122e-21,  2.1754e-21,  5.1056e-21,\n",
      "         2.1633e-21,  2.1803e-21, -3.0127e-22,  5.1100e-21, -6.0027e-21,\n",
      "         2.6577e-22, -3.2190e-22, -2.3457e-22, -9.9706e-21,  2.1100e-21,\n",
      "         4.4894e-21, -8.1675e-22,  2.3138e-21,  3.5576e-21,  6.1537e-21,\n",
      "         1.4852e-21, -8.5759e-22, -3.0375e-21, -2.8587e-22, -1.2340e-21,\n",
      "         1.9547e-21,  2.7724e-21,  3.6278e-21, -2.2718e-21,  1.8146e-21,\n",
      "         4.7328e-21, -1.0862e-21,  3.1799e-22,  1.0627e-21,  3.3839e-22,\n",
      "        -5.6338e-21,  2.0574e-21,  3.9934e-21,  2.7348e-21,  2.3975e-21,\n",
      "        -1.1992e-21, -1.1314e-21,  6.9221e-21, -2.3565e-22, -8.5174e-22]), 'exp_avg_sq': tensor([0.0012, 0.0025, 0.0005, 0.0005, 0.0004, 0.0010, 0.0017, 0.0031, 0.0008,\n",
      "        0.0025, 0.0005, 0.0013, 0.0029, 0.0010, 0.0011, 0.0009, 0.0018, 0.0006,\n",
      "        0.0020, 0.0006, 0.0003, 0.0008, 0.0011, 0.0009, 0.0018, 0.0005, 0.0009,\n",
      "        0.0010, 0.0004, 0.0006, 0.0008, 0.0015, 0.0022, 0.0041, 0.0016, 0.0011,\n",
      "        0.0012, 0.0007, 0.0011, 0.0005, 0.0009, 0.0017, 0.0019, 0.0014, 0.0033,\n",
      "        0.0011, 0.0025, 0.0015, 0.0015, 0.0025, 0.0014, 0.0026, 0.0014, 0.0012,\n",
      "        0.0018, 0.0012, 0.0009, 0.0009, 0.0023, 0.0011, 0.0010, 0.0006, 0.0010,\n",
      "        0.0014, 0.0007, 0.0008, 0.0014, 0.0017, 0.0015, 0.0007, 0.0008, 0.0018,\n",
      "        0.0004, 0.0013, 0.0007, 0.0014, 0.0018, 0.0019, 0.0018, 0.0009, 0.0005,\n",
      "        0.0009, 0.0018, 0.0010, 0.0026, 0.0010, 0.0013, 0.0022, 0.0006, 0.0027,\n",
      "        0.0013, 0.0007, 0.0010, 0.0006, 0.0019, 0.0011, 0.0026, 0.0015, 0.0021,\n",
      "        0.0007])}, 8: {'step': tensor(3820.), 'exp_avg': tensor([ 1.4190e-20, -3.9941e-20, -9.1178e-21, -2.6558e-20,  1.4485e-20,\n",
      "        -2.2945e-20, -1.1665e-20,  1.0026e-20, -2.8976e-20,  1.3320e-20,\n",
      "         3.4118e-21, -2.1763e-20,  4.1855e-21, -2.3928e-20,  1.6756e-20,\n",
      "         7.3517e-21,  1.7725e-20, -5.1323e-20,  8.8147e-22, -2.7534e-20,\n",
      "         5.0057e-21,  1.2691e-19,  7.6379e-21,  1.6248e-20,  5.6211e-21]), 'exp_avg_sq': tensor([ 0.0479,  0.1578,  0.0546,  0.6597,  0.0674,  0.6318,  0.0678,  0.0969,\n",
      "         0.7711,  0.1261,  1.1861,  0.0649,  0.1532,  0.2280,  0.0707,  0.1679,\n",
      "        12.9480,  0.7802,  0.0260,  0.1805,  0.0410, 22.2419,  0.2269,  0.0223,\n",
      "         0.1492])}, 9: {'step': tensor(3820.), 'exp_avg': tensor([[ 4.6973e-21,  1.1195e-20, -1.3264e-20, -4.6179e-21,  1.1239e-20,\n",
      "          6.3034e-21, -1.2568e-20, -4.4008e-22,  1.1707e-20, -4.2423e-21,\n",
      "          4.2448e-21,  1.3915e-20, -1.3359e-20, -2.5137e-23, -4.5764e-21,\n",
      "         -7.4963e-21],\n",
      "        [-2.2267e-20, -5.3741e-20,  6.6701e-20,  2.3486e-20, -6.1652e-20,\n",
      "         -3.0579e-20,  6.1559e-20,  1.6532e-22, -5.7353e-20,  2.4091e-20,\n",
      "         -1.9597e-20, -6.9704e-20,  6.8806e-20, -3.0484e-21,  2.5026e-20,\n",
      "          3.8413e-20],\n",
      "        [-6.4592e-21, -1.6362e-20,  2.0995e-20,  7.4603e-21, -2.0662e-20,\n",
      "         -9.7809e-21,  1.9083e-20, -1.9186e-22, -1.8130e-20,  8.1127e-21,\n",
      "         -5.6846e-21, -2.2356e-20,  2.1712e-20, -6.8523e-22,  7.8207e-21,\n",
      "          1.2474e-20],\n",
      "        [-1.8916e-20, -3.7020e-20,  4.0877e-20,  1.3079e-20, -2.9139e-20,\n",
      "         -1.5332e-20,  3.9558e-20,  2.2315e-22, -3.1596e-20,  1.2054e-20,\n",
      "         -1.5957e-20, -3.6960e-20,  4.4304e-20, -1.1085e-20,  1.9176e-20,\n",
      "          1.9402e-20],\n",
      "        [ 6.4522e-21,  1.5280e-20, -1.8595e-20, -6.5381e-21,  1.6580e-20,\n",
      "          8.5467e-21, -1.7299e-20, -2.0597e-22,  1.6090e-20, -6.4081e-21,\n",
      "          5.6993e-21,  1.9361e-20, -1.9047e-20,  7.3533e-22, -6.8572e-21,\n",
      "         -1.0555e-20],\n",
      "        [-1.5771e-20, -3.1492e-20,  3.4768e-20,  1.0827e-20, -2.5218e-20,\n",
      "         -1.3302e-20,  3.3748e-20,  2.9680e-22, -2.6819e-20,  1.0535e-20,\n",
      "         -1.3469e-20, -3.1763e-20,  3.7766e-20, -9.2444e-21,  1.6084e-20,\n",
      "          1.6697e-20],\n",
      "        [-9.5836e-21, -1.8573e-20,  2.0442e-20,  6.4568e-21, -1.4481e-20,\n",
      "         -7.5066e-21,  1.9814e-20,  3.5171e-23, -1.5574e-20,  6.0614e-21,\n",
      "         -8.0498e-21, -1.8252e-20,  2.2339e-20, -6.0625e-21,  9.8351e-21,\n",
      "          9.5810e-21],\n",
      "        [ 6.7384e-21,  1.3048e-20, -1.4087e-20, -4.3288e-21,  9.5635e-21,\n",
      "          5.2053e-21, -1.3817e-20, -1.7683e-22,  1.0703e-20, -4.0261e-21,\n",
      "          5.7278e-21,  1.2522e-20, -1.5379e-20,  4.1914e-21, -6.7038e-21,\n",
      "         -6.5051e-21],\n",
      "        [-1.9619e-20, -3.9774e-20,  4.4620e-20,  1.4311e-20, -3.3427e-20,\n",
      "         -1.7458e-20,  4.2962e-20,  2.9810e-22, -3.5053e-20,  1.3734e-20,\n",
      "         -1.6729e-20, -4.1472e-20,  4.8053e-20, -1.0473e-20,  2.0167e-20,\n",
      "          2.1958e-20],\n",
      "        [ 7.2741e-21,  1.5363e-20, -1.7779e-20, -6.0600e-21,  1.4138e-20,\n",
      "          7.3799e-21, -1.6838e-20, -1.4542e-22,  1.4620e-20, -5.5989e-21,\n",
      "          6.2318e-21,  1.7258e-20, -1.8676e-20,  2.7137e-21, -7.4409e-21,\n",
      "         -9.2286e-21],\n",
      "        [ 7.2080e-21,  1.6448e-20, -1.9931e-20, -6.2807e-21,  1.8171e-20,\n",
      "          8.3116e-21, -1.8620e-20,  3.3505e-22,  1.5676e-20, -7.6398e-21,\n",
      "          6.2519e-21,  1.9661e-20, -2.1734e-20,  4.0058e-21, -8.7794e-21,\n",
      "         -1.0857e-20],\n",
      "        [-1.3822e-20, -3.1284e-20,  3.7655e-20,  1.2902e-20, -3.2879e-20,\n",
      "         -1.6408e-20,  3.5180e-20,  4.0597e-23, -3.1444e-20,  1.3028e-20,\n",
      "         -1.1973e-20, -3.7922e-20,  3.9458e-20, -4.1511e-21,  1.5170e-20,\n",
      "          2.0684e-20],\n",
      "        [ 7.3329e-21,  1.5005e-20, -1.7245e-20, -5.3362e-21,  1.3896e-20,\n",
      "          6.5041e-21, -1.6412e-20,  2.6143e-22,  1.3005e-20, -5.9516e-21,\n",
      "          6.1953e-21,  1.5880e-20, -1.9093e-20,  5.0712e-21, -8.2993e-21,\n",
      "         -8.5692e-21],\n",
      "        [-1.5985e-20, -3.3278e-20,  3.8082e-20,  1.2500e-20, -2.9828e-20,\n",
      "         -1.5362e-20,  3.6342e-20,  1.8552e-22, -3.0480e-20,  1.2096e-20,\n",
      "         -1.3664e-20, -3.6213e-20,  4.0671e-20, -7.5656e-21,  1.6692e-20,\n",
      "          1.9348e-20],\n",
      "        [ 5.1624e-21,  1.4867e-20, -1.9360e-20, -7.1166e-21,  1.9586e-20,\n",
      "          1.0064e-20, -1.7607e-20, -3.4329e-22,  1.7922e-20, -7.3421e-21,\n",
      "          4.8452e-21,  2.1973e-20, -1.9091e-20, -2.2714e-21, -5.8004e-21,\n",
      "         -1.2221e-20],\n",
      "        [ 7.6874e-21,  1.5335e-20, -1.7255e-20, -5.3946e-21,  1.3101e-20,\n",
      "          6.4429e-21, -1.6562e-20,  1.0371e-22,  1.3095e-20, -5.5558e-21,\n",
      "          6.4900e-21,  1.5692e-20, -1.8964e-20,  5.0395e-21, -8.2606e-21,\n",
      "         -8.3539e-21],\n",
      "        [ 3.9846e-21,  1.6305e-20, -2.3598e-20, -9.1267e-21,  2.7878e-20,\n",
      "          1.3645e-20, -2.0626e-20, -2.4025e-22,  2.3161e-20, -1.0327e-20,\n",
      "          4.1631e-21,  2.9196e-20, -2.2549e-20, -6.2918e-21, -5.5945e-21,\n",
      "         -1.6667e-20],\n",
      "        [-2.9721e-20, -6.8361e-20,  8.3098e-20,  2.9004e-20, -7.3597e-20,\n",
      "         -3.6833e-20,  7.7259e-20,  2.0584e-22, -7.0353e-20,  2.8885e-20,\n",
      "         -2.5825e-20, -8.4748e-20,  8.6343e-20, -6.9170e-21,  3.2549e-20,\n",
      "          4.6345e-20],\n",
      "        [-2.2111e-21, -3.8840e-21,  4.4100e-21,  1.4449e-21, -3.2458e-21,\n",
      "         -1.2866e-21,  4.1325e-21, -2.4482e-22, -3.0558e-21,  1.4420e-21,\n",
      "         -1.7308e-21, -3.5957e-21,  5.0682e-21, -2.0906e-21,  2.5565e-21,\n",
      "          1.9308e-21],\n",
      "        [-1.7088e-20, -3.7665e-20,  4.4836e-20,  1.5429e-20, -3.8020e-20,\n",
      "         -1.9188e-20,  4.2036e-20,  1.0235e-22, -3.7282e-20,  1.5028e-20,\n",
      "         -1.4694e-20, -4.4568e-20,  4.7008e-20, -5.5582e-21,  1.8362e-20,\n",
      "          2.4185e-20],\n",
      "        [ 6.8694e-21,  1.3319e-20, -1.4735e-20, -4.4588e-21,  1.0774e-20,\n",
      "          5.2399e-21, -1.4256e-20,  1.4083e-22,  1.0836e-20, -4.6771e-21,\n",
      "          5.7591e-21,  1.2981e-20, -1.6446e-20,  5.1197e-21, -7.4106e-21,\n",
      "         -6.8689e-21],\n",
      "        [ 8.7139e-20,  1.7904e-19, -2.0603e-19, -6.9693e-20,  1.6077e-19,\n",
      "          8.2293e-20, -1.9559e-19, -3.6729e-22,  1.6596e-19, -6.4443e-20,\n",
      "          7.3637e-20,  1.9526e-19, -2.1909e-19,  3.9961e-20, -9.0785e-20,\n",
      "         -1.0449e-19],\n",
      "        [ 8.0534e-21,  1.5762e-20, -1.7570e-20, -5.4837e-21,  1.2976e-20,\n",
      "          6.4124e-21, -1.6915e-20,  1.0775e-22,  1.3221e-20, -5.5253e-21,\n",
      "          6.7661e-21,  1.5745e-20, -1.9369e-20,  5.4651e-21, -8.5614e-21,\n",
      "         -8.3383e-21],\n",
      "        [ 6.0085e-21,  1.6502e-20, -2.1180e-20, -7.5820e-21,  2.1039e-20,\n",
      "          1.0642e-20, -1.9356e-20, -2.6135e-22,  1.9103e-20, -8.0401e-21,\n",
      "          5.5543e-21,  2.3510e-20, -2.1258e-20, -1.3247e-21, -6.8361e-21,\n",
      "         -1.3046e-20],\n",
      "        [ 6.8356e-21,  1.3964e-20, -1.5857e-20, -4.8835e-21,  1.2439e-20,\n",
      "          6.0455e-21, -1.5210e-20,  1.1551e-22,  1.2044e-20, -5.2905e-21,\n",
      "          5.8068e-21,  1.4596e-20, -1.7469e-20,  4.4923e-21, -7.5315e-21,\n",
      "         -7.8263e-21]]), 'exp_avg_sq': tensor([[1.4108e-02, 6.8529e-02, 1.6860e-01, 3.8424e-02, 5.0456e-01, 5.6969e-02,\n",
      "         1.4659e-01, 2.9205e-03, 2.0264e-01, 4.6400e-02, 7.8440e-03, 3.4948e-01,\n",
      "         2.8475e-01, 3.5359e-02, 2.0613e-02, 1.7234e-01],\n",
      "        [1.8133e-01, 2.9343e-01, 2.8510e-01, 7.5067e-02, 5.4000e-01, 4.0918e-02,\n",
      "         3.0818e-01, 5.8476e-03, 2.6797e-01, 3.2349e-02, 7.8892e-02, 3.5398e-01,\n",
      "         5.0588e-01, 2.3938e-01, 1.5570e-01, 1.8924e-01],\n",
      "        [2.2860e-02, 2.7502e-02, 9.2373e-02, 5.4315e-02, 3.8713e-01, 2.3092e-02,\n",
      "         6.0095e-02, 6.2905e-03, 1.4928e-01, 2.0945e-02, 7.6791e-03, 2.3294e-01,\n",
      "         1.6347e-01, 3.8864e-02, 2.1895e-02, 1.3025e-01],\n",
      "        [6.1144e-02, 2.3761e-01, 7.6066e-01, 2.1643e-01, 3.0384e+00, 2.7094e-01,\n",
      "         6.4239e-01, 3.3976e-02, 1.0356e+00, 2.4020e-01, 4.2813e-02, 1.9830e+00,\n",
      "         1.6839e+00, 1.9872e-01, 9.4294e-02, 1.0548e+00],\n",
      "        [9.9657e-02, 1.8292e-01, 2.5124e-01, 4.1739e-02, 6.1491e-01, 7.1247e-02,\n",
      "         2.5691e-01, 2.7629e-03, 2.4043e-01, 6.1813e-02, 4.6205e-02, 4.1803e-01,\n",
      "         4.4168e-01, 1.8222e-01, 9.8781e-02, 2.0113e-01],\n",
      "        [6.4211e-02, 2.0652e-01, 6.8648e-01, 1.9337e-01, 3.1765e+00, 2.5200e-01,\n",
      "         5.9090e-01, 3.5700e-02, 9.3067e-01, 2.5887e-01, 4.0175e-02, 1.9601e+00,\n",
      "         1.6696e+00, 1.8129e-01, 8.5118e-02, 1.0727e+00],\n",
      "        [2.3956e-02, 7.2259e-02, 2.0868e-01, 5.0904e-02, 7.7081e-01, 7.5258e-02,\n",
      "         1.8104e-01, 7.6499e-03, 2.6244e-01, 6.6254e-02, 1.4798e-02, 5.1310e-01,\n",
      "         4.4118e-01, 6.6621e-02, 3.4544e-02, 2.6422e-01],\n",
      "        [1.3560e-02, 2.7601e-02, 7.5178e-02, 2.6090e-02, 2.4119e-01, 1.3415e-02,\n",
      "         6.0388e-02, 3.7949e-03, 8.5055e-02, 1.7593e-02, 5.9276e-03, 1.4573e-01,\n",
      "         1.5820e-01, 1.0883e-02, 2.0232e-02, 7.9718e-02],\n",
      "        [5.2938e-02, 2.0663e-01, 7.3175e-01, 2.0499e-01, 3.3357e+00, 2.9414e-01,\n",
      "         6.1936e-01, 3.5360e-02, 1.0340e+00, 2.6788e-01, 3.3434e-02, 2.1079e+00,\n",
      "         1.6941e+00, 1.9205e-01, 6.8635e-02, 1.1469e+00],\n",
      "        [1.2037e-01, 1.3964e-01, 9.9717e-02, 1.3605e-02, 2.4515e-01, 1.9102e-02,\n",
      "         1.2914e-01, 2.1584e-03, 5.8872e-02, 2.0887e-02, 5.0008e-02, 1.2642e-01,\n",
      "         2.0482e-01, 1.9985e-01, 1.0506e-01, 7.2225e-02],\n",
      "        [1.2271e-01, 1.2256e-01, 7.5341e-01, 2.3115e-01, 5.3890e+00, 2.9651e-01,\n",
      "         5.6116e-01, 4.1935e-02, 1.0900e+00, 4.9481e-01, 1.1251e-02, 2.7667e+00,\n",
      "         2.0138e+00, 1.5215e-01, 5.5037e-02, 1.5918e+00],\n",
      "        [1.9522e-02, 4.4015e-02, 7.9735e-02, 1.9488e-02, 2.0581e-01, 2.1956e-02,\n",
      "         7.5668e-02, 2.1045e-03, 8.8494e-02, 1.8121e-02, 9.5052e-03, 1.4570e-01,\n",
      "         1.5190e-01, 2.6311e-02, 2.0029e-02, 7.4720e-02],\n",
      "        [3.4908e-02, 4.0133e-02, 5.7393e-02, 1.7328e-02, 2.7938e-01, 1.6380e-02,\n",
      "         5.2666e-02, 2.5711e-03, 6.8575e-02, 2.1577e-02, 1.2773e-02, 1.4796e-01,\n",
      "         1.2476e-01, 6.4017e-02, 3.0619e-02, 8.4804e-02],\n",
      "        [1.7286e-02, 8.5094e-02, 2.8002e-01, 8.2730e-02, 1.1858e+00, 9.1245e-02,\n",
      "         2.3365e-01, 1.3652e-02, 3.7895e-01, 9.1534e-02, 1.3405e-02, 7.4029e-01,\n",
      "         6.3660e-01, 4.1207e-02, 2.6730e-02, 4.0521e-01],\n",
      "        [8.2863e-02, 1.2001e-01, 1.1828e-01, 1.8000e-02, 2.6446e-01, 2.6024e-02,\n",
      "         1.3825e-01, 2.6852e-03, 9.1556e-02, 2.1855e-02, 3.7795e-02, 1.6737e-01,\n",
      "         2.4522e-01, 1.4503e-01, 8.0106e-02, 8.8416e-02],\n",
      "        [5.3724e-02, 5.4200e-02, 6.0387e-02, 1.7276e-02, 2.9336e-01, 1.9955e-02,\n",
      "         5.9637e-02, 2.4715e-03, 6.9620e-02, 2.2678e-02, 1.8699e-02, 1.5425e-01,\n",
      "         1.2413e-01, 9.4194e-02, 4.4165e-02, 8.9810e-02],\n",
      "        [9.4042e+00, 7.4064e+00, 1.5809e+00, 1.4136e-01, 1.6431e+01, 1.2271e+00,\n",
      "         3.5421e+00, 1.8977e-02, 9.6281e-01, 1.2561e+00, 3.1383e+00, 6.2551e+00,\n",
      "         2.2659e+00, 1.6325e+01, 6.6667e+00, 4.4266e+00],\n",
      "        [5.7267e-01, 4.5102e-01, 3.9328e-01, 1.4667e-01, 8.8725e-01, 7.2308e-02,\n",
      "         3.9443e-01, 1.4938e-02, 3.1806e-01, 1.0032e-01, 1.9073e-01, 4.5656e-01,\n",
      "         5.4199e-01, 5.0618e-01, 3.9745e-01, 2.6578e-01],\n",
      "        [1.9196e-02, 1.6751e-01, 6.7442e-01, 2.6102e-01, 2.5516e+00, 1.2794e-01,\n",
      "         5.0061e-01, 4.2333e-02, 8.8540e-01, 1.5227e-01, 3.0265e-02, 1.5421e+00,\n",
      "         1.5208e+00, 1.7997e-02, 9.3633e-02, 8.7423e-01],\n",
      "        [4.1510e-02, 7.6193e-02, 1.6624e-01, 5.5373e-02, 6.5495e-01, 4.7391e-02,\n",
      "         1.4101e-01, 7.4788e-03, 2.2372e-01, 4.8765e-02, 1.6011e-02, 4.0417e-01,\n",
      "         3.4312e-01, 4.7454e-02, 3.3005e-02, 2.2467e-01],\n",
      "        [4.6264e-03, 1.6398e-02, 4.5719e-02, 1.6860e-02, 1.9106e-01, 1.0110e-02,\n",
      "         3.7968e-02, 2.5633e-03, 5.7806e-02, 1.3861e-02, 3.7070e-03, 1.0910e-01,\n",
      "         1.0711e-01, 1.5196e-02, 9.0999e-03, 6.0771e-02],\n",
      "        [2.4900e+00, 6.9144e-01, 8.0398e+00, 3.4316e+00, 7.9361e+01, 5.4823e+00,\n",
      "         5.5013e+00, 7.1735e-01, 1.7157e+01, 6.4091e+00, 1.9773e-01, 4.3650e+01,\n",
      "         2.3289e+01, 6.1237e+00, 3.5854e-01, 2.5706e+01],\n",
      "        [6.6828e-02, 5.2707e-02, 4.7102e-02, 1.3817e-02, 3.4133e-01, 2.2627e-02,\n",
      "         4.7075e-02, 2.0625e-03, 6.2779e-02, 2.8413e-02, 2.0443e-02, 1.6774e-01,\n",
      "         9.7850e-02, 1.1471e-01, 4.7680e-02, 1.0064e-01],\n",
      "        [1.1148e-01, 3.9568e-01, 7.4843e-01, 1.6822e-01, 1.6500e+00, 9.5658e-02,\n",
      "         7.0499e-01, 2.6955e-02, 6.7941e-01, 1.1992e-01, 8.4489e-02, 1.0968e+00,\n",
      "         1.6501e+00, 1.0218e-01, 2.0976e-01, 5.8225e-01],\n",
      "        [3.0201e-02, 4.0677e-03, 6.7128e-02, 6.0919e-02, 7.7311e-01, 4.4532e-02,\n",
      "         2.6143e-02, 7.3738e-03, 1.8630e-01, 5.7512e-02, 9.8058e-03, 4.0084e-01,\n",
      "         1.4616e-01, 1.0110e-01, 5.1261e-03, 2.2559e-01]])}, 10: {'step': tensor(3820.), 'exp_avg': tensor([-2.6789e-21,  1.9456e-20, -3.6213e-20, -6.7439e-22, -2.9890e-21,\n",
      "        -4.7456e-20,  1.7143e-21,  7.8634e-21, -2.5075e-21,  1.1939e-20,\n",
      "        -6.3811e-21, -5.4664e-21,  6.4624e-21,  2.5628e-22, -1.9611e-21,\n",
      "        -4.2289e-20, -4.7800e-21,  8.1118e-21,  2.4347e-22,  2.1293e-21,\n",
      "         4.4666e-21, -1.4980e-21,  2.3517e-20, -1.0881e-21,  9.9743e-22,\n",
      "         2.9442e-21, -6.6801e-22, -3.1260e-21, -1.7376e-20,  1.6656e-20,\n",
      "         8.9340e-21, -2.4237e-20, -2.0023e-21,  1.2995e-20,  6.8128e-21,\n",
      "        -6.4430e-21, -1.8007e-21, -1.2598e-20, -9.2705e-21,  1.2663e-20,\n",
      "         2.6763e-21, -6.6411e-21, -9.0520e-22, -6.7860e-21, -3.4481e-21,\n",
      "        -3.0670e-20, -6.1454e-21,  2.1437e-20,  3.2373e-21,  5.5178e-21,\n",
      "        -3.7584e-21, -1.3343e-20,  2.7639e-20,  4.2020e-21, -3.4840e-21,\n",
      "        -8.3286e-21, -7.2181e-21, -1.5424e-20,  1.8227e-21,  2.0529e-20,\n",
      "         5.7351e-21,  5.7509e-21, -3.0031e-21,  1.7956e-20, -2.5565e-20,\n",
      "         2.6189e-24, -2.6013e-21, -3.0846e-21, -4.2659e-20,  2.3833e-21,\n",
      "         1.9291e-20, -4.1944e-21,  6.4978e-21,  1.0768e-20,  2.8164e-20,\n",
      "         1.4143e-21,  8.6091e-22, -1.0105e-20, -4.3538e-21, -3.3371e-21,\n",
      "         8.4926e-21,  1.3788e-20,  1.1262e-20, -1.0536e-20,  3.8608e-21,\n",
      "         1.6217e-20, -2.8907e-21, -1.3559e-21,  1.9848e-21, -1.6488e-22,\n",
      "        -2.4069e-20,  5.3653e-21,  1.3280e-20,  9.4131e-21,  1.1168e-20,\n",
      "        -4.3726e-21, -7.4526e-21,  2.4573e-20, -3.3677e-21, -9.7167e-21]), 'exp_avg_sq': tensor([0.0080, 0.0039, 0.0100, 0.0045, 0.0036, 0.0171, 0.0100, 0.0137, 0.0102,\n",
      "        0.0210, 0.0096, 0.0040, 0.0036, 0.0198, 0.0053, 0.0160, 0.0193, 0.0066,\n",
      "        0.0223, 0.0042, 0.0098, 0.0158, 0.0225, 0.0114, 0.0054, 0.0065, 0.0039,\n",
      "        0.0122, 0.0080, 0.0039, 0.0170, 0.0096, 0.0107, 0.0119, 0.0335, 0.0045,\n",
      "        0.0047, 0.0079, 0.0053, 0.0045, 0.0192, 0.0015, 0.0086, 0.0037, 0.0036,\n",
      "        0.0067, 0.0320, 0.0178, 0.0040, 0.0192, 0.0066, 0.0175, 0.0230, 0.0180,\n",
      "        0.0267, 0.0215, 0.0140, 0.0252, 0.0240, 0.0175, 0.0076, 0.0016, 0.0071,\n",
      "        0.0207, 0.0065, 0.0164, 0.0174, 0.0087, 0.0218, 0.0016, 0.0077, 0.0126,\n",
      "        0.0100, 0.0067, 0.0081, 0.0324, 0.0254, 0.0273, 0.0067, 0.0039, 0.0073,\n",
      "        0.0125, 0.0185, 0.0063, 0.0111, 0.0146, 0.0203, 0.0186, 0.0099, 0.0055,\n",
      "        0.0067, 0.0094, 0.0100, 0.0047, 0.0135, 0.0054, 0.0398, 0.0240, 0.0215,\n",
      "        0.0094])}, 11: {'step': tensor(3820.), 'exp_avg': tensor([ 2.8096e-29,  1.5776e-28,  2.3855e-27,  5.4026e-28, -2.6933e-28,\n",
      "         4.0259e-27, -1.1879e-28, -7.6313e-29,  3.3687e-28,  1.8707e-27,\n",
      "         1.0350e-29,  1.1945e-28, -6.0094e-28,  1.7562e-29,  9.8493e-29,\n",
      "        -1.5782e-27,  1.4926e-28,  1.2833e-27, -1.2075e-28, -5.2074e-28,\n",
      "         2.2481e-29, -9.3413e-28,  6.8965e-28,  1.2387e-28,  8.7961e-28,\n",
      "        -6.3321e-29,  7.0289e-28,  7.4037e-28,  2.3623e-28,  6.9987e-28,\n",
      "        -8.9068e-28, -1.7148e-27, -9.2147e-28,  9.7598e-28,  6.4562e-28,\n",
      "         1.4958e-28, -5.7266e-29,  2.5038e-28,  1.4563e-28, -3.9901e-28,\n",
      "         1.5180e-28, -2.3969e-28, -4.2355e-28,  1.3868e-28,  1.0855e-28,\n",
      "        -1.8481e-27, -1.1757e-28, -1.0913e-27, -1.1327e-28, -7.9915e-28,\n",
      "         1.5316e-27, -4.0116e-28,  2.6824e-27,  2.5442e-28,  3.7300e-29,\n",
      "         1.7963e-28,  2.0432e-29,  4.0157e-28,  7.2876e-28,  2.7820e-27,\n",
      "         1.0099e-29, -6.8530e-28, -8.7805e-28,  9.3071e-28, -1.1453e-28,\n",
      "         1.9140e-28,  5.8069e-28, -9.3712e-28,  1.4680e-27, -1.6861e-28,\n",
      "        -2.9497e-27,  3.0050e-29,  4.4577e-28, -5.9329e-28,  1.9352e-27,\n",
      "        -1.4751e-27,  1.0955e-27, -1.2438e-29, -9.0815e-29, -2.9725e-28,\n",
      "         1.0418e-27,  1.7910e-27, -1.2553e-27,  2.4882e-28,  2.3187e-27,\n",
      "        -3.6081e-28,  2.5636e-29,  4.2462e-28,  1.0728e-27, -2.0225e-28,\n",
      "        -6.7007e-28, -3.7629e-28,  9.3738e-28, -8.8545e-28, -1.6360e-27,\n",
      "         6.7879e-28, -1.8270e-29, -4.4702e-29,  9.7804e-28, -8.5353e-29]), 'exp_avg_sq': tensor([3.6411e-16, 2.5681e-16, 1.2912e-15, 1.2694e-16, 5.1425e-16, 9.6653e-16,\n",
      "        5.3117e-16, 6.6528e-16, 1.3255e-16, 1.0004e-15, 2.0709e-16, 4.3276e-16,\n",
      "        4.7438e-16, 4.9787e-16, 5.6943e-16, 3.0194e-16, 1.1719e-16, 8.9219e-17,\n",
      "        5.0165e-16, 8.9584e-17, 4.7559e-16, 6.2474e-16, 6.3232e-16, 2.7713e-16,\n",
      "        2.2671e-16, 1.2739e-15, 2.6356e-16, 6.3472e-16, 1.5852e-16, 1.6543e-16,\n",
      "        2.4217e-16, 4.6366e-16, 7.0496e-16, 7.2789e-16, 5.9648e-16, 1.5816e-16,\n",
      "        1.5561e-16, 5.7298e-16, 3.1427e-16, 3.8377e-16, 4.0485e-16, 2.2680e-16,\n",
      "        3.4221e-16, 5.0293e-16, 3.0195e-16, 2.0750e-16, 5.4844e-16, 3.2926e-16,\n",
      "        4.9048e-16, 2.4149e-16, 4.7171e-16, 6.7464e-16, 1.0885e-15, 9.8366e-16,\n",
      "        7.6356e-16, 6.5553e-16, 6.6109e-16, 5.6210e-16, 2.0122e-16, 7.7511e-16,\n",
      "        1.4441e-16, 2.2026e-16, 5.6048e-16, 2.9797e-16, 3.7116e-16, 1.2278e-15,\n",
      "        3.8390e-16, 5.4980e-16, 2.6682e-16, 2.1446e-16, 1.4976e-16, 1.2297e-15,\n",
      "        1.6017e-16, 5.1227e-16, 2.1819e-16, 2.4674e-16, 7.2456e-16, 5.8501e-16,\n",
      "        3.2991e-16, 3.7271e-16, 2.2451e-16, 1.0807e-16, 4.5925e-16, 1.0260e-15,\n",
      "        2.6578e-16, 2.1682e-16, 6.4872e-16, 1.0411e-15, 3.6288e-16, 2.1677e-16,\n",
      "        2.7017e-16, 3.0951e-16, 7.6990e-16, 1.1346e-16, 1.0645e-15, 1.0909e-15,\n",
      "        4.1442e-16, 3.6314e-16, 5.3277e-16, 1.1551e-15])}, 12: {'step': tensor(3820.), 'exp_avg': tensor([-5.8227e-18,  6.1375e-18,  5.5753e-18, -3.2442e-18, -2.2637e-18,\n",
      "        -4.6060e-18,  3.6975e-18,  5.2630e-19]), 'exp_avg_sq': tensor([ 69.3165, 126.8454, 159.5825,  20.3189,  55.0424,  81.0456,  55.2706,\n",
      "          8.9967])}, 13: {'step': tensor(3820.), 'exp_avg': tensor([[-4.0384e-18, -2.2885e-19,  1.4393e-17],\n",
      "        [ 4.4389e-18,  2.9200e-19, -1.5450e-17],\n",
      "        [ 3.8400e-18,  2.1901e-19, -1.3786e-17],\n",
      "        [-2.3537e-18, -1.6464e-19,  8.3618e-18],\n",
      "        [-1.6173e-18, -9.9058e-20,  5.4828e-18],\n",
      "        [-3.2453e-18, -1.9269e-19,  1.1429e-17],\n",
      "        [ 2.6376e-18,  1.6399e-19, -9.1905e-18],\n",
      "        [ 3.3819e-19,  1.0247e-20, -1.2400e-18]]), 'exp_avg_sq': tensor([[3.8233e+00, 1.3905e-01, 6.9921e+00],\n",
      "        [6.7905e+00, 1.5158e-01, 3.5361e+01],\n",
      "        [2.0641e+01, 4.4383e-01, 6.6584e+01],\n",
      "        [3.5631e+00, 1.0439e-01, 2.0905e+00],\n",
      "        [3.1813e+00, 8.5187e-02, 1.8001e+01],\n",
      "        [5.0743e+00, 1.9143e-01, 9.1912e+00],\n",
      "        [3.6334e+00, 2.5558e-02, 1.5305e+01],\n",
      "        [8.1666e-01, 5.4666e-02, 8.0209e-01]])}, 14: {'step': tensor(3820.), 'exp_avg': tensor([ 2.4389e-20,  2.0547e-20,  1.2298e-20, -5.7001e-21,  1.5500e-20,\n",
      "        -6.2335e-21,  2.4575e-20,  1.1831e-20,  5.1367e-21,  1.1915e-20,\n",
      "         9.6339e-21,  9.7731e-21,  1.2250e-20,  1.7911e-20,  8.2144e-21,\n",
      "        -3.0488e-21,  1.8274e-20,  1.4461e-20,  1.0987e-20,  1.3322e-20,\n",
      "         1.5050e-20,  6.1904e-21,  2.3882e-20,  1.1687e-20,  1.6972e-20,\n",
      "         1.0040e-20,  1.8205e-20,  1.9319e-21,  3.1862e-21,  2.0069e-20,\n",
      "         1.3083e-20,  1.7407e-20,  5.2529e-21,  1.2333e-20,  7.6248e-21,\n",
      "         1.2773e-20,  3.1722e-20,  8.5440e-21,  1.3629e-20,  1.4117e-20,\n",
      "         8.8735e-21,  1.5659e-20,  1.4047e-20,  1.5132e-20,  1.2111e-20,\n",
      "         8.4152e-21,  1.2141e-20,  1.9660e-20,  7.0539e-21,  1.4697e-20,\n",
      "        -1.4504e-21,  8.3564e-21,  1.8473e-20,  1.1993e-20,  1.1398e-20,\n",
      "         1.7827e-20,  1.8603e-20,  7.3274e-21,  6.3085e-21,  1.6920e-20,\n",
      "         1.6256e-20,  8.5532e-21, -1.2803e-21,  1.0861e-20,  1.0228e-20,\n",
      "         1.3814e-20, -8.9687e-22,  2.0005e-21, -1.7330e-21,  1.6165e-20,\n",
      "         2.2221e-20,  1.7670e-20,  9.3406e-21,  2.1964e-20,  1.9488e-20,\n",
      "         1.4376e-20,  3.9132e-21,  2.5921e-20,  1.0053e-20,  2.0933e-20,\n",
      "         2.1759e-20,  2.2950e-20,  2.7311e-20,  1.8441e-20,  2.4671e-20,\n",
      "         2.0662e-20,  1.5566e-20,  1.1150e-20,  1.2308e-20,  1.5333e-20,\n",
      "         1.9108e-20,  1.3661e-20,  1.1406e-20,  1.5858e-20,  1.6004e-20,\n",
      "         1.9696e-20,  2.1112e-20,  2.3866e-20,  1.3156e-21,  1.8342e-20]), 'exp_avg_sq': tensor([0.0046, 0.0014, 0.0023, 0.0055, 0.0052, 0.0009, 0.0055, 0.0067, 0.0076,\n",
      "        0.0084, 0.0015, 0.0058, 0.0013, 0.0024, 0.0021, 0.0012, 0.0013, 0.0156,\n",
      "        0.0100, 0.0013, 0.0094, 0.0145, 0.0048, 0.0092, 0.0068, 0.0079, 0.0025,\n",
      "        0.0013, 0.0035, 0.0039, 0.0010, 0.0043, 0.0010, 0.0116, 0.0265, 0.0041,\n",
      "        0.0100, 0.0022, 0.0034, 0.0045, 0.0014, 0.0491, 0.0509, 0.0102, 0.0106,\n",
      "        0.0011, 0.0012, 0.0019, 0.0112, 0.0101, 0.0118, 0.0112, 0.0060, 0.0013,\n",
      "        0.0041, 0.0036, 0.0029, 0.0016, 0.0041, 0.0031, 0.0016, 0.0005, 0.0024,\n",
      "        0.0089, 0.0138, 0.0031, 0.0101, 0.0058, 0.0081, 0.0038, 0.0017, 0.0007,\n",
      "        0.0172, 0.0059, 0.0010, 0.0014, 0.0026, 0.0046, 0.0093, 0.0031, 0.0043,\n",
      "        0.0030, 0.0112, 0.0028, 0.0197, 0.0030, 0.0032, 0.0282, 0.0060, 0.0368,\n",
      "        0.0050, 0.0023, 0.0059, 0.0052, 0.0125, 0.0060, 0.0017, 0.0018, 0.0101,\n",
      "        0.0012])}, 15: {'step': tensor(3820.), 'exp_avg': tensor([-1.3258e-19, -1.2785e-19, -1.5178e-19, -7.8655e-20, -1.3329e-19,\n",
      "        -1.5090e-19, -1.8341e-19, -1.4037e-19, -1.4998e-19, -1.2129e-19,\n",
      "        -1.5171e-19, -1.3877e-19, -1.5481e-19, -1.6424e-19, -1.4131e-19,\n",
      "        -1.5502e-19, -1.6485e-19, -1.6682e-19, -1.4746e-19, -1.6595e-19,\n",
      "        -1.5737e-19, -1.5723e-19, -1.6640e-19, -1.5273e-19, -1.5791e-19,\n",
      "        -1.4976e-19, -1.8363e-19, -2.8316e-20, -1.3780e-19, -1.6097e-19,\n",
      "        -1.4510e-19, -1.8661e-19, -1.4834e-19, -1.3472e-19, -1.4916e-19,\n",
      "        -1.3772e-19, -1.3184e-19, -1.5436e-19, -1.4325e-19, -1.7371e-19,\n",
      "        -1.6159e-19, -1.5353e-19, -1.5290e-19, -1.5981e-19, -1.4150e-19,\n",
      "        -1.6741e-19, -1.5424e-19, -1.5470e-19, -1.4987e-19, -1.4184e-19,\n",
      "        -6.4911e-20, -1.4981e-19, -1.3886e-19, -1.4310e-19, -1.4735e-19,\n",
      "        -1.5607e-19, -1.5907e-19, -1.3804e-19, -1.5121e-19, -1.5179e-19,\n",
      "        -1.7098e-19, -1.5304e-19, -4.7189e-20, -1.2844e-19, -1.8334e-19,\n",
      "        -1.2063e-19, -7.3418e-20, -2.8286e-20, -1.7401e-19, -1.6392e-19,\n",
      "        -1.6920e-19, -1.9347e-19, -1.4291e-19, -1.6622e-19, -1.2529e-19,\n",
      "        -1.4320e-19, -1.4264e-19, -1.7331e-19, -1.5510e-19, -2.0371e-19,\n",
      "        -1.7287e-19, -1.7812e-19, -1.5335e-19, -1.5244e-19, -2.0332e-19,\n",
      "        -1.6336e-19, -1.9447e-19, -1.4211e-19, -1.5369e-19, -1.7720e-19,\n",
      "        -1.5364e-19, -1.4136e-19, -1.5377e-19, -1.5571e-19, -1.6562e-19,\n",
      "        -1.8285e-19, -1.7370e-19, -1.9429e-19, -2.3278e-20, -1.4939e-19]), 'exp_avg_sq': tensor([0.0222, 0.0141, 0.0163, 0.0271, 0.0464, 0.0506, 0.0320, 0.0396, 0.0423,\n",
      "        0.0199, 0.0402, 0.0427, 0.0178, 0.0426, 0.0170, 0.0170, 0.0345, 0.0527,\n",
      "        0.0495, 0.0343, 0.0244, 0.0829, 0.0257, 0.0341, 0.0632, 0.0234, 0.0217,\n",
      "        0.0423, 0.0655, 0.0251, 0.0230, 0.0455, 0.0440, 0.0776, 0.0969, 0.0352,\n",
      "        0.0626, 0.0475, 0.0168, 0.0152, 0.0329, 0.1678, 0.1766, 0.0635, 0.0842,\n",
      "        0.0364, 0.0415, 0.0240, 0.0683, 0.0423, 0.0444, 0.0961, 0.0308, 0.0312,\n",
      "        0.0450, 0.0498, 0.0250, 0.0443, 0.0548, 0.0305, 0.0224, 0.0612, 0.0537,\n",
      "        0.0268, 0.0608, 0.0437, 0.0693, 0.0478, 0.0536, 0.0344, 0.0611, 0.0513,\n",
      "        0.0798, 0.0890, 0.0326, 0.0339, 0.0539, 0.0593, 0.0666, 0.0635, 0.0202,\n",
      "        0.0565, 0.0490, 0.0726, 0.1960, 0.0290, 0.0321, 0.1278, 0.0426, 0.1300,\n",
      "        0.0351, 0.0281, 0.0513, 0.0348, 0.1806, 0.0503, 0.0614, 0.0305, 0.0568,\n",
      "        0.0584])}, 16: {'step': tensor(3820.), 'exp_avg': tensor([ 2.1785e-18,  8.0416e-18,  2.8044e-18, -8.4695e-18, -9.1356e-18,\n",
      "         1.6971e-18,  4.9986e-18, -2.1150e-18]), 'exp_avg_sq': tensor([ 26.2346,  46.3506,  27.1869,  33.0519,  19.5386, 150.8792,  26.7634,\n",
      "         23.1831])}, 17: {'step': tensor(3820.), 'exp_avg': tensor([[-1.5942e-18, -3.1280e-18,  1.7354e-18,  2.0473e-18,  1.8895e-18,\n",
      "         -2.1609e-18,  3.9682e-19,  1.2571e-18],\n",
      "        [-5.8824e-18, -1.1584e-17,  6.4133e-18,  7.5798e-18,  6.9738e-18,\n",
      "         -7.9781e-18,  1.4638e-18,  4.6481e-18],\n",
      "        [-2.0707e-18, -4.0707e-18,  2.3012e-18,  2.6133e-18,  2.5056e-18,\n",
      "         -2.8207e-18,  5.0911e-19,  1.6041e-18],\n",
      "        [ 6.2307e-18,  1.2251e-17, -6.8363e-18, -7.9619e-18, -7.4384e-18,\n",
      "          8.4619e-18, -1.5439e-18, -4.8855e-18],\n",
      "        [ 6.7391e-18,  1.3221e-17, -7.2807e-18, -8.7066e-18, -7.9201e-18,\n",
      "          9.1182e-18, -1.6835e-18, -5.3442e-18],\n",
      "        [-1.3006e-18, -2.5302e-18,  1.3901e-18,  1.6734e-18,  1.5119e-18,\n",
      "         -1.7540e-18,  3.2554e-19,  1.0289e-18],\n",
      "        [-3.6638e-18, -7.1999e-18,  3.9720e-18,  4.7316e-18,  4.3208e-18,\n",
      "         -4.9619e-18,  9.1426e-19,  2.9033e-18],\n",
      "        [ 1.5419e-18,  3.0417e-18, -1.6950e-18, -1.9769e-18, -1.8432e-18,\n",
      "          2.0955e-18, -3.8219e-19, -1.2119e-18]]), 'exp_avg_sq': tensor([[  4.0386,   5.8094,   0.5378,  14.1958,   0.4259,   3.6679,   0.5382,\n",
      "           5.5559],\n",
      "        [  6.0239,   2.4859,  11.4264,  34.1718,  10.0076,   2.7122,   1.4105,\n",
      "          14.8441],\n",
      "        [  2.4259,   0.8820,   7.2608,  17.6596,   6.8892,   1.0551,   0.6930,\n",
      "           7.5209],\n",
      "        [  1.5675,   1.6025,   5.8359,  10.4067,   6.1788,   1.2132,   0.4116,\n",
      "           4.3594],\n",
      "        [  2.9037,   4.7281,   1.7172,   9.9166,   1.5821,   2.6703,   0.3910,\n",
      "           3.9977],\n",
      "        [ 18.6335,   8.4827,  25.2838, 104.6697,  20.6917,   8.6782,   4.2506,\n",
      "          44.7196],\n",
      "        [  3.3240,   1.7796,   4.2342,  15.5778,   3.8289,   1.8784,   0.6588,\n",
      "           6.7666],\n",
      "        [  2.5743,   1.6877,   3.7726,  14.9673,   3.2256,   1.3386,   0.5890,\n",
      "           6.2848]])}, 18: {'step': tensor(3820.), 'exp_avg': tensor([ 1.7741e-20,  1.3793e-20,  9.0389e-21, -1.1994e-22,  1.0804e-20,\n",
      "        -5.7801e-22,  1.9888e-20,  1.0021e-20,  8.5418e-21,  8.9085e-21,\n",
      "         1.0899e-20,  9.2700e-21,  1.0556e-20,  1.4627e-20,  8.2477e-21,\n",
      "         3.0887e-21,  1.2331e-20,  1.1435e-20,  1.0618e-20,  1.1441e-20,\n",
      "         1.4186e-20,  8.6957e-21,  1.9998e-20,  9.7365e-21,  1.3636e-20,\n",
      "         1.0637e-20,  1.3119e-20,  1.9976e-21,  6.0832e-21,  1.7765e-20,\n",
      "         1.0952e-20,  1.5412e-20,  9.0705e-21,  1.0493e-20,  8.3033e-21,\n",
      "         1.0808e-20,  8.3383e-21,  9.9422e-21,  9.8937e-21,  1.3842e-20,\n",
      "         1.2826e-20,  1.1671e-20,  1.1704e-20,  1.1492e-20,  6.5799e-21,\n",
      "         7.4542e-21,  1.1198e-20,  1.4242e-20,  8.2942e-21,  1.0206e-20,\n",
      "         8.8282e-22,  9.2216e-21,  1.4448e-20,  1.0807e-20,  9.3705e-21,\n",
      "         1.1773e-20,  1.1736e-20,  8.0669e-21,  9.1768e-21,  1.2270e-20,\n",
      "         1.4176e-20,  9.7784e-21,  6.7153e-22,  1.0256e-20,  1.1654e-20,\n",
      "         3.4177e-21, -1.6735e-21,  2.0255e-21,  4.3875e-21,  1.3145e-20,\n",
      "         1.7729e-20,  1.6316e-20,  8.9218e-21,  1.4399e-20,  1.2662e-20,\n",
      "         1.2221e-20, -2.3832e-21,  1.6831e-20,  7.8508e-21,  1.9783e-20,\n",
      "         1.6693e-20,  2.0441e-20,  2.3151e-20,  1.4528e-20,  1.9122e-20,\n",
      "         1.5078e-20,  1.7429e-20,  1.0529e-20,  1.2884e-20,  1.4512e-20,\n",
      "         1.4413e-20,  9.7297e-21,  1.0609e-20,  1.3560e-20,  1.5359e-20,\n",
      "         1.5377e-20,  1.4965e-20,  2.2299e-20,  1.3467e-21,  9.6843e-21]), 'exp_avg_sq': tensor([0.0015, 0.0012, 0.0012, 0.0030, 0.0047, 0.0005, 0.0024, 0.0051, 0.0033,\n",
      "        0.0018, 0.0009, 0.0036, 0.0011, 0.0016, 0.0012, 0.0010, 0.0011, 0.0094,\n",
      "        0.0034, 0.0013, 0.0097, 0.0033, 0.0015, 0.0043, 0.0042, 0.0010, 0.0009,\n",
      "        0.0012, 0.0074, 0.0020, 0.0013, 0.0015, 0.0012, 0.0064, 0.0034, 0.0032,\n",
      "        0.0087, 0.0008, 0.0023, 0.0042, 0.0010, 0.0067, 0.0139, 0.0038, 0.0210,\n",
      "        0.0007, 0.0022, 0.0010, 0.0050, 0.0054, 0.0074, 0.0043, 0.0024, 0.0029,\n",
      "        0.0017, 0.0019, 0.0032, 0.0012, 0.0024, 0.0017, 0.0008, 0.0004, 0.0032,\n",
      "        0.0053, 0.0208, 0.0048, 0.0082, 0.0055, 0.0077, 0.0010, 0.0009, 0.0007,\n",
      "        0.0042, 0.0078, 0.0007, 0.0005, 0.0037, 0.0049, 0.0097, 0.0025, 0.0051,\n",
      "        0.0024, 0.0135, 0.0027, 0.0087, 0.0021, 0.0029, 0.0120, 0.0069, 0.0051,\n",
      "        0.0051, 0.0014, 0.0008, 0.0024, 0.0026, 0.0044, 0.0006, 0.0012, 0.0083,\n",
      "        0.0028])}, 19: {'step': tensor(3820.), 'exp_avg': tensor([1.2397e-19, 1.1431e-19, 1.4607e-19, 3.6601e-20, 1.1890e-19, 1.5144e-19,\n",
      "        1.7557e-19, 1.2714e-19, 1.2774e-19, 9.5016e-20, 1.3430e-19, 1.2261e-19,\n",
      "        1.4639e-19, 1.1410e-19, 1.2889e-19, 1.5076e-19, 1.1758e-19, 1.4738e-19,\n",
      "        1.3089e-19, 1.3971e-19, 1.4857e-19, 1.3955e-19, 1.5110e-19, 1.3572e-19,\n",
      "        1.4966e-19, 1.3383e-19, 1.6478e-19, 2.7498e-20, 1.3306e-19, 1.4428e-19,\n",
      "        1.2816e-19, 1.7889e-19, 1.2270e-19, 1.0566e-19, 1.3349e-19, 1.2114e-19,\n",
      "        7.7277e-20, 1.4834e-19, 1.2872e-19, 1.6171e-19, 1.4967e-19, 1.3906e-19,\n",
      "        1.3433e-19, 1.4471e-19, 1.0363e-19, 1.5635e-19, 1.2840e-19, 1.3590e-19,\n",
      "        1.3797e-19, 1.2752e-19, 4.0863e-20, 1.4290e-19, 1.1092e-19, 1.3037e-19,\n",
      "        1.3217e-19, 1.4393e-19, 1.5032e-19, 1.3677e-19, 1.2935e-19, 1.2301e-19,\n",
      "        1.5635e-19, 1.2826e-19, 3.0736e-20, 1.1723e-19, 1.7980e-19, 7.5552e-20,\n",
      "        4.9820e-20, 2.7534e-20, 1.7534e-19, 1.4942e-19, 1.4671e-19, 1.7895e-19,\n",
      "        1.2590e-19, 1.4996e-19, 9.8260e-20, 1.3212e-19, 9.8076e-20, 1.6779e-19,\n",
      "        1.3848e-19, 2.0024e-19, 1.2965e-19, 1.4716e-19, 1.0952e-19, 1.3713e-19,\n",
      "        1.8755e-19, 1.4929e-19, 1.6519e-19, 1.3515e-19, 1.4194e-19, 1.4634e-19,\n",
      "        1.5017e-19, 1.2895e-19, 1.2861e-19, 1.4443e-19, 1.4068e-19, 1.7964e-19,\n",
      "        1.5824e-19, 1.5907e-19, 2.5290e-20, 1.0733e-19]), 'exp_avg_sq': tensor([0.0120, 0.0083, 0.0094, 0.0228, 0.0143, 0.0100, 0.0105, 0.0179, 0.0235,\n",
      "        0.0092, 0.0190, 0.0102, 0.0109, 0.0324, 0.0086, 0.0205, 0.0094, 0.0227,\n",
      "        0.0113, 0.0206, 0.0088, 0.0182, 0.0191, 0.0172, 0.0077, 0.0124, 0.0080,\n",
      "        0.0131, 0.0112, 0.0134, 0.0108, 0.0118, 0.0099, 0.0127, 0.0137, 0.0145,\n",
      "        0.0156, 0.0143, 0.0128, 0.0139, 0.0340, 0.0227, 0.0156, 0.0216, 0.0172,\n",
      "        0.0179, 0.0111, 0.0112, 0.0331, 0.0208, 0.0200, 0.0168, 0.0139, 0.0169,\n",
      "        0.0152, 0.0185, 0.0151, 0.0182, 0.0094, 0.0274, 0.0117, 0.0103, 0.0210,\n",
      "        0.0127, 0.0129, 0.0151, 0.0302, 0.0143, 0.0106, 0.0099, 0.0272, 0.0126,\n",
      "        0.0360, 0.0216, 0.0159, 0.0205, 0.0128, 0.0223, 0.0216, 0.0130, 0.0213,\n",
      "        0.0291, 0.0139, 0.0207, 0.0113, 0.0182, 0.0273, 0.0164, 0.0184, 0.0095,\n",
      "        0.0216, 0.0167, 0.0114, 0.0342, 0.0113, 0.0158, 0.0157, 0.0171, 0.0240,\n",
      "        0.0144])}, 20: {'step': tensor(3820.), 'exp_avg': tensor([ 7.9318e-19,  5.6021e-18,  8.2885e-18, -8.9394e-18, -4.2444e-18,\n",
      "        -2.8196e-18,  3.6186e-18, -2.2990e-18]), 'exp_avg_sq': tensor([ 16.6328,  28.7738,  43.6722,  14.1422,  33.1285,  10.3402, 112.1996,\n",
      "         12.7475])}, 21: {'step': tensor(3820.), 'exp_avg': tensor([[ 5.9339e-19,  6.3027e-19, -1.2798e-18,  9.3409e-19, -5.8270e-19,\n",
      "          1.7275e-20, -1.5039e-19, -1.8222e-19],\n",
      "        [ 4.3761e-18,  4.7803e-18, -9.5756e-18,  6.9714e-18, -4.4585e-18,\n",
      "          1.9152e-19, -1.0737e-18, -1.3449e-18],\n",
      "        [ 6.4476e-18,  7.0004e-18, -1.4064e-17,  1.0245e-17, -6.5398e-18,\n",
      "          2.6532e-19, -1.5749e-18, -1.9777e-18],\n",
      "        [-6.9590e-18, -7.3751e-18,  1.4992e-17, -1.0945e-17,  7.0226e-18,\n",
      "         -2.2970e-19,  1.6047e-18,  2.1018e-18],\n",
      "        [-3.2998e-18, -3.6522e-18,  7.2697e-18, -5.2864e-18,  3.3623e-18,\n",
      "         -1.5778e-19,  8.4195e-19,  1.0242e-18],\n",
      "        [-2.2070e-18, -2.4575e-18,  4.8770e-18, -3.5440e-18,  2.2567e-18,\n",
      "         -1.1147e-19,  5.6608e-19,  6.8757e-19],\n",
      "        [ 2.8551e-18,  3.0265e-18, -6.1512e-18,  4.4901e-18, -2.9014e-18,\n",
      "          9.8337e-20, -6.4219e-19, -8.5962e-19],\n",
      "        [-1.8064e-18, -1.9526e-18,  3.9311e-18, -2.8646e-18,  1.8408e-18,\n",
      "         -7.3507e-20,  4.2850e-19,  5.5095e-19]]), 'exp_avg_sq': tensor([[3.9853e+00, 5.4019e+00, 9.0542e-01, 4.3605e-01, 1.5104e+00, 1.6412e+00,\n",
      "         4.3129e+00, 7.2111e-02],\n",
      "        [2.5493e+00, 1.6652e+01, 1.0586e+01, 3.8712e+00, 1.8487e+00, 2.8587e+00,\n",
      "         1.1273e+01, 5.5448e-01],\n",
      "        [7.0342e+00, 2.1769e+01, 7.0740e+00, 1.9392e+00, 3.3763e+00, 5.0105e+00,\n",
      "         1.5295e+01, 5.2122e-01],\n",
      "        [3.3357e+00, 1.0040e+01, 4.5497e+00, 1.5711e+00, 1.9099e+00, 2.2501e+00,\n",
      "         6.9067e+00, 2.5593e-01],\n",
      "        [1.1410e+01, 2.4136e+01, 4.1246e+00, 8.8129e-01, 5.5379e+00, 6.3197e+00,\n",
      "         2.0784e+01, 3.4193e-01],\n",
      "        [1.5050e+00, 8.2194e+00, 5.7516e+00, 2.2218e+00, 8.9417e-01, 1.4928e+00,\n",
      "         4.7618e+00, 2.5383e-01],\n",
      "        [2.7907e+01, 1.2964e+02, 4.8820e+01, 1.3797e+01, 1.1976e+01, 2.6950e+01,\n",
      "         9.0289e+01, 3.0528e+00],\n",
      "        [5.7237e-01, 2.9668e+00, 1.7455e+00, 6.1879e-01, 6.2406e-01, 5.3297e-01,\n",
      "         2.2883e+00, 9.0068e-02]])}, 22: {'step': tensor(3820.), 'exp_avg': tensor([ 5.9361e-21,  2.0979e-20, -1.7789e-20, -5.4176e-21,  5.1725e-21,\n",
      "        -2.7500e-20,  9.7583e-21,  1.5313e-20,  5.6897e-21,  1.7205e-20,\n",
      "         1.9605e-21,  4.2196e-21,  1.0774e-20,  3.5354e-21,  6.2559e-21,\n",
      "        -2.3468e-20, -1.3151e-21,  1.4204e-20,  8.1008e-21,  7.8453e-21,\n",
      "         1.0902e-20,  6.4579e-21,  2.5338e-20,  8.2216e-21,  8.8712e-21,\n",
      "         9.8686e-21,  6.9190e-21, -8.5369e-21, -5.7714e-21,  1.9617e-20,\n",
      "         1.3804e-20, -9.3124e-21,  8.8090e-21,  1.7727e-20,  1.2402e-20,\n",
      "         4.9654e-22, -1.0343e-22, -2.2738e-21, -3.6962e-22,  1.6216e-20,\n",
      "         9.7384e-21,  4.2438e-21,  7.3339e-21,  7.7360e-22, -3.0845e-21,\n",
      "        -1.5183e-20,  1.3831e-21,  2.2670e-20,  9.6604e-21,  1.1925e-20,\n",
      "        -7.1510e-21, -1.2713e-21,  2.8099e-20,  1.2362e-20,  3.1252e-21,\n",
      "         5.5711e-22,  5.5695e-21, -4.2159e-21,  1.0151e-20,  2.1828e-20,\n",
      "         1.1601e-20,  1.1427e-20, -8.2596e-21,  1.9424e-20, -9.6181e-21,\n",
      "        -2.8852e-21, -7.4829e-21, -8.4557e-21, -2.3284e-20,  1.1167e-20,\n",
      "         2.0635e-20,  5.1959e-21,  1.1068e-20,  1.5350e-20,  2.8378e-20,\n",
      "         9.6184e-21, -5.0612e-21, -2.6637e-22,  2.3912e-21,  5.9002e-21,\n",
      "         1.0848e-20,  1.6735e-20,  1.5931e-20, -3.9144e-23,  1.1942e-20,\n",
      "         1.9154e-20,  4.0667e-21,  5.9760e-21,  8.3890e-21,  5.5059e-21,\n",
      "        -9.8509e-21,  1.0182e-20,  1.7106e-20,  1.3647e-20,  1.5095e-20,\n",
      "         4.9631e-21,  3.9239e-21,  2.5448e-20, -8.6647e-21, -5.0468e-21]), 'exp_avg_sq': tensor([0.0129, 0.0156, 0.0121, 0.0108, 0.0100, 0.0215, 0.0170, 0.0219, 0.0130,\n",
      "        0.0228, 0.0121, 0.0156, 0.0126, 0.0136, 0.0147, 0.0188, 0.0238, 0.0225,\n",
      "        0.0129, 0.0079, 0.0134, 0.0152, 0.0136, 0.0100, 0.0155, 0.0144, 0.0112,\n",
      "        0.0130, 0.0271, 0.0123, 0.0140, 0.0110, 0.0176, 0.0178, 0.0312, 0.0191,\n",
      "        0.0083, 0.0175, 0.0129, 0.0118, 0.0116, 0.0192, 0.0265, 0.0100, 0.0227,\n",
      "        0.0137, 0.0255, 0.0103, 0.0167, 0.0162, 0.0129, 0.0140, 0.0187, 0.0184,\n",
      "        0.0169, 0.0186, 0.0225, 0.0158, 0.0176, 0.0113, 0.0116, 0.0051, 0.0125,\n",
      "        0.0147, 0.0239, 0.0134, 0.0140, 0.0192, 0.0217, 0.0114, 0.0111, 0.0182,\n",
      "        0.0074, 0.0063, 0.0127, 0.0172, 0.0203, 0.0136, 0.0083, 0.0093, 0.0144,\n",
      "        0.0092, 0.0275, 0.0153, 0.0194, 0.0153, 0.0143, 0.0227, 0.0123, 0.0131,\n",
      "        0.0126, 0.0143, 0.0112, 0.0054, 0.0202, 0.0117, 0.0202, 0.0235, 0.0218,\n",
      "        0.0180])}, 23: {'step': tensor(3820.), 'exp_avg': tensor([-1.8382e-19, -1.7593e-19, -1.8916e-19, -2.6906e-20, -1.8287e-19,\n",
      "        -1.9440e-19, -1.7904e-19, -1.7525e-19, -1.7662e-19, -1.0631e-19,\n",
      "        -1.8405e-19, -1.7927e-19, -1.7886e-19, -1.0617e-19, -1.8175e-19,\n",
      "        -1.9440e-19, -1.1583e-19, -1.6818e-19, -1.7662e-19, -1.6225e-19,\n",
      "        -1.7714e-19, -1.7137e-19, -1.7583e-19, -1.7614e-19, -1.7624e-19,\n",
      "        -1.7942e-19, -1.6105e-19, -2.9988e-20, -1.8872e-19, -1.7963e-19,\n",
      "        -1.6623e-19, -1.8218e-19, -1.7040e-19, -1.1481e-19, -1.7174e-19,\n",
      "        -1.5583e-19, -2.6995e-20, -1.8618e-19, -1.7704e-19, -1.7871e-19,\n",
      "        -1.8340e-19, -1.7589e-19, -1.7093e-19, -1.7595e-19, -7.0429e-20,\n",
      "        -1.9109e-19, -1.4935e-19, -1.7729e-19, -1.7558e-19, -1.7506e-19,\n",
      "        -2.9225e-20, -1.8365e-19, -1.3379e-19, -1.7770e-19, -1.6319e-19,\n",
      "        -1.8313e-19, -1.7956e-19, -1.8927e-19, -1.6656e-19, -1.5143e-19,\n",
      "        -1.6825e-19, -1.7078e-19, -2.9599e-20, -1.7958e-19, -1.8882e-19,\n",
      "        -2.4463e-20, -2.8793e-20, -2.9879e-20, -1.9171e-19, -1.7805e-19,\n",
      "        -1.6809e-19, -1.6915e-19, -1.7281e-19, -1.7510e-19, -1.3075e-19,\n",
      "        -1.8141e-19, -2.4601e-20, -1.8512e-19, -1.7159e-19, -1.8047e-19,\n",
      "        -1.3238e-19, -1.5550e-19, -1.1177e-19, -1.7831e-19, -1.7464e-19,\n",
      "        -1.8118e-19, -1.6665e-19, -1.7469e-19, -1.7741e-19, -1.5019e-19,\n",
      "        -1.8872e-19, -1.7443e-19, -1.5728e-19, -1.8245e-19, -1.5261e-19,\n",
      "        -1.8502e-19, -1.7763e-19, -1.3027e-19, -2.9898e-20, -1.1682e-19]), 'exp_avg_sq': tensor([0.0092, 0.0068, 0.0070, 0.0093, 0.0087, 0.0071, 0.0088, 0.0089, 0.0093,\n",
      "        0.0089, 0.0095, 0.0079, 0.0098, 0.0096, 0.0087, 0.0090, 0.0082, 0.0084,\n",
      "        0.0091, 0.0100, 0.0082, 0.0092, 0.0093, 0.0107, 0.0061, 0.0068, 0.0062,\n",
      "        0.0098, 0.0070, 0.0081, 0.0086, 0.0086, 0.0048, 0.0048, 0.0097, 0.0061,\n",
      "        0.0099, 0.0060, 0.0103, 0.0113, 0.0097, 0.0066, 0.0073, 0.0094, 0.0059,\n",
      "        0.0090, 0.0091, 0.0107, 0.0082, 0.0058, 0.0087, 0.0086, 0.0093, 0.0099,\n",
      "        0.0100, 0.0092, 0.0084, 0.0118, 0.0058, 0.0099, 0.0105, 0.0090, 0.0104,\n",
      "        0.0104, 0.0074, 0.0101, 0.0110, 0.0085, 0.0079, 0.0052, 0.0080, 0.0112,\n",
      "        0.0098, 0.0104, 0.0100, 0.0101, 0.0070, 0.0060, 0.0099, 0.0093, 0.0096,\n",
      "        0.0100, 0.0068, 0.0085, 0.0064, 0.0105, 0.0116, 0.0080, 0.0113, 0.0081,\n",
      "        0.0077, 0.0107, 0.0085, 0.0117, 0.0070, 0.0074, 0.0096, 0.0116, 0.0085,\n",
      "        0.0063])}, 24: {'step': tensor(3820.), 'exp_avg': tensor([-4.1708e-21,  1.4928e-21, -1.0415e-21,  2.9191e-21, -2.0119e-22,\n",
      "        -7.3622e-22,  2.7733e-21, -1.0356e-21]), 'exp_avg_sq': tensor([0.0093, 0.0276, 0.0174, 0.0051, 0.0007, 0.0020, 0.0224, 0.0346])}, 25: {'step': tensor(3820.), 'exp_avg': tensor([[-3.0321e-19,  3.2969e-20, -1.9294e-19, -1.1303e-19,  1.9881e-19,\n",
      "          7.2277e-20,  3.8117e-19, -1.3446e-19],\n",
      "        [ 1.1645e-19, -1.2715e-20,  7.4099e-20,  4.3396e-20, -7.6315e-20,\n",
      "         -2.7874e-20, -1.4628e-19,  5.1605e-20],\n",
      "        [-8.3827e-20,  9.1656e-21, -5.3337e-20, -3.1248e-20,  5.4921e-20,\n",
      "          2.0083e-20,  1.0528e-19, -3.7138e-20],\n",
      "        [ 2.2274e-19, -2.4287e-20,  1.4173e-19,  8.3030e-20, -1.4599e-19,\n",
      "         -5.3229e-20, -2.7987e-19,  9.8729e-20],\n",
      "        [-2.5354e-20,  2.8248e-21, -1.6131e-20, -9.4530e-21,  1.6569e-20,\n",
      "          6.1790e-21,  3.1737e-20, -1.1196e-20],\n",
      "        [-5.1038e-20,  5.5306e-21, -3.2476e-20, -1.9025e-20,  3.3478e-20,\n",
      "          1.2128e-20,  6.4197e-20, -2.2647e-20],\n",
      "        [ 2.0060e-19, -2.1797e-20,  1.2764e-19,  7.4780e-20, -1.3154e-19,\n",
      "         -4.7786e-20, -2.5220e-19,  8.8968e-20],\n",
      "        [-7.6361e-20,  8.3092e-21, -4.8590e-20, -2.8453e-20,  5.0065e-20,\n",
      "          1.8222e-20,  9.5975e-20, -3.3860e-20]]), 'exp_avg_sq': tensor([[0.0552, 0.0066, 0.0204, 0.0303, 0.0354, 0.0114, 0.1332, 0.0180],\n",
      "        [0.0543, 0.0079, 0.0229, 0.0124, 0.0239, 0.0220, 0.0771, 0.0090],\n",
      "        [0.0149, 0.0021, 0.0068, 0.0045, 0.0091, 0.0054, 0.0305, 0.0037],\n",
      "        [0.0441, 0.0045, 0.0166, 0.0203, 0.0246, 0.0090, 0.0913, 0.0118],\n",
      "        [0.0086, 0.0014, 0.0027, 0.0034, 0.0022, 0.0035, 0.0078, 0.0007],\n",
      "        [0.0137, 0.0026, 0.0044, 0.0068, 0.0044, 0.0061, 0.0164, 0.0019],\n",
      "        [0.0347, 0.0041, 0.0140, 0.0143, 0.0218, 0.0064, 0.0772, 0.0103],\n",
      "        [0.0242, 0.0037, 0.0111, 0.0051, 0.0126, 0.0106, 0.0401, 0.0046]])}, 26: {'step': tensor(3820.), 'exp_avg': tensor([ 1.7288e-23,  2.3366e-23,  1.2445e-23, -9.2929e-25,  1.8236e-23,\n",
      "        -4.3431e-24,  1.0767e-24,  3.0579e-24,  1.2355e-24,  1.9420e-23,\n",
      "        -4.9656e-23,  6.9055e-24, -3.6565e-23,  3.2005e-24,  1.2851e-23,\n",
      "        -1.8376e-23, -1.2188e-23,  2.2205e-23,  1.0548e-23,  7.6668e-24,\n",
      "        -2.2755e-23, -5.5582e-21, -1.7800e-23,  1.4283e-23, -2.9200e-23]), 'exp_avg_sq': tensor([3.1753e-06, 1.7407e-05, 6.5867e-06, 5.0277e-06, 6.0841e-06, 5.1575e-06,\n",
      "        5.1885e-06, 5.8800e-06, 3.9008e-06, 5.3886e-06, 3.3049e-05, 1.3851e-05,\n",
      "        1.0495e-05, 2.3822e-06, 6.9718e-06, 9.9624e-06, 2.9502e-06, 1.3142e-05,\n",
      "        5.1826e-06, 1.4802e-05, 5.9613e-06, 5.6176e-05, 1.1345e-05, 5.8190e-06,\n",
      "        2.0050e-05])}, 27: {'step': tensor(3820.), 'exp_avg': tensor([-7.1065e-24, -2.8055e-22, -2.9383e-22, -5.5931e-22,  6.4284e-23,\n",
      "        -6.1039e-22, -4.1806e-22,  4.2073e-22, -5.0048e-22,  1.6158e-22,\n",
      "         5.8411e-22, -3.7859e-22,  6.5773e-22, -4.1716e-22, -1.0561e-22,\n",
      "         5.5540e-22, -4.9849e-22, -4.0690e-22, -2.4488e-22, -3.7223e-22,\n",
      "         5.3851e-22, -9.6910e-20,  5.3954e-22, -3.4151e-23,  4.8346e-22]), 'exp_avg_sq': tensor([2.8701e-04, 3.3704e-04, 1.2898e-03, 3.3989e-04, 3.2894e-04, 2.2555e-04,\n",
      "        1.5681e-04, 3.9086e-04, 1.3961e-04, 3.0112e-04, 2.1545e-03, 1.7118e-04,\n",
      "        4.5630e-04, 1.3769e-04, 2.5432e-04, 5.0345e-04, 1.1436e-04, 1.0538e-03,\n",
      "        4.3849e-04, 1.7999e-04, 3.5106e-04, 1.3154e-02, 5.4553e-04, 2.7052e-05,\n",
      "        1.4018e-03])}, 28: {'step': tensor(3820.), 'exp_avg': tensor([-1.1816e-20,  1.8396e-20, -7.7501e-20,  1.8839e-20,  7.3100e-20,\n",
      "        -2.2374e-20, -3.6027e-20,  3.7384e-20]), 'exp_avg_sq': tensor([0.0106, 0.0132, 0.0147, 0.0193, 0.0269, 0.0058, 0.0243, 0.0018])}, 29: {'step': tensor(3820.), 'exp_avg': tensor([[ 5.3081e-21,  7.1008e-21, -9.1212e-21,  1.7339e-20, -1.6260e-20,\n",
      "          5.4269e-21, -1.6813e-20,  7.9647e-21],\n",
      "        [-8.4860e-21, -1.1205e-20,  1.4373e-20, -2.7192e-20,  2.5540e-20,\n",
      "         -8.4444e-21,  2.6373e-20, -1.2441e-20],\n",
      "        [ 3.4727e-20,  4.6905e-20, -6.0329e-20,  1.1510e-19, -1.0785e-19,\n",
      "          3.6253e-20, -1.1153e-19,  5.3010e-20],\n",
      "        [-8.4817e-21, -1.1378e-20,  1.4619e-20, -2.7819e-20,  2.6079e-20,\n",
      "         -8.7215e-21,  2.6971e-20, -1.2788e-20],\n",
      "        [-3.3117e-20, -4.4364e-20,  5.7013e-20, -1.0844e-19,  1.0170e-19,\n",
      "         -3.3985e-20,  1.0512e-19, -4.9824e-20],\n",
      "        [ 1.0207e-20,  1.3621e-20, -1.7496e-20,  3.3232e-20, -3.1179e-20,\n",
      "          1.0390e-20, -3.2217e-20,  1.5251e-20],\n",
      "        [ 1.6555e-20,  2.1940e-20, -2.8162e-20,  5.3350e-20, -5.0092e-20,\n",
      "          1.6607e-20, -5.1740e-20,  2.4435e-20],\n",
      "        [-1.6712e-20, -2.2620e-20,  2.9104e-20, -5.5567e-20,  5.2063e-20,\n",
      "         -1.7527e-20,  5.3836e-20, -2.5607e-20]]), 'exp_avg_sq': tensor([[0.0167, 0.0014, 0.0021, 0.0056, 0.0042, 0.0041, 0.0035, 0.0053],\n",
      "        [0.0120, 0.0021, 0.0065, 0.0312, 0.0191, 0.0060, 0.0096, 0.0047],\n",
      "        [0.0094, 0.0052, 0.0064, 0.0210, 0.0089, 0.0031, 0.0205, 0.0051],\n",
      "        [0.0159, 0.0027, 0.0068, 0.0450, 0.0199, 0.0098, 0.0240, 0.0115],\n",
      "        [0.0220, 0.0079, 0.0078, 0.0138, 0.0070, 0.0040, 0.0207, 0.0068],\n",
      "        [0.0108, 0.0016, 0.0061, 0.0366, 0.0183, 0.0065, 0.0160, 0.0078],\n",
      "        [0.0280, 0.0047, 0.0037, 0.0063, 0.0021, 0.0073, 0.0092, 0.0083],\n",
      "        [0.0037, 0.0004, 0.0007, 0.0076, 0.0027, 0.0019, 0.0070, 0.0031]])}, 30: {'step': tensor(3820.), 'exp_avg': tensor([ 1.8194e-23,  1.4231e-23, -5.2926e-25, -3.4366e-23,  2.0558e-23,\n",
      "        -4.1514e-23, -1.8304e-23,  2.1588e-23, -2.7359e-23,  2.3916e-23,\n",
      "        -1.4468e-23, -9.4841e-24, -5.1138e-24, -1.8611e-23,  1.0927e-23,\n",
      "         6.4782e-24, -2.6926e-23,  9.2483e-26,  8.7903e-25, -9.9211e-24,\n",
      "         1.4024e-24, -3.9889e-21,  7.3671e-24,  1.3803e-23, -1.2546e-24]), 'exp_avg_sq': tensor([2.5057e-06, 1.6160e-05, 7.5484e-06, 5.0712e-06, 7.7357e-06, 3.7681e-06,\n",
      "        6.2692e-06, 5.6554e-06, 2.9691e-06, 4.2453e-06, 3.2178e-05, 1.2521e-05,\n",
      "        9.0994e-06, 3.4943e-06, 9.9997e-06, 9.1480e-06, 3.7413e-06, 1.0200e-05,\n",
      "        6.2043e-06, 1.4760e-05, 5.1776e-06, 1.0789e-04, 1.0060e-05, 6.4012e-06,\n",
      "        2.0821e-05])}, 31: {'step': tensor(3820.), 'exp_avg': tensor([-1.1191e-22, -5.2124e-22, -4.8452e-22, -8.2689e-22, -1.7996e-23,\n",
      "        -8.9392e-22, -6.4545e-22,  3.3514e-22, -7.5351e-22,  8.7964e-23,\n",
      "         4.6030e-22, -6.0507e-22,  5.4394e-22, -6.4562e-22, -2.2040e-22,\n",
      "         4.5833e-22, -7.0399e-22, -6.6823e-22, -4.0569e-22, -5.9579e-22,\n",
      "         4.3859e-22, -4.8714e-20,  4.4088e-22, -1.2869e-22,  3.7394e-22]), 'exp_avg_sq': tensor([1.0013e-04, 2.9995e-04, 5.7531e-04, 2.8327e-04, 6.9649e-05, 2.4169e-04,\n",
      "        1.9920e-04, 1.1552e-04, 2.2211e-04, 9.1415e-05, 4.5203e-04, 1.7947e-04,\n",
      "        1.2072e-04, 2.1109e-04, 8.1195e-05, 1.2984e-04, 1.5604e-04, 2.7989e-04,\n",
      "        1.6310e-04, 2.3012e-04, 9.4652e-05, 2.4091e-03, 1.4772e-04, 1.1177e-05,\n",
      "        2.7406e-04])}, 32: {'step': tensor(3820.), 'exp_avg': tensor([ 5.0378e-21, -4.3183e-23, -2.9681e-20, -9.8491e-21,  5.8183e-20,\n",
      "        -2.2705e-20,  1.3974e-20,  2.0469e-20, -5.4033e-20,  1.8648e-20]), 'exp_avg_sq': tensor([0.0004, 0.0025, 0.0030, 0.0011, 0.0214, 0.0080, 0.0033, 0.0018, 0.0082,\n",
      "        0.0007])}, 33: {'step': tensor(3820.), 'exp_avg': tensor([[-3.3654e-21,  9.2858e-21,  5.3614e-22,  4.1357e-22, -1.4618e-21,\n",
      "          7.3132e-21, -7.6263e-21, -4.8139e-21],\n",
      "        [-9.9361e-23,  2.4100e-22,  1.7430e-23,  1.4388e-23, -3.7366e-23,\n",
      "          1.9410e-22, -2.1457e-22, -1.2812e-22],\n",
      "        [ 1.9017e-20, -5.3438e-20, -3.0055e-21, -2.1409e-21,  8.5348e-21,\n",
      "         -4.1979e-20,  4.3370e-20,  2.7791e-20],\n",
      "        [ 6.1277e-21, -1.7475e-20, -9.6422e-22, -6.3215e-22,  2.8261e-21,\n",
      "         -1.3703e-20,  1.4046e-20,  9.1157e-21],\n",
      "        [-3.7469e-20,  1.0435e-19,  5.9230e-21,  4.4891e-21, -1.6503e-20,\n",
      "          8.2046e-20, -8.5212e-20, -5.4110e-20],\n",
      "        [ 1.4529e-20, -4.0540e-20, -2.2976e-21, -1.7179e-21,  6.4243e-21,\n",
      "         -3.1870e-20,  3.3060e-20,  2.1033e-20],\n",
      "        [-9.0101e-21,  2.4782e-20,  1.4234e-21,  1.1825e-21, -3.8548e-21,\n",
      "          1.9502e-20, -2.0412e-20, -1.2783e-20],\n",
      "        [-1.2988e-20,  3.6746e-20,  2.0534e-21,  1.3842e-21, -5.9157e-21,\n",
      "          2.8852e-20, -2.9683e-20, -1.9156e-20],\n",
      "        [ 3.5073e-20, -9.7468e-20, -5.5521e-21, -4.2327e-21,  1.5397e-20,\n",
      "         -7.6662e-20,  7.9701e-20,  5.0535e-20],\n",
      "        [-1.1816e-20,  3.3515e-20,  1.8660e-21,  1.2399e-21, -5.4090e-21,\n",
      "          2.6307e-20, -2.7030e-20, -1.7484e-20]]), 'exp_avg_sq': tensor([[2.0804e-04, 1.2261e-03, 6.4632e-05, 2.5569e-04, 7.1695e-04, 8.6136e-04,\n",
      "         4.0898e-04, 1.1873e-03],\n",
      "        [2.7380e-03, 2.9733e-02, 2.4546e-03, 2.8385e-03, 1.9006e-02, 2.6848e-02,\n",
      "         1.0547e-02, 2.4884e-02],\n",
      "        [2.9078e-03, 5.1312e-02, 8.0413e-04, 4.0313e-03, 3.0818e-02, 4.0011e-02,\n",
      "         1.1900e-02, 4.4669e-02],\n",
      "        [2.0315e-04, 1.7973e-03, 9.0535e-05, 2.7283e-04, 1.0789e-03, 1.3920e-03,\n",
      "         6.2554e-04, 1.6459e-03],\n",
      "        [5.0389e-03, 7.2519e-03, 5.9212e-04, 1.3195e-02, 4.6829e-03, 5.5353e-03,\n",
      "         1.9741e-02, 7.2519e-03],\n",
      "        [8.3875e-03, 1.1037e-02, 1.7724e-03, 7.9068e-03, 7.2536e-03, 6.7949e-03,\n",
      "         9.8993e-03, 1.3367e-02],\n",
      "        [1.7355e-03, 1.2762e-02, 1.7062e-04, 1.4429e-03, 8.5295e-03, 8.6852e-03,\n",
      "         2.2564e-03, 1.3016e-02],\n",
      "        [7.1064e-04, 9.8589e-03, 1.4809e-04, 7.2659e-04, 5.9322e-03, 7.3312e-03,\n",
      "         1.7488e-03, 9.0588e-03],\n",
      "        [5.5563e-03, 2.2157e-02, 6.2094e-04, 6.0631e-03, 1.2586e-02, 1.4932e-02,\n",
      "         1.0065e-02, 2.0508e-02],\n",
      "        [5.9818e-04, 2.0862e-03, 6.6813e-04, 5.1895e-04, 1.3127e-03, 2.2022e-03,\n",
      "         1.5146e-03, 1.7490e-03]])}, 34: {'step': tensor(3820.), 'exp_avg': tensor([-4.8738e-22,  3.7088e-21,  2.8337e-21,  5.6045e-21, -1.4375e-21,\n",
      "         6.1052e-21,  4.0720e-21, -4.8395e-21,  4.9725e-21, -2.4101e-21,\n",
      "        -6.9534e-21,  3.8842e-21, -7.6553e-21,  4.1688e-21,  3.2731e-22,\n",
      "        -6.5093e-21,  4.4249e-21,  4.9562e-21,  2.0106e-21,  3.8097e-21,\n",
      "        -6.1221e-21,  1.5349e-19, -6.3584e-21, -5.1888e-22, -5.5941e-21]), 'exp_avg_sq': tensor([3.5820e-04, 2.0339e-04, 2.3383e-04, 8.0988e-04, 2.0295e-04, 5.5326e-04,\n",
      "        2.6774e-04, 3.5917e-04, 5.5392e-04, 3.1727e-04, 7.1225e-04, 2.7719e-04,\n",
      "        3.8905e-04, 2.7107e-04, 2.4982e-04, 3.8595e-04, 3.0861e-04, 2.7247e-04,\n",
      "        7.6514e-05, 2.3361e-04, 3.1264e-04, 1.1570e-02, 3.7172e-04, 1.9635e-04,\n",
      "        4.5590e-04])}, 35: {'step': tensor(3820.), 'exp_avg': tensor([ 1.5321e-27,  1.3040e-27, -3.5124e-27,  4.8298e-27,  2.9616e-27,\n",
      "        -1.9655e-27, -1.1829e-29,  1.7794e-28,  3.3831e-27, -1.1804e-27,\n",
      "         8.2846e-28, -7.1131e-28,  6.2938e-28, -1.1073e-27, -1.9493e-27,\n",
      "        -7.1921e-28,  5.2850e-27,  2.1393e-28, -1.3937e-27,  3.1997e-27,\n",
      "         4.4489e-28, -8.8738e-27,  6.9254e-28,  4.7198e-28,  1.1187e-27]), 'exp_avg_sq': tensor([2.6360e-16, 8.1164e-16, 5.1295e-16, 7.9478e-16, 2.9984e-16, 1.8943e-15,\n",
      "        1.4984e-16, 8.5690e-16, 3.6711e-16, 1.6647e-16, 6.1708e-16, 4.4666e-16,\n",
      "        1.3128e-15, 1.6108e-15, 1.0743e-16, 9.7173e-16, 2.5217e-16, 5.6059e-16,\n",
      "        9.1578e-17, 4.4086e-16, 1.6204e-16, 1.1852e-15, 1.4538e-16, 1.1306e-16,\n",
      "        8.5632e-16])}, 36: {'step': tensor(3820.), 'exp_avg': tensor([ 5.7842e-20,  7.7568e-20, -2.2735e-19,  2.6774e-19,  1.7875e-19,\n",
      "         2.4757e-19, -2.9832e-19,  5.6917e-19, -2.5399e-21, -4.8324e-19,\n",
      "        -5.0230e-20, -3.3695e-19]), 'exp_avg_sq': tensor([5.4757, 0.6396, 0.4732, 1.2785, 1.6288, 2.0987, 1.1928, 3.5645, 0.3848,\n",
      "        4.8769, 6.2143, 0.8601])}, 37: {'step': tensor(3820.), 'exp_avg': tensor([[ 1.2356e-18, -1.1279e-19,  7.8718e-19,  4.5842e-19, -8.2784e-19,\n",
      "         -2.5276e-19, -1.5951e-18,  5.6331e-19],\n",
      "        [ 1.8326e-18, -1.7706e-19,  1.1673e-18,  6.7965e-19, -1.2203e-18,\n",
      "         -3.9454e-19, -2.3466e-18,  8.2863e-19],\n",
      "        [-5.8736e-18,  5.9149e-19, -3.7415e-18, -2.1681e-18,  3.8943e-18,\n",
      "          1.3199e-18,  7.4659e-18, -2.6399e-18],\n",
      "        [ 6.0037e-18, -5.5313e-19,  3.8244e-18,  2.2309e-18, -4.0179e-18,\n",
      "         -1.2359e-18, -7.7432e-18,  2.7333e-18],\n",
      "        [ 4.2816e-18, -4.1573e-19,  2.7271e-18,  1.5873e-18, -2.8494e-18,\n",
      "         -9.2638e-19, -5.4777e-18,  1.9346e-18],\n",
      "        [ 5.7600e-18, -5.4460e-19,  3.6691e-18,  2.1370e-18, -3.8446e-18,\n",
      "         -1.2158e-18, -7.3992e-18,  2.6128e-18],\n",
      "        [-7.0575e-18,  6.8039e-19, -4.4954e-18, -2.6161e-18,  4.7008e-18,\n",
      "          1.5175e-18,  9.0385e-18, -3.1923e-18],\n",
      "        [ 1.4315e-17, -1.4193e-18,  9.1183e-18,  5.2936e-18, -9.5065e-18,\n",
      "         -3.1655e-18, -1.8246e-17,  6.4486e-18],\n",
      "        [-4.3745e-20,  4.0878e-21, -2.7816e-20, -1.6754e-20,  2.9139e-20,\n",
      "          8.7496e-21,  5.6689e-20, -1.9827e-20],\n",
      "        [-1.1092e-17,  1.0410e-18, -7.0658e-18, -4.1156e-18,  7.4095e-18,\n",
      "          2.3257e-18,  1.4264e-17, -5.0369e-18],\n",
      "        [-1.3040e-18,  1.2947e-19, -8.3042e-19, -4.8413e-19,  8.6542e-19,\n",
      "          2.8737e-19,  1.6631e-18, -5.8714e-19],\n",
      "        [-8.0575e-18,  7.7618e-19, -5.1325e-18, -2.9862e-18,  5.3674e-18,\n",
      "          1.7318e-18,  1.0320e-17, -3.6452e-18]]), 'exp_avg_sq': tensor([[ 75.9146,  36.1687,  17.2282,  49.7952,   4.4778, 101.6360,   7.3682,\n",
      "           1.1327],\n",
      "        [  6.2175,   1.7849,   1.9277,   2.7983,   1.3151,   4.5944,   4.2687,\n",
      "           0.4739],\n",
      "        [  5.0167,   2.6144,   1.3200,   3.3106,   0.5198,   7.6067,   1.0195,\n",
      "           0.1843],\n",
      "        [  2.8583,   1.6142,   0.9770,   2.0190,   0.9827,   4.5344,   2.3910,\n",
      "           0.5332],\n",
      "        [ 12.1577,   5.8039,   3.3017,   7.0316,   1.2275,  16.7084,   3.1529,\n",
      "           0.4940],\n",
      "        [ 14.5572,   8.4924,   3.2642,  11.0389,   0.8147,  24.3549,   1.4173,\n",
      "           0.3883],\n",
      "        [ 21.9092,  10.7893,   4.9516,  14.3576,   1.8706,  30.8217,   3.7347,\n",
      "           0.7487],\n",
      "        [ 42.5875,  22.2473,  10.0376,  28.4779,   2.6045,  62.4980,   4.7710,\n",
      "           0.7895],\n",
      "        [  4.4629,   2.6752,   0.9792,   3.5837,   0.2769,   7.4474,   0.5507,\n",
      "           0.1388],\n",
      "        [ 56.8280,  28.4910,  12.9179,  37.4610,   3.1985,  82.9548,   5.1846,\n",
      "           0.9401],\n",
      "        [ 55.6443,  28.7243,  12.7299,  39.1475,   3.0076,  79.2789,   5.5200,\n",
      "           1.0561],\n",
      "        [  6.4208,   3.1486,   1.7274,   3.8145,   0.6862,   8.9008,   1.5715,\n",
      "           0.3087]])}, 38: {'step': tensor(3820.), 'exp_avg': tensor([3.6311e-20, 4.0154e-20, 3.3346e-20, 3.3689e-20, 3.7188e-20, 3.2250e-20,\n",
      "        3.2309e-20, 3.8991e-20, 3.4178e-20, 3.7555e-20, 3.6439e-20, 3.3593e-20,\n",
      "        3.8059e-20, 3.3386e-20, 3.5721e-20, 3.8295e-20, 3.3173e-20, 4.0121e-20,\n",
      "        3.2990e-20, 3.4134e-20, 3.8510e-20, 1.3206e-18, 3.7855e-20, 3.6224e-20,\n",
      "        3.7262e-20]), 'exp_avg_sq': tensor([0.0104, 0.0126, 0.0025, 0.0251, 0.0082, 0.0196, 0.0044, 0.0131, 0.0120,\n",
      "        0.0122, 0.0482, 0.0053, 0.0153, 0.0077, 0.0077, 0.0193, 0.0366, 0.0247,\n",
      "        0.0016, 0.0073, 0.0069, 0.1722, 0.0243, 0.0041, 0.0337])}, 39: {'step': tensor(3820.), 'exp_avg': tensor([-2.4554e-19, -2.7926e-19, -2.3357e-19, -2.4093e-19, -2.4859e-19,\n",
      "        -2.3516e-19, -2.2982e-19, -2.7091e-19, -2.4343e-19, -2.5195e-19,\n",
      "        -2.8096e-19, -2.3734e-19, -2.7503e-19, -2.3693e-19, -2.4167e-19,\n",
      "        -2.7226e-19, -2.3582e-19, -2.8215e-19, -2.2939e-19, -2.3900e-19,\n",
      "        -2.7602e-19, -9.0168e-18, -2.7062e-19, -2.4506e-19, -2.8181e-19]), 'exp_avg_sq': tensor([0.0729, 0.0993, 0.0629, 0.1758, 0.0638, 0.1974, 0.0577, 0.1011, 0.0708,\n",
      "        0.0744, 0.6772, 0.0526, 0.1166, 0.0557, 0.0618, 0.1289, 0.3198, 0.2295,\n",
      "        0.0604, 0.0520, 0.0784, 3.4604, 0.1378, 0.0524, 0.5205])}, 40: {'step': tensor(3820.), 'exp_avg': tensor([ 2.0947e-18,  6.0762e-19,  5.6335e-18, -7.7272e-18, -4.8108e-19,\n",
      "        -3.7479e-18, -4.1113e-18,  6.1541e-18,  5.7271e-18, -5.2993e-18,\n",
      "        -5.4885e-18,  6.6381e-18]), 'exp_avg_sq': tensor([ 5.2909, 10.2386, 16.4066,  6.6334,  4.9351,  4.2289,  4.9789,  8.7162,\n",
      "        16.3212,  5.0875,  2.8111, 12.3258])}, 41: {'step': tensor(3820.), 'exp_avg': tensor([[ 1.8339e-18,  1.1957e-19, -1.5407e-18,  7.2823e-19,  7.9635e-20,\n",
      "         -1.3150e-18, -3.4063e-18, -2.2859e-18,  3.9930e-18,  1.2434e-18,\n",
      "          3.6778e-18, -2.3164e-18],\n",
      "        [ 5.3955e-19, -2.4972e-20, -3.4667e-19,  1.8376e-19,  2.1260e-20,\n",
      "         -3.3717e-19, -8.0636e-19, -5.7427e-19,  9.4578e-19,  3.4246e-19,\n",
      "          8.8470e-19, -5.9225e-19],\n",
      "        [ 4.9353e-18,  2.7350e-19, -4.0604e-18,  1.9340e-18,  2.1353e-19,\n",
      "         -3.4999e-18, -9.0093e-18, -6.0744e-18,  1.0562e-17,  3.3279e-18,\n",
      "          9.7402e-18, -6.1624e-18],\n",
      "        [-6.7656e-18, -4.2221e-19,  5.6508e-18, -2.6768e-18, -2.9324e-19,\n",
      "          4.8364e-18,  1.2506e-17,  8.4032e-18, -1.4660e-17, -4.5799e-18,\n",
      "         -1.3507e-17,  8.5183e-18],\n",
      "        [-4.1852e-19, -3.7619e-20,  3.6947e-19, -1.7035e-19, -1.9328e-20,\n",
      "          3.0919e-19,  8.1026e-19,  5.3941e-19, -9.5020e-19, -2.8813e-19,\n",
      "         -8.7365e-19,  5.4386e-19],\n",
      "        [-3.2881e-18, -1.6023e-19,  2.6670e-18, -1.2786e-18, -1.4055e-19,\n",
      "          2.3132e-18,  5.9321e-18,  4.0104e-18, -6.9540e-18, -2.2083e-18,\n",
      "         -6.4170e-18,  4.0735e-18],\n",
      "        [-3.5929e-18, -2.5760e-19,  3.0589e-18, -1.4371e-18, -1.5795e-19,\n",
      "          2.5960e-18,  6.7480e-18,  4.5175e-18, -7.9109e-18, -2.4455e-18,\n",
      "         -7.2824e-18,  4.5723e-18],\n",
      "        [ 5.3886e-18,  3.5785e-19, -4.5402e-18,  2.1452e-18,  2.3267e-19,\n",
      "         -3.8690e-18, -1.0033e-17, -6.7267e-18,  1.1759e-17,  3.6554e-18,\n",
      "          1.0828e-17, -6.8171e-18],\n",
      "        [ 5.0037e-18,  3.5780e-19, -4.2583e-18,  2.0006e-18,  2.2016e-19,\n",
      "         -3.6149e-18, -9.3946e-18, -6.2902e-18,  1.1014e-17,  3.4055e-18,\n",
      "          1.0139e-17, -6.3664e-18],\n",
      "        [-4.6408e-18, -2.7153e-19,  3.8439e-18, -1.8273e-18, -2.0030e-19,\n",
      "          3.3022e-18,  8.5192e-18,  5.7341e-18, -9.9867e-18, -3.1344e-18,\n",
      "         -9.2054e-18,  5.8160e-18],\n",
      "        [-4.8036e-18, -3.0976e-19,  4.0294e-18, -1.9053e-18, -2.0883e-19,\n",
      "          3.4420e-18,  8.9110e-18,  5.9826e-18, -1.0446e-17, -3.2557e-18,\n",
      "         -9.6227e-18,  6.0624e-18],\n",
      "        [ 5.8086e-18,  3.7519e-19, -4.8733e-18,  2.3036e-18,  2.5295e-19,\n",
      "         -4.1630e-18, -1.0777e-17, -7.2358e-18,  1.2634e-17,  3.9373e-18,\n",
      "          1.1638e-17, -7.3318e-18]]), 'exp_avg_sq': tensor([[18.5922, 10.0833,  1.7657,  4.4588,  0.7634,  0.4957,  2.2587,  2.3661,\n",
      "          7.3079,  0.4463, 10.5099,  1.7832],\n",
      "        [25.9211, 15.6743,  2.8646,  7.3675,  1.4340,  0.9202,  3.3328,  4.7099,\n",
      "         12.6530,  0.3656, 18.5751,  1.7297],\n",
      "        [24.8471, 14.2960,  2.7249,  8.6641,  2.0588,  1.1750,  5.6040,  5.9739,\n",
      "         12.9967,  0.8818, 18.2514,  2.6387],\n",
      "        [11.0662,  6.6715,  1.5397,  3.5819,  0.8484,  0.5925,  3.2481,  2.9643,\n",
      "          7.2611,  0.4253,  9.4140,  1.2089],\n",
      "        [10.4575,  6.5533,  1.2022,  3.7768,  0.8082,  0.5192,  1.4654,  2.7109,\n",
      "          5.6070,  0.1898,  8.6975,  0.7682],\n",
      "        [11.5737,  5.8471,  1.3819,  2.5497,  0.5721,  0.5511,  3.4382,  2.6741,\n",
      "          6.4402,  0.6238,  8.0962,  1.8135],\n",
      "        [10.2935,  5.7847,  1.2079,  4.2637,  1.0800,  0.4416,  2.7938,  2.3131,\n",
      "          5.2780,  0.2477,  7.2529,  1.2830],\n",
      "        [11.5653,  7.6007,  1.9569,  4.6915,  1.2040,  0.9219,  3.8330,  4.4243,\n",
      "          8.9473,  0.5405, 12.2385,  1.0444],\n",
      "        [26.8339, 17.3033,  3.4695,  8.2724,  1.7053,  1.3087,  4.8297,  6.6683,\n",
      "         16.3658,  0.5904, 23.3868,  1.6920],\n",
      "        [12.1407,  6.7708,  1.5549,  2.6071,  0.5520,  0.3701,  3.1231,  1.6891,\n",
      "          6.3264,  0.4088,  7.8613,  1.2198],\n",
      "        [ 5.8248,  3.7402,  0.9803,  1.7707,  0.4915,  0.3814,  2.0531,  1.9338,\n",
      "          4.3614,  0.2776,  5.8886,  0.5168],\n",
      "        [15.2505, 10.1763,  2.7105,  5.6249,  1.4038,  1.2087,  5.7511,  6.0283,\n",
      "         13.2551,  0.7212, 17.2311,  1.6211]])}, 42: {'step': tensor(3820.), 'exp_avg': tensor([6.6655e-20, 7.5216e-20, 6.7180e-20, 6.8911e-20, 6.5509e-20, 6.8575e-20,\n",
      "        6.6791e-20, 6.8323e-20, 6.9877e-20, 6.5311e-20, 6.6034e-20, 6.8319e-20,\n",
      "        6.5555e-20, 6.8577e-20, 6.5678e-20, 6.5781e-20, 6.5345e-20, 7.7368e-20,\n",
      "        6.6449e-20, 6.8209e-20, 6.6107e-20, 9.1328e-19, 6.5493e-20, 6.6476e-20,\n",
      "        6.8893e-20]), 'exp_avg_sq': tensor([0.0102, 0.0069, 0.0028, 0.0376, 0.0086, 0.0347, 0.0040, 0.0127, 0.0171,\n",
      "        0.0121, 0.0396, 0.0031, 0.0142, 0.0065, 0.0084, 0.0165, 0.0189, 0.0143,\n",
      "        0.0019, 0.0045, 0.0086, 0.2422, 0.0191, 0.0021, 0.0284])}, 43: {'step': tensor(3820.), 'exp_avg': tensor([-4.5022e-19, -4.8581e-19, -4.3866e-19, -4.4633e-19, -4.5564e-19,\n",
      "        -4.4065e-19, -4.3367e-19, -4.7759e-19, -4.4925e-19, -4.5817e-19,\n",
      "        -4.8682e-19, -4.4197e-19, -4.8308e-19, -4.4121e-19, -4.4787e-19,\n",
      "        -4.7981e-19, -4.4325e-19, -4.9034e-19, -4.3645e-19, -4.4301e-19,\n",
      "        -4.8423e-19, -6.7101e-18, -4.7801e-19, -4.5569e-19, -4.8839e-19]), 'exp_avg_sq': tensor([0.0561, 0.0428, 0.0491, 0.0547, 0.0584, 0.0519, 0.0402, 0.0595, 0.0349,\n",
      "        0.0615, 0.2182, 0.0411, 0.0833, 0.0341, 0.0600, 0.0855, 0.1178, 0.0451,\n",
      "        0.0477, 0.0392, 0.0618, 0.8224, 0.0887, 0.0504, 0.1207])}, 44: {'step': tensor(3820.), 'exp_avg': tensor([ 5.8588e-18,  1.0498e-17, -4.7945e-18, -3.5902e-18,  1.5280e-18,\n",
      "        -1.2785e-18,  2.5104e-18, -1.9258e-18, -2.1266e-18, -3.1541e-18,\n",
      "         7.9177e-20,  8.4072e-19, -4.4812e-18,  1.2187e-18,  9.7081e-19,\n",
      "        -2.1541e-18]), 'exp_avg_sq': tensor([ 2.7806, 11.5159,  2.8751,  0.5943,  1.1385,  0.3095,  0.9943,  3.2004,\n",
      "         2.1813,  0.9166,  1.9072,  1.8646,  2.3961,  2.4932,  0.7468,  2.8517])}, 45: {'step': tensor(3820.), 'exp_avg': tensor([[-1.7342e-19,  5.3339e-18, -6.3934e-18,  9.3895e-18,  1.0444e-17,\n",
      "         -1.0047e-18, -2.7565e-18,  1.1796e-18,  7.4003e-18, -1.2395e-17,\n",
      "         -2.2723e-18, -4.8168e-18],\n",
      "        [-3.1606e-19,  9.5385e-18, -1.1419e-17,  1.6757e-17,  1.8648e-17,\n",
      "         -1.7562e-18, -4.9161e-18,  2.0966e-18,  1.3181e-17, -2.2135e-17,\n",
      "         -4.0270e-18, -8.5995e-18],\n",
      "        [ 1.5486e-19, -4.3121e-18,  5.1345e-18, -7.5086e-18, -8.3746e-18,\n",
      "          7.1551e-19,  2.1956e-18, -9.2421e-19, -5.8582e-18,  9.9495e-18,\n",
      "          1.7526e-18,  3.8597e-18],\n",
      "        [ 1.0240e-19, -3.2854e-18,  3.9481e-18, -5.8078e-18, -6.4531e-18,\n",
      "          6.4739e-19,  1.7078e-18, -7.3499e-19, -4.5944e-18,  7.6552e-18,\n",
      "          1.4240e-18,  2.9771e-18],\n",
      "        [-5.4332e-20,  1.3540e-18, -1.5990e-18,  2.3257e-18,  2.6029e-18,\n",
      "         -1.8700e-19, -6.7664e-19,  2.7874e-19,  1.7910e-18, -3.0965e-18,\n",
      "         -5.1742e-19, -1.1986e-18],\n",
      "        [ 4.0863e-20, -1.1519e-18,  1.3728e-18, -2.0089e-18, -2.2398e-18,\n",
      "          1.9490e-19,  5.8769e-19, -2.4814e-19, -1.5700e-18,  2.6609e-18,\n",
      "          4.7179e-19,  1.0323e-18],\n",
      "        [-7.5835e-20,  2.2810e-18, -2.7305e-18,  4.0068e-18,  4.4595e-18,\n",
      "         -4.1959e-19, -1.1753e-18,  5.0158e-19,  3.1524e-18, -5.2942e-18,\n",
      "         -9.6363e-19, -2.0563e-18],\n",
      "        [ 5.8751e-20, -1.7492e-18,  2.0932e-18, -3.0709e-18, -3.4190e-18,\n",
      "          3.1988e-19,  9.0024e-19, -3.8460e-19, -2.4164e-18,  4.0604e-18,\n",
      "          7.3888e-19,  1.5761e-18],\n",
      "        [ 6.1654e-20, -1.9447e-18,  2.3350e-18, -3.4331e-18, -3.8163e-18,\n",
      "          3.7787e-19,  1.0088e-18, -4.3375e-19, -2.7136e-18,  4.5286e-18,\n",
      "          8.3928e-19,  1.7602e-18],\n",
      "        [ 9.1019e-20, -2.8835e-18,  3.4632e-18, -5.0927e-18, -5.6605e-18,\n",
      "          5.6283e-19,  1.4966e-18, -6.4404e-19, -4.0270e-18,  6.7168e-18,\n",
      "          1.2468e-18,  2.6109e-18],\n",
      "        [-3.4137e-21,  6.6177e-20, -7.6312e-20,  1.0927e-19,  1.2350e-19,\n",
      "         -3.9851e-21, -3.1288e-20,  1.2097e-20,  8.0899e-20, -1.4740e-19,\n",
      "         -2.0780e-20, -5.6731e-20],\n",
      "        [-2.1243e-20,  7.8433e-19, -9.5060e-19,  1.4060e-18,  1.5575e-18,\n",
      "         -1.7763e-19, -4.1523e-19,  1.8287e-19,  1.1277e-18, -1.8462e-18,\n",
      "         -3.6139e-19, -7.1888e-19],\n",
      "        [ 1.3363e-19, -4.0811e-18,  4.8902e-18, -7.1803e-18, -7.9883e-18,\n",
      "          7.6418e-19,  2.1074e-18, -9.0136e-19, -5.6572e-18,  9.4820e-18,\n",
      "          1.7356e-18,  3.6839e-18],\n",
      "        [-3.5680e-20,  1.1141e-18, -1.3368e-18,  1.9646e-18,  2.1844e-18,\n",
      "         -2.1383e-19, -5.7712e-19,  2.4755e-19,  1.5509e-18, -2.5922e-18,\n",
      "         -4.7820e-19, -1.0075e-18],\n",
      "        [-3.1175e-20,  8.7738e-19, -1.0464e-18,  1.5319e-18,  1.7085e-18,\n",
      "         -1.5080e-19, -4.4796e-19,  1.9038e-19,  1.2007e-18, -2.0310e-18,\n",
      "         -3.6338e-19, -7.8706e-19],\n",
      "        [ 6.7980e-20, -1.9414e-18,  2.3150e-18, -3.3885e-18, -3.7762e-18,\n",
      "          3.3122e-19,  9.9203e-19, -4.1825e-19, -2.6475e-18,  4.4840e-18,\n",
      "          7.9519e-19,  1.7410e-18]]), 'exp_avg_sq': tensor([[ 0.3851,  1.6253,  0.9082,  1.9624,  2.6447,  5.9534,  0.4269,  0.1514,\n",
      "          2.0974, 14.3570,  1.7271,  0.3952],\n",
      "        [ 1.1637,  2.0319,  3.1916,  6.7969,  4.5962, 13.6317,  1.3824,  0.3705,\n",
      "          3.8050, 21.0952,  3.5955,  1.1572],\n",
      "        [ 0.4521,  3.4998,  1.2690,  2.5857,  4.4969,  9.3225,  0.3332,  0.1550,\n",
      "          2.1717, 23.7084,  1.5478,  0.6735],\n",
      "        [ 0.0759,  0.2323,  0.3935,  0.8021,  0.7660,  0.9500,  0.1418,  0.0264,\n",
      "          0.6309,  2.1955,  0.3362,  0.1855],\n",
      "        [ 0.1652,  1.2757,  0.7407,  1.1874,  2.2323,  2.5805,  0.2860,  0.0642,\n",
      "          0.9050,  8.7171,  0.7033,  0.3416],\n",
      "        [ 0.0733,  0.5111,  0.5097,  0.8105,  1.1287,  1.0682,  0.1872,  0.0263,\n",
      "          0.4588,  3.4204,  0.2694,  0.1972],\n",
      "        [ 0.1243,  0.4103,  0.5753,  1.0269,  0.8392,  1.7325,  0.1887,  0.0376,\n",
      "          0.6136,  2.9201,  0.3701,  0.1842],\n",
      "        [ 0.4604,  1.5324,  0.8295,  1.6869,  1.4695,  6.8949,  0.3879,  0.1243,\n",
      "          1.0917, 11.3416,  1.2516,  0.1907],\n",
      "        [ 0.2780,  0.6140,  0.4408,  1.1302,  0.8723,  3.5692,  0.2584,  0.0856,\n",
      "          0.7527,  6.2095,  0.8147,  0.1524],\n",
      "        [ 0.1241,  0.4144,  0.9081,  1.5335,  1.3395,  1.2042,  0.4618,  0.0702,\n",
      "          0.9869,  3.1761,  0.9380,  0.3478],\n",
      "        [ 0.2319,  1.2815,  0.4357,  1.0506,  1.6125,  4.3116,  0.1693,  0.0882,\n",
      "          1.0844, 10.1379,  0.8835,  0.2069],\n",
      "        [ 0.1702,  0.7037,  1.0690,  2.0023,  2.2815,  1.7759,  0.4879,  0.1130,\n",
      "          1.9000,  6.1840,  1.4312,  0.5500],\n",
      "        [ 0.2219,  0.7229,  0.8033,  1.6884,  1.8162,  2.8497,  0.3342,  0.0963,\n",
      "          1.8422,  6.5620,  1.4151,  0.4050],\n",
      "        [ 0.1665,  0.2951,  0.4150,  0.9573,  0.8280,  1.7976,  0.2864,  0.0864,\n",
      "          1.0620,  3.5599,  1.1859,  0.1986],\n",
      "        [ 0.0628,  0.2149,  0.2065,  0.3903,  0.5839,  0.6636,  0.1366,  0.0407,\n",
      "          0.4644,  2.3437,  0.5110,  0.1025],\n",
      "        [ 0.3185,  1.0277,  1.4937,  2.6236,  2.4128,  3.7779,  0.5440,  0.0968,\n",
      "          1.3090,  7.1881,  1.0386,  0.5561]])}, 46: {'step': tensor(3820.), 'exp_avg': tensor([ 1.0129e-20,  1.7188e-20,  1.8922e-20,  2.5589e-20,  8.3080e-21,\n",
      "         2.7493e-20,  2.2452e-20, -2.3822e-21,  2.3624e-20,  5.6244e-21,\n",
      "        -7.5496e-21,  2.1220e-20, -9.4869e-21,  2.2003e-20,  1.2965e-20,\n",
      "        -6.3346e-21,  2.4152e-20,  2.0118e-20,  1.7337e-20,  2.0864e-20,\n",
      "        -5.7914e-21,  9.4630e-22, -5.7644e-21,  1.0944e-20, -4.5383e-21]), 'exp_avg_sq': tensor([0.0695, 0.0599, 0.0369, 0.1451, 0.0493, 0.1350, 0.0629, 0.0895, 0.1338,\n",
      "        0.0698, 0.1169, 0.0422, 0.0926, 0.0885, 0.0445, 0.0977, 0.0516, 0.0741,\n",
      "        0.0216, 0.0653, 0.0681, 0.1606, 0.1038, 0.0123, 0.1117])}, 47: {'step': tensor(3820.), 'exp_avg': tensor([2.4281e-19, 2.4317e-19, 2.4148e-19, 2.4311e-19, 2.4392e-19, 2.4321e-19,\n",
      "        2.4222e-19, 2.4402e-19, 2.4358e-19, 2.4407e-19, 2.4389e-19, 2.4209e-19,\n",
      "        2.4508e-19, 2.4265e-19, 2.4354e-19, 2.4441e-19, 2.4303e-19, 2.4250e-19,\n",
      "        2.4207e-19, 2.4216e-19, 2.4591e-19, 2.4513e-19, 2.4428e-19, 2.4301e-19,\n",
      "        2.4427e-19]), 'exp_avg_sq': tensor([0.0387, 0.0412, 0.0412, 0.0402, 0.0386, 0.0407, 0.0413, 0.0389, 0.0403,\n",
      "        0.0387, 0.0390, 0.0413, 0.0390, 0.0409, 0.0384, 0.0390, 0.0414, 0.0409,\n",
      "        0.0417, 0.0410, 0.0388, 0.0405, 0.0390, 0.0417, 0.0390])}, 48: {'step': tensor(3820.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 49: {'step': tensor(3820.), 'exp_avg': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'exp_avg_sq': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])}, 50: {'step': tensor(3820.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 51: {'step': tensor(3820.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 52: {'step': tensor(3820.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 53: {'step': tensor(3820.), 'exp_avg': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'exp_avg_sq': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])}, 54: {'step': tensor(3820.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 55: {'step': tensor(3820.), 'exp_avg': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'exp_avg_sq': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 56: {'step': tensor(3820.), 'exp_avg': tensor([0.]), 'exp_avg_sq': tensor([0.])}, 57: {'step': tensor(3820.), 'exp_avg': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'exp_avg_sq': tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])}, 60: {'step': tensor(3820.), 'exp_avg': tensor([-4.6967e-19, -5.6916e-19,  8.7930e-19, -2.1484e-18, -1.2002e-18,\n",
      "         1.8952e-18,  2.5913e-19,  8.6476e-19, -1.0416e-18,  2.9981e-19,\n",
      "         3.2476e-19,  1.0379e-18, -9.8083e-19,  2.5295e-19, -1.2905e-18,\n",
      "         1.8867e-18]), 'exp_avg_sq': tensor([0.2913, 0.2292, 0.5585, 0.0991, 0.2838, 0.3105, 0.2136, 0.1478, 0.2976,\n",
      "        0.4039, 0.0848, 0.2375, 0.0355, 0.3108, 0.1286, 1.0617])}, 61: {'step': tensor(3820.), 'exp_avg': tensor([[-3.5049e-18,  9.3770e-19,  1.0704e-19,  2.3595e-19,  1.0439e-18,\n",
      "          5.8218e-19, -3.6915e-19,  1.2462e-18, -1.3151e-18,  1.5994e-18,\n",
      "         -1.7195e-18,  1.6523e-18, -2.6913e-18,  2.8064e-18, -3.9022e-19,\n",
      "         -5.1068e-19],\n",
      "        [-4.2769e-18,  1.1309e-18,  1.2862e-19,  2.9288e-19,  1.2652e-18,\n",
      "          7.1265e-19, -4.5037e-19,  1.5174e-18, -1.5969e-18,  1.9483e-18,\n",
      "         -2.0896e-18,  2.0135e-18, -3.2766e-18,  3.4185e-18, -4.6557e-19,\n",
      "         -6.2296e-19],\n",
      "        [ 6.9130e-18, -1.7343e-18, -1.9255e-19, -5.0921e-19, -1.9839e-18,\n",
      "         -1.1690e-18,  7.2686e-19, -2.4293e-18,  2.5250e-18, -3.1238e-18,\n",
      "          3.3167e-18, -3.2364e-18,  5.2423e-18, -5.4825e-18,  6.7719e-19,\n",
      "          1.0058e-18],\n",
      "        [-1.6577e-17,  4.2422e-18,  4.7696e-19,  1.1882e-18,  4.8128e-18,\n",
      "          2.7865e-18, -1.7445e-18,  5.8461e-18, -6.1048e-18,  7.5147e-18,\n",
      "         -8.0073e-18,  7.7761e-18, -1.2620e-17,  1.3186e-17, -1.6917e-18,\n",
      "         -2.4124e-18],\n",
      "        [-9.3494e-18,  2.3677e-18,  2.6471e-19,  6.7982e-19,  2.6980e-18,\n",
      "          1.5763e-18, -9.8355e-19,  3.2910e-18, -3.4282e-18,  4.2314e-18,\n",
      "         -4.4999e-18,  4.3809e-18, -7.1030e-18,  7.4255e-18, -9.3398e-19,\n",
      "         -1.3603e-18],\n",
      "        [ 1.4972e-17, -3.7431e-18, -4.1715e-19, -1.1064e-18, -4.2896e-18,\n",
      "         -2.5319e-18,  1.5749e-18, -5.2578e-18,  5.4606e-18, -6.7639e-18,\n",
      "          7.1744e-18, -7.0053e-18,  1.1347e-17, -1.1869e-17,  1.4573e-18,\n",
      "          2.1775e-18],\n",
      "        [ 2.1252e-18, -5.0564e-19, -5.4927e-20, -1.6691e-19, -5.9208e-19,\n",
      "         -3.6415e-19,  2.2322e-19, -7.3994e-19,  7.5975e-19, -9.5313e-19,\n",
      "          1.0017e-18, -9.8942e-19,  1.5959e-18, -1.6729e-18,  1.8617e-19,\n",
      "          3.0879e-19],\n",
      "        [ 6.6752e-18, -1.7078e-18, -1.9048e-19, -4.7959e-19, -1.9367e-18,\n",
      "         -1.1235e-18,  7.0194e-19, -2.3541e-18,  2.4580e-18, -3.0245e-18,\n",
      "          3.2241e-18, -3.1320e-18,  5.0805e-18, -5.3085e-18,  6.8005e-19,\n",
      "          9.7179e-19],\n",
      "        [-8.2689e-18,  2.0527e-18,  2.2785e-19,  6.1674e-19,  2.3595e-18,\n",
      "          1.4012e-18, -8.6959e-19,  2.9003e-18, -3.0072e-18,  3.7317e-18,\n",
      "         -3.9530e-18,  3.8663e-18, -6.2586e-18,  6.5486e-18, -7.9304e-19,\n",
      "         -1.2025e-18],\n",
      "        [ 2.1568e-18, -5.8814e-19, -6.7605e-20, -1.4100e-19, -6.4955e-19,\n",
      "         -3.5630e-19,  2.2724e-19, -7.6964e-19,  8.1594e-19, -9.8709e-19,\n",
      "          1.0653e-18, -1.0190e-18,  1.6625e-18, -1.7320e-18,  2.4902e-19,\n",
      "          3.1440e-19],\n",
      "        [ 2.4637e-18, -6.4682e-19, -7.4265e-20, -1.6990e-19, -7.2638e-19,\n",
      "         -4.1049e-19,  2.5971e-19, -8.7283e-19,  9.1705e-19, -1.1219e-18,\n",
      "          1.2006e-18, -1.1585e-18,  1.8853e-18, -1.9677e-18,  2.6496e-19,\n",
      "          3.5856e-19],\n",
      "        [ 8.0560e-18, -2.0546e-18, -2.2984e-19, -5.8064e-19, -2.3338e-18,\n",
      "         -1.3562e-18,  8.4743e-19, -2.8393e-18,  2.9625e-18, -3.6493e-18,\n",
      "          3.8868e-18, -3.7780e-18,  6.1283e-18, -6.4044e-18,  8.1605e-19,\n",
      "          1.1725e-18],\n",
      "        [-7.7927e-18,  1.9338e-18,  2.1431e-19,  5.8168e-19,  2.2230e-18,\n",
      "          1.3209e-18, -8.1939e-19,  2.7331e-18, -2.8336e-18,  3.5163e-18,\n",
      "         -3.7250e-18,  3.6437e-18, -5.8976e-18,  6.1710e-18, -7.4669e-19,\n",
      "         -1.1333e-18],\n",
      "        [ 2.0773e-18, -4.9272e-19, -5.4673e-20, -1.6295e-19, -5.7852e-19,\n",
      "         -3.5507e-19,  2.1862e-19, -7.2278e-19,  7.4169e-19, -9.3237e-19,\n",
      "          9.7811e-19, -9.6614e-19,  1.5597e-18, -1.6354e-18,  1.8142e-19,\n",
      "          3.0152e-19],\n",
      "        [-1.0124e-17,  2.5524e-18,  2.8450e-19,  7.4061e-19,  2.9138e-18,\n",
      "          1.7092e-18, -1.0648e-18,  3.5607e-18, -3.7052e-18,  4.5784e-18,\n",
      "         -4.8652e-18,  4.7416e-18, -7.6844e-18,  8.0349e-18, -1.0020e-18,\n",
      "         -1.4729e-18],\n",
      "        [ 1.4455e-17, -3.7443e-18, -4.2250e-19, -1.0194e-18, -4.2257e-18,\n",
      "         -2.4223e-18,  1.5215e-18, -5.1090e-18,  5.3503e-18, -6.5642e-18,\n",
      "          7.0116e-18, -6.7898e-18,  1.1030e-17, -1.1518e-17,  1.5111e-18,\n",
      "          2.1044e-18]]), 'exp_avg_sq': tensor([[ 5.3859,  1.0565,  1.4540,  0.2057,  0.4260,  1.0788,  0.3446,  0.8197,\n",
      "          0.6261,  2.4948,  1.2133,  1.0861,  3.2582,  3.8035,  0.5357,  0.3548],\n",
      "        [ 4.0560,  0.8505,  1.4890,  0.2627,  1.0722,  0.7776,  0.1915,  0.6532,\n",
      "          0.6408,  2.3072,  1.5886,  0.6529,  3.1599,  3.6720,  1.0212,  0.2261],\n",
      "        [ 5.5879,  2.0829,  6.9508,  0.7611,  1.4826,  4.3126,  1.0786,  0.6570,\n",
      "          0.4875,  9.5030,  1.2238,  1.5386,  5.9180,  5.7371,  0.9856,  0.9779],\n",
      "        [ 1.9849,  0.2882,  0.5738,  0.0926,  0.1416,  0.4713,  0.1094,  0.3310,\n",
      "          0.2463,  0.9442,  0.3099,  0.4747,  1.2575,  1.3620,  0.1120,  0.1301],\n",
      "        [ 3.0548,  1.0250,  3.2623,  0.4941,  1.1981,  2.0581,  0.4233,  0.3798,\n",
      "          0.3900,  3.9450,  1.1505,  0.8402,  2.8272,  3.0902,  1.0360,  0.5677],\n",
      "        [ 9.5528,  1.4869,  3.8984,  0.4156,  1.0974,  1.9852,  0.6830,  1.1366,\n",
      "          0.7761,  6.3662,  1.7517,  1.3844,  6.6999,  7.5815,  0.8868,  0.6092],\n",
      "        [ 2.1831,  0.8809,  1.0463,  0.1823,  0.4444,  0.8547,  0.2947,  0.2293,\n",
      "          0.2766,  1.6210,  0.5661,  0.5414,  1.3146,  1.7462,  0.4759,  0.1855],\n",
      "        [ 4.1082,  0.3027,  2.1290,  0.2283,  0.5948,  1.0782,  0.2798,  0.6241,\n",
      "          0.3598,  3.1742,  0.7803,  0.6637,  3.3600,  3.4666,  0.3023,  0.3511],\n",
      "        [ 4.5286,  0.8211,  2.3617,  0.3558,  0.6574,  1.5183,  0.3820,  0.4624,\n",
      "          0.2951,  3.4071,  0.6629,  0.9318,  2.9296,  3.4099,  0.5361,  0.4346],\n",
      "        [ 3.9982,  1.2236,  3.9685,  0.5414,  0.7701,  2.9820,  0.5334,  0.5619,\n",
      "          0.4629,  5.1044,  0.6277,  1.4816,  3.3150,  3.3720,  0.3273,  0.6435],\n",
      "        [ 1.2018,  0.5068,  0.3536,  0.0804,  0.1052,  0.4228,  0.1622,  0.1830,\n",
      "          0.1836,  0.5704,  0.3577,  0.3909,  0.5998,  0.7304,  0.2719,  0.1140],\n",
      "        [ 3.1501,  0.8376,  1.1821,  0.2162,  0.2985,  1.1895,  0.2408,  0.4970,\n",
      "          0.4930,  1.6381,  0.7438,  0.9759,  1.7990,  2.1815,  0.3042,  0.2834],\n",
      "        [ 2.6082,  0.2999,  0.9183,  0.0829,  0.3200,  0.4360,  0.1468,  0.4159,\n",
      "          0.3165,  1.5832,  0.6619,  0.3568,  1.9909,  2.1133,  0.2032,  0.1234],\n",
      "        [ 3.3307,  1.4046,  1.2172,  0.2383,  0.2910,  1.4988,  0.3447,  0.4710,\n",
      "          0.5598,  1.8356,  0.7979,  1.1577,  1.6372,  2.1329,  0.4056,  0.2565],\n",
      "        [ 1.1258,  0.3736,  0.8402,  0.1161,  0.2342,  0.6004,  0.1862,  0.1193,\n",
      "          0.0952,  1.2894,  0.1953,  0.2729,  0.8781,  0.9662,  0.1741,  0.1252],\n",
      "        [10.5963,  4.1555,  3.7012,  0.6186,  0.9018,  3.9698,  1.1350,  1.6249,\n",
      "          1.6363,  5.9455,  2.7331,  3.0939,  5.7367,  7.1213,  1.4370,  0.8510]])}, 62: {'step': tensor(3820.), 'exp_avg': tensor([1.1557e-19, 1.1722e-19, 1.2903e-19, 1.2211e-19, 5.4210e-19, 1.2785e-19,\n",
      "        1.1231e-19, 1.0931e-19, 1.3703e-19, 1.1015e-19]), 'exp_avg_sq': tensor([0.0127, 0.0054, 0.0039, 0.0103, 0.0406, 0.0377, 0.0365, 0.0233, 0.0483,\n",
      "        0.0157])}, 63: {'step': tensor(3820.), 'exp_avg': tensor([6.6970e-19, 6.7344e-19, 6.8921e-19, 6.7751e-19, 2.7578e-18, 6.9368e-19,\n",
      "        6.6391e-19, 6.6268e-19, 7.2218e-19, 6.6353e-19]), 'exp_avg_sq': tensor([0.1384, 0.1405, 0.1347, 0.1360, 0.3038, 0.2425, 0.1980, 0.1610, 0.1934,\n",
      "        0.1672])}, 64: {'step': tensor(3820.), 'exp_avg': tensor([ 1.1075e-17,  9.3262e-19,  5.5277e-18,  4.5614e-18,  4.5624e-19,\n",
      "        -1.4034e-18, -5.9059e-18, -2.6126e-18,  2.8654e-18, -2.3129e-18,\n",
      "        -1.3318e-17,  3.2352e-18,  6.2574e-18,  1.6104e-18, -6.9620e-18,\n",
      "        -4.0075e-18]), 'exp_avg_sq': tensor([0.8837, 2.2931, 0.7829, 1.3823, 0.8006, 0.4437, 0.4091, 0.6333, 1.0186,\n",
      "        0.5386, 0.7940, 0.7088, 0.8889, 0.8925, 0.5643, 0.3855])}, 65: {'step': tensor(3820.), 'exp_avg': tensor([[ 6.6587e-18,  1.0726e-17,  7.1246e-18, -2.0472e-17, -1.0049e-17,\n",
      "         -1.4709e-17,  1.0041e-17,  6.4860e-18, -1.1147e-17,  1.8031e-17,\n",
      "         -9.8048e-18, -4.6762e-18,  7.2860e-18,  9.2357e-18,  1.2655e-17,\n",
      "         -1.1017e-17],\n",
      "        [ 6.1545e-19,  9.0963e-19,  6.8753e-19, -1.8334e-18, -9.7574e-19,\n",
      "         -1.3114e-18,  8.9026e-19,  6.3074e-19, -1.0226e-18,  1.6153e-18,\n",
      "         -9.2819e-19, -4.0077e-19,  7.0379e-19,  8.3185e-19,  1.0871e-18,\n",
      "         -9.6340e-19],\n",
      "        [ 3.3423e-18,  5.3552e-18,  3.5858e-18, -1.0255e-17, -5.0594e-18,\n",
      "         -7.3661e-18,  5.0266e-18,  3.2663e-18, -5.5920e-18,  9.0322e-18,\n",
      "         -4.9286e-18, -2.3366e-18,  3.6674e-18,  4.6281e-18,  6.3234e-18,\n",
      "         -5.5112e-18],\n",
      "        [ 2.7156e-18,  4.4151e-18,  2.8925e-18, -8.3796e-18, -4.0771e-18,\n",
      "         -6.0232e-18,  4.1145e-18,  2.6302e-18, -4.5512e-18,  7.3804e-18,\n",
      "         -3.9890e-18, -1.9216e-18,  2.9573e-18,  3.7778e-18,  5.2014e-18,\n",
      "         -4.5194e-18],\n",
      "        [ 2.3678e-19,  4.3746e-19,  2.3353e-19, -7.6825e-19, -3.2527e-19,\n",
      "         -5.5600e-19,  3.8301e-19,  2.0922e-19, -4.0170e-19,  6.7640e-19,\n",
      "         -3.3364e-19, -1.8773e-19,  2.3832e-19,  3.4337e-19,  5.0652e-19,\n",
      "         -4.2928e-19],\n",
      "        [-8.6771e-19, -1.3618e-18, -9.4102e-19,  2.6419e-18,  1.3298e-18,\n",
      "          1.8957e-18, -1.2918e-18, -8.5891e-19,  1.4492e-18, -2.3271e-18,\n",
      "          1.2873e-18,  5.9578e-19, -9.6268e-19, -1.1939e-18, -1.6130e-18,\n",
      "          1.4118e-18],\n",
      "        [-3.5501e-18, -5.7199e-18, -3.7989e-18,  1.0917e-17,  5.3583e-18,\n",
      "          7.8434e-18, -5.3544e-18, -3.4580e-18,  5.9441e-18, -9.6150e-18,\n",
      "          5.2280e-18,  2.4929e-18, -3.8847e-18, -4.9246e-18, -6.7479e-18,\n",
      "          5.8742e-18],\n",
      "        [-1.5009e-18, -2.5230e-18, -1.5702e-18,  4.6919e-18,  2.2075e-18,\n",
      "          3.3781e-18, -2.3127e-18, -1.4226e-18,  2.5241e-18, -4.1319e-18,\n",
      "          2.1834e-18,  1.0932e-18, -1.6045e-18, -2.1103e-18, -2.9579e-18,\n",
      "          2.5528e-18],\n",
      "        [ 1.7202e-18,  2.7748e-18,  1.8394e-18, -5.2919e-18, -2.5942e-18,\n",
      "         -3.8025e-18,  2.5959e-18,  1.6743e-18, -2.8804e-18,  4.6608e-18,\n",
      "         -2.5323e-18, -1.2095e-18,  1.8810e-18,  2.3870e-18,  3.2731e-18,\n",
      "         -2.8488e-18],\n",
      "        [-1.4561e-18, -2.2474e-18, -1.5925e-18,  4.4061e-18,  2.2533e-18,\n",
      "          3.1588e-18, -2.1503e-18, -1.4558e-18,  2.4282e-18, -3.8812e-18,\n",
      "          2.1702e-18,  9.8522e-19, -1.6295e-18, -1.9935e-18, -2.6685e-18,\n",
      "          2.3438e-18],\n",
      "        [-8.0140e-18, -1.2898e-17, -8.5782e-18,  2.4630e-17,  1.2099e-17,\n",
      "          1.7696e-17, -1.2079e-17, -7.8101e-18,  1.3414e-17, -2.1693e-17,\n",
      "          1.1803e-17,  5.6242e-18, -8.7727e-18, -1.1112e-17, -1.5219e-17,\n",
      "          1.3253e-17],\n",
      "        [ 1.9122e-18,  3.1291e-18,  2.0284e-18, -5.9137e-18, -2.8573e-18,\n",
      "         -4.2526e-18,  2.9060e-18,  1.8437e-18, -3.2055e-18,  5.2085e-18,\n",
      "         -2.8023e-18, -1.3618e-18,  2.0740e-18,  2.6652e-18,  3.6835e-18,\n",
      "         -3.1967e-18],\n",
      "        [ 3.7573e-18,  6.0599e-18,  4.0185e-18, -1.1558e-17, -5.6677e-18,\n",
      "         -8.3050e-18,  5.6698e-18,  3.6576e-18, -6.2918e-18,  1.0180e-17,\n",
      "         -5.5317e-18, -2.6409e-18,  4.1092e-18,  5.2137e-18,  7.1480e-18,\n",
      "         -6.2213e-18],\n",
      "        [ 9.4390e-19,  1.5573e-18,  9.9763e-19, -2.9291e-18, -1.4046e-18,\n",
      "         -2.1070e-18,  1.4407e-18,  9.0570e-19, -1.5843e-18,  2.5798e-18,\n",
      "         -1.3807e-18, -6.7632e-19,  1.0197e-18,  1.3192e-18,  1.8306e-18,\n",
      "         -1.5858e-18],\n",
      "        [-4.1395e-18, -6.7376e-18, -4.4058e-18,  1.2778e-17,  6.2094e-18,\n",
      "          9.1858e-18, -6.2750e-18, -4.0063e-18,  6.9377e-18, -1.1254e-17,\n",
      "          6.0780e-18,  2.9328e-18, -4.5047e-18, -5.7605e-18, -7.9368e-18,\n",
      "          6.8950e-18],\n",
      "        [-2.3739e-18, -3.8769e-18, -2.5213e-18,  7.3365e-18,  3.5523e-18,\n",
      "          5.2751e-18, -3.6043e-18, -2.2921e-18,  3.9791e-18, -6.4616e-18,\n",
      "          3.4813e-18,  1.6873e-18, -2.5779e-18, -3.3068e-18, -4.5650e-18,\n",
      "          3.9631e-18]]), 'exp_avg_sq': tensor([[0.3317, 0.4662, 0.6546, 1.7863, 1.3410, 1.0244, 0.3944, 0.4376, 0.7230,\n",
      "         0.9843, 0.6810, 0.6921, 0.5650, 0.2633, 1.3383, 1.1038],\n",
      "        [0.7559, 1.4943, 0.5815, 4.9085, 1.9717, 3.0712, 1.2364, 0.6747, 1.6391,\n",
      "         2.3249, 1.4183, 1.0803, 1.1952, 0.8582, 3.7639, 2.2346],\n",
      "        [0.4300, 1.1448, 0.2957, 2.6916, 0.7331, 1.5317, 0.8350, 0.3575, 0.8788,\n",
      "         1.3077, 0.5890, 0.4762, 0.5721, 0.4312, 1.8599, 1.0570],\n",
      "        [0.5492, 1.0733, 0.7224, 3.1493, 1.9135, 1.7178, 0.8324, 0.5332, 1.1342,\n",
      "         1.6828, 1.0335, 0.6954, 0.8694, 0.4996, 1.9825, 1.2534],\n",
      "        [0.7893, 2.1252, 1.3201, 6.9471, 3.3562, 2.8577, 2.3062, 0.6951, 1.8303,\n",
      "         4.3975, 1.7207, 1.3837, 1.1624, 0.7903, 2.0766, 1.4098],\n",
      "        [0.4521, 0.5510, 0.5117, 2.2577, 1.6323, 1.0201, 0.7321, 0.3711, 0.6167,\n",
      "         1.4565, 0.8517, 0.6314, 0.6306, 0.2995, 0.8159, 0.6576],\n",
      "        [0.2636, 0.7837, 0.3918, 2.2026, 0.9651, 1.0975, 0.5941, 0.2586, 0.6885,\n",
      "         1.2121, 0.5797, 0.1857, 0.4544, 0.3019, 0.9889, 0.5217],\n",
      "        [0.4345, 0.4486, 0.6817, 1.1984, 1.4626, 0.5702, 0.3904, 0.3101, 0.3606,\n",
      "         0.7261, 0.5896, 0.3938, 0.5365, 0.1621, 0.6086, 0.4799],\n",
      "        [0.8171, 0.5965, 1.3258, 2.2233, 3.8600, 0.9086, 1.0551, 0.6184, 0.7609,\n",
      "         1.7023, 1.3828, 1.9255, 0.8910, 0.2669, 1.4507, 1.6819],\n",
      "        [0.4765, 1.1092, 0.5605, 3.1353, 1.3208, 1.5201, 1.0345, 0.3747, 0.8756,\n",
      "         1.7423, 0.8306, 0.4162, 0.6885, 0.4188, 1.3350, 0.7115],\n",
      "        [0.4233, 1.5326, 0.7614, 3.2412, 1.5943, 1.4625, 1.1909, 0.3319, 0.9216,\n",
      "         1.7916, 0.7270, 0.2304, 0.5890, 0.3601, 1.2570, 0.5105],\n",
      "        [0.7279, 1.1316, 0.9461, 3.0807, 2.4824, 1.7012, 0.8015, 0.4333, 0.9586,\n",
      "         1.7031, 1.0261, 1.0137, 0.8084, 0.5833, 2.4093, 1.7254],\n",
      "        [0.5616, 0.4718, 0.6536, 2.1718, 2.0555, 1.0873, 0.5232, 0.5288, 0.7739,\n",
      "         1.3367, 1.0815, 0.6377, 0.8519, 0.3023, 0.9682, 0.8200],\n",
      "        [0.4604, 0.5626, 0.6364, 2.3235, 1.8292, 1.2970, 0.5802, 0.4723, 0.8404,\n",
      "         1.2924, 0.9713, 0.5776, 0.7685, 0.3846, 1.3842, 0.9911],\n",
      "        [0.4851, 0.7059, 0.6174, 1.9294, 1.6352, 1.0594, 0.5933, 0.3597, 0.6045,\n",
      "         1.0363, 0.7403, 0.5061, 0.6516, 0.3145, 1.2762, 0.8306],\n",
      "        [0.4658, 0.5631, 0.3869, 2.0148, 1.2872, 0.9621, 0.5188, 0.2482, 0.5213,\n",
      "         1.2343, 0.7116, 0.4214, 0.5215, 0.3125, 0.7931, 0.5828]])}, 66: {'step': tensor(3820.), 'exp_avg': tensor([2.3524e-19, 2.3435e-19, 2.4920e-19, 2.4081e-19, 5.9028e-19, 2.3715e-19,\n",
      "        2.3300e-19, 2.3076e-19, 2.5176e-19, 2.3029e-19]), 'exp_avg_sq': tensor([0.0046, 0.0015, 0.0013, 0.0039, 0.0118, 0.0142, 0.0127, 0.0083, 0.0179,\n",
      "        0.0056])}, 67: {'step': tensor(3820.), 'exp_avg': tensor([-1.3060e-18, -1.3041e-18, -1.3351e-18, -1.3170e-18, -3.1251e-18,\n",
      "        -1.3135e-18, -1.3006e-18, -1.2974e-18, -1.3436e-18, -1.2997e-18]), 'exp_avg_sq': tensor([0.2415, 0.2528, 0.2370, 0.2389, 0.3146, 0.3433, 0.2962, 0.2578, 0.2619,\n",
      "        0.2619])}, 68: {'step': tensor(3820.), 'exp_avg': tensor([-3.2925e-19, -4.7514e-19,  5.2323e-18, -4.5101e-18, -8.7191e-18,\n",
      "        -3.1646e-18, -4.7939e-18, -2.1774e-18, -1.7210e-18,  8.6168e-18,\n",
      "         2.8535e-18, -2.9974e-18, -2.5071e-18,  2.3960e-18,  6.8343e-18,\n",
      "         2.2475e-18, -4.3746e-18,  6.7231e-18, -2.8463e-19, -6.0917e-18,\n",
      "         2.1589e-19, -6.7505e-18,  1.1044e-17,  1.6543e-18, -9.2408e-18,\n",
      "         5.7752e-18,  9.5588e-18, -6.7669e-19,  9.9431e-18, -3.4166e-18,\n",
      "        -7.5140e-18, -3.3500e-18]), 'exp_avg_sq': tensor([0.8698, 0.2592, 0.4059, 1.0229, 0.6449, 0.7424, 0.4686, 1.0724, 0.9594,\n",
      "        1.4858, 2.0780, 0.3560, 0.4082, 0.3231, 0.6813, 0.3690, 0.8265, 0.3123,\n",
      "        0.3929, 0.3495, 0.3199, 0.4245, 0.4343, 0.5485, 0.8586, 0.6880, 0.3917,\n",
      "        0.6642, 0.4710, 0.4433, 0.3675, 0.4479])}, 69: {'step': tensor(3820.), 'exp_avg': tensor([[ 1.2471e-19, -4.6908e-19, -1.8955e-19, -3.9447e-19,  2.1206e-20,\n",
      "         -3.7897e-19, -2.9448e-20,  1.9010e-20,  8.9858e-19, -2.9435e-20,\n",
      "          4.1308e-19, -1.6596e-19,  5.7350e-19, -3.8496e-19, -2.0586e-19,\n",
      "          7.1128e-20],\n",
      "        [ 1.8711e-19, -6.7753e-19, -2.6466e-19, -5.6256e-19,  2.6584e-20,\n",
      "         -5.3272e-19, -4.3312e-20,  3.2532e-20,  1.2672e-18, -3.8160e-20,\n",
      "          5.8087e-19, -2.3068e-19,  8.1528e-19, -5.4539e-19, -2.8687e-19,\n",
      "          8.9672e-20],\n",
      "        [-2.2801e-18,  7.4825e-18,  2.6586e-18,  5.9973e-18, -1.5818e-19,\n",
      "          5.4348e-18,  4.9430e-19, -5.1763e-19, -1.3060e-17,  3.0074e-19,\n",
      "         -5.9424e-18,  2.2754e-18, -8.6163e-18,  5.7028e-18,  2.8441e-18,\n",
      "         -6.0637e-19],\n",
      "        [ 2.0314e-18, -6.4564e-18, -2.2136e-18, -5.1100e-18,  9.7179e-20,\n",
      "         -4.5553e-18, -4.3214e-19,  4.9384e-19,  1.0989e-17, -2.2222e-19,\n",
      "          4.9852e-18, -1.8815e-18,  7.3179e-18, -4.8244e-18, -2.3575e-18,\n",
      "          4.0685e-19],\n",
      "        [ 3.8284e-18, -1.2472e-17, -4.3961e-18, -9.9679e-18,  2.4650e-19,\n",
      "         -9.0001e-18, -8.2635e-19,  8.8336e-19,  2.1646e-17, -4.8497e-19,\n",
      "          9.8426e-18, -3.7569e-18,  1.4310e-17, -9.4633e-18, -4.6983e-18,\n",
      "          9.5985e-19],\n",
      "        [ 1.3895e-18, -4.5267e-18, -1.5956e-18, -3.6179e-18,  8.9548e-20,\n",
      "         -3.2667e-18, -2.9997e-19,  3.2060e-19,  7.8567e-18, -1.7600e-19,\n",
      "          3.5724e-18, -1.3636e-18,  5.1941e-18, -3.4348e-18, -1.7054e-18,\n",
      "          3.4839e-19],\n",
      "        [ 2.1290e-18, -6.8597e-18, -2.3890e-18, -5.4590e-18,  1.2107e-19,\n",
      "         -4.9014e-18, -4.5641e-19,  5.0308e-19,  1.1804e-17, -2.5343e-19,\n",
      "          5.3620e-18, -2.0367e-18,  7.8288e-18, -5.1700e-18, -2.5490e-18,\n",
      "          4.8591e-19],\n",
      "        [ 9.4272e-19, -3.1132e-18, -1.1134e-18, -2.5012e-18,  6.9649e-20,\n",
      "         -2.2737e-18, -2.0525e-19,  2.1093e-19,  5.4598e-18, -1.2841e-19,\n",
      "          2.4855e-18, -9.5428e-19,  3.5956e-18, -2.3816e-18, -1.1924e-18,\n",
      "          2.6290e-19],\n",
      "        [ 7.3269e-19, -2.4593e-18, -8.9536e-19, -1.9883e-18,  6.1788e-20,\n",
      "         -1.8214e-18, -1.6066e-19,  1.5786e-19,  4.3659e-18, -1.0903e-19,\n",
      "          1.9907e-18, -7.6948e-19,  2.8628e-18, -1.8997e-18, -9.5983e-19,\n",
      "          2.3027e-19],\n",
      "        [-3.7841e-18,  1.2326e-17,  4.3442e-18,  9.8506e-18, -2.4303e-19,\n",
      "          8.8934e-18,  8.1656e-19, -8.7351e-19, -2.1390e-17,  4.7921e-19,\n",
      "         -9.7262e-18,  3.7122e-18, -1.4142e-17,  9.3516e-18,  4.6423e-18,\n",
      "         -9.4788e-19],\n",
      "        [-1.2765e-18,  4.0842e-18,  1.4104e-18,  3.2409e-18, -6.7310e-20,\n",
      "          2.8995e-18,  2.7302e-19, -3.0600e-19, -6.9888e-18,  1.4500e-19,\n",
      "         -3.1721e-18,  1.2009e-18, -4.6444e-18,  3.0645e-18,  1.5044e-18,\n",
      "         -2.7222e-19],\n",
      "        [ 1.2976e-18, -4.2854e-18, -1.5338e-18, -3.4435e-18,  9.4969e-20,\n",
      "         -3.1301e-18, -2.8188e-19,  2.9046e-19,  7.5164e-18, -1.7771e-19,\n",
      "          3.4223e-18, -1.3141e-18,  4.9504e-18, -3.2788e-18, -1.6411e-18,\n",
      "          3.6314e-19],\n",
      "        [ 1.1264e-18, -3.5888e-18, -1.2343e-18, -2.8433e-18,  5.5388e-20,\n",
      "         -2.5378e-18, -2.3973e-19,  2.7253e-19,  6.1205e-18, -1.2547e-19,\n",
      "          2.7774e-18, -1.0495e-18,  4.0730e-18, -2.6859e-18, -1.3145e-18,\n",
      "          2.3160e-19],\n",
      "        [-1.0547e-18,  3.4274e-18,  1.2054e-18,  2.7369e-18, -6.5646e-20,\n",
      "          2.4679e-18,  2.2698e-19, -2.4478e-19, -5.9375e-18,  1.3224e-19,\n",
      "         -2.6995e-18,  1.0293e-18, -3.9284e-18,  2.5969e-18,  1.2871e-18,\n",
      "         -2.5965e-19],\n",
      "        [-3.0004e-18,  9.7755e-18,  3.4468e-18,  7.8136e-18, -1.9297e-19,\n",
      "          7.0553e-18,  6.4733e-19, -6.9217e-19, -1.6969e-17,  3.8083e-19,\n",
      "         -7.7160e-18,  2.9454e-18, -1.1218e-17,  7.4182e-18,  3.6831e-18,\n",
      "         -7.5367e-19],\n",
      "        [-1.0212e-18,  3.2183e-18,  1.0925e-18,  2.5384e-18, -4.3230e-20,\n",
      "          2.2526e-18,  2.1621e-19, -2.5250e-19, -5.4401e-18,  1.0570e-19,\n",
      "         -2.4658e-18,  9.2681e-19, -3.6320e-18,  2.3919e-18,  1.1622e-18,\n",
      "         -1.8710e-19],\n",
      "        [ 1.9202e-18, -6.2575e-18, -2.2068e-18, -5.0020e-18,  1.2384e-19,\n",
      "         -4.5171e-18, -4.1439e-19,  4.4279e-19,  1.0864e-17, -2.4398e-19,\n",
      "          4.9401e-18, -1.8859e-18,  7.1816e-18, -4.7492e-18, -2.3582e-18,\n",
      "          4.8311e-19],\n",
      "        [-3.0033e-18,  9.6220e-18,  3.3289e-18,  7.6398e-18, -1.5995e-19,\n",
      "          6.8394e-18,  6.4209e-19, -7.1809e-19, -1.6483e-17,  3.4498e-19,\n",
      "         -7.4829e-18,  2.8348e-18, -1.0950e-17,  7.2261e-18,  3.5500e-18,\n",
      "         -6.4992e-19],\n",
      "        [ 1.5480e-19, -4.1029e-19, -1.0813e-19, -2.9860e-19, -9.3948e-21,\n",
      "         -2.3553e-19, -2.9879e-20,  5.0315e-20,  5.8583e-19,  1.0359e-21,\n",
      "          2.5951e-19, -8.6576e-20,  4.1802e-19, -2.6784e-19, -1.1114e-19,\n",
      "         -2.1120e-20],\n",
      "        [ 2.7366e-18, -8.7200e-18, -2.9980e-18, -6.9086e-18,  1.3616e-19,\n",
      "         -6.1673e-18, -5.8339e-19,  6.6165e-19,  1.4873e-17, -3.0380e-19,\n",
      "          6.7485e-18, -2.5500e-18,  9.8962e-18, -6.5264e-18, -3.1950e-18,\n",
      "          5.6184e-19],\n",
      "        [-1.0597e-19,  3.0992e-19,  9.5639e-20,  2.3672e-19,  5.6019e-22,\n",
      "          2.0092e-19,  2.1468e-20, -2.9940e-20, -4.9049e-19,  5.7589e-21,\n",
      "         -2.2050e-19,  7.9503e-20, -3.3583e-19,  2.1885e-19,  1.0039e-19,\n",
      "         -4.1680e-21],\n",
      "        [ 2.9871e-18, -9.6582e-18, -3.3765e-18, -7.6966e-18,  1.7697e-19,\n",
      "         -6.9229e-18, -6.4175e-19,  7.0058e-19,  1.6665e-17, -3.6273e-19,\n",
      "          7.5726e-18, -2.8809e-18,  1.1041e-17, -7.2948e-18, -3.6046e-18,\n",
      "          7.0291e-19],\n",
      "        [-4.8856e-18,  1.5801e-17,  5.5255e-18,  1.2593e-17, -2.9081e-19,\n",
      "          1.1329e-17,  1.0501e-18, -1.1451e-18, -2.7271e-17,  5.9389e-19,\n",
      "         -1.2392e-17,  4.7148e-18, -1.8067e-17,  1.1937e-17,  5.8997e-18,\n",
      "         -1.1521e-18],\n",
      "        [-7.5596e-19,  2.3695e-18,  7.9845e-19,  1.8645e-18, -3.0010e-20,\n",
      "          1.6498e-18,  1.6003e-19, -1.8881e-19, -3.9872e-18,  7.4796e-20,\n",
      "         -1.8058e-18,  6.7686e-19, -2.6661e-18,  1.7546e-18,  8.4977e-19,\n",
      "         -1.2950e-19],\n",
      "        [ 4.0626e-18, -1.3219e-17, -4.6530e-18, -1.0560e-17,  2.5850e-19,\n",
      "         -9.5288e-18, -8.7643e-19,  9.3984e-19,  2.2921e-17, -5.1094e-19,\n",
      "          1.0421e-17, -3.9755e-18,  1.5158e-17, -1.0023e-17, -4.9724e-18,\n",
      "          1.0082e-18],\n",
      "        [-2.5285e-18,  8.2600e-18,  2.9207e-18,  6.6089e-18, -1.6730e-19,\n",
      "          5.9755e-18,  5.4648e-19, -5.7992e-19, -1.4367e-17,  3.2554e-19,\n",
      "         -6.5345e-18,  2.4973e-18, -9.4908e-18,  6.2782e-18,  3.1222e-18,\n",
      "         -6.4881e-19],\n",
      "        [-4.2343e-18,  1.3677e-17,  4.7760e-18,  1.0895e-17, -2.4780e-19,\n",
      "          9.7940e-18,  9.0909e-19, -9.9538e-19, -2.3580e-17,  5.1123e-19,\n",
      "         -1.0714e-17,  4.0739e-18, -1.5628e-17,  1.0323e-17,  5.0978e-18,\n",
      "         -9.8756e-19],\n",
      "        [ 3.3844e-19, -9.7219e-19, -2.9213e-19, -7.3634e-19, -5.1306e-21,\n",
      "         -6.1759e-19, -6.8094e-20,  9.8333e-20,  1.5122e-18, -1.4281e-20,\n",
      "          6.7809e-19, -2.4154e-19,  1.0423e-18, -6.7738e-19, -3.0597e-19,\n",
      "          1.7953e-21],\n",
      "        [-4.4019e-18,  1.4226e-17,  4.9712e-18,  1.1335e-17, -2.5928e-19,\n",
      "          1.0193e-17,  9.4535e-19, -1.0334e-18, -2.4539e-17,  5.3329e-19,\n",
      "         -1.1150e-17,  4.2409e-18, -1.6260e-17,  1.0742e-17,  5.3064e-18,\n",
      "         -1.0319e-18],\n",
      "        [ 1.5462e-18, -4.8918e-18, -1.6683e-18, -3.8645e-18,  6.9344e-20,\n",
      "         -3.4367e-18, -3.2805e-19,  3.7932e-19,  8.2955e-18, -1.6426e-19,\n",
      "          3.7615e-18, -1.4166e-18,  5.5317e-18, -3.6448e-18, -1.7757e-18,\n",
      "          2.9547e-19],\n",
      "        [ 3.2964e-18, -1.0748e-17, -3.7923e-18, -8.5929e-18,  2.1396e-19,\n",
      "         -7.7620e-18, -7.1172e-19,  7.5920e-19,  1.8667e-17, -4.1981e-19,\n",
      "          8.4885e-18, -3.2413e-18,  1.2338e-17, -8.1595e-18, -4.0531e-18,\n",
      "          8.3263e-19],\n",
      "        [ 1.5009e-18, -4.7949e-18, -1.6538e-18, -3.8028e-18,  7.6845e-20,\n",
      "         -3.3993e-18, -3.2017e-19,  3.6103e-19,  8.1951e-18, -1.6963e-19,\n",
      "          3.7196e-18, -1.4073e-18,  5.4488e-18, -3.5946e-18, -1.7625e-18,\n",
      "          3.1636e-19]]), 'exp_avg_sq': tensor([[ 0.8922,  1.5412,  0.3717,  0.5545,  0.2650,  0.3863,  0.0794,  0.1941,\n",
      "          2.0849,  0.4138,  0.3914,  0.1636,  0.5190,  0.3648,  0.2819,  2.4819],\n",
      "        [ 0.4099,  1.0658,  0.3056,  0.5974,  0.1419,  1.1320,  0.0847,  0.1026,\n",
      "          5.8677,  0.3218,  0.8112,  0.1328,  1.1685,  0.6606,  0.5056,  0.7020],\n",
      "        [ 0.3617,  0.9800,  0.2710,  0.5702,  0.0749,  0.6739,  0.0621,  0.0500,\n",
      "          3.6109,  0.2009,  0.6758,  0.0964,  1.0087,  0.3983,  0.2702,  0.4541],\n",
      "        [ 0.6583,  1.0239,  0.4371,  0.4008,  0.1332,  0.5948,  0.0562,  0.1141,\n",
      "          2.4823,  0.2433,  0.4974,  0.1680,  0.6380,  0.6547,  0.3299,  1.2225],\n",
      "        [ 0.6863,  1.6078,  0.5148,  0.8563,  0.3513,  1.5018,  0.1702,  0.2047,\n",
      "          7.6182,  0.5784,  1.0854,  0.1701,  1.5924,  1.0273,  0.6371,  1.4121],\n",
      "        [ 0.9033,  1.9746,  0.4059,  0.9403,  0.3138,  0.9506,  0.1390,  0.1465,\n",
      "          5.2990,  0.3679,  0.8299,  0.1486,  1.3821,  0.9823,  0.5017,  1.5682],\n",
      "        [ 0.6282,  1.3252,  0.2900,  0.5034,  0.3306,  0.3880,  0.1380,  0.1755,\n",
      "          2.0064,  0.4126,  0.5526,  0.1465,  0.6460,  0.3155,  0.2373,  1.2511],\n",
      "        [ 1.0110,  1.8635,  0.4854,  0.9987,  0.2719,  0.8313,  0.0729,  0.1086,\n",
      "          4.0418,  0.2739,  0.7213,  0.2432,  1.1227,  0.5629,  0.4653,  2.0822],\n",
      "        [ 0.6480,  1.3897,  0.3045,  0.7796,  0.1838,  1.0526,  0.1023,  0.1012,\n",
      "          5.4953,  0.3610,  0.7863,  0.1522,  1.1692,  0.5500,  0.4359,  1.1286],\n",
      "        [ 1.2665,  2.4175,  0.4092,  0.8586,  0.2351,  0.7492,  0.0670,  0.1967,\n",
      "          3.8650,  0.3457,  0.5931,  0.2446,  1.0081,  0.4629,  0.4815,  2.7185],\n",
      "        [ 2.0382,  3.6080,  1.0254,  1.8065,  0.3585,  2.0307,  0.1632,  0.3215,\n",
      "         10.7947,  0.7484,  1.5076,  0.4550,  2.4271,  2.2671,  1.1148,  4.3814],\n",
      "        [ 0.3122,  0.6747,  0.1434,  0.2552,  0.1010,  0.2776,  0.0339,  0.0648,\n",
      "          1.3527,  0.1258,  0.2811,  0.0806,  0.4250,  0.1940,  0.1619,  0.6565],\n",
      "        [ 0.6347,  1.2339,  0.3249,  0.5013,  0.3110,  0.5135,  0.1590,  0.1476,\n",
      "          2.3616,  0.3798,  0.5592,  0.1582,  0.6167,  0.3965,  0.2866,  1.0887],\n",
      "        [ 0.3252,  0.6647,  0.2174,  0.3492,  0.1643,  0.5356,  0.0888,  0.0915,\n",
      "          2.4302,  0.2607,  0.4764,  0.1112,  0.6030,  0.3775,  0.2443,  0.5032],\n",
      "        [ 0.8158,  1.5355,  0.6457,  0.6345,  0.8048,  1.1474,  0.3354,  0.3380,\n",
      "          4.8701,  0.9198,  1.0848,  0.1866,  1.1174,  0.7336,  0.5177,  1.8502],\n",
      "        [ 0.2584,  0.5786,  0.2963,  0.2960,  0.0452,  0.5545,  0.0275,  0.0530,\n",
      "          2.3555,  0.1967,  0.5672,  0.1311,  0.7504,  0.3271,  0.2481,  0.5101],\n",
      "        [ 0.7231,  1.4478,  0.2447,  0.6645,  0.2102,  0.3088,  0.0748,  0.1263,\n",
      "          1.5870,  0.2416,  0.3413,  0.1419,  0.5886,  0.3640,  0.1985,  1.3198],\n",
      "        [ 0.2517,  0.7089,  0.1641,  0.3370,  0.0582,  0.4548,  0.0276,  0.0621,\n",
      "          2.2867,  0.1390,  0.4062,  0.0887,  0.6587,  0.2976,  0.2049,  0.4589],\n",
      "        [ 0.4125,  0.8693,  0.2609,  0.3969,  0.2820,  0.4668,  0.1257,  0.1517,\n",
      "          2.2561,  0.3630,  0.4937,  0.0810,  0.5822,  0.3199,  0.1720,  0.8717],\n",
      "        [ 0.3111,  0.6717,  0.3605,  0.3806,  0.1380,  0.8287,  0.0699,  0.1054,\n",
      "          4.1096,  0.2974,  0.6179,  0.0863,  0.8590,  0.7739,  0.3802,  0.7062],\n",
      "        [ 0.8388,  1.9740,  0.3556,  1.0564,  0.2368,  0.9559,  0.1596,  0.1287,\n",
      "          5.2907,  0.4149,  0.9479,  0.1864,  1.3554,  0.5731,  0.4519,  1.0532],\n",
      "        [ 0.4259,  0.7149,  0.3258,  0.3472,  0.2566,  0.5256,  0.1159,  0.1100,\n",
      "          2.3289,  0.3216,  0.4917,  0.1102,  0.5016,  0.4642,  0.2604,  0.8205],\n",
      "        [ 0.5084,  1.1491,  0.2194,  0.5657,  0.0899,  0.3720,  0.0573,  0.0666,\n",
      "          2.0394,  0.1567,  0.4460,  0.1076,  0.6809,  0.2886,  0.1826,  0.7251],\n",
      "        [ 0.4838,  1.1736,  0.4912,  0.6144,  0.1895,  1.6233,  0.1311,  0.1390,\n",
      "          8.2035,  0.4324,  1.0821,  0.1643,  1.4098,  0.9299,  0.7191,  0.7469],\n",
      "        [ 0.8820,  1.7954,  0.4463,  0.8422,  0.3101,  0.9911,  0.1641,  0.1278,\n",
      "          4.5893,  0.4151,  0.9446,  0.2437,  1.3039,  0.6343,  0.5201,  1.2449],\n",
      "        [ 0.5039,  0.9869,  0.2401,  0.4195,  0.2602,  0.3899,  0.0846,  0.0938,\n",
      "          1.9290,  0.2640,  0.3890,  0.1216,  0.5401,  0.2978,  0.2360,  1.0907],\n",
      "        [ 0.4545,  0.8713,  0.2897,  0.3220,  0.2282,  0.5002,  0.0853,  0.1323,\n",
      "          2.1336,  0.2890,  0.4910,  0.1279,  0.6133,  0.3398,  0.2541,  1.0537],\n",
      "        [ 0.6298,  1.5465,  0.2719,  0.8103,  0.1576,  0.8994,  0.1123,  0.0866,\n",
      "          4.9465,  0.3064,  0.7745,  0.1370,  1.1053,  0.4572,  0.4244,  0.6734],\n",
      "        [ 0.5500,  1.2212,  0.6040,  0.6078,  0.5785,  1.3548,  0.2638,  0.3359,\n",
      "          6.3092,  0.8939,  1.1789,  0.1528,  1.3159,  0.7689,  0.4449,  1.5325],\n",
      "        [ 0.9488,  1.8964,  0.3584,  1.1625,  0.3967,  0.9143,  0.1960,  0.1479,\n",
      "          4.5076,  0.4911,  0.8138,  0.2393,  1.1617,  0.6341,  0.4292,  1.4403],\n",
      "        [ 0.2905,  0.6741,  0.3243,  0.3401,  0.4569,  0.7034,  0.1728,  0.2299,\n",
      "          3.1311,  0.6623,  0.6949,  0.1034,  0.8343,  0.5455,  0.2743,  1.0969],\n",
      "        [ 0.5083,  0.9669,  0.2919,  0.5001,  0.1571,  0.4022,  0.0638,  0.1032,\n",
      "          1.9526,  0.2397,  0.3730,  0.1157,  0.5354,  0.4466,  0.2044,  1.1054]])}, 70: {'step': tensor(3820.), 'exp_avg': tensor([3.4686e-20, 3.9850e-20, 4.8108e-20, 3.9990e-20, 6.0790e-20, 5.4451e-20,\n",
      "        3.1548e-20, 3.0382e-20, 7.2235e-20, 3.0134e-20]), 'exp_avg_sq': tensor([3.1031, 3.0264, 3.0692, 3.1033, 2.9567, 2.9525, 3.1234, 3.1165, 2.9266,\n",
      "        3.1066])}, 71: {'step': tensor(3820.), 'exp_avg': tensor([-4.9135e-18, -4.9135e-18, -4.9135e-18, -4.9135e-18, -4.9135e-18,\n",
      "        -4.9135e-18, -4.9135e-18, -4.9135e-18, -4.9135e-18, -4.9135e-18]), 'exp_avg_sq': tensor([0.1616, 0.1616, 0.1616, 0.1616, 0.1616, 0.1616, 0.1616, 0.1616, 0.1616,\n",
      "        0.1616])}, 72: {'step': tensor(3820.), 'exp_avg': tensor([[ 5.6052e-45, -5.6052e-45, -5.6052e-45,  ..., -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45,  5.6052e-45,  5.6052e-45,  ..., -5.6052e-45,\n",
      "         -5.6052e-45,  5.6052e-45],\n",
      "        [ 8.2906e-20, -8.3318e-21, -1.3558e-20,  ..., -4.0732e-20,\n",
      "          1.6865e-20, -2.6949e-20],\n",
      "        ...,\n",
      "        [ 8.7164e-17, -8.2927e-18, -1.3957e-17,  ..., -4.3646e-17,\n",
      "          1.9120e-17, -2.9034e-17],\n",
      "        [ 5.6052e-45, -5.6052e-45,  5.6052e-45,  ..., -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45],\n",
      "        [ 5.6052e-45, -5.6052e-45, -5.6052e-45,  ..., -5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45]]), 'exp_avg_sq': tensor([[7.0022e-01, 5.3823e-02, 5.7951e-02,  ..., 1.1084e-01, 2.1863e-01,\n",
      "         6.1785e-02],\n",
      "        [6.3196e+00, 1.7341e-01, 7.6307e-01,  ..., 1.8283e+00, 1.6642e+00,\n",
      "         1.4988e+00],\n",
      "        [6.5762e+00, 2.3861e-01, 8.1118e-01,  ..., 3.3723e+00, 2.0321e+00,\n",
      "         1.5865e+00],\n",
      "        ...,\n",
      "        [1.9279e+00, 2.3375e-02, 4.7966e-01,  ..., 1.4479e+00, 1.0572e+00,\n",
      "         2.8076e-01],\n",
      "        [1.5379e+00, 1.2562e-01, 3.1300e-01,  ..., 3.7731e-01, 8.0978e-01,\n",
      "         5.5486e-01],\n",
      "        [8.3291e-01, 5.5430e-03, 9.4226e-02,  ..., 1.2855e-01, 6.6398e-02,\n",
      "         1.2040e-01]])}, 73: {'step': tensor(3820.), 'exp_avg': tensor([ 5.6052e-45,  5.6052e-45,  4.0737e-21,  5.6052e-45,  9.5960e-35,\n",
      "         7.1063e-36,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  2.5199e-34,  5.6052e-45,  5.6052e-45,\n",
      "         5.4857e-31,  1.3284e-41,  5.6052e-45,  5.6052e-45,  7.0065e-45,\n",
      "         1.1101e-20,  5.6052e-45,  1.8217e-44,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         6.9606e-34,  2.9427e-44,  5.6052e-45,  3.1611e-23,  6.1657e-44,\n",
      "         5.6052e-45,  5.6052e-45,  1.6197e-33,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -5.6052e-45,  1.2612e-44,  5.6052e-45,\n",
      "         5.6052e-45,  3.2722e-18,  5.6052e-45,  1.7690e-20,  5.6052e-45,\n",
      "         3.5651e-33,  5.6052e-45,  4.8359e-32,  5.6052e-45,  5.6052e-45,\n",
      "         1.4013e-44,  5.6052e-45,  6.0632e-40,  5.6052e-45,  5.6052e-45,\n",
      "         2.6662e-34,  4.3148e-18,  5.6052e-45,  5.6052e-45]), 'exp_avg_sq': tensor([1.2797e-03, 2.5815e-02, 2.9235e-02, 1.1689e-02, 3.2382e-03, 1.6776e-02,\n",
      "        9.9248e-04, 1.7504e-03, 6.5612e-04, 1.0435e-02, 1.1179e-03, 4.4961e-04,\n",
      "        5.1170e-04, 9.8027e-04, 1.7394e-03, 3.5674e-03, 2.5858e-03, 2.7669e-03,\n",
      "        1.0486e-03, 3.8352e-03, 2.2537e-03, 1.6981e-03, 3.5142e-04, 2.7582e-03,\n",
      "        4.9025e-04, 6.7623e-04, 2.3963e-02, 1.6171e-02, 2.7345e-03, 8.8751e-03,\n",
      "        1.6575e-02, 6.5168e-03, 1.1729e-03, 2.1161e-02, 2.3388e-02, 8.7486e-04,\n",
      "        1.0692e-03, 5.7504e-03, 4.9416e-03, 1.3131e-03, 1.6384e-03, 1.6564e-03,\n",
      "        3.8129e-02, 4.0943e-03, 1.1782e-02, 8.0578e-03, 3.0307e-02, 7.5701e-03,\n",
      "        2.6532e-03, 1.7998e-05, 1.7773e-03, 1.5655e-03, 1.8009e-03, 3.2968e-03,\n",
      "        1.7777e-03, 2.2284e-04, 1.2113e-03, 1.5474e-03, 1.1920e-03, 1.4500e-02,\n",
      "        5.2814e-03, 5.9126e-03, 7.3738e-03, 2.2238e-03])}}\n",
      "param_groups \t [{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73]}]\n"
     ]
    }
   ],
   "source": [
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'{model_name}_state_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, model_name+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2.704826593399048,\n",
       "  5.198240756988525,\n",
       "  13.315263748168945,\n",
       "  2.823438882827759,\n",
       "  3.2965333461761475,\n",
       "  16.09800910949707,\n",
       "  9.872518539428711,\n",
       "  1.0003350973129272,\n",
       "  0.7661793828010559,\n",
       "  6.772861480712891,\n",
       "  5.174842834472656,\n",
       "  9.828278541564941,\n",
       "  15.874943733215332,\n",
       "  53.55030059814453,\n",
       "  1.0800198316574097,\n",
       "  10.528260231018066,\n",
       "  53.853294372558594,\n",
       "  4.662607669830322,\n",
       "  4.270350933074951,\n",
       "  0.867901086807251,\n",
       "  1.5554147958755493,\n",
       "  2.229698896408081,\n",
       "  2.005354166030884,\n",
       "  3.3499433994293213,\n",
       "  15.229602813720703,\n",
       "  14.188955307006836,\n",
       "  16.699132919311523,\n",
       "  22.360225677490234,\n",
       "  22.466737747192383,\n",
       "  31.5380802154541,\n",
       "  1.7847511768341064,\n",
       "  2.5743556022644043,\n",
       "  53.521114349365234,\n",
       "  2.719676971435547,\n",
       "  2.6633896827697754,\n",
       "  18.13672637939453,\n",
       "  3.7198853492736816,\n",
       "  0.4871591627597809,\n",
       "  8.857869148254395,\n",
       "  45.62668991088867,\n",
       "  3.154035806655884,\n",
       "  4.935939311981201,\n",
       "  5.192224979400635,\n",
       "  9.803498268127441,\n",
       "  17.924827575683594,\n",
       "  9.848934173583984,\n",
       "  3.585824489593506,\n",
       "  86.6318130493164,\n",
       "  17.3171443939209,\n",
       "  2.581406354904175,\n",
       "  2.7631795406341553,\n",
       "  16.747119903564453,\n",
       "  3.547388792037964,\n",
       "  0.8788779377937317,\n",
       "  0.5995727181434631,\n",
       "  5.787005424499512,\n",
       "  2.118100166320801,\n",
       "  1.919079065322876,\n",
       "  11.341294288635254,\n",
       "  2.263032913208008,\n",
       "  0.6949743628501892,\n",
       "  4.012384414672852,\n",
       "  0.35861092805862427,\n",
       "  0.8392153978347778,\n",
       "  1.9523204565048218,\n",
       "  1.5161124467849731,\n",
       "  22.870882034301758,\n",
       "  9.66711711883545,\n",
       "  0.4888782203197479,\n",
       "  5.462646484375,\n",
       "  6.092201232910156,\n",
       "  1.016375184059143,\n",
       "  5.394891738891602,\n",
       "  0.7768035531044006,\n",
       "  17.16086196899414,\n",
       "  0.9088374376296997,\n",
       "  1.3090628385543823,\n",
       "  4.259058475494385,\n",
       "  0.8640763759613037,\n",
       "  1.96882963180542,\n",
       "  2.9054343700408936,\n",
       "  10.186197280883789,\n",
       "  8.666426658630371,\n",
       "  2.021890640258789,\n",
       "  37.51947021484375,\n",
       "  15.764997482299805,\n",
       "  2.097499132156372,\n",
       "  6.830977916717529,\n",
       "  3.6878957748413086,\n",
       "  19.14760971069336,\n",
       "  1.3249049186706543,\n",
       "  4.118762016296387,\n",
       "  7.989927768707275,\n",
       "  10.915167808532715,\n",
       "  29.659832000732422,\n",
       "  35.79417419433594,\n",
       "  16.774860382080078,\n",
       "  1.543757438659668,\n",
       "  110.32952880859375,\n",
       "  12.100777626037598,\n",
       "  0.5776466727256775,\n",
       "  10.142349243164062,\n",
       "  3.035236358642578,\n",
       "  13.713397979736328,\n",
       "  3.816195487976074,\n",
       "  9.482223510742188,\n",
       "  3.255971908569336,\n",
       "  24.57541275024414,\n",
       "  10.109694480895996,\n",
       "  12.866683959960938,\n",
       "  11.060444831848145,\n",
       "  20.535160064697266,\n",
       "  5.805521488189697,\n",
       "  9.43932056427002,\n",
       "  10.969657897949219,\n",
       "  14.198473930358887,\n",
       "  5.688391208648682,\n",
       "  20.013891220092773,\n",
       "  8.729480743408203,\n",
       "  1.674066185951233,\n",
       "  36.130615234375,\n",
       "  6.818122863769531,\n",
       "  3.175856351852417,\n",
       "  22.70490074157715,\n",
       "  5.9099812507629395,\n",
       "  0.4547455608844757,\n",
       "  1.45606529712677,\n",
       "  25.354225158691406,\n",
       "  9.80893325805664,\n",
       "  18.04686164855957,\n",
       "  8.206413269042969,\n",
       "  13.117918014526367,\n",
       "  20.550674438476562,\n",
       "  13.554835319519043,\n",
       "  1.045912265777588,\n",
       "  45.946327209472656,\n",
       "  0.7859334349632263,\n",
       "  42.173946380615234,\n",
       "  7.0339250564575195,\n",
       "  11.827227592468262,\n",
       "  4.80800724029541,\n",
       "  4.400030612945557,\n",
       "  3.5169429779052734,\n",
       "  42.460262298583984,\n",
       "  2.992161750793457,\n",
       "  61.76719665527344,\n",
       "  13.275609970092773,\n",
       "  41.199893951416016,\n",
       "  1.9388231039047241,\n",
       "  1.7367182970046997,\n",
       "  5.621242523193359,\n",
       "  7.279980659484863,\n",
       "  5.48419189453125,\n",
       "  49.14460372924805,\n",
       "  4.1668596267700195,\n",
       "  21.214513778686523,\n",
       "  3.4210243225097656,\n",
       "  24.54138946533203,\n",
       "  1.8284838199615479,\n",
       "  13.43665599822998,\n",
       "  1.6863292455673218,\n",
       "  0.40624549984931946,\n",
       "  16.733816146850586,\n",
       "  2.2687463760375977,\n",
       "  1.8972417116165161,\n",
       "  25.289302825927734,\n",
       "  4.335816860198975,\n",
       "  0.8518805503845215,\n",
       "  2.106466054916382,\n",
       "  1.0783138275146484,\n",
       "  1.1433900594711304,\n",
       "  18.154211044311523,\n",
       "  14.370222091674805,\n",
       "  6.093416213989258,\n",
       "  45.29472351074219,\n",
       "  0.9568530917167664,\n",
       "  5.3788676261901855,\n",
       "  5.844310283660889,\n",
       "  3.7407867908477783,\n",
       "  1.1640912294387817,\n",
       "  5.3128886222839355,\n",
       "  0.44115859270095825,\n",
       "  8.20824909210205,\n",
       "  4.9891581535339355,\n",
       "  2.888672113418579,\n",
       "  4.037245273590088,\n",
       "  0.322966068983078,\n",
       "  0.23082919418811798,\n",
       "  4.936459541320801,\n",
       "  39.93437957763672,\n",
       "  0.22667832672595978,\n",
       "  29.57611083984375,\n",
       "  62.06330108642578,\n",
       "  8.148748397827148],\n",
       " [27.181671142578125,\n",
       "  46.7053108215332,\n",
       "  0.5775931477546692,\n",
       "  18.145309448242188,\n",
       "  19.823272705078125,\n",
       "  1.222131609916687,\n",
       "  1.5900646448135376,\n",
       "  1.0873397588729858,\n",
       "  0.6155239343643188,\n",
       "  25.250816345214844,\n",
       "  0.21160487830638885,\n",
       "  23.210893630981445,\n",
       "  3.53255558013916,\n",
       "  0.49781733751296997,\n",
       "  6.42727518081665,\n",
       "  1.8676376342773438,\n",
       "  5.443838596343994,\n",
       "  35.25676727294922,\n",
       "  0.8407770991325378,\n",
       "  36.5833625793457,\n",
       "  1.2122560739517212,\n",
       "  25.440689086914062,\n",
       "  55.801753997802734,\n",
       "  3.1841704845428467,\n",
       "  1.1490204334259033,\n",
       "  1.726120114326477,\n",
       "  0.6069270968437195,\n",
       "  0.8175901174545288,\n",
       "  0.3303978741168976,\n",
       "  5.444737911224365,\n",
       "  0.7473751902580261,\n",
       "  20.440824508666992,\n",
       "  2.3824214935302734,\n",
       "  2.538160562515259,\n",
       "  1.1115511655807495,\n",
       "  2.5566086769104004,\n",
       "  4.197916507720947,\n",
       "  8.023086547851562,\n",
       "  2.8924777507781982,\n",
       "  25.886518478393555,\n",
       "  9.207832336425781,\n",
       "  3.2628908157348633,\n",
       "  4.177851676940918,\n",
       "  0.26979491114616394,\n",
       "  32.592506408691406,\n",
       "  5.443792343139648,\n",
       "  20.047550201416016,\n",
       "  1.6963348388671875,\n",
       "  1.475588083267212,\n",
       "  0.7018646001815796,\n",
       "  25.359506607055664,\n",
       "  29.34391975402832,\n",
       "  2.70133113861084,\n",
       "  0.5495991706848145,\n",
       "  12.431327819824219,\n",
       "  48.082149505615234,\n",
       "  0.529217541217804,\n",
       "  0.9486518502235413,\n",
       "  0.1961567997932434,\n",
       "  0.8649198412895203,\n",
       "  7.758583068847656,\n",
       "  3.615036725997925,\n",
       "  4.44827938079834,\n",
       "  9.91455078125,\n",
       "  9.520406723022461,\n",
       "  30.620840072631836,\n",
       "  32.2344856262207,\n",
       "  0.5394095778465271,\n",
       "  1.0339170694351196,\n",
       "  53.23109817504883,\n",
       "  9.778298377990723,\n",
       "  12.965744018554688,\n",
       "  12.68330192565918,\n",
       "  8.50987434387207,\n",
       "  0.4265194833278656,\n",
       "  24.38487434387207,\n",
       "  0.7621620297431946,\n",
       "  36.87624740600586,\n",
       "  0.7346929907798767,\n",
       "  5.7444353103637695,\n",
       "  16.96875,\n",
       "  4.063361167907715,\n",
       "  0.3896864354610443,\n",
       "  14.440710067749023,\n",
       "  2.7547202110290527,\n",
       "  0.3997734785079956,\n",
       "  6.123706817626953,\n",
       "  1.8189308643341064,\n",
       "  21.993806838989258,\n",
       "  5.953886032104492,\n",
       "  11.222068786621094,\n",
       "  0.7353714108467102,\n",
       "  0.11078941076993942,\n",
       "  15.505916595458984,\n",
       "  20.05398178100586,\n",
       "  58.98081588745117,\n",
       "  13.300873756408691,\n",
       "  29.598037719726562,\n",
       "  6.715970039367676,\n",
       "  3.714550018310547,\n",
       "  3.7526729106903076,\n",
       "  1.6419223546981812,\n",
       "  52.779850006103516,\n",
       "  0.3401187062263489,\n",
       "  7.360928058624268,\n",
       "  28.85964012145996,\n",
       "  6.290478229522705,\n",
       "  37.85420227050781,\n",
       "  9.8411865234375,\n",
       "  11.932409286499023,\n",
       "  0.6800362467765808,\n",
       "  49.429298400878906,\n",
       "  1.2473052740097046,\n",
       "  8.519445419311523,\n",
       "  5.326987266540527,\n",
       "  0.9189756512641907,\n",
       "  7.105715274810791,\n",
       "  1.892228364944458,\n",
       "  12.138153076171875,\n",
       "  6.111774921417236,\n",
       "  3.589543104171753,\n",
       "  1.2883989810943604,\n",
       "  1.7023115158081055,\n",
       "  3.8498706817626953,\n",
       "  2.908352851867676,\n",
       "  0.9184759855270386,\n",
       "  1.0212591886520386,\n",
       "  7.122376441955566,\n",
       "  6.732410907745361,\n",
       "  5.144501686096191,\n",
       "  4.854119777679443,\n",
       "  6.543369293212891,\n",
       "  0.3381232023239136,\n",
       "  9.557618141174316,\n",
       "  2.9639039039611816,\n",
       "  8.982439994812012,\n",
       "  53.80054473876953,\n",
       "  0.6904776692390442,\n",
       "  4.799500465393066,\n",
       "  1.9255938529968262,\n",
       "  0.45198413729667664,\n",
       "  0.38417744636535645,\n",
       "  25.38662338256836,\n",
       "  13.64249038696289,\n",
       "  10.207216262817383,\n",
       "  1.3610576391220093,\n",
       "  21.111278533935547,\n",
       "  24.605722427368164,\n",
       "  1.0504916906356812,\n",
       "  4.160204887390137,\n",
       "  18.85479736328125,\n",
       "  1.2725862264633179,\n",
       "  0.4366109073162079,\n",
       "  9.999670028686523,\n",
       "  46.153873443603516,\n",
       "  7.210074424743652,\n",
       "  2.3893697261810303,\n",
       "  7.822183132171631,\n",
       "  45.8588981628418,\n",
       "  3.8593175411224365,\n",
       "  1.6076730489730835,\n",
       "  1.328518271446228,\n",
       "  6.223233222961426,\n",
       "  1.3316060304641724,\n",
       "  5.251704692840576,\n",
       "  4.568398952484131,\n",
       "  5.108389854431152,\n",
       "  4.268512725830078,\n",
       "  1.5620540380477905,\n",
       "  30.523239135742188,\n",
       "  0.5821083188056946,\n",
       "  28.851144790649414,\n",
       "  3.05397367477417,\n",
       "  13.137351989746094,\n",
       "  86.47338104248047,\n",
       "  11.000306129455566,\n",
       "  0.7675381898880005,\n",
       "  0.8615167737007141,\n",
       "  1.1916416883468628,\n",
       "  13.696884155273438,\n",
       "  1.2448304891586304,\n",
       "  16.48255157470703,\n",
       "  0.9224311113357544,\n",
       "  0.48528560996055603,\n",
       "  64.15789794921875,\n",
       "  21.540653228759766,\n",
       "  6.004839897155762,\n",
       "  1.528403639793396],\n",
       " [369.4215087890625,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1090.693359375,\n",
       "  0.16680756211280823,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  164.62606811523438,\n",
       "  196.48118591308594,\n",
       "  0.746796727180481,\n",
       "  0.0,\n",
       "  1.2641557455062866,\n",
       "  0.0,\n",
       "  0.027335483580827713,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.5911548137664795,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.18943478167057037,\n",
       "  318.8017578125,\n",
       "  0.022387951612472534,\n",
       "  0.0,\n",
       "  269.3727111816406,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  6.239467144012451,\n",
       "  0.00872468389570713,\n",
       "  0.12391109764575958,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  20.654966354370117,\n",
       "  1.7440382242202759,\n",
       "  14.81767749786377,\n",
       "  0.0,\n",
       "  621.52001953125,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.3534511625766754,\n",
       "  669.17138671875,\n",
       "  0.7347842454910278,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  323.6144714355469,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1556.918212890625,\n",
       "  5.069479465484619,\n",
       "  0.0,\n",
       "  0.6601237058639526,\n",
       "  1.4897452592849731,\n",
       "  0.18417902290821075,\n",
       "  0.33422502875328064,\n",
       "  0.054580677300691605,\n",
       "  0.0,\n",
       "  14.822598457336426,\n",
       "  0.27928391098976135,\n",
       "  0.0,\n",
       "  208.91375732421875,\n",
       "  0.0,\n",
       "  2.837961435317993,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  3.2211248874664307,\n",
       "  0.6177758574485779,\n",
       "  0.0,\n",
       "  3.2681310176849365,\n",
       "  8.811262130737305,\n",
       "  0.13150343298912048,\n",
       "  32.1849250793457,\n",
       "  4.183220386505127,\n",
       "  335.0560607910156,\n",
       "  0.0,\n",
       "  42.39211654663086,\n",
       "  0.0,\n",
       "  5.323235034942627,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  8.727231979370117,\n",
       "  0.03639485687017441,\n",
       "  531.1358642578125,\n",
       "  0.0,\n",
       "  14.817427635192871,\n",
       "  200.9522705078125,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.438779354095459,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0886812210083008,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.2463073432445526,\n",
       "  321.5522155761719,\n",
       "  430.532958984375,\n",
       "  0.0,\n",
       "  3.6485891342163086,\n",
       "  0.15102963149547577,\n",
       "  77.26891326904297,\n",
       "  1155.94677734375,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.14003604650497437,\n",
       "  0.007335471920669079,\n",
       "  0.08017150312662125,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.4499712586402893,\n",
       "  0.0,\n",
       "  0.01923861913383007,\n",
       "  0.3740415871143341,\n",
       "  30.09784507751465,\n",
       "  0.046519555151462555,\n",
       "  6.534254550933838,\n",
       "  0.0,\n",
       "  0.20569008588790894,\n",
       "  9.893606185913086,\n",
       "  0.012925470247864723,\n",
       "  49.14921569824219,\n",
       "  0.0,\n",
       "  45.319091796875,\n",
       "  0.0,\n",
       "  468.81805419921875,\n",
       "  519.5311889648438,\n",
       "  0.14548057317733765,\n",
       "  0.5344939827919006,\n",
       "  0.0,\n",
       "  1416.775146484375,\n",
       "  47.807586669921875,\n",
       "  0.0,\n",
       "  0.13062375783920288,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  84.05532836914062,\n",
       "  0.0,\n",
       "  80.4331283569336,\n",
       "  36.20896530151367,\n",
       "  0.0909595862030983,\n",
       "  0.0,\n",
       "  297.3111572265625,\n",
       "  0.29044386744499207,\n",
       "  679.9290161132812,\n",
       "  0.2698877453804016,\n",
       "  0.024907981976866722,\n",
       "  0.0,\n",
       "  0.004155474714934826,\n",
       "  0.0,\n",
       "  16.499284744262695,\n",
       "  0.0,\n",
       "  0.009237494319677353,\n",
       "  143.96932983398438,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  8.255437850952148,\n",
       "  0.07592713832855225,\n",
       "  0.0,\n",
       "  104.26712799072266,\n",
       "  3.794236898422241,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.07990852743387222,\n",
       "  18.74992561340332,\n",
       "  0.0,\n",
       "  1.6542521715164185,\n",
       "  241.86387634277344,\n",
       "  17.724409103393555,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  62.96738815307617,\n",
       "  0.0,\n",
       "  0.27038389444351196,\n",
       "  0.006136915180832148,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  120.216796875,\n",
       "  201.08119201660156,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1739.36865234375,\n",
       "  88.45665740966797,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  438.0220947265625,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  22.55211067199707,\n",
       "  6.89896297454834,\n",
       "  7.041296005249023,\n",
       "  1.3479567766189575,\n",
       "  0.0,\n",
       "  1392.8565673828125,\n",
       "  0.08919113874435425,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.05784056335687637,\n",
       "  0.0,\n",
       "  27.091596603393555,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  416.43927001953125,\n",
       "  19.785079956054688,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  716.4700927734375,\n",
       "  48.42450714111328,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  71.19123077392578,\n",
       "  0.0,\n",
       "  0.23122519254684448,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1221.6280517578125,\n",
       "  0.0,\n",
       "  0.7778826951980591,\n",
       "  36.29043197631836,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  14.188423156738281,\n",
       "  0.0,\n",
       "  0.4222561717033386,\n",
       "  25.245635986328125,\n",
       "  0.0,\n",
       "  1.7902697324752808,\n",
       "  73.66743469238281,\n",
       "  0.0,\n",
       "  18.676931381225586,\n",
       "  0.14865238964557648,\n",
       "  0.0,\n",
       "  6.442417621612549,\n",
       "  0.8299885392189026,\n",
       "  0.0,\n",
       "  1.448937177658081,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  7.410762786865234,\n",
       "  0.0,\n",
       "  4.229274272918701,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.42179790139198303,\n",
       "  0.0,\n",
       "  0.022912221029400826,\n",
       "  0.5214875340461731,\n",
       "  25.36416244506836,\n",
       "  22.662694931030273,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  13.232925415039062,\n",
       "  11.78125286102295,\n",
       "  21.407855987548828,\n",
       "  0.0,\n",
       "  0.057163625955581665,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  45.674072265625,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  4.392370700836182,\n",
       "  0.0,\n",
       "  40.342079162597656,\n",
       "  1447.2496337890625,\n",
       "  0.0,\n",
       "  0.23837828636169434,\n",
       "  11.517620086669922,\n",
       "  1.8539519309997559,\n",
       "  0.10214409232139587,\n",
       "  0.0,\n",
       "  0.07379524409770966,\n",
       "  0.0,\n",
       "  322.24041748046875,\n",
       "  0.0,\n",
       "  93.05884552001953,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  52.09365463256836,\n",
       "  0.9262378215789795,\n",
       "  0.0,\n",
       "  222.84317016601562,\n",
       "  0.0,\n",
       "  0.17627356946468353,\n",
       "  302.72088623046875,\n",
       "  0.0,\n",
       "  0.5517711043357849,\n",
       "  8.653677940368652,\n",
       "  0.0,\n",
       "  177.7516326904297,\n",
       "  0.0,\n",
       "  0.8097395300865173,\n",
       "  0.0,\n",
       "  0.09531355649232864,\n",
       "  49.996742248535156,\n",
       "  0.0,\n",
       "  0.010969500057399273,\n",
       "  1065.09033203125,\n",
       "  25.992618560791016,\n",
       "  0.0,\n",
       "  2.854539632797241,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  30.593305587768555,\n",
       "  1051.51904296875,\n",
       "  7.44715690612793,\n",
       "  0.0,\n",
       "  1.2923084497451782,\n",
       "  0.8824797868728638,\n",
       "  0.0,\n",
       "  19.364330291748047,\n",
       "  0.8865857124328613,\n",
       "  13.790212631225586,\n",
       "  0.0,\n",
       "  0.0009307044092565775,\n",
       "  10.435123443603516,\n",
       "  13.047834396362305,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  9.110109329223633,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.15615229308605194,\n",
       "  1.220004677772522,\n",
       "  0.0,\n",
       "  465.8341979980469,\n",
       "  0.1694256216287613,\n",
       "  0.0,\n",
       "  416.1944274902344,\n",
       "  4.663385391235352,\n",
       "  86.2950439453125,\n",
       "  0.0,\n",
       "  3738.822509765625,\n",
       "  0.0,\n",
       "  60.50342559814453,\n",
       "  0.22918786108493805,\n",
       "  0.2958122491836548,\n",
       "  0.29455557465553284,\n",
       "  0.3711045980453491,\n",
       "  0.710006594657898,\n",
       "  93.80224609375,\n",
       "  0.7748044729232788,\n",
       "  0.0,\n",
       "  135.83729553222656,\n",
       "  0.42544129490852356,\n",
       "  0.11775003373622894,\n",
       "  2058.11865234375,\n",
       "  231.99996948242188,\n",
       "  18.02908706665039,\n",
       "  0.0,\n",
       "  0.299012154340744,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.1680129766464233,\n",
       "  0.0],\n",
       " [1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_16884\\3520072505.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tr_results = np.asarray(train_results)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "tr_results = np.asarray(train_results)\n",
    "tr_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [117], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tr_results[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mshape\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "tr_results[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(123)\n",
    "\n",
    "w = 0.8    # bar width\n",
    "x = [1, 2] # x-coordinates of your bars\n",
    "colors = [(0, 0, 1, 1), (1, 0, 0, 1)]    # corresponding colors\n",
    "y = [np.random.random(30) * 2 + 5,       # data series\n",
    "    np.random.random(10) * 3 + 8]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(x,\n",
    "       height=[np.mean(yi) for yi in y],\n",
    "       yerr=[np.std(yi) for yi in y],    # error bars\n",
    "       capsize=12, # error bar cap width in points\n",
    "       width=w,    # bar width\n",
    "       tick_label=[\"control\", \"test\"],\n",
    "       color=(0,0,0,0),  # face color transparent\n",
    "       edgecolor=colors,\n",
    "       #ecolor=colors,    # error bar colors; setting this raises an error for whatever reason.\n",
    "       )\n",
    "\n",
    "for i in range(len(x)):\n",
    "    # distribute scatter randomly across whole width of bar\n",
    "    ax.scatter(x[i] + np.random.random(y[i].size) * w - w / 2, y[i], color=colors[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save(f'{model_name}_training_loss.npy', tr_loss, allow_pickle=True)\n",
    "np.save(f'{model_name}_training_accuracy.npy', tr_acc, allow_pickle=True)\n",
    "\n",
    "np.save(f'{model_name}_validation_loss.npy', v_loss, allow_pickle=True)\n",
    "np.save(f'{model_name}_validation_accuracy.npy', v_acc, allow_pickle=True)\n",
    "\n",
    "np.save(f'{model_name}_test_loss.npy', tst_loss, allow_pickle=True)\n",
    "np.save(f'{model_name}_test_accuracy.npy', tst_acc, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "training_loss = np.load(f'{model_name}_training_loss.npy', allow_pickle=True)\n",
    "training_accuracy = np.load(f'{model_name}_training_accuracy.npy', allow_pickle=True)\n",
    "\n",
    "validation_loss = np.load(f'{model_name}_validation_loss.npy', allow_pickle=True)\n",
    "validation_accuracy = np.load(f'{model_name}_validation_accuracy.npy', allow_pickle=True)\n",
    "\n",
    "test_loss = np.load(f'{model_name}_test_loss.npy', allow_pickle=True)\n",
    "test_accuracy = np.load(f'{model_name}_test_accuracy.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a sequence of integers to represent the epoch numbers\n",
    "epochs = range(1, num_epochs+1)\n",
    " \n",
    "# Plot and label the training and validation loss values\n",
    "plt.plot(epochs, training_loss, label='Training Loss')\n",
    "plt.plot(epochs, validation_loss, label='Validation Loss')\n",
    " \n",
    "# Add in a title and axes labels\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    " \n",
    "# Set the tick locations\n",
    "plt.xticks(np.arange(0, num_epochs+1, num_epochs/10))\n",
    " \n",
    "# Display the plot\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(f'{model_name}_Training and Validation Loss.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a sequence of integers to represent the epoch numbers\n",
    "epochs = range(1, num_epochs+1)\n",
    " \n",
    "# Plot and label the training and validation loss values\n",
    "plt.plot(epochs, training_accuracy, label='Training Accuracy')\n",
    "plt.plot(epochs, validation_accuracy, label='Validation Accuracy')\n",
    "plt.plot(epochs, test_accuracy, label='Test Accuracy')\n",
    " \n",
    "# Add in a title and axes labels\n",
    "plt.title('Accuracy vs. Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    " \n",
    "# Set the tick locations\n",
    "plt.xticks(np.arange(0, num_epochs+1, num_epochs/10))\n",
    "plt.ylim(0,1)\n",
    " \n",
    "# Display the plot\n",
    "plt.legend(loc='best')\n",
    "plt.savefig(f'{model_name}_Accuracy vs. Epochs.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_fraction = [0,0]\n",
    "\n",
    "train_fraction = [0,0]\n",
    "val_fraction = [0,0]\n",
    "test_fraction = [0,0]\n",
    "\n",
    "for grph in train_dataset: \n",
    "    if grph.y == 1: \n",
    "        train_fraction[1] +=1\n",
    "        dataset_fraction[1] +=1 \n",
    "    else: \n",
    "        train_fraction[0] +=1\n",
    "        dataset_fraction[0] +=1 \n",
    "\n",
    "for grph in val_dataset: \n",
    "    if grph.y == 1:\n",
    "         val_fraction[1] +=1\n",
    "         dataset_fraction[1] +=1  \n",
    "    else:\n",
    "         val_fraction[0] +=1\n",
    "         dataset_fraction[0] +=1\n",
    "\n",
    "for grph in test_dataset: \n",
    "    if grph.y == 1:\n",
    "         test_fraction[1] +=1\n",
    "         dataset_fraction[1] +=1 \n",
    "    else:\n",
    "         test_fraction[0] +=1\n",
    "         dataset_fraction[0] +=1\n",
    "\n",
    "print(f'Overall dataset percentage of label 1 = {dataset_fraction[1]/len(dataset)})')\n",
    "print(f'Training dataset percentage of label 1 = {train_fraction} = {train_fraction[1]/len(train_dataset)}')\n",
    "print(f'Validation dataset percentage of label 1 = {val_fraction} = {val_fraction[1]/len(val_dataset)}')\n",
    "print(f'Test dataset percentage of label 1 = {test_fraction} = {test_fraction[1]/len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Graph: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, pos0, adj0 = torch.load(f'{model_name}_img0_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Embedding GNN\n",
    "print(x0[0].shape)\n",
    "x0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pos0[0].shape)\n",
    "pos0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adj0[0].shape)\n",
    "adj0[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index, _ = dense_to_sparse(adj0[0])\n",
    "visualize_points(pos0[0].cpu(), edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph After 1st Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_emb, x1_pool, pos1, adj1, s1= torch.load(f'{model_name}_img1_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Embedding GNN (adj0 @ x_0 @ w_gnn_emb)\n",
    "print(x1_emb[0].shape)\n",
    "x1_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Pooling GNN: adj_0 @ x_0 @ w_gnn_pool\n",
    "print(s1[0].shape)\n",
    "s1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Coordinate Matrix (pos_out = softmax(s).t() @ pos_in)\n",
    "print(pos1[0].shape)\n",
    "pos1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Feature Matrix (x_out = softmax(s).t() @ x_in)\n",
    "print(x1_pool[0].shape)\n",
    "x1_pool[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Adjacency Matrix = softmax(adj_out = softmax(s.t()) @ adj_in @ softmax(s))\n",
    "print(adj1[0].shape)\n",
    "adj1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index, _ = dense_to_sparse(adj1[0])\n",
    "visualize_points(pos1[0].cpu(), edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph after 2nd reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_emb, x2_pool, pos2, adj2, s2 = torch.load(f'{model_name}_img2_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Embedding GNN (adj1 @ x1_pool @ w_gnn_emb)\n",
    "print(x2_emb[0].shape)\n",
    "x2_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Pooling GNN: adj1 @ x1_pool @ w_gnn_pool), dim=1\n",
    "print(s2[0].shape)\n",
    "s2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Coordinate Matrix (pos_out = softmax(s.t()) @ pos_in)\n",
    "print(pos2[0].shape)\n",
    "pos2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Feature Matrix (x_out = softmax(s2).t() @ x2_emb)\n",
    "print(x2_pool[0].shape)\n",
    "x2_pool[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Adjacency Matrix (adj = softmax(s).T @ adj @ softmax(s)\n",
    "print(adj2[0].shape)\n",
    "adj2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index, _ = dense_to_sparse(adj2[0])\n",
    "visualize_points(pos2[0].cpu(), edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph after 3rd reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3_emb, x3_pool, pos3, adj3, s3 = torch.load(f'{model_name}_img3_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Embedding GNN (adj_0 @ x_0 @ w_gnn_emb)\n",
    "print(x3_emb[0].shape)\n",
    "x3_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of Pooling GNN: torch.softmax(adj_0 @ x_0 @ w_gnn_pool), dim=1)\n",
    "print(s3[0].shape)\n",
    "s3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Coordinate Matrix (pos_out = softmax(s.t()) @ pos_in)\n",
    "print(pos3[0].shape)\n",
    "pos3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Feature Matrix (x_out = softmax(s.t()) @ x_0)\n",
    "print(x3_pool[0].shape)\n",
    "x3_pool[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Adjacency Matrix (adj = softmax(s.t()) @ adj @ softmax(s)\n",
    "print(adj3[0].shape)\n",
    "adj3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index, _ = dense_to_sparse(adj3[0])\n",
    "visualize_points(pos3[0].cpu(), edge_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3baeb0c3f97feb3023477fbaa09b9f4da769e45e64d8febc6957bb84d33ff77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
